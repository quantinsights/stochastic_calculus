#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{qtree}
\usepackage[many]{tcolorbox}
\tcbuselibrary{listings}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{codegreen}{rgb}{0,0.6,0}

\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\pgfplotsset{plot coordinates/math parser=false}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{calc}
\usetikzlibrary{shapes}
\usetikzlibrary{plotmarks}
\usetikzlibrary{matrix}
\usepackage{tikz-3dplot}

\hypersetup{urlcolor=blue}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams-bytype
theorems-sec-bytype
eqs-within-sections
tcolorbox
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "Garamond"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 10
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered true
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Stochastic Calculus
\end_layout

\begin_layout Author
Quasar Chunawala
\end_layout

\begin_layout Abstract
The most important results and ideas in basic mathematical finance.
\end_layout

\begin_layout Section
Measure.
\end_layout

\begin_layout Subsection
Null Sets.
\end_layout

\begin_layout Definition

\emph on
(Null Set
\emph default
).
 
\begin_inset CommandInset label
LatexCommand label
name "def:null-set"

\end_inset

 A 
\emph on
null set 
\emph default
is a set that can be covered by a sequence of intervals of arbitrarily small
 total length.
 Given any 
\begin_inset Formula $\epsilon>0$
\end_inset

, there exists a sequence of intervals 
\begin_inset Formula $(I_{n})_{n\geq1}$
\end_inset

 such that:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
A & \subseteq\bigcup_{n=1}^{\infty}I_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
and 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
\sum_{n=1}^{\infty}l(I_{n}) & <\epsilon
\end{align*}

\end_inset


\end_layout

\begin_layout Problem
Show that we get an equivalent notion if in the above definition we replace
 the word intervals by any of these: open-intervals, closed-intervals, intervals
 of the form 
\begin_inset Formula $(a,b]$
\end_inset

 or intervals of the form 
\begin_inset Formula $[a,b)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $A$
\end_inset

 be a null set.
 Then, we can cover it by a sequence of intervals, such that total length
 of the cover can be made as small as we please.
 Mathematically,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\forall\epsilon>0,\exists(I_{n})_{n\geq1},A\subseteq\bigcup_{n=1}^{\infty}I_{n},\text{ such that }\sum_{n=1}^{\infty}l(I_{n})<\frac{\epsilon}{2}
\]

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $I_{n}=[a_{n},b_{n}]$
\end_inset

 and define:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
J_{n} & :=\left(a_{n}-\frac{\epsilon}{2^{n+2}},b_{n}+\frac{\epsilon}{2^{n+2}}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since, 
\begin_inset Formula $I_{n}\subseteq J_{n}$
\end_inset

, it follows that: 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
A\subseteq\bigcup_{n=1}^{\infty}I_{n}\subseteq\bigcup_{n=1}^{\infty}J_{n}
\]

\end_inset


\end_layout

\begin_layout Proof
Moreover,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
l(J_{n}) & =l(I_{n})+\frac{\epsilon}{2^{n+1}}\\
\sum_{n=1}^{\infty}l(J_{n}) & =\sum_{n=1}^{\infty}l(I_{n})+\frac{\epsilon}{2^{2}}\left(1+\frac{1}{2}+\frac{1}{2^{2}}+\ldots\right)\\
 & <\frac{\epsilon}{2}+\frac{\epsilon}{2^{2}}\cdot\frac{1}{1-1/2}\\
 & =\epsilon
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Consequently, 
\begin_inset Formula $A$
\end_inset

 can be covered by a sequence of open intervals, whose total length can
 be made arbitrarily small.
 This closes the proof.
\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $(N_{n})_{n\geq1}$
\end_inset

 is a sequence of null sets, then their countable union
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
N & =\bigcup_{n=1}^{\infty}N_{n}
\end{align*}

\end_inset

 is also null.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $N_{1}$
\end_inset

 is null, there exists a sequence of intervals 
\begin_inset Formula $(I_{k}^{1})$
\end_inset

 such that 
\begin_inset Formula $N_{1}\subseteq\bigcup_{k=1}^{\infty}I_{k}^{1}$
\end_inset

 and 
\begin_inset Formula $\sum_{k=1}^{\infty}l(I_{k}^{1})<\frac{\epsilon}{2^{2}}$
\end_inset

.
\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $N_{2}$
\end_inset

 is null, there exists a sequence of intervals 
\begin_inset Formula $(I_{k}^{2})$
\end_inset

 such that 
\begin_inset Formula $N_{2}\subseteq\bigcup_{k=1}^{\infty}I_{k}^{2}$
\end_inset

 and 
\begin_inset Formula $\sum_{k=1}^{\infty}l(I_{k}^{2})<\frac{\epsilon}{2^{3}}$
\end_inset

.
\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $N_{j}$
\end_inset

 is null, there exists a sequence of intervals 
\begin_inset Formula $(I_{k}^{j})$
\end_inset

 such that 
\begin_inset Formula $N_{j}\subseteq\bigcup_{k=1}^{\infty}I_{k}^{j}$
\end_inset

 and 
\begin_inset Formula $\sum_{k=1}^{\infty}l(I_{k}^{j})<\frac{\epsilon}{2^{2+j}}$
\end_inset

.
\end_layout

\begin_layout Proof
Clearly, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\bigcup_{j=1}^{\infty} & N_{j}\subseteq\bigcup_{j=1}^{\infty}\bigcup_{k}^{\infty}I_{k}^{j}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Moreover,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sum_{j=1}^{\infty}\sum_{k=1}^{\infty}l(I_{k}^{j}) & <\frac{\epsilon}{2^{2}}+\frac{\epsilon}{2^{3}}+\ldots\\
 & =\frac{\epsilon}{2^{2}}\left[1+\frac{1}{2}+\frac{1}{2^{2}}+\ldots\right]\\
 & =\frac{\epsilon}{2}<\epsilon
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Consequently, 
\begin_inset Formula $N$
\end_inset

 is a null set.
\end_layout

\begin_layout Standard
A singleton set 
\begin_inset Formula $\{x\}$
\end_inset

 is a null set - let 
\begin_inset Formula $I_{1}=[x-\frac{\epsilon}{4},x+\frac{\epsilon}{4}],I_{n}=[x,x]$
\end_inset

 for 
\begin_inset Formula $n\geq2$
\end_inset

.
 Thus, any countable set is a null set, and null sets appear to be closely
 related to countable sets - this is no surprise, as any proper interval
 is uncountable, so any countable subset is quite sparse when compared with
 an interval, hence makes no real contribution to its 
\emph on
length
\emph default
.
\end_layout

\begin_layout Standard
However, uncountable sets can be null, provided their points are sufficiently
 
\emph on
sparsely distributed
\emph default
, as the following example due to Cantor shows:
\end_layout

\begin_layout Standard
1.
 Start with the interval 
\begin_inset Formula $C_{0}=[0,1]$
\end_inset

, remove the open middle one-third, that is the interval 
\begin_inset Formula $\left(\frac{1}{3},\frac{2}{3}\right)$
\end_inset

, ontaining 
\begin_inset Formula $C_{1}$
\end_inset

 which consists of two intervals 
\begin_inset Formula $[0,\frac{1}{3}]$
\end_inset

 and 
\begin_inset Formula $[\frac{2}{3},1]$
\end_inset

.
\end_layout

\begin_layout Standard
2.
 Next, remove the middle third of each of these two intervals leaving 
\begin_inset Formula $C_{2}$
\end_inset

, consisting of four intervals 
\begin_inset Formula $[0,\frac{1}{9}]$
\end_inset

, 
\begin_inset Formula $[\frac{2}{9},\frac{3}{9}]$
\end_inset

, 
\begin_inset Formula $[\frac{6}{9},\frac{7}{9}]$
\end_inset

 and 
\begin_inset Formula $[\frac{8}{9},1]$
\end_inset

.
\end_layout

\begin_layout Standard
3.
 At the 
\begin_inset Formula $n$
\end_inset

th stage, we have a set 
\begin_inset Formula $C_{n}$
\end_inset

 consisting of 
\begin_inset Formula $2^{n}$
\end_inset

 disjoint closed intervals, each of length 
\begin_inset Formula $\frac{1}{3^{n}}$
\end_inset

.
 Thus, the total length of 
\begin_inset Formula $C_{n}$
\end_inset

 is 
\begin_inset Formula $\left(\frac{2}{3}\right)^{n}$
\end_inset

.
 
\end_layout

\begin_layout Standard
We call 
\begin_inset Formula 
\begin{align*}
C & =\bigcap_{n=1}^{\infty}C_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
the 
\emph on
Cantor set
\emph default
.
 Now, we show that 
\begin_inset Formula $C$
\end_inset

 is null as promised.
 
\end_layout

\begin_layout Standard
Given any 
\begin_inset Formula $\epsilon>0$
\end_inset

, choose 
\begin_inset Formula $n$
\end_inset

 such that 
\begin_inset Formula $\left(\frac{2}{3}\right)^{n}<\epsilon$
\end_inset

.
 Since, 
\begin_inset Formula $C\subseteq C_{n}$
\end_inset

 and 
\begin_inset Formula $C_{n}$
\end_inset

 is a union of disjoint intervals of total length less than 
\begin_inset Formula $\epsilon$
\end_inset

, we see that 
\begin_inset Formula $C$
\end_inset

 is a null set.
 All that remains to be checked is that 
\begin_inset Formula $C$
\end_inset

 is an uncountable set.
 
\end_layout

\begin_layout Problem
Prove that 
\begin_inset Formula $C$
\end_inset

 is uncountable.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $x\in C$
\end_inset

 be an arbitrary point.
 
\end_layout

\begin_layout Proof
Starting with 
\begin_inset Formula $I_{0}=[0,1]$
\end_inset

, for all 
\begin_inset Formula $n\in\mathbf{N}$
\end_inset

, define the sequence of intervals 
\begin_inset Formula $(I_{n})$
\end_inset

, where 
\begin_inset Formula $I_{n}=[a_{n},b_{n}]$
\end_inset

, 
\begin_inset Formula $(L_{n})$
\end_inset

 and 
\begin_inset Formula $(R_{n})$
\end_inset

 as:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
L_{n+1} & =\left[a_{n},a_{n}+\frac{1}{3^{n+1}}\right]\\
R_{n+1} & =\left[b_{n}-\frac{1}{3^{n+1}},b_{n}\right]\\
I_{n+1} & =\begin{cases}
L_{n+1} & \text{ if }x\in L_{n+1}\\
R_{n+1} & \text{ otherwise}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Clearly, the left-end point of 
\begin_inset Formula $I_{n+1}$
\end_inset

, is 
\begin_inset Formula $a_{n}$
\end_inset

, if 
\begin_inset Formula $x\in L_{n+1}$
\end_inset

, otherwise it is 
\begin_inset Formula $b_{n}-\frac{1}{3^{n+1}}=a_{n}+\frac{1}{3^{n}}-\frac{1}{3^{n+1}}=a_{n}+\frac{2}{3^{n+1}}$
\end_inset

.
 To summarize:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
a_{n+1} & =\begin{cases}
a_{n}+\frac{0}{3^{n+1}} & \text{ if }x\in L_{n+1}\\
a_{n}+\frac{2}{3^{n+1}} & \text{ if }x\in R_{n+1}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We have that, since 
\begin_inset Formula $C\subseteq[0,1]$
\end_inset

, it implies 
\begin_inset Formula $x\in I_{0}$
\end_inset

.
 By construction, if 
\begin_inset Formula $x\in I_{n}$
\end_inset

, then 
\begin_inset Formula $x\in I_{n+1}$
\end_inset

.
 
\end_layout

\begin_layout Proof
Hence, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
a_{n+1} & =\sum_{i=1}^{n+1}\frac{x_{k}}{2^{k}}
\end{align*}

\end_inset

where 
\begin_inset Formula $x_{k}\in\{0,2\}$
\end_inset

 and (by induction)
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
x\in I_{n},\quad\forall n\in\mathbf{N}
\]

\end_inset


\end_layout

\begin_layout Proof
Pick an arbitrary 
\begin_inset Formula $\epsilon>0$
\end_inset

.
 We can choose 
\begin_inset Formula $N$
\end_inset

 such that 
\begin_inset Formula $l(I_{N})=\frac{1}{3^{N}}<\epsilon$
\end_inset

.
 Consequently, for all 
\begin_inset Formula $n\geq N$
\end_inset

, 
\begin_inset Formula $|a_{n}-x|<l(I_{n})<\epsilon$
\end_inset

.
 Hence, 
\begin_inset Formula $(a_{n})\to x$
\end_inset

.
\end_layout

\begin_layout Proof
Thus, 
\begin_inset Formula $x$
\end_inset

 can be written in the ternary system as an infinite-length (non-terminating)
 string of 
\begin_inset Formula $0s$
\end_inset

 and 
\begin_inset Formula $2$
\end_inset

s.
 That is 
\begin_inset Formula $x=\left(0.x_{1}x_{2}x_{3}\ldots\right)_{3}$
\end_inset

.
\end_layout

\begin_layout Proof
By Cantor's diagonal argument, the collection of all infinite-length (non-termin
ating) binary strings consisting of 
\begin_inset Formula $0s$
\end_inset

 and 
\begin_inset Formula $2s$
\end_inset

 is uncountable.
 So, 
\begin_inset Formula $C$
\end_inset

 is uncountable.
\end_layout

\begin_layout Subsection
Outer Measure.
\end_layout

\begin_layout Definition
(
\emph on
Outer measure
\emph default
) 
\begin_inset CommandInset label
LatexCommand label
name "def:lebesgue-measure"

\end_inset

 The 
\emph on
outer measure 
\emph default
of any set 
\begin_inset Formula $A\subseteq\mathbf{R}$
\end_inset

 is given by:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
\mu^{*}(A) & =\inf Z_{A}
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
where 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
Z_{A} & =\left\{ \sum_{n=1}^{\infty}l(I_{n}):I_{n}\text{ are intervals },A\subseteq\bigcup_{n=1}^{\infty}I_{n}\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We say that the 
\begin_inset Formula $(I_{n})_{n\geq1}$
\end_inset

 covers the set 
\begin_inset Formula $A$
\end_inset

.
 So, the outer measure is the infimum of lengths of all possible covers
 of 
\begin_inset Formula $A$
\end_inset

 (Note again, that some of the 
\begin_inset Formula $I_{n}$
\end_inset

 may be empty; this avoids having to worry whether the sequence 
\begin_inset Formula $(I_{n})$
\end_inset

 has finitely or infinitely many different members.)
\end_layout

\begin_layout Standard
Clearly, 
\begin_inset Formula $\mu^{*}(A)\geq0$
\end_inset

 for any 
\begin_inset Formula $A\subseteq\mathbf{R}$
\end_inset

.
 For some sets 
\begin_inset Formula $A$
\end_inset

, the series 
\begin_inset Formula $\sum_{n=1}^{\infty}l(I_{n})$
\end_inset

 may diverge for any covering of 
\begin_inset Formula $A$
\end_inset

, so 
\begin_inset Formula $\mu^{*}(A)$
\end_inset

 may be equal to 
\begin_inset Formula $\infty$
\end_inset

.
 Since we wish to be able to add the outer measures of various sets we have
 to adopt a convention to deal with infinity.
 An obvious choice is 
\begin_inset Formula $a+\infty=\infty$
\end_inset

, 
\begin_inset Formula $\infty+\infty=\infty$
\end_inset

 and a less obvious but quite practical assumption is 
\begin_inset Formula $0\times\infty=0$
\end_inset

, as we have already seen.
 
\end_layout

\begin_layout Standard
The set 
\begin_inset Formula $Z_{A}$
\end_inset

 is bounded from below by 
\begin_inset Formula $0$
\end_inset

 so that the infimum always exists.
 If 
\begin_inset Formula $r\in Z_{A}$
\end_inset

, then 
\begin_inset Formula $[r,+\infty]\subseteq Z_{A}$
\end_inset

 (clearly we may expand the first interval of any cover to increase the
 total length by any number).
 This shows that 
\begin_inset Formula $Z_{A}$
\end_inset

 is either 
\begin_inset Formula $+\infty$
\end_inset

 or the interval 
\begin_inset Formula $(x,\infty)$
\end_inset

 or 
\begin_inset Formula $[x,\infty]$
\end_inset

 for some real number 
\begin_inset Formula $x$
\end_inset

.
 So, the infimum of 
\begin_inset Formula $Z_{A}$
\end_inset

 is just 
\begin_inset Formula $x$
\end_inset

.
\end_layout

\begin_layout Standard
First, we show that the concept of a null set is consistent with that of
 Outer measure.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "th:null-set-has-outer-measure-zero"

\end_inset

A set 
\begin_inset Formula $A\subseteq\mathbf{R}$
\end_inset

 is a null set if and only if 
\begin_inset Formula $\mu^{\star}(A)=0$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
(
\begin_inset Formula $\Longrightarrow$
\end_inset

 direction).
\end_layout

\begin_layout Proof
Suppose that 
\begin_inset Formula $A$
\end_inset

 is a null set.
 We wish to show that 
\begin_inset Formula $\inf Z_{A}=0$
\end_inset

.
 To this end, our claim is, that given any 
\begin_inset Formula $\epsilon>0$
\end_inset

, there exists 
\begin_inset Formula $z\in Z_{A}$
\end_inset

 such that 
\begin_inset Formula $0<z<\epsilon$
\end_inset

.
 
\end_layout

\begin_layout Proof
By definition of a null set, we can find a sequence of intervals 
\begin_inset Formula $(I_{n})_{n\geq1}$
\end_inset

 covering 
\begin_inset Formula $A$
\end_inset

 such that 
\begin_inset Formula $\sum_{n=1}^{\infty}l(I_{n})<\epsilon/2$
\end_inset

 and so 
\begin_inset Formula $\sum_{n=1}^{\infty}l(I_{n})$
\end_inset

 is an element of 
\begin_inset Formula $Z_{A}$
\end_inset

.
\end_layout

\begin_layout Proof
(
\begin_inset Formula $\Longleftarrow$
\end_inset

direction).
\end_layout

\begin_layout Proof
Suppose that 
\begin_inset Formula $A$
\end_inset

 is a set such that 
\begin_inset Formula $\mu^{*}(A)=0$
\end_inset

.
 That is, 
\begin_inset Formula $\inf Z_{A}=0$
\end_inset

.
 Pick an arbitrary 
\begin_inset Formula $\epsilon>0$
\end_inset

.
 By the definition of 
\begin_inset Formula $\inf$
\end_inset

, there exists 
\begin_inset Formula $z\in Z_{A}$
\end_inset

, such that 
\begin_inset Formula $z<\epsilon$
\end_inset

.
 But, a member of 
\begin_inset Formula $Z_{A}$
\end_inset

 is the total length of some covering of 
\begin_inset Formula $A$
\end_inset

.
 That is, there exists a covering 
\begin_inset Formula $(I_{n})$
\end_inset

 of 
\begin_inset Formula $A$
\end_inset

, with total length smaller than 
\begin_inset Formula $\epsilon$
\end_inset

.
 Since, 
\begin_inset Formula $\epsilon>0$
\end_inset

 was arbitrary to begin with, this is true for all 
\begin_inset Formula $\epsilon>0$
\end_inset

.
 Hence, 
\begin_inset Formula $A$
\end_inset

 is a null set.
\end_layout

\begin_layout Standard
This combines our general 
\emph on
outer measure
\emph default
 with the special case of zero measure.
 Note that, 
\begin_inset Formula $\mu^{*}(\emptyset)=0$
\end_inset

 and 
\begin_inset Formula $\mu^{*}(\{x\})=0$
\end_inset

 and 
\begin_inset Formula $\mu^{*}(\mathbf{Q})=0$
\end_inset

.
\end_layout

\begin_layout Standard
Next, we observe that 
\begin_inset Formula $\mu^{\star}$
\end_inset

 is monotone: the bigger the set, the greater is its outer measure.
 
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:monotonicity-of-lebesgue-measure"

\end_inset

If 
\begin_inset Formula $A\subset B$
\end_inset

, then 
\begin_inset Formula $\mu^{*}(A)\leq\mu^{*}(B)$
\end_inset

.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $(I_{n})$
\end_inset

 be an arbitrary covering for 
\begin_inset Formula $B$
\end_inset

.
 Then, 
\begin_inset Formula $B\subseteq\bigcup_{n=1}^{\infty}I_{n}$
\end_inset

.
 Since 
\begin_inset Formula $A\subset B$
\end_inset

, it follows that 
\begin_inset Formula $A\subset\bigcup_{n=1}^{\infty}I_{n}$
\end_inset

.
 Thus, 
\begin_inset Formula $(I_{n})_{n\geq1}$
\end_inset

 covers 
\begin_inset Formula $A$
\end_inset

.
 So, every cover for 
\begin_inset Formula $B$
\end_inset

 covers 
\begin_inset Formula $A$
\end_inset

.
 Consequently, 
\begin_inset Formula $Z_{B}\subseteq Z_{A}$
\end_inset

.
 
\end_layout

\begin_layout Proof
Now, 
\begin_inset Formula $B\setminus A$
\end_inset

 is non-empty, so let 
\begin_inset Formula $x\in B\setminus A$
\end_inset

.
 
\end_layout

\begin_layout Proof
Now, let 
\begin_inset Formula $(J_{n})$
\end_inset

 be a covering for 
\begin_inset Formula $A$
\end_inset

, where 
\begin_inset Formula $J_{n}=(a_{n},b_{n})$
\end_inset

.
 Define:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
J_{n}' & =\begin{cases}
(a_{n},x)\cup(x,b_{n}) & \text{if }x\in J_{n}\\
J_{n} & \text{otherwise}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
\begin_inset Formula $(J_{n}')_{n\geq1}$
\end_inset

 covers 
\begin_inset Formula $A$
\end_inset

, but not 
\begin_inset Formula $B$
\end_inset

.
 Let 
\begin_inset Formula $z=\sum_{n=1}^{\infty}l(J_{n}')$
\end_inset

.
 Thus, there exists 
\begin_inset Formula $z\in Z_{A}$
\end_inset

, such that 
\begin_inset Formula $z\notin Z_{B}$
\end_inset

.
 So, 
\begin_inset Formula $Z_{B}\subset Z_{A}$
\end_inset

.
\end_layout

\begin_layout Proof
By the properties of 
\begin_inset Formula $\inf$
\end_inset

, it follows that 
\begin_inset Formula $\inf Z_{A}\leq\inf Z_{B}$
\end_inset

.
 Thus, 
\begin_inset Formula $\mu^{*}(A)\leq\mu^{*}(B)$
\end_inset

.
\end_layout

\begin_layout Theorem
The outer measure of an interval equals its length.
\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $I$
\end_inset

 is an interval, we have:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
\mu^{\star}(I) & =l(I)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
If 
\begin_inset Formula $I$
\end_inset

 is unbounded then, it is clear that it cannot be covered by a system of
 intervals of with finite total length.
 This shows that 
\begin_inset Formula $\mu^{*}(I)=\infty$
\end_inset

 and so 
\begin_inset Formula $\mu^{*}(I)=l(I)=\infty$
\end_inset

.
\end_layout

\begin_layout Proof
So we restrict ourselves to bounded intervals.
 
\end_layout

\begin_layout Proof
Step 1.
 
\begin_inset Formula $\mu^{\star}(I)\leq l(I)$
\end_inset

.
\end_layout

\begin_layout Proof
Take the following sequence of intervals.
 
\begin_inset Formula $I_{1}=I$
\end_inset

, 
\begin_inset Formula $I_{n}=[0,0]$
\end_inset

 for all 
\begin_inset Formula $n\geq2$
\end_inset

.
 Then, 
\begin_inset Formula $\sum_{n=1}^{\infty}l(I_{n})=l(I)$
\end_inset

.
 So, 
\begin_inset Formula $l(I)\in Z_{I}$
\end_inset

.
 But, 
\begin_inset Formula $\mu^{\star}(I)=\inf Z_{I}\leq l(I)$
\end_inset

.
\end_layout

\begin_layout Proof
Step II.
 
\begin_inset Formula $l(I)\leq\mu^{*}(I)$
\end_inset

.
\end_layout

\begin_layout Proof
(i) 
\begin_inset Formula $I=[a,b]$
\end_inset

.
 We shall show that for any 
\begin_inset Formula $\epsilon>0$
\end_inset

 :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
l([a,b] & \leq\mu^{*}([a,b])+\epsilon\label{eq:inequality-zero}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
Pick an arbitrary 
\begin_inset Formula $\epsilon>0$
\end_inset

.
 By the definition of outer measure, there exists a sequence of intervals
 
\begin_inset Formula $(I_{n})$
\end_inset

 such that :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\inf Z_{I}=\mu^{*}(I)\leq\sum_{n=1}^{\infty}l(I_{n})<\mu^{*}(I)+\frac{\epsilon}{2}\label{eq:inequality-1}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
We shall slightly increase each of the intervals to an open one.
 Let the endpoints of 
\begin_inset Formula $I_{n}$
\end_inset

 be 
\begin_inset Formula $a_{n}$
\end_inset

, 
\begin_inset Formula $b_{n}$
\end_inset

 and we take:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
J_{n} & =\left(a_{n}-\frac{\epsilon}{2^{n+2}},b_{n}+\frac{\epsilon}{2^{n+2}}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
It is clear that
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
l(I_{n}) & =l(J_{n})-\frac{\epsilon}{2^{n+1}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
so that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sum_{n=1}^{\infty}l(I_{n}) & =\sum_{n=1}^{\infty}l(J_{n})-\frac{\epsilon}{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We insert this in 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:inequality-1"
plural "false"
caps "false"
noprefix "false"

\end_inset

, and we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
\sum_{n=1}^{\infty}l(J_{n}) & \leq\mu^{*}([a,b])+\epsilon\label{eq:inequality-2}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
The new sequence of intervals cover 
\begin_inset Formula $[a,b]$
\end_inset

, so by the Heine Borel theorem, we can choose a finite number of 
\begin_inset Formula $J_{n}$
\end_inset

 to cover 
\begin_inset Formula $[a,b]$
\end_inset

 (the set 
\begin_inset Formula $[a,b]$
\end_inset

 is compact in 
\begin_inset Formula $\mathbf{R})$
\end_inset

.
 We can add some intervals to this finite family to form an initial segment
 of the sequence - just for the simplicity of notation.
 So, for some finite index 
\begin_inset Formula $m$
\end_inset

 we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
[a,b] & \subseteq\bigcup_{n=1}^{m}J_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $J_{n}=[c_{n},d_{n}]$
\end_inset

.
 Put 
\begin_inset Formula $c=\min\{c_{1},\ldots,c_{m}\}$
\end_inset

 and 
\begin_inset Formula $d=\max\{d_{1},\ldots,d_{m}\}$
\end_inset

.
 Then, the above covering means that 
\begin_inset Formula $c<a$
\end_inset

 and 
\begin_inset Formula $b<d$
\end_inset

 and hence 
\begin_inset Formula $l([a,b])<d-c$
\end_inset

.
\end_layout

\begin_layout Proof
Next, the number 
\begin_inset Formula $d-c$
\end_inset

 is certainly smaller than the total length of 
\begin_inset Formula $J_{n}$
\end_inset

, 
\begin_inset Formula $n=1,2,3,\ldots,m$
\end_inset

 (some overlapping takes place) and 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
l(a,b) & <d-c<\sum_{j=1}^{m}l(J_{n})\label{eq:inequality-3}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
Now, it is sufficient to put 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:inequality-2"
plural "false"
caps "false"
noprefix "false"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:inequality-3"
plural "false"
caps "false"
noprefix "false"

\end_inset

 together to deduce 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:inequality-zero"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 (The finite sum is less than equal to the sum of the series, since all
 terms are non-negative) Letting 
\begin_inset Formula $\epsilon\to0$
\end_inset

, we have the desired result.
 
\begin_inset Formula $l([a,b])\leq\mu([a,b])$
\end_inset

.
\end_layout

\begin_layout Proof
(ii) What if 
\begin_inset Formula $I=(a,b)$
\end_inset

?
\end_layout

\begin_layout Proof
Fix an arbitrary 
\begin_inset Formula $\epsilon>0$
\end_inset

 as before.
 As before it is sufficient to show 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:inequality-zero"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
l((a,b) & =l\left(\left[a+\frac{\epsilon}{2},b-\frac{\epsilon}{2}\right]\right)+\epsilon\\
 & =\mu^{*}\left(\left[a+\frac{\epsilon}{2},b-\frac{\epsilon}{2}\right]\right)+\epsilon\\
 & \quad\{\text{ From part I }\}\\
 & \leq\mu^{*}((a,b))+\epsilon\\
 & \quad\{\text{ By monotonicity of outer measure }\eqref{prop:monotonicity-of-lebesgue-measure}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(iii) 
\begin_inset Formula $I=(a,b]$
\end_inset

 or 
\begin_inset Formula $I=[a,b)$
\end_inset

.
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
l(I) & =l((a,b))\leq\mu^{*}((a,b)) & \{\text{ From part II }\}\\
 & \leq\mu^{*}(I) & \{\text{ Monotonicity of Lebesgue Measure }\}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
This closes the proof.
\end_layout

\begin_layout Theorem
(Countable Subadditivity).
 
\begin_inset CommandInset label
LatexCommand label
name "th:countable-subadditivity-of-outer-measure"

\end_inset

 The outer measure is countably subadditive.
 
\end_layout

\begin_layout Theorem
For all sequences of sets 
\begin_inset Formula $(E_{n})$
\end_inset

, we have:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
\mu^{\star}(\bigcup_{n=1}^{\infty}E_{n}) & \leq\sum_{n=1}^{\infty}\mu^{\star}(E_{n})
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
(Note that both sides might be infinite here.)
\end_layout

\begin_layout Proof
(A warm-up)
\end_layout

\begin_layout Proof
Let's first prove a simpler statement:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{*}(E_{1}\cup E_{2}) & \leq\mu^{*}(E_{1})+\mu^{*}(E_{2})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Take an 
\begin_inset Formula $\epsilon>0$
\end_inset

 and we show an even easier inequality:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{*}(E_{1}\cup E_{2}) & \leq\mu^{*}(E_{1})+\mu^{*}(E_{2})+\epsilon
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By the definition of outer measure, 
\end_layout

\begin_layout Proof
There exists a sequence of intervals 
\begin_inset Formula $(I_{n}^{1})$
\end_inset

 covering 
\begin_inset Formula $E_{1}$
\end_inset

 such that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{*}(E_{1}) & <\sum_{n=1}^{\infty}l(I_{n}^{1})<\mu^{*}(E_{1})+\frac{\epsilon}{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
There exists a sequence of intervals 
\begin_inset Formula $(I_{n}^{2})$
\end_inset

 covering 
\begin_inset Formula $E_{2}$
\end_inset

 such that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{*}(E_{2}) & <\sum_{n=1}^{\infty}l(I_{n}^{2})<\mu^{*}(E_{2})+\frac{\epsilon}{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, the sequence of intervals 
\begin_inset Formula $I_{1}^{1},I_{1}^{2},I_{2}^{1},I_{2}^{2},\ldots$
\end_inset

 covers 
\begin_inset Formula $E_{1}\cup E_{2}$
\end_inset

.
 Hence,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{*}(E_{1}\cup E_{2}) & \leq\sum_{n=1}^{\infty}\left(l(I_{n}^{1})+l(I_{n}^{2})\right)\\
 & \leq\mu^{*}(E_{1})+\frac{\epsilon}{2}+\mu^{*}(E_{2})+\frac{\epsilon}{2}\\
 & =\mu^{*}(E_{1})+\mu^{*}(E_{2})+\epsilon
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $\epsilon$
\end_inset

 was arbitrary, this is true for all 
\begin_inset Formula $\epsilon>0$
\end_inset

.
\end_layout

\begin_layout Proof
Choosing 
\begin_inset Formula $\epsilon=\frac{1}{n}$
\end_inset

, passing to the limit as 
\begin_inset Formula $n\to\infty$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{*}(E_{1}\cup E_{2}) & \leq\mu^{*}(E_{1})+\mu^{*}(E_{2})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(
\emph on
Proof of the theorem
\emph default
.)
\end_layout

\begin_layout Proof
If the right-hand side is infinite, then inequality is of course true.
 So, suppose that 
\begin_inset Formula $\sum_{k=1}^{\infty}\mu^{*}(E_{n})<\infty$
\end_inset

.
 For each given 
\begin_inset Formula $\epsilon>0$
\end_inset

 and 
\begin_inset Formula $k\geq1$
\end_inset

, find a covering sequence 
\begin_inset Formula $(I_{n}^{k})$
\end_inset

 of 
\begin_inset Formula $E_{k}$
\end_inset

 with :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sum_{n=1}^{\infty}l(I_{n}^{k}) & <\mu^{*}(E_{k})+\frac{\epsilon}{2^{k}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The iterated series
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sum_{k=1}^{\infty}\left(\sum_{n=1}^{\infty}l(I_{n}^{k})\right) & <\sum_{k=1}^{\infty}\mu^{*}(E_{k})+\epsilon<\infty
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, 
\begin_inset Formula $I_{1}^{1},I_{2}^{1},I_{1}^{2},I_{3}^{1},I_{2}^{2},I_{1}^{3},\ldots$
\end_inset

 is a countable sequence (since 
\begin_inset Formula $\mathbf{N}\times\mathbf{N}$
\end_inset

 is countable) that covers 
\begin_inset Formula $\bigcup_{k=1}^{\infty}E_{k}$
\end_inset

.
 So, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{*}\left(\bigcup_{k=1}^{\infty}E_{k}\right) & \leq\sum_{k=1}^{\infty}\left(\sum_{n=1}^{\infty}l(I_{n}^{k})\right)<\sum_{k=1}^{\infty}\mu^{*}(E_{k})+\epsilon
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
To complete the proof, we simply let 
\begin_inset Formula $\epsilon\to0$
\end_inset

.
\end_layout

\begin_layout Problem
Prove that if 
\begin_inset Formula $\mu^{\star}(A)=0$
\end_inset

 then for each 
\begin_inset Formula $B$
\end_inset

, 
\begin_inset Formula $\mu^{\star}(A\cup B)=\mu^{\star}(B)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $B$
\end_inset

 be an arbitrary set.
 By countable additivity of outer-measure, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{*}(A\cup B) & \leq\mu^{*}(A)+\mu^{*}(B)\\
 & =\mu^{*}(B)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $B\subseteq A\cup B$
\end_inset

, by the monotonicity of outer-measure,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{*}(B) & \leq\mu^{*}(A\cup B)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
From the above discussion, it follows that, 
\begin_inset Formula $\mu^{*}(A\cup B)=\mu^{*}(B)$
\end_inset

.
 Since, 
\begin_inset Formula $B$
\end_inset

 was arbitrary, this must be true for all sets 
\begin_inset Formula $B$
\end_inset

.
 This closes the proof.
\end_layout

\begin_layout Problem
Prove that if 
\begin_inset Formula $\mu^{\star}(A\triangle B)=0$
\end_inset

, then 
\begin_inset Formula $\mu^{\star}(A)=\mu^{\star}(B)$
\end_inset

.
\end_layout

\begin_layout Proof
We know that, 
\begin_inset Formula $A\subseteq B\cup(A\triangle B)$
\end_inset

.
 Hence:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{*}(A) & \leq\mu^{*}(B\cup(A\triangle B))\\
 & \quad\{\text{ Monotonicity of Outer Measure }\}\\
 & \leq\mu^{*}(B)+\mu^{*}(A\triangle B)\\
 & \quad\{\text{ Countable Subadditivity }\}\\
 & =\mu^{*}(B)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
On the other hand, 
\begin_inset Formula $B\subseteq A\cup(A\triangle B)$
\end_inset

.
 Hence, 
\begin_inset Formula $\mu^{*}(B)\leq\mu^{*}(A)$
\end_inset

.
 Consequently, it follows that 
\begin_inset Formula 
\[
\mu^{*}(A)=\mu^{*}(B)
\]

\end_inset


\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:outer-measure-is-translation-invariant"

\end_inset

 The outer measure is translation invariant.
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\[
\mu^{*}(A)=\mu^{*}(A+t)
\]

\end_inset


\end_layout

\begin_layout Proposition
for each 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $A\subset\mathbf{R}$
\end_inset

 and 
\begin_inset Formula $t$
\end_inset

 be a fixed real.
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $(I_{n})$
\end_inset

 be any sequence of intervals covering 
\begin_inset Formula $A$
\end_inset

.
 Then, 
\begin_inset Formula $I_{n}'=[a_{n}+t,b_{n}+t]$
\end_inset

 is a covering for 
\begin_inset Formula $A+t$
\end_inset

.
 Now, 
\begin_inset Formula $l(I_{n}')=l(I_{n})$
\end_inset

 for all 
\begin_inset Formula $n\in\mathbf{N}.$
\end_inset

 So, 
\begin_inset Formula $\sum_{n=1}^{\infty}l(I_{n}')=\sum_{n=1}^{\infty}l(I_{n})$
\end_inset

.
 Hence, if 
\begin_inset Formula $z\in Z_{A}$
\end_inset

, it follows that 
\begin_inset Formula $z\in Z_{A+t}$
\end_inset

 and vice-versa.
 Consequently, 
\begin_inset Formula $Z_{A}=Z_{A+t}$
\end_inset

.
 So, 
\begin_inset Formula $\inf Z_{A}=\inf Z_{A+t}$
\end_inset

.
 Therefore, 
\begin_inset Formula $\mu^{*}(A)=\mu^{*}(A+t)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Lebesgue measurable sets and Lebesgue measure.
\end_layout

\begin_layout Standard
With the outer measure, subadditivity as in Theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:countable-subadditivity-of-outer-measure"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is as far as we can get.
 We wish to however, ensure, that, if the sets 
\begin_inset Formula $(E_{n})$
\end_inset

 are pairwise disjoint (that is 
\begin_inset Formula $E_{i}\cap E_{j}=\emptyset$
\end_inset

, 
\begin_inset Formula $i\neq j$
\end_inset

) then the inequality in Theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:countable-subadditivity-of-outer-measure"
plural "false"
caps "false"
noprefix "false"

\end_inset

 becomes an equality.
 It turns out that this will not in general be true for the outer-measure.
 But our wish is entirely a reasonable one: any length function should atleast
 be finitely additive, since decomposing a set into finitely many disjoint
 pieces, should not alter it's length.
 Moreover, since we constructed our length function via the approximation
 of complicated sets by simpler sets (that is intervals), it seems fair
 to demand a 
\emph on
continuity property
\emph default
 : if pairwise disjoint 
\begin_inset Formula $E_{n}$
\end_inset

 have union 
\begin_inset Formula $E$
\end_inset

, then the lengths of sets 
\begin_inset Formula $B_{n}=E\setminus\bigcup_{k=1}^{n}E_{k}$
\end_inset

 may be expected to decrease to 
\begin_inset Formula $0$
\end_inset

 as 
\begin_inset Formula $n\to\infty$
\end_inset

.
 Combining this with finite additivity leads quite naturally to demand that
 length be countably additive, that is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mu^{\star}\left(\bigcup_{n=1}^{\infty}E_{n}\right)=\sum_{n=1}^{\infty}\mu^{\star}(E_{n})\quad\text{when }E_{i}\cap E_{j}=\emptyset\text{ for }i\neq j\label{eq:countable-additivity-property}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
We therefore turn to the task of finding the class of sets in 
\begin_inset Formula $\mathbf{R}$
\end_inset

 which have this property.
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:lebesgue-measurable-set"

\end_inset

A set 
\begin_inset Formula $E$
\end_inset

 is Lebesgue 
\emph on
measurable
\emph default
 if for every set 
\begin_inset Formula $A\subseteq\mathbf{R}$
\end_inset

 we have:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align}
\mu^{\star}(A) & =\mu^{\star}(A\cap E)+\mu^{\star}(A\cap E^{C})\label{eq:lebesgue-measurable-set}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
We write 
\begin_inset Formula $E\subset\mathcal{F}.$
\end_inset

 
\end_layout

\begin_layout Standard
We obviously have 
\begin_inset Formula $A=(A\cap E)\cup(A\cap E^{C})$
\end_inset

, hence by countable subadditivity 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:countable-subadditivity-of-outer-measure"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mu^{*}(A) & \leq\mu^{*}(A\cap E)+\mu^{*}(A\cap E^{C})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
for any 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $E$
\end_inset

.
 So, our future task of verifying countable additivity property 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:countable-additivity-property"
plural "false"
caps "false"
noprefix "false"

\end_inset

 has simplified: 
\begin_inset Formula $E\in\mathcal{F}$
\end_inset

 if and only the following inequality holds:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mu^{*}(A) & \geq\mu^{*}(A\cap E)+\mu^{*}(A\cap E^{C})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
for all 
\begin_inset Formula $A\subseteq\mathbf{R}$
\end_inset

.
\end_layout

\begin_layout Standard
Now, we give examples of measurable sets.
\end_layout

\begin_layout Theorem
(i) Any null set is measurable.
\end_layout

\begin_layout Theorem
(ii) Any interval is measurable.
\end_layout

\begin_layout Proof
(i) If 
\begin_inset Formula $N$
\end_inset

 is a null set, then by Theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:null-set-has-outer-measure-zero"
plural "false"
caps "false"
noprefix "false"

\end_inset

, the null set has outer measure zero, so 
\begin_inset Formula $\mu^{*}(N)=0$
\end_inset

.
 For all 
\begin_inset Formula $A\subseteq\mathbf{R}$
\end_inset

, since 
\begin_inset Formula $A\cap N\subseteq N$
\end_inset

 and 
\begin_inset Formula $A\cap N^{C}\subseteq A$
\end_inset

.
 Thus,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{*}(A\cap N)+\mu^{*}(A\cap N^{C}) & \leq\mu^{*}(N)+\mu^{*}(A)\\
\mu^{*}(A\cap N)+\mu^{*}(A\cap N^{C}) & \leq\mu^{*}(A)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(ii) Let 
\begin_inset Formula $E=I$
\end_inset

 be an interval.
 Suppose, for example, 
\begin_inset Formula $I=[a,b]$
\end_inset

.
 Take any 
\begin_inset Formula $A\subseteq\mathbf{R}$
\end_inset

 and 
\begin_inset Formula $\epsilon>0$
\end_inset

.
 Find a covering of 
\begin_inset Formula $A$
\end_inset

 with:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}(A) & \leq\sum_{n=1}^{\infty}l(I_{n})\leq\mu^{\star}(A)+\epsilon
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Clearly, the intervals 
\begin_inset Formula $I_{n}'=I_{n}\cap[a,b]$
\end_inset

 cover 
\begin_inset Formula $A\cap[a,b]$
\end_inset

 and hence 
\begin_inset Formula $\sum l(I_{n}')\in Z_{A\cap[a,b]}$
\end_inset

, that is,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}(A\cap[a,b]) & \leq\sum_{n=1}^{\infty}l(I_{n}')
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The intervals 
\begin_inset Formula $I_{n}''=I_{n}\cap(-\infty,a)$
\end_inset

 and 
\begin_inset Formula $I_{n}'''=I_{n}\cap(b,+\infty)$
\end_inset

 cover 
\begin_inset Formula $A\cap[a,b]^{c}$
\end_inset

, so:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{*}(A\cap[a,b]^{c}) & \leq\sum_{n=1}^{\infty}l(I_{n}'')+l(I_{n}''')
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since, the intervals 
\begin_inset Formula $I_{n}'\cup I_{n}''\cup I_{n}'''$
\end_inset

 cover 
\begin_inset Formula $A$
\end_inset

, it follows that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{*}(A\cap[a,b])+\mu^{*}(A\cap[a,b]^{c}) & \leq\sum_{n=1}^{\infty}l(I_{n}')+l(I_{n}'')+l(I_{n}''')\\
 & =\sum_{n=1}^{\infty}l(I_{n})\\
 & \leq\mu^{*}(A)+\epsilon
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Letting 
\begin_inset Formula $\epsilon\to0$
\end_inset

, we have the desired result.
\end_layout

\begin_layout Standard
The fundamental properties of the class 
\begin_inset Formula $\mathcal{F}$
\end_inset

 of all Lebesgue measurable subsets of 
\begin_inset Formula $\mathbf{R}$
\end_inset

 can now be proved.
 They fall into two categories: first we show that certain set operations
 on 
\begin_inset Formula $\mathcal{F}$
\end_inset

 produce sets in 
\begin_inset Formula $\mathcal{F}$
\end_inset

(these are what we call closure properties) and second we prove that for
 sets in 
\begin_inset Formula $\mathcal{F}$
\end_inset

 the outer measure 
\begin_inset Formula $\mu^{*}$
\end_inset

 has the property of countable additivity announced above.
\end_layout

\begin_layout Theorem
(Closure properties of 
\begin_inset Formula $\mathcal{F}$
\end_inset

)
\begin_inset CommandInset label
LatexCommand label
name "th:closure-properties-of-curly-F"

\end_inset


\end_layout

\begin_layout Theorem
(i) 
\begin_inset Formula $\mathbf{R}\in\mathcal{F}$
\end_inset

.
\end_layout

\begin_layout Theorem
(ii) If 
\begin_inset Formula $E\in\mathcal{F}$
\end_inset

, then 
\begin_inset Formula $E^{C}\in\mathcal{F}$
\end_inset

.
\end_layout

\begin_layout Theorem
(iii) If 
\begin_inset Formula $E_{n}\in\mathcal{F}$
\end_inset

, for all 
\begin_inset Formula $n=1,2,3,\ldots$
\end_inset

 then 
\begin_inset Formula $\bigcup_{n=1}^{\infty}E_{n}\in\mathcal{F}$
\end_inset

.
\end_layout

\begin_layout Theorem
Moreover, if 
\begin_inset Formula $E_{n}\in\mathcal{F}$
\end_inset

, for all 
\begin_inset Formula $n=1,2,3,\ldots$
\end_inset

 and 
\begin_inset Formula $E_{i}\cap E_{j}=\emptyset$
\end_inset

 for 
\begin_inset Formula $i\neq j$
\end_inset

, then:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{equation}
\mu^{\star}(\bigcup_{n=1}^{\infty}E_{n})=\sum_{n=1}^{\infty}\mu^{\star}(E_{n})\label{eq:countable-additivity}
\end{equation}

\end_inset


\end_layout

\begin_layout Remark*
This result is the most important theorem in this chapter and provides the
 basis for all that follows.
 It also allows us to give names to the quantities under discussion.
 
\end_layout

\begin_layout Remark*
Conditions (i)-(iii) mean that 
\begin_inset Formula $\mathcal{F}$
\end_inset

 is a sigma-algebra.
 In other words, we say that a family of sets is a sigma-algebra, if it
 contains the base set and is closed under countable unions, and complements.
 A 
\begin_inset Formula $[0,\infty)$
\end_inset

-valued function defined on a sigma-algebra is called a measure if it satisfies
 countable additivity 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:countable-additivity"
plural "false"
caps "false"
noprefix "false"

\end_inset

 for pairwise disjoint sets.
 
\end_layout

\begin_layout Remark*
An alternative, rather more abstract and general approach to measure theory
 is to begin with the above properties as axioms, i.e.
 to call the the triple 
\begin_inset Formula $(\Omega,\mathcal{F},\mu)$
\end_inset

 a measure space, if 
\begin_inset Formula $\Omega$
\end_inset

 is an abstractly given set, 
\begin_inset Formula $\mathcal{F}$
\end_inset

 is a sigma-algebra of the subsets of 
\begin_inset Formula $\Omega$
\end_inset

 and 
\begin_inset Formula $\mu:\mathcal{F}\to[0,\infty]$
\end_inset

 is a function satisfying countable additivity.
 The task of defining the Lebesgue measure on 
\begin_inset Formula $\mathbf{R}$
\end_inset

 then becomes that of verifying, with 
\begin_inset Formula $\mathcal{F}$
\end_inset

 and 
\begin_inset Formula $\mu=\mu^{\star}$
\end_inset

 on 
\begin_inset Formula $\mathcal{F}$
\end_inset

 defined above, that the triple 
\begin_inset Formula $(\Omega,\mathcal{F},\mu)$
\end_inset

 satisfies these axioms.
\end_layout

\begin_layout Remark*
Although the requirements of probability theory will mean that we have to
 consider such general measure spaces in due course, we have chosen our
 more concrete approach to the fundamental example of Lebesgue measure in
 order to demonstrate how this important measure space arises quite naturally
 from the considerations of the 
\emph on
lengths
\emph default
 of sets in 
\begin_inset Formula $\mathbf{R}$
\end_inset

 and leads to a theory of integration which greatly extends that of Riemann.
 It is also sufficient to allow us to develop most of the important examples
 of probability distributions.
\end_layout

\begin_layout Proof
(1) Let 
\begin_inset Formula $A\subseteq\mathbf{R}$
\end_inset

.
 Note that 
\begin_inset Formula $A\cap\mathbf{R}=A$
\end_inset

, 
\begin_inset Formula $\mathbf{R}^{C}=\emptyset$
\end_inset

, so that 
\begin_inset Formula $A\cap\mathbf{R}^{C}=\emptyset$
\end_inset

.
 Thus, the equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:lebesgue-measurable-set"
plural "false"
caps "false"
noprefix "false"

\end_inset

 now reads, 
\begin_inset Formula $\mu^{\star}(A)=\mu^{\star}(A)+\mu^{\star}(\emptyset)$
\end_inset

 which is obviously true, since 
\begin_inset Formula $\emptyset$
\end_inset

 is a null set and 
\begin_inset Formula $\mu^{\star}(\emptyset)=0$
\end_inset

.
\end_layout

\begin_layout Proof
(2) Suppose 
\begin_inset Formula $E\in\mathcal{F}$
\end_inset

 and take any arbitrary 
\begin_inset Formula $A\subseteq\mathbf{R}$
\end_inset

.
 We have to show 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:lebesgue-measurable-set"
plural "false"
caps "false"
noprefix "false"

\end_inset

 for 
\begin_inset Formula $E^{C}$
\end_inset

, that is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\mu^{\star}(A)=\mu^{\star}(A\cap E^{C})+\mu^{\star}(A\cap(E^{C})^{C})
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
but since 
\begin_inset Formula $(E^{C})^{C}=E$
\end_inset

, this reduces to the condition for 
\begin_inset Formula $E$
\end_inset

 which holds by hypothesis.
\end_layout

\begin_layout Proof
(3) We split the proof (iii) into several steps.
 But first:
\end_layout

\begin_layout Proof

\series bold
A warm up.
 
\series default
Suppose that 
\begin_inset Formula $E_{1}\cap E_{2}=\emptyset$
\end_inset

, 
\begin_inset Formula $E_{1},E_{2}\in\mathcal{F}$
\end_inset

.
 We shall show that 
\begin_inset Formula $E_{1}\cup E_{2}\in\mathcal{F}$
\end_inset

 and 
\begin_inset Formula $\mu^{\star}(E_{1}\cup E_{2})=\mu^{\star}(E_{1})+\mu^{\star}(E_{2})$
\end_inset

.
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $A\subseteq\mathbf{R}$
\end_inset

.
 We have the condition for 
\begin_inset Formula $E_{1}$
\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\mu^{\star}(A)=\mu^{\star}(A\cap E_{1})+\mu^{\star}(A\cap E_{1}^{C})\label{eq:condition-for-E1}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Now, we apply 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:lebesgue-measurable-set"
plural "false"
caps "false"
noprefix "false"

\end_inset

 for 
\begin_inset Formula $E_{2}$
\end_inset

 with 
\begin_inset Formula $A\cap E_{1}^{C}$
\end_inset

 in place of 
\begin_inset Formula $A$
\end_inset

.
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}(A\cap E_{1}^{C}) & =\mu^{\star}(A\cap E_{1}^{C}\cap E_{2})+\mu^{\star}(A\cap E_{1}^{C}\cap E_{2}^{C})\\
 & =\mu^{\star}(A\cap(E_{1}^{C}\cap E_{2}))+\mu^{\star}(A\cap(E_{1}^{C}\cap E_{2}^{C}))
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The situation is depicted in the figure below.
\end_layout

\begin_layout Proof
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (-2,0) circle (1.5cm);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (-2.5,0) node {$E_1$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,0) circle (2cm);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,0) node {$A$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (2,-0.5) circle (1.5cm);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (2.5,-0.5) node {$E_2$};
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Figure.
 The sets $A$, $E_1$ and $E_2$.
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $E_{1}$
\end_inset

 and 
\begin_inset Formula $E_{2}$
\end_inset

 are disjoint, 
\begin_inset Formula $E_{1}^{C}\cap E_{2}=E_{2}$
\end_inset

.
 By De-Morgan's laws, 
\begin_inset Formula $E_{1}^{C}\cap E_{2}^{C}=(E_{1}\cup E_{2})^{C}$
\end_inset

.
 We substitute and we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}(A\cap E_{1}^{C}) & =\mu^{\star}(A\cap E_{2})+\mu^{\star}(A\cap(E_{1}\cup E_{2})^{C})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Substituting this into 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:condition-for-E1"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\mu^{\star}(A)=\mu^{\star}(A\cap E_{1})+\mu^{\star}(A\cap E_{2})+\mu^{\star}(A\cap(E_{1}\cup E_{2})^{C})\label{eq:updated-equation-for-E1}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Now, by the subadditivity property of 
\begin_inset Formula $\mu^{\star}$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}(A\cap E_{1})+\mu^{\star}(A\cap E_{2}) & \geq\mu^{\star}((A\cap E_{1})\cup(A\cap E_{2}))\\
 & =\mu^{\star}(A\cap(E_{1}\cup E_{2}))
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
So, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:updated-equation-for-E1"
plural "false"
caps "false"
noprefix "false"

\end_inset

 gives:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}(A) & \geq\mu^{\star}(A\cap(E_{1}\cup E_{2}))+\mu^{\star}(A\cap(E_{1}\cup E_{2})^{C})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
which is sufficient for 
\begin_inset Formula $E_{1}\cup E_{2}$
\end_inset

 to belong to 
\begin_inset Formula $\mathcal{F}$
\end_inset

.
\end_layout

\begin_layout Proof
Finally, let 
\begin_inset Formula $A=E_{1}\cup E_{2}$
\end_inset

.
 Then, the equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:updated-equation-for-E1"
plural "false"
caps "false"
noprefix "false"

\end_inset

 yields:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}(E_{1}\cup E_{2}) & =\mu^{\star}(E_{1})+\mu^{\star}(E_{2})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We return to the main proof of (iii).
\end_layout

\begin_layout Proof

\series bold
Step 1.
 
\series default
Our claim is: if pariwise disjoint 
\begin_inset Formula $E_{k}$
\end_inset

, 
\begin_inset Formula $k=1,2,\ldots$
\end_inset

 are in 
\begin_inset Formula $\mathcal{F}$
\end_inset

 then their countable union is in 
\begin_inset Formula $\mathcal{F}$
\end_inset

 and countable additivity 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:countable-additivity-property"
plural "false"
caps "false"
noprefix "false"

\end_inset

 holds.
 
\end_layout

\begin_layout Proof
We begin as in the proof of the 
\series bold
Warm Up 
\series default
and we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
\mu^{\star}(A) & =\mu^{\star}(A\cap E_{1})+\mu^{\star}(A\cap E_{1}^{C})\nonumber \\
\mu^{\star}(A) & =\mu^{\star}(A\cap E_{1})+\mu^{\star}(A\cap E_{2})+\mu^{\star}(A\cap(E_{1}\cup E_{2})^{C})\label{eq:updated-equation-for-m(A)}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
(See 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:updated-equation-for-E1"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 
\end_layout

\begin_layout Proof
\begin_inset Formula $E_{3}$
\end_inset

 is also measurable.
 Let 
\begin_inset Formula $A=A\cap E_{1}^{C}\cap E_{2}^{C}$
\end_inset

.
 Then:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}(A\cap E_{1}^{C}\cap E_{2}^{C}) & =\mu^{\star}(A\cap E_{1}^{C}\cap E_{2}^{C}\cap E_{3})+\mu^{\star}(A\cap E_{1}^{C}\cap E_{2}^{C}\cap E_{3}^{C})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
But, 
\begin_inset Formula $E_{1}^{C}\cap E_{2}^{C}\cap E_{3}=E_{3}$
\end_inset

 since they are pairwise disjoint.
 So,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
\mu^{\star}(A\cap(E_{1}\cup E_{2})^{C}) & =\mu^{\star}(A\cap E_{3})+\mu^{\star}(A\cap(E_{1}\cup E_{2}\cup E_{3})^{C})\label{eq:m(A-intersects-E1C-intersects-E2C)}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
Substituting the value of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:m(A-intersects-E1C-intersects-E2C)"
plural "false"
caps "false"
noprefix "false"

\end_inset

 in equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:updated-equation-for-m(A)"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we get after 
\begin_inset Formula $n=3$
\end_inset

 steps:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\mu^{\star}(A)=\sum_{k=1}^{3}\mu^{\star}(A\cap E_{k})+\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{3}E_{k}\right)^{C}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
We proceed by mathematical induction.
 We induct on 
\begin_inset Formula $k$
\end_inset

.
 Our hypothesis is, that after 
\begin_inset Formula $n$
\end_inset

 steps, we expect:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\mu^{\star}(A)=\sum_{k=1}^{n}\mu^{\star}(A\cap E_{k})+\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{n}E_{k}\right)^{C}\right)\label{eq:update-equation-of-m(A)-after-n-steps}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Let's assume that 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\mu^{\star}(A)=\sum_{k=1}^{n-1}\mu^{\star}(A\cap E_{k})+\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{n-1}E_{k}\right)^{C}\right)\label{eq:updated-equation-of-m(A)-upto-n-1-steps}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
is true.
 
\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $E_{n}\in\mathcal{F}$
\end_inset

, we may apply the definition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:lebesgue-measurable-set"
plural "false"
caps "false"
noprefix "false"

\end_inset

 with 
\begin_inset Formula $A=A\bigcap\left(\bigcup_{k=1}^{n-1}E_{k}\right)^{C}$
\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{n-1}E_{k}\right)^{C}\right)=\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{n-1}E_{k}\right)^{C}\bigcap E_{n}\right)+\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{n-1}E_{k}\right)^{C}\bigcap E_{n}^{C}\right)\label{eq:measure-of-the-set-A-intersection-union-all-Ek}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Now we make the same observations as in the 
\series bold
Warm Up
\series default
:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\left(\bigcup_{k=1}^{n-1}E_{k}\right)^{C}\bigcap E_{n} & =E_{n}\quad\left\{ E_{i}\text{ are pairwise disjoint}\right\} \\
\left(\bigcup_{k=1}^{n-1}E_{k}\right)^{C}\bigcap E_{n}^{C} & =\left(\bigcup_{k=1}^{n}E_{n}\right)^{C}\quad\left\{ \text{De-Morgan's laws}\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Inserting these into equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:measure-of-the-set-A-intersection-union-all-Ek"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{n-1}E_{k}\right)^{C}\right) & =\mu^{\star}(A\cap E_{n})+\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{n}E_{n}\right)^{C}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
and inserting this into 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:updated-equation-of-m(A)-upto-n-1-steps"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we get :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}(A) & =\sum_{k=1}^{n-1}\mu^{\star}(A\cap E_{k})+\mu^{\star}(A\cap E_{n})+\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{n}E_{n}\right)^{C}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
This proves the induction hypothesis.
\end_layout

\begin_layout Proof
As will be seen at the next step, the fact that 
\begin_inset Formula $E_{k}$
\end_inset

 are pairwise disjoint is not necessary in order to ensure that their union
 belongs to 
\begin_inset Formula $\mathcal{F}$
\end_inset

.
 However, with this assumption we have equality in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:update-equation-of-m(A)-after-n-steps"
plural "false"
caps "false"
noprefix "false"

\end_inset

which does not hold otherwise.
 This equality will allow us to prove countable additivity 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:countable-additivity"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 
\end_layout

\begin_layout Proof
Since:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\left(\bigcup_{k=1}^{n}E_{k}\right)^{C} & \supseteq\left(\bigcup_{k=1}^{\infty}E_{k}\right)^{C}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
from 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:update-equation-of-m(A)-after-n-steps"
plural "false"
caps "false"
noprefix "false"

\end_inset

 by monotonicity of measure, we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}(A) & =\sum_{k=1}^{n}\mu^{\star}(A\cap E_{k})+\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{n}E_{k}\right)^{C}\right)\\
 & \geq\sum_{k=1}^{n}\mu^{\star}(A\cap E_{k})+\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{\infty}E_{k}\right)^{C}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By the Order Limit Theorem, the inequality remains true, if we pass to the
 limit, as 
\begin_inset Formula $n\to\infty$
\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\mu^{\star}(A)\geq\sum_{k=1}^{\infty}\mu^{\star}(A\cap E_{k})+\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{\infty}E_{k}\right)^{C}\right)\label{eq:inequality-for-the-measure-union-all-Ek}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
By countable sub-additivity of 
\begin_inset Formula $\mu^{\star}$
\end_inset

 (Theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:countable-subadditivity-of-outer-measure"
plural "false"
caps "false"
noprefix "false"

\end_inset

) :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sum_{k=1}^{\infty}\mu^{\star}(A\cap E_{k}) & \geq\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{\infty}E_{k}\right)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
and so:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\mu^{\star}(A)\geq\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{\infty}E_{k}\right)\right)+\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{\infty}E_{k}\right)^{C}\right)\label{eq:union-all-Ek-is-measurable}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
So, we have shown that 
\begin_inset Formula $\bigcup_{k=1}^{\infty}E_{k}\in\mathcal{F}$
\end_inset

 and hence the two sides of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:union-all-Ek-is-measurable"
plural "false"
caps "false"
noprefix "false"

\end_inset

 are equal.
 
\end_layout

\begin_layout Proof
The right hand side of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:inequality-for-the-measure-union-all-Ek"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is squeezed between the left and right of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:union-all-Ek-is-measurable"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 That is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}(A) & =\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{\infty}E_{k}\right)\right)+\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{\infty}E_{k}\right)^{C}\right)\\
 & \leq\sum_{k=1}^{\infty}\mu^{\star}(A\cap E_{k})+\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{\infty}E_{k}\right)^{C}\right)\\
 & \leq\mu^{\star}(A)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Consequently,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
\mu^{\star}(A) & =\sum_{k=1}^{\infty}\mu^{\star}(A\cap E_{k})+\mu^{\star}\left(A\bigcap\left(\bigcup_{k=1}^{\infty}E_{k}\right)^{C}\right)\label{eq:an-equality-involving-union-all-Ek}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
The equality here is a consequence of the assumption that 
\begin_inset Formula $E_{k}$
\end_inset

 are pairwise disjoint.
 It holds for any set 
\begin_inset Formula $A$
\end_inset

 so we may insert 
\begin_inset Formula $A=\bigcup_{j=1}^{\infty}E_{j}$
\end_inset

.
 The last term on the right is zero, because the length of the empty set,
 
\begin_inset Formula $\mu^{\star}(\emptyset)=0$
\end_inset

.
 And, since the 
\begin_inset Formula $E_{i}$
\end_inset

 are disjoint, 
\begin_inset Formula $\left(\bigcup_{j=1}^{\infty}E_{j}\right)\bigcap E_{k}=E_{k}$
\end_inset

.
 As a result, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}\left(\bigcup_{j=1}^{\infty}E_{j}\right) & =\sum_{j=1}^{\infty}\mu^{\star}(E_{j})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof

\series bold
Step 2.
 
\series default
Our claim is, if 
\begin_inset Formula $E_{1},E_{2}\in\mathcal{F}$
\end_inset

, then 
\begin_inset Formula $E_{1}\cup E_{2}\in\mathcal{F}$
\end_inset

 (not necessarily disjoint).
\end_layout

\begin_layout Proof
Again we begin as in the 
\series bold
Warm Up
\series default
:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\mu^{\star}(A)=\mu^{\star}(A\cap E_{1})+\mu^{\star}(A\cap E_{1}^{C})\label{eq:the-fact-that-E1-is-measurable}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Next applying the definition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:lebesgue-measurable-set"
plural "false"
caps "false"
noprefix "false"

\end_inset

 to 
\begin_inset Formula $E_{2}$
\end_inset

 and with 
\begin_inset Formula $A\cap E_{1}^{C}$
\end_inset

 in place of 
\begin_inset Formula $A$
\end_inset

 we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}(A\cap E_{1}^{C}) & =\mu^{\star}(A\cap E_{1}^{C}\cap E_{2})+\mu^{\star}(A\cap E_{1}^{C}\cap E_{2}^{C})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We insert this into 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:the-fact-that-E1-is-measurable"
plural "false"
caps "false"
noprefix "false"

\end_inset

 to get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\mu^{\star}(A)=\mu^{\star}(A\cap E_{1})+\mu^{\star}(A\cap E_{1}^{C}\cap E_{2})+\mu^{\star}(A\cap E_{1}^{C}\cap E_{2}^{C})\label{eq:an-intermediate-equality}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
By DeMorgan's law, 
\begin_inset Formula $E_{1}^{C}\cap E_{2}^{C}=(E_{1}\cup E_{2})^{C}$
\end_inset

 so as before:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}(A\cap E_{1}^{C}\cap E_{2}^{C}) & =\mu^{\star}(A\cap(E_{1}\cup E_{2})^{C})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, consider the set 
\begin_inset Formula $(A\cap E_{1})\cup(A\cap E_{1}^{C}\cap E_{2})$
\end_inset

.
 This, can be written as: 
\begin_inset Formula $A\cap(E_{1}\cup(E_{1}^{C}\cap E_{2}))=A\cap(E_{1}\cup E_{1}^{C})\cap(E_{1}\cup E_{2})=A\cap(E_{1}\cup E_{2})$
\end_inset

.
 
\end_layout

\begin_layout Proof
By Countable Subadditivity of 
\begin_inset Formula $\mu^{\star}$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}(A\cap E_{1})+\mu^{\star}(A\cap E_{1}^{C}\cap E_{2}) & \geq\mu^{\star}(A\cap(E_{1}\cup E_{2}))
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Inserting these facts into 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:an-intermediate-equality"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu^{\star}(A) & \geq\mu^{\star}(A\cap(E_{1}\cup E_{2}))+\mu^{\star}(A\cap(E_{1}\cup E_{2})^{C})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
as required.
\end_layout

\begin_layout Proof

\series bold
Step 3.
 
\series default
Our claim is, if 
\begin_inset Formula $E_{k}\in\mathcal{F}$
\end_inset

, 
\begin_inset Formula $k=1,2,\ldots,n$
\end_inset

, then the finite union 
\begin_inset Formula $E_{1}\cup E_{2}\cup\ldots\cup E_{n}\in\mathcal{F}$
\end_inset

.
 (not necessarily disjoint)
\end_layout

\begin_layout Proof
We argue by induction.
 Suppose that the claim is true for 
\begin_inset Formula $n-1$
\end_inset

.
 Then, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
E_{1}\cup E_{2}\cup\ldots\cup E_{n} & =(E_{1}\cup\ldots\cup E_{n-1})\cup E_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
so that the result follows from 
\series bold
Step 2
\series default
.
\end_layout

\begin_layout Proof

\series bold
Step 4.
 
\series default
If 
\begin_inset Formula $E_{1},E_{2}\in\mathcal{F}$
\end_inset

, then 
\begin_inset Formula $E_{1}\cap E_{2}\in\mathcal{F}$
\end_inset

.
\end_layout

\begin_layout Proof
We have 
\begin_inset Formula $E_{1}^{C},E_{2}^{C}\in\mathcal{F}$
\end_inset

 by (ii), 
\begin_inset Formula $E_{1}^{C}\cup E_{2}^{C}\in\mathcal{F}$
\end_inset

 by step 2, and 
\begin_inset Formula $(E_{1}^{C}\cup E_{2}^{C})^{C}\in\mathcal{F}$
\end_inset

 by (ii) again.
 But, by De-Morgan's laws, this is 
\begin_inset Formula $(E_{1}^{C}\cup E_{2}^{C})^{C}=E_{1}\cap E_{2}$
\end_inset

.
\end_layout

\begin_layout Proof

\series bold
Step 5.
 
\series default
The general case: if 
\begin_inset Formula $E_{1},E_{2},\ldots$
\end_inset

 are in 
\begin_inset Formula $\mathcal{F}$
\end_inset

, then so is the countably infinite union 
\begin_inset Formula $\bigcup_{k=1}^{\infty}E_{k}$
\end_inset

.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $E_{k}\in\mathcal{F}$
\end_inset

, 
\begin_inset Formula $k=1,2,\ldots$
\end_inset

.
 We define the auxiliary sequence of pairwise disjoint sets 
\begin_inset Formula $F_{k}$
\end_inset

 with the same union as 
\begin_inset Formula $E_{k}$
\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
F_{1} & =E_{1}\\
F_{2} & =E_{2}\setminus E_{1}=E_{2}\cap E_{1}^{C}\\
F_{3} & =E_{3}\setminus(E_{1}\cup E_{2})=E_{3}\cap(E_{1}\cup E_{2})^{C}\\
\vdots\\
F_{k} & =E_{k}\setminus(E_{1}\cup E_{2}\cup\ldots\cup E_{k-1})=E_{k}\cap(E_{1}\cup\ldots\cup E_{k-1})^{C}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By steps 3 and 4, we know that all 
\begin_inset Formula $F_{k}$
\end_inset

 are in 
\begin_inset Formula $\mathcal{F}$
\end_inset

.
 By the very construction, they are pairwise disjoint, so by step 1, their
 union is in 
\begin_inset Formula $\mathcal{F}$
\end_inset

.
 We shall show that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\bigcup_{k=1}^{\infty}F_{k} & =\bigcup_{k=1}^{\infty}E_{k}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The inclusion:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\bigcup_{k=1}^{\infty}F_{k} & \subseteq\bigcup_{k=1}^{\infty}E_{k}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
is obvious since for each 
\begin_inset Formula $k$
\end_inset

, 
\begin_inset Formula $F_{k}\subseteq E_{k}$
\end_inset

 by definition.
 For the inverse, let 
\begin_inset Formula $a\in\bigcup_{k=1}^{\infty}E_{k}$
\end_inset

.
 Put 
\begin_inset Formula $S=\{n\in\mathbf{N}:a\in E_{n}\}$
\end_inset

 which is non-empty since 
\begin_inset Formula $a$
\end_inset

 belongs to the union.
 Let 
\begin_inset Formula $n_{0}=\min S\in S$
\end_inset

.
 If 
\begin_inset Formula $n_{0}=1$
\end_inset

, then 
\begin_inset Formula $a\in E_{1}=F_{1}$
\end_inset

.
 Suppose 
\begin_inset Formula $n_{0}>1$
\end_inset

.
 So, 
\begin_inset Formula $a\in E_{n_{0}}$
\end_inset

 and by definition of 
\begin_inset Formula $n_{0}$
\end_inset

, 
\begin_inset Formula $a\notin E_{1}$
\end_inset

,
\begin_inset Formula $\ldots,$
\end_inset


\begin_inset Formula $a\notin E_{n_{0}-1}$
\end_inset

.
 By the definition of 
\begin_inset Formula $F_{n_{0}}$
\end_inset

, this means that 
\begin_inset Formula $a\in F_{n_{0}}$
\end_inset

 so 
\begin_inset Formula $a$
\end_inset

 is in 
\begin_inset Formula $\bigcup_{k=1}^{\infty}F_{k}$
\end_inset

.
 This closes the proof.
\end_layout

\begin_layout Standard
Using De-Morgan's laws, we can easily verify an additional property of 
\begin_inset Formula $\mathcal{F}$
\end_inset

.
\end_layout

\begin_layout Proposition
If 
\begin_inset Formula $E_{k}\in\mathcal{F}$
\end_inset

, 
\begin_inset Formula $k=1,2,\ldots,$
\end_inset

 then 
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
E & =\bigcap_{k=1}^{\infty}E_{k}\in\mathcal{F}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
\begin_inset Formula $\mathcal{F}$
\end_inset

 is closed under complementation.
 Thus, 
\begin_inset Formula $E_{k}\in\mathcal{F}\implies E_{k}^{C}\in\mathcal{F}$
\end_inset

.
 Since, 
\begin_inset Formula $\mathcal{F}$
\end_inset

 is closed under countable unions, 
\begin_inset Formula $\bigcup_{k=1}^{\infty}E_{k}^{C}\in\mathcal{F}$
\end_inset

.
 And it follows that, 
\begin_inset Formula $\left(\bigcup_{k=1}^{\infty}E_{k}^{C}\right)^{C}\in\mathcal{F}$
\end_inset

.
 By De-Morgan's laws, 
\begin_inset Formula $\left(\bigcup_{k=1}^{\infty}E_{k}^{C}\right)^{C}=\bigcap_{k=1}^{\infty}E_{k}$
\end_inset

.
 This closes the proof.
\end_layout

\begin_layout Standard
We can therefore summarize the properties of the family 
\begin_inset Formula $\mathcal{F}$
\end_inset

 of Lebesgue measurable sets as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula $\mathcal{F}$
\end_inset

 is closed under countable unions, countable intersections and complements.
 It contains intervals and null sets.
 
\end_layout

\begin_layout Definition
(
\emph on
Lebesgue Measure
\emph default
).
 
\begin_inset CommandInset label
LatexCommand label
name "def:Lebesgue-Measure"

\end_inset

We shall write 
\begin_inset Formula $\mu(E)$
\end_inset

 instead of 
\begin_inset Formula $\mu^{\star}(E)$
\end_inset

 for any 
\begin_inset Formula $E$
\end_inset

 in 
\begin_inset Formula $\mathcal{F}$
\end_inset

 and call 
\begin_inset Formula $\mu(E)$
\end_inset

 the Lebesgue measure of the set 
\begin_inset Formula $E$
\end_inset

.
 
\end_layout

\begin_layout Definition
The Lebesgue measure 
\begin_inset Formula $\mu:\mathcal{F}\to[0,\infty]$
\end_inset

 is a countably additive set function defined on the sigma-algebra 
\begin_inset Formula $\mathcal{F}$
\end_inset

 of measurable sets.
 The Lebesgue measure of an interval is equal to its length.
 The Lebesgue measure of a null-set is zero.
\end_layout

\begin_layout Subsection
Basic Properties of Lebesgue Measure.
\end_layout

\begin_layout Standard
Since Lebesgue measure is nothing else than the outer measure restricted
 to a special class of sets 
\begin_inset Formula $\mathcal{F}$
\end_inset

, some properties of the outer measure are automatically inherited by the
 Lebesgue measure.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:properties-of-lebesgue-measure"

\end_inset

Suppose that 
\begin_inset Formula $A,B\in\mathcal{F}$
\end_inset

.
 
\end_layout

\begin_layout Proposition
(1) If 
\begin_inset Formula $A\subset B$
\end_inset

, then 
\begin_inset Formula $\mu(A)\leq\mu(B)$
\end_inset

.
\end_layout

\begin_layout Proposition
(2) If 
\begin_inset Formula $A\subset B$
\end_inset

 and 
\begin_inset Formula $\mu(A)$
\end_inset

 is finite, then 
\begin_inset Formula $\mu(B\setminus A)=\mu(B)-\mu(A)$
\end_inset

.
\end_layout

\begin_layout Proposition
(3) 
\begin_inset Formula $\mu$
\end_inset

 is translation invariant.
\end_layout

\begin_layout Proposition
Since the empty set 
\begin_inset Formula $\emptyset\in\mathcal{F}$
\end_inset

, we can take 
\begin_inset Formula $E_{i}=\emptyset$
\end_inset

 for all 
\begin_inset Formula $i>n$
\end_inset

 in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:countable-additivity"
plural "false"
caps "false"
noprefix "false"

\end_inset

 to conclude that Lebesgue measure is finitely additive: if 
\begin_inset Formula $E_{i}\in\mathcal{F}$
\end_inset

 are pairwise disjoint, then:
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
\mu\left(\bigcup_{i=1}^{n}E_{i}\right) & =\sum_{i=1}^{n}\mu(E_{i})
\end{align*}

\end_inset


\end_layout

\begin_layout Remark*
Property (2) is derived as follows.
 Since 
\begin_inset Formula $B=(B\setminus A)\cup A$
\end_inset

 and 
\begin_inset Formula $B\setminus A$
\end_inset

 and 
\begin_inset Formula $A$
\end_inset

 are disjoint, 
\begin_inset Formula $\mu(B)=\mu(B\setminus A)+\mu(A)$
\end_inset

.
 Consequently, 
\begin_inset Formula $\mu(B\setminus A)=\mu(B)-\mu(A)$
\end_inset

.
\end_layout

\begin_layout Problem
Find a formula describing 
\begin_inset Formula $\mu(A\cup B)$
\end_inset

 and 
\begin_inset Formula $\mu(A\cup B\cup C)$
\end_inset

 in terms of measures of the individual sets and their intersections (we
 do not assume that the sets are pairwise disjoint).
\end_layout

\begin_layout Proof
We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
A\cup B & =\left(A\cap(A\cap B)^{C}\right)\cup\left(B\cap(A\cap B)^{C}\right)\cup(A\cap B)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The three sets 
\begin_inset Formula $A\setminus(A\cap B)$
\end_inset

, 
\begin_inset Formula $B\setminus(A\cap B)$
\end_inset

 and 
\begin_inset Formula $A\cap B$
\end_inset

 are pairwise disjoint.
 Consequently, by finite additivity of the Lebesgue measure:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu(A\cup B) & =\mu(A\setminus(A\cap B))+\mu(B\setminus(A\cap B))+\mu(A\cap B)\\
 & =\mu(A)-\mu(A\cap B)+\mu(B)-\mu(A\cap B)+\mu(A\cap B)\\
 & \quad\left\{ \because(A\cap B)\subseteq A,\mu(A\setminus(A\cap B))=\mu(A)-\mu(A\cap B)\right\} \\
 & =\mu(A)+\mu(B)-\mu(A\cap B)
\end{align*}

\end_inset

Let 
\begin_inset Formula $B=B\cup C$
\end_inset


\begin_inset Formula 
\begin{align*}
\mu(A\cup(B\cup C)) & =\mu(A)+\mu(B\cup C)-\mu(A\cap(B\cup C))\\
 & =\mu(A)+\mu(B)+\mu(C)-\mu(B\cap C)-\mu((A\cap B)\cup(A\cap C))\\
 & =\mu(A)+\mu(B)+\mu(C)-\mu(B\cap C)-\mu(A\cap B)-\mu(A\cap C)\\
 & +\mu(A\cap B\cap C)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Recalling that the 
\emph on
symmetric difference 
\begin_inset Formula $A\Delta B$
\end_inset

 
\emph default
of two sets is defined by 
\begin_inset Formula $A\Delta B=(A\setminus B)\cup(B\setminus A)$
\end_inset

 the following result is also easy to check:
\end_layout

\begin_layout Proposition
If 
\begin_inset Formula $A\in\mathcal{F}$
\end_inset

, and 
\begin_inset Formula $\mu(A\Delta B)=0$
\end_inset

, then 
\begin_inset Formula $B\in\mathcal{F}$
\end_inset

 and 
\begin_inset Formula $\mu(A)=\mu(B)$
\end_inset

.
\end_layout

\begin_layout Proof
Null sets belong to 
\begin_inset Formula $\mathcal{F}$
\end_inset

.
 Since 
\begin_inset Formula $A\Delta B$
\end_inset

 is a null set, it belongs to 
\begin_inset Formula $\mathcal{F}$
\end_inset

.
 Now, 
\begin_inset Formula $A\cap B^{C}$
\end_inset

 and
\begin_inset Formula $A^{C}\cap B$
\end_inset

 are subsets of 
\begin_inset Formula $A\Delta B$
\end_inset

, they are also null sets and belong to 
\begin_inset Formula $\mathcal{F}$
\end_inset

.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu(A) & =\mu(A\cap(B\cup B^{C}))\\
 & =\mu(A\cap B)+\mu(A\cap B^{C})\\
 & =\mu(A\cap B)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
And likewise, 
\begin_inset Formula $\mu(B)=\mu(A\cap B)$
\end_inset

.
 Hence, 
\begin_inset Formula $\mu(A)=\mu(B)$
\end_inset

.
\end_layout

\begin_layout Lemma
Let 
\begin_inset Formula $(A_{n})_{n=1}^{\infty}$
\end_inset

, 
\begin_inset Formula $(B_{n})_{n=1}^{\infty}$
\end_inset

 be a sequence of sets.
 The difference of the union of sets is contained in the union of the difference
 of sets.
 We have:
\end_layout

\begin_layout Lemma
\begin_inset Formula 
\begin{align*}
\left(\bigcup_{n\geq1}A_{n}\right)-\left(\bigcup_{n\geq1}B_{n}\right) & \subset\bigcup_{n\geq1}(A_{n}-B_{n})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
A-\left(\bigcup_{n\geq1}B_{n}\right) & =A\bigcap\left(\bigcup_{n\geq1}B_{n}\right)^{C}\\
 & =A\bigcap\left(\bigcap_{n\geq1}B_{n}^{C}\right)\\
 & =\bigcap_{n\geq1}\left(A\cap B_{n}^{C}\right)\\
 & =\bigcap_{n\geq1}(A-B_{n})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Thus,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\left(\bigcup_{n\geq1}A_{n}\right)-\left(\bigcup_{n\geq1}B_{n}\right) & =\left(\bigcup_{n\geq1}A_{n}\right)\bigcap\left(\bigcup_{n\geq1}B_{n}\right)^{C}\\
 & =\left(\bigcup_{m\geq1}A_{m}\right)\bigcap\left(\bigcap_{n\geq1}B_{n}^{C}\right)\\
 & =\bigcup_{m\geq1}\left(A_{m}\cap\left(\bigcap_{n\geq1}B_{n}^{C}\right)\right)\\
 & =\bigcup_{m\geq1}\bigcap_{n\geq1}(A_{m}\cap B_{n}^{C})\\
 & =\bigcup_{m\geq1}\left\{ \bigcap_{n\geq1}(A_{m}-B_{n})\right\} \\
 & \subset\bigcup_{m\geq1}\left\{ A_{m}-B_{m}\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Every open set in 
\begin_inset Formula $\mathbf{R}$
\end_inset

 can be expressed as the union of a countable number of open intervals.
 This ensures that open sets in 
\begin_inset Formula $\mathbf{R}$
\end_inset

 are Lebesgue measurable, since 
\begin_inset Formula $\mathcal{F}$
\end_inset

 contains intervals and is closed under countable unions.
 We can approximate the measure of any 
\begin_inset Formula $A\in\mathcal{F}$
\end_inset

 from the above by the measures of a sequence of open sets containing 
\begin_inset Formula $A$
\end_inset

.
 This is clear from the below result:
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "th:for-each-set-A-there-exists-an-open-set-O-st-length(O)-equals-outer-measure(A)"

\end_inset

(i)For any 
\begin_inset Formula $\epsilon>0$
\end_inset

, 
\begin_inset Formula $A\in\mathbf{R}$
\end_inset

, we can find an open set 
\begin_inset Formula $O$
\end_inset

 such that :
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
A & \subset O,\quad\mu(O)\leq\mu^{\star}(A)+\epsilon
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
Consequently, for any 
\begin_inset Formula $E\in\mathcal{F}$
\end_inset

 we can find an open set 
\begin_inset Formula $O$
\end_inset

 containing 
\begin_inset Formula $E$
\end_inset

 such that 
\begin_inset Formula $\mu(O\setminus E)<\epsilon$
\end_inset

.
\end_layout

\begin_layout Theorem
(ii) For any 
\begin_inset Formula $A\subset\mathbf{R}$
\end_inset

, we can find a sequence of open sets 
\begin_inset Formula $O_{n},$
\end_inset

such that:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
A\subset\bigcap_{n=1}^{\infty}O_{n}, & \quad\mu\left(\bigcap_{n=1}^{\infty}O_{n}\right)=\mu^{\star}(A)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(i) By definition of 
\begin_inset Formula $\mu^{\star}(A)$
\end_inset

 we can find a sequence 
\begin_inset Formula $(I_{n})$
\end_inset

 of intervals with 
\begin_inset Formula $A\subset\bigcup_{n=1}^{\infty}I_{n}$
\end_inset

 and 
\begin_inset Formula $\sum_{n=1}^{\infty}l(I_{n})\leq\mu^{\star}(A)+\epsilon/2$
\end_inset

.
 That is, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\exists(I_{n})_{n=1}^{\infty},\quad A\subset\bigcup_{n}I_{n},\quad\sum_{n=1}^{\infty}l(I_{n})-\frac{\epsilon}{2}\leq\mu^{\star}(A)
\]

\end_inset


\end_layout

\begin_layout Proof
Each 
\begin_inset Formula $I_{n}$
\end_inset

 is contained in an open interval whose length is very close to that of
 
\begin_inset Formula $I_{n}$
\end_inset

; if the left and right end-points of 
\begin_inset Formula $I_{n}$
\end_inset

 are 
\begin_inset Formula $a_{n}$
\end_inset

 and 
\begin_inset Formula $b_{n}$
\end_inset

 respectively, let 
\begin_inset Formula $J_{n}=\left(a_{n}-\frac{\epsilon}{2^{n+2}},b_{n}+\frac{\epsilon}{2^{n+2}}\right)$
\end_inset

.
 Set 
\begin_inset Formula $O=\bigcup_{n=1}^{\infty}J_{n}$
\end_inset

, which is open.
 Remember, that 
\begin_inset Formula $J_{n}$
\end_inset

's are overlapping.
 Then, 
\begin_inset Formula $A\subset O$
\end_inset

 and 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu(O) & \leq\sum_{n=1}^{\infty}l(J_{n})=\sum_{n=1}^{\infty}l(I_{n})+\frac{\epsilon}{2}\leq\mu^{\star}(A)+\epsilon
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
When 
\begin_inset Formula $\mu(E)<\infty$
\end_inset

 the final statement follows at once from (ii) in proposition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:properties-of-lebesgue-measure"
plural "false"
caps "false"
noprefix "false"

\end_inset

, since 
\begin_inset Formula $\mu(O\setminus E)=\mu(O)-\mu(E)\leq\epsilon$
\end_inset

.
\end_layout

\begin_layout Proof
When 
\begin_inset Formula $\mu(E)=\infty$
\end_inset

 we first write 
\begin_inset Formula $\mathbf{R}$
\end_inset

 as the countable union of the finite intervals: 
\begin_inset Formula $\mathbf{R}=\bigcup_{n}(-n,n)$
\end_inset

.
 Now, 
\begin_inset Formula $E_{n}=E\cap(-n,n)$
\end_inset

 has finite measure, so we can find an open set 
\begin_inset Formula $O_{n}\supset E_{n}$
\end_inset

 with 
\begin_inset Formula $\mu(O_{n}\setminus E_{n})\leq\frac{\epsilon}{2^{n}}$
\end_inset

.
 The set 
\begin_inset Formula $O=\bigcup_{n}O_{n}$
\end_inset

 is open and contains 
\begin_inset Formula $E$
\end_inset

.
 Now,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
O\setminus E & =\left(\bigcup_{n}O_{n}\right)\setminus\left(\bigcup_{n}E_{n}\right)\\
 & \subset\bigcup_{n}(O_{n}\setminus E_{n})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
so that 
\begin_inset Formula $\mu(O\setminus E)\leq\sum_{n}\mu(O_{n}\setminus E_{n})\leq\epsilon$
\end_inset

.
\end_layout

\begin_layout Proof
(ii) In (i) use 
\begin_inset Formula $\epsilon=\frac{1}{n}$
\end_inset

 and let 
\begin_inset Formula $O_{n}$
\end_inset

 be the open set so obtained.
 With 
\begin_inset Formula $E=\bigcap_{n}O_{n}$
\end_inset

 we obtain a measurable set containing 
\begin_inset Formula $A$
\end_inset

 such that 
\begin_inset Formula $\mu(E)<\mu(O_{n})\leq\mu^{\star}(A)+\frac{1}{n}$
\end_inset

 for each 
\begin_inset Formula $n$
\end_inset

, hence the result follows.
 
\end_layout

\begin_layout Remark*
Theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:for-each-set-A-there-exists-an-open-set-O-st-length(O)-equals-outer-measure(A)"
plural "false"
caps "false"
noprefix "false"

\end_inset

 shows how the freedom of movement allowed by the closure properties of
 the sigma-field 
\begin_inset Formula $\mathcal{F}$
\end_inset

 can be exploited by producing, for any set 
\begin_inset Formula $A\subset\mathbf{R}$
\end_inset

, a measurable set 
\begin_inset Formula $O\supset A$
\end_inset

 which is obtained from open intervals using two operations and whose measure(le
ngth) equals the outer measure of 
\begin_inset Formula $A$
\end_inset

.
\end_layout

\begin_layout Theorem
(Continuity Property of the Lebesgue measure) 
\begin_inset CommandInset label
LatexCommand label
name "th:continuity-property-of-lebesgue-measure"

\end_inset

 The Lebesgue measure 
\begin_inset Formula $\mu$
\end_inset

 preserves limits.
\end_layout

\begin_layout Theorem
(1) Suppose that 
\begin_inset Formula $(A_{n})_{n=1}^{\infty}$
\end_inset

 is a sequence of measurable sets in 
\begin_inset Formula $\mathcal{F}$
\end_inset

.
 Then, we have:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{equation}
\lim_{m\to\infty}\mu\left(\bigcup_{i=1}^{m}A_{i}\right)=\mu\left(\lim_{m\to\infty}\bigcup_{i=1}^{m}A_{i}\right)=\mu\left(\bigcup_{i=1}^{\infty}A_{i}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Theorem
(2) If 
\begin_inset Formula $A_{n}\subset A_{n+1}$
\end_inset

 is a monotonically increasing sequence of sets in 
\begin_inset Formula $\mathcal{F}$
\end_inset

, then we have:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{equation}
\lim_{m\to\infty}\mu(A_{m})=\mu\left(\bigcup_{m=1}^{\infty}A_{m}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Theorem
(3) If 
\begin_inset Formula $A_{n}\supset A_{n+1}$
\end_inset

 is a monotonically decreasing sequence of sets in 
\begin_inset Formula $\mathcal{F}$
\end_inset

, then we have:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{equation}
\lim_{m\to\infty}\mu(A_{m})=\mu\left(\bigcap_{m=1}^{\infty}A_{m}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
(1) Define a new family of sets 
\begin_inset Formula $B_{1}=A_{1}$
\end_inset

, 
\begin_inset Formula $B_{2}=A_{2}\setminus A_{1}$
\end_inset

, 
\begin_inset Formula $\ldots$
\end_inset

, 
\begin_inset Formula $B_{n}=A_{n}\setminus\bigcup_{n=1}^{\infty}A_{i}$
\end_inset

 and so forth.
 Then, we make the following claims:
\end_layout

\begin_layout Proof
Claim I.
\begin_inset Formula $B_{i}\cap B_{j}=\emptyset$
\end_inset

, for all 
\begin_inset Formula $i\neq j$
\end_inset

.
\end_layout

\begin_layout Proof
We proceed by contradiction.
 Let 
\begin_inset Formula $m<n$
\end_inset

.
 Assume that there exists an element 
\begin_inset Formula $x\in B_{m}\cap B_{n}$
\end_inset

.
 It follows that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
x\in(B_{m}\cap B_{n}) & \Longleftrightarrow(x\in B_{m})\land(x\in B_{n})\\
 & \Longleftrightarrow\left(x\in\left(A_{m}\setminus\bigcup_{i=1}^{m-1}A_{i}\right)\right)\land\left(x\in\left(A_{n}\setminus\bigcup_{j=1}^{n-1}A_{j}\right)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
In words, 
\begin_inset Formula $x$
\end_inset

 belongs to both 
\begin_inset Formula $A_{m}$
\end_inset

 and the set 
\begin_inset Formula $\left(\bigcup_{j=1}^{n-1}A_{j}\right)^{C}$
\end_inset

.
 Since, 
\begin_inset Formula $m,n\in\mathbf{Z}_{+}$
\end_inset

, and 
\begin_inset Formula $m<n$
\end_inset

, we must have 
\begin_inset Formula $m\leq n-1$
\end_inset

.
 If 
\begin_inset Formula $x\in A_{m}$
\end_inset

, then it must belong to 
\begin_inset Formula $\bigcup_{j=1}^{n-1}A_{j}$
\end_inset

.
 This is a contradiction.
 Hence, our initial assumption is false.
 
\begin_inset Formula $B_{m}\cap B_{n}$
\end_inset

 is disjoint.
 
\end_layout

\begin_layout Proof
Claim II.
 
\begin_inset Formula $\bigcup_{i=1}^{\infty}A_{i}=\bigcup_{i=1}^{\infty}B_{i}$
\end_inset

.
\end_layout

\begin_layout Proof
We proceed by mathematical induction.
 The claim is vacuously true for 
\begin_inset Formula $n=1$
\end_inset

, since 
\begin_inset Formula $B_{1}=A_{1}$
\end_inset

 by construction.
 For 
\begin_inset Formula $n=2$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
A_{1}\cup A_{2} & =(A_{2}\cup A_{1})\cap(A_{1}\cup A_{1}^{C})\\
 & =((A_{2}\cup A_{1})\cap A_{1})\cup((A_{2}\cup A_{1})\cap A_{1}^{C})\\
 & =A_{1}\cup((A_{2}\cap A_{1}^{C})\cup\emptyset)\\
 & =A_{1}\cup(A_{2}\setminus A_{1})\\
 & =B_{1}\cup B_{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Assume that the claim is true for 
\begin_inset Formula $n-1$
\end_inset

.
 Define 
\begin_inset Formula $S=\left(\bigcup_{i=1}^{n-1}A_{i}\right)$
\end_inset

We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\bigcup_{i=1}^{n}A_{i} & =(A_{n}\cup S)\cap\left(S\cup S^{C}\right)\\
 & =S\cup(A_{n}\setminus S)\\
 & =\left(\bigcup_{i=1}^{n-1}A_{i}\right)\bigcup\left(A_{n}\setminus\left(\bigcup_{i=1}^{n-1}A_{i}\right)\right)\\
 & =\left(\bigcup_{i=1}^{n-1}B_{i}\right)\bigcup B_{n}\\
 & \quad\{\text{since the claim holds for }n-1\}\\
 & =\bigcup_{i=1}^{n}B_{i}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Hence, the proposition holds true for all 
\begin_inset Formula $n$
\end_inset

.
 Passing to the limit as 
\begin_inset Formula $n\to\infty$
\end_inset

, we have the desired result.
 This closes the proof.
\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $\{B_{i},i\geq1\}$
\end_inset

 is a disjoint sequence of events, and using the above claims, we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu\left(\bigcup_{i=1}^{\infty}A_{i}\right) & =\mu\left(\bigcup_{i=1}^{\infty}B_{i}\right)\\
 & =\sum_{i=1}^{\infty}\mu(B_{i})\\
 & \quad\left\{ \text{Countable additivity}\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Therefore:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu\left(\bigcup_{i=1}^{\infty}A_{i}\right) & =\sum_{i=1}^{\infty}\mu(B_{i})\\
 & =\lim_{m\to\infty}\sum_{i=1}^{m}\mu(B_{i})\\
 & \quad\begin{array}{c}
\{\text{An infinite series converges to the limit }\\
\text{of the sequence of partial sums.}\}
\end{array}\\
 & =\lim_{m\to\infty}\mu\left(\bigcup_{i=1}^{m}B_{i}\right)\\
 & \quad\{\text{Finite additivity}\}\\
 & =\lim_{m\to\infty}\mu\left(\bigcup_{i=1}^{m}A_{i}\right)\\
 & \quad\left\{ \text{By construction}\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(2) If 
\begin_inset Formula $A_{n}\subset A_{n+1}$
\end_inset

, then 
\begin_inset Formula $\bigcup_{i=1}^{m}A_{i}=A_{m}$
\end_inset

.
 Consequently,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu\left(\bigcup_{i=1}^{\infty}A_{i}\right) & =\lim_{m\to\infty}\mu\left(\bigcup_{i=1}^{m}A_{i}\right)=\lim_{m\to\infty}\mu(A_{m})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(3) If 
\begin_inset Formula $A_{n}\supset A_{n+1}$
\end_inset

, then 
\begin_inset Formula $A_{1}\setminus A_{n}\subset A_{1}\setminus A_{n+1}$
\end_inset

.
 Thus, 
\begin_inset Formula $\{A_{1}\setminus A_{n},n\geq1\}$
\end_inset

 is an increasing sequence of sets.
 From (2), it follows that: 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim_{m\to\infty}\mu(A_{1}\setminus A_{m}) & =\mu\left(\lim_{m\to\infty}\bigcup_{i=1}^{m}A_{1}\setminus A_{i}\right)\\
 & =\mu\left(\lim_{m\to\infty}\bigcup_{i=1}^{m}\left(A_{1}\cap A_{i}^{C}\right)\right)\\
 & =\mu\left(\lim_{m\to\infty}A_{1}\bigcap\left(\bigcup_{i=1}^{m}A_{i}^{C}\right)\right)\\
 & =\mu\left(\lim_{m\to\infty}A_{1}\bigcap\left(\bigcap_{i=1}^{m}A_{i}\right)^{C}\right)\\
\lim_{m\to\infty}\mu(A_{1})-\lim_{m\to\infty}\mu(A_{m}) & =\mu(A_{1})-\mu\left(\lim_{m\to\infty}\bigcap_{i=1}^{m}A_{i}\right)\\
\Longrightarrow\lim_{m\to\infty}\mu(A_{m}) & =\mu\left(\lim_{m\to\infty}\bigcap_{i=1}^{m}A_{i}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Remark*
The proof of theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:continuity-property-of-lebesgue-measure"
plural "false"
caps "false"
noprefix "false"

\end_inset

 simply relies on countable additivity of 
\begin_inset Formula $\mu$
\end_inset

 and on the definition of the sum of an infinite series in 
\begin_inset Formula $[0,\infty]$
\end_inset

, i.e.
 that:
\end_layout

\begin_layout Remark*
\begin_inset Formula 
\begin{align*}
\sum_{i=1}^{\infty}\mu(A_{i}) & =\lim_{n\to\infty}\sum_{i=1}^{n}\mu(A_{i})
\end{align*}

\end_inset


\end_layout

\begin_layout Remark*
Consequently, this result is true not only for the set function 
\begin_inset Formula $\mu$
\end_inset

, but any countably additive set function defined on a sigma-field.
 It also leads us to the following claim, which, though, we consider it
 here only for 
\begin_inset Formula $\mu$
\end_inset

, actually characterizes countably additive set functions.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,0) ellipse (4.0cm and 3.5cm);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,3.1) node {$B_1$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,0) ellipse (3.0cm and 2.5 cm);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,2.1) node {$B_2$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,0) ellipse (2.3cm and 1.8cm);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,1.4) node {$
\backslash
vdots$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=lightgray](0,0) ellipse (1.5cm and 1.0 cm);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,0.7) node {$B_n$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (-1.2,0.0) node {$A_n$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=white](0,0) ellipse (1.0cm and 0.5 cm);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,0.2) node {$B_{n+1}$};
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Figure.
 The sets $B_n$ and $A_n$(light-gray).
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Theorem
The set function 
\begin_inset Formula $\mu$
\end_inset

 satisfies:
\end_layout

\begin_layout Theorem
(1) 
\begin_inset Formula $\mu$
\end_inset

 is finitely additive, that is, for pairwise disjoint sets 
\begin_inset Formula $(A_{i})$
\end_inset

 we have:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
\mu\left(\bigcup_{i=1}^{n}A_{i}\right) & =\sum_{i=1}^{n}\mu(A_{i})
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
for each 
\begin_inset Formula $n$
\end_inset

;
\end_layout

\begin_layout Theorem
(ii) 
\begin_inset Formula $\mu$
\end_inset

 is continuous at 
\begin_inset Formula $\emptyset$
\end_inset

, that is, if 
\begin_inset Formula $(B_{n})$
\end_inset

 decrease to 
\begin_inset Formula $\emptyset$
\end_inset

, 
\begin_inset Formula $\mu(B_{n})$
\end_inset

 decreases to 
\begin_inset Formula $0$
\end_inset

.
\end_layout

\begin_layout Proof
To prove this claim, recall that 
\begin_inset Formula $\mu:\mathcal{F}\to[0,\infty]$
\end_inset

 is countably additive.
 This implies (i), as we have already seen.
 To prove (ii), consider a sequence 
\begin_inset Formula $(B_{n})$
\end_inset

 in 
\begin_inset Formula $\mathcal{F}$
\end_inset

 which decreases to 
\begin_inset Formula $\emptyset$
\end_inset

.
 Then, 
\begin_inset Formula $A_{n}=B_{n}\setminus B_{n+1}$
\end_inset

 defines a disjoint sequence in 
\begin_inset Formula $\mathcal{F}$
\end_inset

 and 
\begin_inset Formula $\bigcup_{n=1}^{\infty}A_{n}=B_{1}$
\end_inset

.
 We may assume that 
\begin_inset Formula $B_{1}$
\end_inset

 is bounded, so that 
\begin_inset Formula $\mu(B_{n})$
\end_inset

 is finite for all 
\begin_inset Formula $n$
\end_inset

, so that, 
\begin_inset Formula $\mu(A_{n})=\mu(B_{n}\setminus B_{n+1})=\mu(B_{n})-\mu(B_{n+1})\geq0$
\end_inset

 and hence we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mu(B_{1}) & =\sum_{n=1}^{\infty}\mu(A_{n})\\
 & =\sum_{n=1}^{\infty}\mu(B_{n})-\mu(B_{n+1})\\
 & =\lim_{n\to\infty}(\mu(B_{1})-\mu(B_{n}))
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
which shows that 
\begin_inset Formula $\lim_{n\to\infty}\mu(B_{n})\to0$
\end_inset

.
\end_layout

\begin_layout Subsection
Borel Sets.
\end_layout

\begin_layout Standard
The definition of 
\begin_inset Formula $\mathcal{F}$
\end_inset

 does not lend itself easily to the verification that a particular set belongs
 to 
\begin_inset Formula $\mathcal{F}$
\end_inset

; in our proofs we have had to work quite hard to show that 
\begin_inset Formula $\mathcal{F}$
\end_inset

 is closed under various operations.
 It is therefore useful to add another construction to our armoury; one
 which shows more directly, how open sets(and indeed open intervals) and
 the structure of sigma-fields lie at the heart of many of the concepts
 we have developed.
 We begin with an auxiliary construction enabling us to produce new sigma-fields.
\end_layout

\begin_layout Theorem
The intersection of a family of 
\begin_inset Formula $\sigma$
\end_inset

-fields is a 
\begin_inset Formula $\sigma$
\end_inset

-field.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $\mathcal{F}_{\alpha}$
\end_inset

 be 
\begin_inset Formula $\sigma$
\end_inset

-fields for 
\begin_inset Formula $\alpha\in\Lambda$
\end_inset

 (the index set 
\begin_inset Formula $\Lambda$
\end_inset

 can be arbitrary).
 Put 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathcal{F} & =\bigcap_{\alpha\in\Lambda}\mathcal{F}_{\alpha}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We verify the conditions of the definition.
 
\end_layout

\begin_layout Proof
1.
 
\begin_inset Formula $\mathbf{R}\in\mathcal{F}_{\alpha}$
\end_inset

 for all 
\begin_inset Formula $\alpha\in\Lambda$
\end_inset

 so 
\begin_inset Formula $\mathbf{R}\in\mathcal{F}$
\end_inset

.
\end_layout

\begin_layout Proof
2.
 If 
\begin_inset Formula $E\in\mathcal{F}$
\end_inset

, then 
\begin_inset Formula $E\in\mathcal{F}_{\alpha}$
\end_inset

 for all 
\begin_inset Formula $\alpha\in\Lambda$
\end_inset

.
 Since 
\begin_inset Formula $\mathcal{F}_{\alpha}$
\end_inset

 is a 
\begin_inset Formula $\sigma$
\end_inset

-field, it is closed under complementation, so 
\begin_inset Formula $E^{C}$
\end_inset

 belongs to 
\begin_inset Formula $\mathcal{F}_{\alpha}$
\end_inset

 for all 
\begin_inset Formula $\alpha\in\Lambda$
\end_inset

.
 Hence, 
\begin_inset Formula $E^{C}\in\mathcal{F}$
\end_inset

.
\end_layout

\begin_layout Proof
3.
 If 
\begin_inset Formula $E_{k}$
\end_inset

 belongs to 
\begin_inset Formula $\mathcal{F}$
\end_inset

 for 
\begin_inset Formula $k=1,2,3,\ldots$
\end_inset

, then 
\begin_inset Formula $E_{k}\in\mathcal{F}_{\alpha}$
\end_inset

 for all 
\begin_inset Formula $\alpha$
\end_inset

, 
\begin_inset Formula $k$
\end_inset

 hence, 
\begin_inset Formula $\bigcup_{k=1}^{\infty}E_{k}\in\mathcal{F}_{\alpha}$
\end_inset

 for all 
\begin_inset Formula $\alpha$
\end_inset

 and so 
\begin_inset Formula $\bigcup_{k=1}^{\infty}E_{k}\in\mathcal{F}$
\end_inset

.
\end_layout

\begin_layout Definition
Put 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{equation}
\mathcal{B}=\bigcap\left\{ \mathcal{F}:\mathcal{F}\text{ is a sigma-field containing all intervals}\right\} 
\end{equation}

\end_inset


\end_layout

\begin_layout Definition
We say that 
\begin_inset Formula $\mathcal{B}$
\end_inset

 is the 
\begin_inset Formula $\sigma$
\end_inset

-field generated by all the intervals and we call the elements of 
\begin_inset Formula $\mathcal{B}$
\end_inset

 - 
\emph on
Borel sets 
\emph default
(after Emile Borel 1871-1956).
 It is obviously the smallest 
\begin_inset Formula $\sigma$
\end_inset

-field containing all the intervals.
 In general, we say that 
\begin_inset Formula $\mathcal{G}$
\end_inset

 is the 
\begin_inset Formula $\sigma$
\end_inset

-field generated by a family of sets 
\begin_inset Formula $\mathcal{A}$
\end_inset

 if 
\begin_inset Formula $\mathcal{G}=\bigcap\{\mathcal{F}:\mathcal{F}\text{ is a sigma-field such that }\mathcal{F}\supset A\}$
\end_inset

.
\end_layout

\begin_layout Example
(Borel Sets) The following examples illustrate how the closure properties
 of the 
\begin_inset Formula $\sigma$
\end_inset

-field 
\begin_inset Formula $\mathcal{B}$
\end_inset

 may be used to verify that most familiar sets in 
\begin_inset Formula $\mathbf{R}$
\end_inset

 belong to 
\begin_inset Formula $\mathcal{B}$
\end_inset

.
 
\end_layout

\begin_layout Example
(1) By construction, all intervals belong to 
\begin_inset Formula $\mathcal{B}$
\end_inset

 and since 
\begin_inset Formula $\mathcal{B}$
\end_inset

 is a 
\begin_inset Formula $\sigma$
\end_inset

-field, all open sets must belong to 
\begin_inset Formula $\mathcal{B}$
\end_inset

, as any open set is the countable union of open intervals.
\end_layout

\begin_layout Example
(2) Countable sets are Borel sets, since each set is a countable union of
 closed intervals of the form 
\begin_inset Formula $[a,a]$
\end_inset

 ; in particular 
\begin_inset Formula $\mathbf{N}$
\end_inset

 and 
\begin_inset Formula $\mathbf{Q}$
\end_inset

 are Borel sets.
 Since, 
\begin_inset Formula $\mathcal{B}$
\end_inset

 is a 
\begin_inset Formula $\sigma$
\end_inset

-field, it is closed under complementation.
 So, 
\begin_inset Formula $\mathbf{R}\setminus\mathbf{Q}$
\end_inset

 - the set of irrational numbers belongs to 
\begin_inset Formula $\mathcal{B}$
\end_inset

 and it is a borel set.
 Similarly, finite sets are also Borel sets.
 
\end_layout

\begin_layout Standard
The definition of 
\begin_inset Formula $\mathcal{B}$
\end_inset

 is also very flexible - as long as we start will all intervals of a particular
 type, these collections generate the same Borel 
\begin_inset Formula $\sigma$
\end_inset

-field:
\end_layout

\begin_layout Theorem
If instead of all intervals, we take all open intervals, all closed intervals,
 all intervals of the form 
\begin_inset Formula $(a,\infty)$
\end_inset

 (or of the form 
\begin_inset Formula $[a,\infty)$
\end_inset

, 
\begin_inset Formula $(-\infty,b)$
\end_inset

 or 
\begin_inset Formula $(-\infty,b]$
\end_inset

), all open sets, or all closed sets, then the 
\begin_inset Formula $\sigma$
\end_inset

-field generated by them is the same as 
\begin_inset Formula $\mathcal{B}$
\end_inset

.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $I$
\end_inset

 be the set of all intervals and 
\begin_inset Formula $O$
\end_inset

 be the set of all open intervals.
 Consider for example the 
\begin_inset Formula $\sigma$
\end_inset

-field generated by the family of open intervals 
\begin_inset Formula $O$
\end_inset

 and denote it by 
\begin_inset Formula $\mathcal{C}$
\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathcal{C} & =\bigcap\{\mathcal{F}\supset O,\mathcal{F}\text{is a sigma-field}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We have to show that 
\begin_inset Formula $\mathcal{B}=\mathcal{C}$
\end_inset

.
 Since open intervals are intervals, 
\begin_inset Formula $O\subset I$
\end_inset

 (the family of all intervals), then :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\{\mathcal{F}\supset I\} & \subset\{\mathcal{F}\supset O\}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
that is the collection of all 
\begin_inset Formula $\sigma$
\end_inset

-fields 
\begin_inset Formula $\mathcal{F}$
\end_inset

 which contain 
\begin_inset Formula $I$
\end_inset

 is smaller than the collection of all 
\begin_inset Formula $\sigma$
\end_inset

-fields which contain the smaller family 
\begin_inset Formula $O$
\end_inset

, since it is a more demanding requirement to contain a bigger family, so
 there are fewer such objects.
 The inclusion is reversed after we take the intersection on both sides,
 thus 
\begin_inset Formula $\mathcal{C}\subset\mathcal{B}$
\end_inset

 (the intersection of a smaller family is bigger, as the requirement of
 belong to each of its members is a less stringent one).
 
\end_layout

\begin_layout Proof
We shall show that 
\begin_inset Formula $\mathcal{C}$
\end_inset

 contains all the intervals.
 This will be sufficient, since 
\begin_inset Formula $\mathcal{B}$
\end_inset

 is the intersection of such 
\begin_inset Formula $\sigma$
\end_inset

-fields, so it is contained in each, and therefore 
\begin_inset Formula $\mathcal{B}\subset\mathcal{C}$
\end_inset

.
\end_layout

\begin_layout Proof
To this end, consider the intervals 
\begin_inset Formula $[a,b)$
\end_inset

, 
\begin_inset Formula $[a,b]$
\end_inset

, 
\begin_inset Formula $(a,b)$
\end_inset

 (the intervals of the form 
\begin_inset Formula $(a,b)$
\end_inset

 are in 
\begin_inset Formula $\mathcal{C}$
\end_inset

 by definition):
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
[a,b) & =\bigcap_{n=1}^{\infty}\left(a-\frac{1}{n},b\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
[a,b] & =\bigcap_{n=1}^{\infty}\left(a-\frac{1}{n},b+\frac{1}{n}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
(a,b] & =\bigcap_{n=1}^{\infty}\left(a,b+\frac{1}{n}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
\begin_inset Formula $\mathcal{C}$
\end_inset

 as a 
\begin_inset Formula $\sigma$
\end_inset

-field is closed with respect to countable intersection, so it contains
 the sets on the right.
 The argument for unbounded intervals is similar:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
(a,\infty) & =\bigcup_{n=1}^{\infty}(a,n)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
and 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
(-\infty,b) & =\bigcup_{n=1}^{\infty}(-n,b)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The proof is complete.
 
\end_layout

\begin_layout Remark*
Since 
\begin_inset Formula $\mathcal{F}$
\end_inset

 is a 
\begin_inset Formula $\sigma$
\end_inset

-field containing all the intervals, and 
\begin_inset Formula $\mathcal{B}$
\end_inset

 is the smallest such 
\begin_inset Formula $\sigma$
\end_inset

-field, we have the inclusion 
\begin_inset Formula $\mathcal{B}\subset\mathcal{F}$
\end_inset

, that is every Borel set in 
\begin_inset Formula $\mathbf{R}$
\end_inset

 is Lebesgue measurable.
 The question therefore arises whether these 
\begin_inset Formula $\sigma$
\end_inset

-fields might be the same.
 In fact, the inclusion is proper.
 It is not altogether straightforward to construct a set in 
\begin_inset Formula $\mathcal{F}\setminus\mathcal{B}$
\end_inset

.
 However, by theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "th:for-each-set-A-there-exists-an-open-set-O-st-length(O)-equals-outer-measure(A)"
plural "false"
caps "false"
noprefix "false"

\end_inset

 (ii), given any 
\begin_inset Formula $E\in\mathcal{F}$
\end_inset

, we can find a Borel set 
\begin_inset Formula $B\supset E$
\end_inset

 of the form 
\begin_inset Formula $B=\bigcap_{n}O_{n}$
\end_inset

, where the 
\begin_inset Formula $O_{n}$
\end_inset

 are open sets, such that 
\begin_inset Formula $\mu(E)=\mu(B)$
\end_inset

.
 In particular, 
\end_layout

\begin_layout Remark*
\begin_inset Formula 
\begin{align*}
\mu(B\Delta E) & =\mu(B\setminus E)=0
\end{align*}

\end_inset


\end_layout

\begin_layout Remark*
Hence, 
\begin_inset Formula $\mu$
\end_inset

 cannot distinguish between the measurable set 
\begin_inset Formula $E$
\end_inset

 and the Borel set 
\begin_inset Formula $B$
\end_inset

 we have constructed.
 
\end_layout

\begin_layout Standard
Thus, given a Lebesgue measurable set 
\begin_inset Formula $E$
\end_inset

 we can find a Borel set 
\begin_inset Formula $B$
\end_inset

 such that their symmetric difference 
\begin_inset Formula $E\Delta B$
\end_inset

 is a null set.
 Now, we know that 
\begin_inset Formula $E\Delta B\in\mathcal{F}$
\end_inset

, and it is obvious that subsets of null sets are also null, and hence in
 
\begin_inset Formula $\mathcal{F}$
\end_inset

.
 However, we cannot conclude that every null set will be a Borel set (if
 
\begin_inset Formula $\mathcal{B}$
\end_inset

 did contain all the null sets then by theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "th:for-each-set-A-there-exists-an-open-set-O-st-length(O)-equals-outer-measure(A)"
plural "false"
caps "false"
noprefix "false"

\end_inset

 (ii), we should have 
\end_layout

\begin_layout Section
Expectation.
\end_layout

\begin_layout Standard
The goal of this section is to define the expectation of random variables
 and establish it's basic properties.
 
\end_layout

\begin_layout Subsection
Lebesgue-measurable functions.
\end_layout

\begin_layout Standard
Integration is concerned with the process of approximation.
 In the Riemann integral, we split the interval 
\begin_inset Formula $I=[a,b]$
\end_inset

 over which we integrate into a partition 
\begin_inset Formula $\{x_{0}=a<x_{1}<x_{2}<\ldots<x_{n}=b\}$
\end_inset

.
 Define 
\begin_inset Formula $I_{n}:=[x_{n-1},x_{n}]$
\end_inset

.
 Then, we construct approximating sums by multiplying the lengths of small
 subintervals by certain numbers 
\begin_inset Formula $a_{n}$
\end_inset

 (related to the values of the function in question; for example 
\begin_inset Formula $a_{n}=\sup_{I_{n}}f(x)$
\end_inset

, 
\begin_inset Formula $a_{n}=\inf_{I_{n}}f(x)$
\end_inset

):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\sum_{n=1}^{\infty}a_{n}l(I_{n})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
For large 
\begin_inset Formula $n$
\end_inset

, this sum is close to the Riemann integral 
\begin_inset Formula $\int_{a}^{b}f(x)dx$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}
\end_layout

\begin_layout Plain Layout

	
\backslash
draw[lightgray,thin] (0,0) grid (8,5);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw[->,thick] (0,0)--(8,0) node[right]{$x$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw[->,thick] (0,0)--(0,5) node[above]{$y$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,3) ..
 controls (3,8) and (7,-1) ..
 (8,5);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw [fill=lightgray,draw=black] (0,0) rectangle (1,3); 
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw [fill=lightgray,draw=black] (1,0) rectangle (2,4.1);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw [fill=lightgray,draw=black] (2,0) rectangle (3,4.4);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw [fill=lightgray,draw=black] (3,0) rectangle (4,4.0);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw [fill=lightgray,draw=black] (4,0) rectangle (5,3.5);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw [fill=lightgray,draw=black] (5,0) rectangle (6,3.0);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw [fill=lightgray,draw=black] (6,0) rectangle (7,2.8);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw [fill=lightgray,draw=black] (7,0) rectangle (8,2.9);
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Figure.
 Riemann sums.
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The approach to the Lebesgue integral is similar but there is a crucial
 difference.
 Instead of splitting the integration domain into various parts, we decompose
 the range of the function.
 Again, a simple way is to introduce short intervals 
\begin_inset Formula $J_{n}$
\end_inset

 of equal length.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}
\end_layout

\begin_layout Plain Layout

	
\backslash
draw[lightgray,thin] (0,0) grid (8,5);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw[->,thick] (0,0)--(8,0) node[right]{$x$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw[->,thick] (0,0)--(0,5) node[above]{$y$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,3) ..
 controls (3,8) and (7,-1) ..
 (8,5);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw [fill=magenta] (0,0) rectangle (0.8,3.0); 
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw [fill=blue]    (0.8,0) rectangle (4.0,4.0); 
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw [fill=magenta] (4,0) rectangle (6.0,3.0); 
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw [fill=green]    (6,0) rectangle (7.2,2.0);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw [fill=magenta] (7.2,0) rectangle (7.8,3.0); 
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw [fill=blue]    (7.8,0) rectangle (8.0,4.0); 
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0.3,0) node [below] {$f^{-1}(J_4)$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (2.5,0) node [below] {$f^{-1}(J_5)$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (5,0) node [below] {$f^{-1}(J_4)$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (6.5,0) node [below] {$f^{-1}(J_3)$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,0.5) node [left] {$J_1$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,1.5) node [left] {$J_2$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,2.5) node [left] {$J_3$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,3.5) node [left] {$J_4$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,4.5) node [left] {$J_5$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,1.0) node [right] {$y_1$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,2.0) node [right] {$y_2$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,3.0) node [right] {$y_3$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,4.0) node [right] {$y_4$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,5.0) node [right] {$y_5$};
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Figure.
 Lebesgue sums.
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
To build the approximating sums, we first take the inverse images of 
\begin_inset Formula $J_{n}$
\end_inset

 by 
\begin_inset Formula $f$
\end_inset

, that is by 
\begin_inset Formula $f^{-1}(J_{n})$
\end_inset

.
 These may be complicated sets, not necessarily intervals.
 Here the theory of measure developed previously comes into its own.
 We are able to measure sets provided they are measurable i.e.
 they are in 
\begin_inset Formula $\mathcal{F}$
\end_inset

.
 Given that, we compute:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\sum_{n=1}^{N}a_{n}\mu(f^{-1}(J_{n}))
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $a_{n}\in J_{n}$
\end_inset

 or 
\begin_inset Formula $a_{n}=\inf J_{n}=y_{n-1}$
\end_inset

 for example.
 The following definition guarantees that the above procedure makes sense.
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:measurable-function"

\end_inset

Suppose that 
\begin_inset Formula $E$
\end_inset

 is a measurable set.
 We say that a function 
\begin_inset Formula $f:E\to\mathbf{R}$
\end_inset

 is (
\emph on
Lebesgue)
\emph default
-measurable if for any interval 
\begin_inset Formula $I\subseteq\mathbf{R}$
\end_inset


\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
f^{-1}(I)=\{x\in\mathbf{R}:f(x)\in I\}\in\mathcal{F}
\]

\end_inset


\end_layout

\begin_layout Standard
In what follows, the term 
\emph on
measurable
\emph default
 (without qualification) will refer to Lebesgue-measurable functions.
\end_layout

\begin_layout Standard
If all the sets 
\begin_inset Formula $f^{-1}(I)\in\mathcal{B}$
\end_inset

, that is, if they are Borel sets, we call 
\begin_inset Formula $f$
\end_inset

 
\emph on
Borel-measurable
\emph default
, or simply a Borel function.
 
\end_layout

\begin_layout Standard
The underlying philosophy is one which is common for various mathematical
 notions : the inverse image of a 
\emph on
nice set
\emph default
 is 
\emph on
nice
\emph default
.
 Remember continous functions, for example, where the inverse image of an
 open set is open.
 The actual meaning of the word nice depends on the particular branch of
 mathematics.
\end_layout

\begin_layout Remark*
The terminology is unfortunate.
 
\emph on
Measurable objects 
\emph default
should be measured (as with measurable sets).
 However, measurable functions will be integrated.
 The confusion here stems from the fact that the word 
\emph on
integrable 
\emph default
which would probably best fit here, carries a more restricted meaning as
 we shall see later.
 
\end_layout

\begin_layout Subsection
Simple Random Variables.
\end_layout

\begin_layout Standard
In the special case of probability spaces we use the phrase 
\emph on
random variable
\emph default
 to mean a measurable function.
 That is, if 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 is a probability space, then 
\begin_inset Formula $X:\Omega\to\mathbf{R}$
\end_inset

 is a random variable if for all 
\begin_inset Formula $x\in\mathbf{R}$
\end_inset

, the set 
\begin_inset Formula $X^{-1}((-\infty,x])$
\end_inset

 is in 
\begin_inset Formula $\mathcal{F}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\{\omega\in\Omega:X(\omega)\leq x\} & \in\mathcal{F}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
A function 
\begin_inset Formula $f:\Omega\to\mathbf{R}$
\end_inset

 is called 
\emph on
simple 
\emph default
if its image 
\begin_inset Formula $f(\Omega)$
\end_inset

 is a finite-set.
 That is, 
\begin_inset Formula $f$
\end_inset

 can be written as a finite linear-combination of indicator functions.
 We can write:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f(\omega)=\sum_{i=1}^{n}a_{i}I_{\omega\in A_{i}}(\omega)
\]

\end_inset


\end_layout

\begin_layout Standard
for all 
\begin_inset Formula $\omega\in\Omega$
\end_inset

, for some distinct 
\begin_inset Formula $a_{1},\ldots,a_{n}\geq0$
\end_inset

 (values) and sets 
\begin_inset Formula $A_{1},\ldots,A_{n}$
\end_inset

 which form a partition of 
\begin_inset Formula $\Omega$
\end_inset

.
\end_layout

\begin_layout Standard
A random variable 
\begin_inset Formula $X:\Omega\to\mathbf{R}$
\end_inset

 is called simple, if its image 
\begin_inset Formula $X(\Omega)$
\end_inset

 takes a finite set of values.
 That is, 
\begin_inset Formula $X$
\end_inset

 can be written as a finite linear-combination of indicator random variables.
 We can write:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X(\omega)=\sum_{i=1}^{n}a_{i}I_{A_{i}}(\omega)
\]

\end_inset


\end_layout

\begin_layout Standard
for all 
\begin_inset Formula $\omega\in\Omega$
\end_inset

, for some distinct 
\begin_inset Formula $a_{1},\ldots,a_{n}\geq0$
\end_inset

 and events 
\begin_inset Formula $A_{1},\ldots,A_{n}$
\end_inset

which form a partition of 
\begin_inset Formula $\Omega$
\end_inset

.
 Note that: 
\begin_inset Formula $X\geq0$
\end_inset

.
 
\end_layout

\begin_layout Standard
The abstract(Lebesgue) integral of a simple function 
\begin_inset Formula $f$
\end_inset

 (with respect to the measure 
\begin_inset Formula $\mu$
\end_inset

), denoted 
\begin_inset Formula $\int fd\mu$
\end_inset

 is defined as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\int fd\mu=\sum_{k=1}^{n}a_{k}\mu(A_{k})
\]

\end_inset


\end_layout

\begin_layout Standard
The 
\series bold
expectation
\series default
 of the simple random variable 
\begin_inset Formula $X$
\end_inset

, denoted by 
\begin_inset Formula $EX$
\end_inset

 is defined as :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\int Xd\mathbb{P}=\mathbb{E}X=\sum_{k=1}^{n}x_{k}\mathbb{P}(A_{k})
\]

\end_inset


\end_layout

\begin_layout Standard
This equates to discretising the 
\begin_inset Formula $y$
\end_inset

-axis.
 
\end_layout

\begin_layout Standard
The expectation of a non-negative random variable 
\begin_inset Formula $X$
\end_inset

 is defined as :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}X & =\sup\{\mathbb{E}Z:Z\text{ is simple and }Z\leq X\}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Note that, we can always take 
\begin_inset Formula $Z=0$
\end_inset

, so that, 
\begin_inset Formula $\mathbb{E}Z=0$
\end_inset

 and therefore 
\begin_inset Formula $\mathbb{E}X$
\end_inset

 is bounded below by 
\begin_inset Formula $0$
\end_inset

.
 That is, 
\begin_inset Formula $\mathbb{E}X\geq0$
\end_inset

.
\end_layout

\begin_layout Standard
The abstract(Lebesgue) integral of a non-negative function 
\begin_inset Formula $f$
\end_inset

 is defined as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\int fd\mu=\sup\{\int qd\mu:q\text{ is simple and }q\leq f\}
\]

\end_inset


\end_layout

\begin_layout Standard
Again, we can always take 
\begin_inset Formula $q=0$
\end_inset

, so that 
\begin_inset Formula $\int qd\mu=0\cdot I_{\Omega}=0$
\end_inset

.
 Therefore, 
\begin_inset Formula $\int fd\mu$
\end_inset

 is bounded below by zero and 
\begin_inset Formula $\int fd\mu\geq0$
\end_inset

.
\end_layout

\begin_layout Standard
For an arbitrary random variable 
\begin_inset Formula $X$
\end_inset

, we can always write :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
X & =X^{+}-X^{-}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $X^{+}=\max\{X,0\}=X\cdot I_{\{X\geq0\}}$
\end_inset

 and 
\begin_inset Formula $X^{-}=\max\{-X,0\}=-X\cdot I_{\{X\leq0\}}$
\end_inset

.
\end_layout

\begin_layout Standard
These are non-negative random variables and the expectation of 
\begin_inset Formula $X$
\end_inset

 is defined as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathbb{E}X=\mathbb{E}X^{+}-\mathbb{E}X^{-}
\]

\end_inset


\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "linearity_of_expectation_of_simple_random_variables"

\end_inset

Let 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 be simple random variables.
 Then, 
\begin_inset Formula $\mathbb{E}(X+Y)=\mathbb{E}X+\mathbb{E}Y$
\end_inset

.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $X=\sum_{k=1}^{m}x_{k}I_{A_{k}}$
\end_inset

 and 
\begin_inset Formula $Y=\sum_{l=1}^{n}y_{l}I_{B_{l}}$
\end_inset

 for some non-negative numbers 
\begin_inset Formula $x_{k},y_{l}$
\end_inset

 and events 
\begin_inset Formula $A_{k}$
\end_inset

 and 
\begin_inset Formula $B_{l}$
\end_inset

 are such that the 
\begin_inset Formula $A_{k}$
\end_inset

 and 
\begin_inset Formula $B_{l}$
\end_inset

 partition 
\begin_inset Formula $\Omega$
\end_inset

.
 Then, the events 
\begin_inset Formula $A_{k}\cap B_{l}$
\end_inset

 partition 
\begin_inset Formula $\Omega$
\end_inset

 and 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}(X+Y) & =\sum_{k\leq m,l\leq n}(x_{k}+y_{l})\mathbb{P}(A_{k}\cap B_{l})\\
 & =\sum_{k\leq m,l\leq n}x_{k}\mathbb{P}(A_{k}\cap B_{l})+\sum_{k\leq m,l\leq n}y_{l}\mathbb{P}(A_{k}\cap B_{l})\\
 & =\sum_{k\leq m}x_{k}\sum_{l\leq n}\mathbb{P}(A_{k}\cap B_{l})+\sum_{l\leq n}y_{l}\sum_{k\leq m}\mathbb{P}(A_{k}\cap B_{l})\\
 & =\sum_{k\leq m}x_{k}(\mathbb{P}(A_{k}\cap B_{1})+\mathbb{P}(A_{k}\cap B_{2})+\ldots+\mathbb{P}(A_{k}\cap B_{n}))\\
 & +\sum_{l\leq n}y_{l}(\mathbb{P}(A_{1}\cap B_{l})+\mathbb{P}(A_{2}\cap B_{l})+\ldots+\mathbb{P}(A_{m}\cap B_{l}))\\
 & =\sum_{k\leq m}x_{k}\mathbb{P}(A_{k})+\sum_{l\leq n}y_{l}\mathbb{P}(B_{l})\\
 & =\mathbb{E}X+\mathbb{E}Y
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Non-negative Random Variables.
\end_layout

\begin_layout Standard
Our main goal is to prove the linearity of expectation.
 We first establish a few basic properties of expectation for non-negative
 random variables.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 be non-negative random variables.
 We have:
\end_layout

\begin_layout Theorem
(a) If 
\begin_inset Formula $A\in\mathcal{F}$
\end_inset

, then 
\begin_inset Formula $\mathbb{E}I_{A}=\int I_{A}\cdot d\mathbb{P}=\mathbb{P}(A)$
\end_inset

.
\end_layout

\begin_layout Theorem
(b) (Monotonicity).
 If 
\begin_inset Formula $X\leq Y$
\end_inset

, then 
\begin_inset Formula $EX\leq EY$
\end_inset

.
\end_layout

\begin_layout Theorem
(c) (Translation and Scaling) For 
\begin_inset Formula $a\geq0$
\end_inset

, 
\begin_inset Formula $\mathbb{E}(a+X)=a+\mathbb{E}X$
\end_inset

 and 
\begin_inset Formula $\mathbb{E}(aX)=a\mathbb{E}X$
\end_inset

.
\end_layout

\begin_layout Theorem
(d) If 
\begin_inset Formula $\mathbb{E}X=0$
\end_inset

, then 
\begin_inset Formula $X=0$
\end_inset

 almost surely (that is 
\begin_inset Formula $\mathbb{P}\{X=0\}=1)$
\end_inset

.
\end_layout

\begin_layout Theorem
(e) If 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 are events such that 
\begin_inset Formula $A\subset B$
\end_inset

, then 
\begin_inset Formula $\mathbb{E}X1_{A}\leq\mathbb{E}X1_{B}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
(a) 
\begin_inset Formula $I_{A}$
\end_inset

is a simple random variable.
 Then, by the definition of the Lebesgue integral, 
\begin_inset Formula $\mathbb{E}I_{A}=\int I_{A}d\mathbb{P}=1\cdot\mathbb{P}(A)$
\end_inset

.
\end_layout

\begin_layout Proof
(b) Let 
\begin_inset Formula $S_{X},S_{Y}$
\end_inset

 be the set of all simple random variables which are less than or equal
 to 
\begin_inset Formula $X,Y$
\end_inset

 respectively.
 Since 
\begin_inset Formula $X\leq Y$
\end_inset

, every simple random variable which is less than or equal to 
\begin_inset Formula $X$
\end_inset

 is also less than or equal 
\begin_inset Formula $Y$
\end_inset

.
 But, there exists simple random variables that are less than or equal to
 
\begin_inset Formula $Y$
\end_inset

 but greater than 
\begin_inset Formula $X$
\end_inset

.
 Consequently, 
\begin_inset Formula $S_{X}\subseteq S_{Y}$
\end_inset

.
 Thus, 
\begin_inset Formula $\{\mathbb{E}Z:\text{Z}\text{ is simple and }Z\leq X\}\subseteq\{\mathbb{E}Z:Z\text{ is simple and }Z\leq Y\}$
\end_inset

.
 Therefore, it follows that 
\begin_inset Formula $\sup\{\mathbb{E}Z:\text{Z}\text{ is simple and }Z\leq X\}\leq\sup\{\mathbb{E}Z:\text{Z}\text{ is simple and }Z\leq Y\}$
\end_inset

.
 Consequently, 
\begin_inset Formula $\mathbb{E}X\leq\mathbb{E}Y$
\end_inset

.
\end_layout

\begin_layout Proof
(c) Let 
\begin_inset Formula $Z$
\end_inset

 be an arbitrary simple random variable which is less than or equal to 
\begin_inset Formula $X$
\end_inset

.
 Then, 
\begin_inset Formula $Z=\sum_{k=1}^{m}x_{k}I_{A_{k}}$
\end_inset

 where 
\begin_inset Formula $x_{k}\geq0$
\end_inset

.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}(a+Z) & =\sum_{k=1}^{m}(a+x_{k})\mathbb{P}(A_{k})\\
 & =a\sum_{k=1}^{m}\mathbb{P}(A_{k})+\sum_{k=1}^{m}x_{k}\mathbb{P}(A_{k})\\
 & =a+\mathbb{E}Z
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Note that, for all simple random variables 
\begin_inset Formula $Z\leq X$
\end_inset

 
\begin_inset Formula $\Longleftrightarrow$
\end_inset


\begin_inset Formula $a+Z\leq a+X$
\end_inset

.
 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}(a+X) & =\sup\{\mathbb{E}(a+Z):a+Z\text{ is a simple random variable and }a+Z\leq a+X\}\\
 & =\sup\{a+\mathbb{E}Z:Z\text{ is a simple random variable and }Z\leq X\}\\
 & =a+\sup\{\mathbb{E}Z:Z\text{ is a simple random variable and }Z\leq X\}\\
 & =a+\mathbb{E}X
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Also, 
\begin_inset Formula 
\begin{align*}
\mathbb{E}(aZ) & =\sum_{k=1}^{m}ax_{k}\mathbb{P}(A_{k})\\
 & =a\sum_{k=1}^{m}x_{k}\mathbb{P}(A_{k})\\
 & =a\mathbb{E}Z
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
\begin_inset Formula $(\forall\text{ simple random variables }Z$
\end_inset

)
\begin_inset Formula $(Z\leq X$
\end_inset

)
\begin_inset Formula $\Longleftrightarrow$
\end_inset


\begin_inset Formula $aZ\leq aX$
\end_inset

.
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}(aX) & =\sup\{\mathbb{E}aZ:aZ\text{ is a simple random variable and }aZ\leq aX\}\\
 & =\sup\{a\mathbb{E}Z:Z\text{ is a simple random variable and }Z\leq X\}\\
 & =a\sup\{\mathbb{E}Z:Z\text{ is a simple random variable and }Z\leq X\}\\
 & =a\mathbb{E}X
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(d) For 
\begin_inset Formula $n\geq1$
\end_inset

, we have 
\begin_inset Formula $X\geq XI_{\{X\geq\frac{1}{n}\}}\geq\frac{1}{n}I_{\{X\geq\frac{1}{n}\}}$
\end_inset

.
 So, by (a) and (b), we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
0=\mathbb{E}X & \geq\frac{1}{n}\mathbb{E}I_{\{X\geq\frac{1}{n}\}}=\frac{1}{n}\mathbb{P}\{X\geq\frac{1}{n}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
But since 
\begin_inset Formula $\mathbb{P}\{X\geq\frac{1}{n}\}\geq0$
\end_inset

, we conclude that 
\begin_inset Formula $\mathbb{P}\{X\geq\frac{1}{n}\}=0$
\end_inset

.
\end_layout

\begin_layout Proof
Now,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}(X>0) & =\mathbb{P}(\bigcup_{n=1}^{\infty}\{X\geq\frac{1}{n}\})=\mathbb{P}(\lim\{X\geq\frac{1}{n}\})=\lim\left(\mathbb{P}\left\{ X\geq\frac{1}{n}\right\} \right)=0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(e) Clearly, if 
\begin_inset Formula $A\subset B$
\end_inset

, then 
\begin_inset Formula $X\cdot I_{A}\leq X\cdot I_{B}$
\end_inset

.
 Thus, by the monotonicity property, 
\begin_inset Formula $\mathbb{E}X1_{A}\leq\mathbb{E}X1_{B}$
\end_inset

.
\end_layout

\begin_layout Standard
The following lemma gives a way to approximate non-negative random variables
 with monotone sequences of simple ones.
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "existence_of_monotonic_sequence"

\end_inset

 If 
\begin_inset Formula $X$
\end_inset

 is a random variable, then there is a sequence 
\begin_inset Formula $(Z_{n})$
\end_inset

 of non-negative simple random variables such that for every 
\begin_inset Formula $\omega\in\Omega$
\end_inset

, 
\begin_inset Formula $Z_{n}(\omega)\leq Z_{n+1}(\omega)$
\end_inset

 and 
\begin_inset Formula $Z_{n}(\omega)\to X(\omega)$
\end_inset

 pointwise.
\end_layout

\begin_layout Proof
For each positive integer 
\begin_inset Formula $n$
\end_inset

, define
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
Z_{n}=\sum_{k=1}^{n\cdot2^{n}}\frac{k-1}{2^{n}}\mathbf{1}_{\{\frac{k-1}{2^{n}}<X<\frac{k}{2^{n}}\}}+n\cdot\mathbf{1}_{\{X\geq n\}}
\]

\end_inset


\end_layout

\begin_layout Proof
Essentially, we are dividing the interval 
\begin_inset Formula $(0,n)$
\end_inset

 on the 
\begin_inset Formula $y-$
\end_inset

axis into 
\begin_inset Formula $n\cdot2^{n}$
\end_inset

 strips, each of size 
\begin_inset Formula $1/2^{n}$
\end_inset

.
 Beyond the point 
\begin_inset Formula $X\geq n$
\end_inset

, 
\begin_inset Formula $Z_{n}$
\end_inset

 takes the constant value 
\begin_inset Formula $n$
\end_inset

.
 
\end_layout

\begin_layout Proof
If 
\begin_inset Formula $n=2$
\end_inset

, this is what 
\begin_inset Formula $Z_{2}(\omega)$
\end_inset

 looks like.
 It chops the interval 
\begin_inset Formula $[0,2]$
\end_inset

 on the 
\begin_inset Formula $Y-$
\end_inset

axis into 
\begin_inset Formula $8$
\end_inset

 sub-intervals.
\end_layout

\begin_layout Proof
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}
\end_layout

\begin_layout Plain Layout

	
\backslash
draw[lightgray,thin,step=0.25] (0,0) grid (10,5);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw[->,thick] (0,0)--(10,0) node[right]{$
\backslash
omega$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw[->,thick] (0,0)--(0,5) node[above]{$X(
\backslash
omega)$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,3) ..
 controls (3,8) and (7,-1) ..
 (10,2);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [blue] (0.00,2.00) -- (6.75,2.00);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [blue] (6.75,1.75) -- (7.25,1.75);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [blue] (7.25,1.50) -- (7.75,1.50);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [blue] (7.75,1.25) -- (9.25,1.25);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [blue] (9.25,1.50) -- (9.75,1.50);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [blue] (9.75,1.75) -- (10.00,1.75);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (0.00,2.00) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (6.75,2.00) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (6.75,1.75) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (7.25,1.75) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (7.25,1.50) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (7.75,1.50) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (7.75,1.25) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (9.25,1.25) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (9.25,1.50) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (9.75,1.50) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (9.75,1.75) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (10.00,1.75) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [blue] (9.50,0.75) node {$Z_2(
\backslash
omega)$};
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Figure.
 The step function $Z_2(
\backslash
omega)$.
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Proof
As 
\begin_inset Formula $n$
\end_inset

 increases, 
\begin_inset Formula $Z_{n}(\omega)$
\end_inset

 better approximates of 
\begin_inset Formula $X(\omega)$
\end_inset

.
 
\end_layout

\begin_layout Proof
Pick any arbitrary 
\begin_inset Formula $\omega\in\Omega$
\end_inset

.
 Let 
\begin_inset Formula $\epsilon>0$
\end_inset

.
\end_layout

\begin_layout Proof
By the Archimedean property, there exists a natural number 
\begin_inset Formula $N_{1}\in\mathbf{N}$
\end_inset

, such that 
\begin_inset Formula $N_{1}>X(\omega)$
\end_inset

.
 
\end_layout

\begin_layout Proof
We have that 
\begin_inset Formula $X(\omega)$
\end_inset

 lies in an interval 
\begin_inset Formula $I_{n}$
\end_inset

, that is 
\begin_inset Formula $\frac{k-1}{2^{n}}<X(\omega)<\frac{k}{2^{n}}$
\end_inset

 for some 
\begin_inset Formula $1\leq k\leq n\cdot2^{n}$
\end_inset

, 
\begin_inset Formula $k\in\mathbf{Z^{+}}$
\end_inset

, for all 
\begin_inset Formula $n\geq N_{1}$
\end_inset

.
 
\end_layout

\begin_layout Proof
There exists 
\begin_inset Formula $N_{2}\in\mathbf{N}$
\end_inset

, such that 
\begin_inset Formula $l(I_{n})=\frac{1}{2^{n}}<\epsilon$
\end_inset

 for all 
\begin_inset Formula $n\geq N_{2}$
\end_inset

.
\end_layout

\begin_layout Proof
Pick 
\begin_inset Formula $N=\max\{N_{1},N_{2}\}$
\end_inset

.
 Then, for all 
\begin_inset Formula $n\geq N$
\end_inset

, 
\begin_inset Formula $|Z_{n}(\omega)-X(\omega)|<\epsilon$
\end_inset

.
\end_layout

\begin_layout Proof
Thus, 
\begin_inset Formula $(Z_{n}(\omega))$
\end_inset

 converges pointwise to 
\begin_inset Formula $X(\omega)$
\end_inset

 for all 
\begin_inset Formula $\omega\in\Omega$
\end_inset

.
\end_layout

\begin_layout Proof
Note that, the partition points at stage 
\begin_inset Formula $(n+1)$
\end_inset

 include the partition points at stage 
\begin_inset Formula $n$
\end_inset

 and new partition points at the mid-points of the old ones.
 Because of this, 
\begin_inset Formula $(Z_{n})$
\end_inset

 is a monotonically increasing sequence.
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lemma:limit-of-expectations-equals-expectation-of-limits-for-positive-simple-rvs"

\end_inset

 If 
\begin_inset Formula $X$
\end_inset

 is a positive random variable, and if 
\begin_inset Formula $(X_{n})_{n=1}^{\infty}$
\end_inset

 is any sequence of positive simple random variables increasing to 
\begin_inset Formula $X$
\end_inset

, then 
\begin_inset Formula $\mathbf{E}[X_{n}]$
\end_inset

 increases to 
\begin_inset Formula $\mathbf{E}[X]$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
Suppose that 
\begin_inset Formula $X\geq0$
\end_inset

 is a random variable and let 
\begin_inset Formula $(X_{n})$
\end_inset

 be a sequence of positive simple random variables, 
\begin_inset Formula $X_{n}\geq0$
\end_inset

 such that 
\begin_inset Formula $X_{n}\uparrow X$
\end_inset

.
 We would like to show that 
\begin_inset Formula $\mathbf{E}X_{n}\rightarrow\mathbf{E}X$
\end_inset

.
 Assume that 
\begin_inset Formula $\mathbf{E}X_{n}\rightarrow a$
\end_inset

.
 We have 
\begin_inset Formula $X_{n}\leq X$
\end_inset

.
 By montonicity of expectations 
\begin_inset Formula $\mathbf{E}X_{n}\leq\mathbf{E}X$
\end_inset

.
 By the order limit theorem, 
\begin_inset Formula $\lim\mathbf{E}X_{n}\leq\mathbf{E}X$
\end_inset

, so 
\begin_inset Formula $a\leq\mathbf{E}X$
\end_inset

.
\end_layout

\begin_layout Proof
We are interested to show that 
\begin_inset Formula $a=\mathbf{E}X$
\end_inset

.
 To prove this, we must show that 
\begin_inset Formula $\mathbf{E}X\leq a$
\end_inset

.
 But, by definition of expectation:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}X & =\sup\left\{ \mathbf{E}Y:Y\text{ is a simple random variable and }0\leq Y\leq X\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Therefore, it is sufficient to prove that if 
\begin_inset Formula $Y$
\end_inset

 is any simple random variable satisfying 
\begin_inset Formula $\mathbf{E}Y\leq a$
\end_inset

, then 
\begin_inset Formula $a$
\end_inset

 is an upper bound for the set 
\begin_inset Formula $\left\{ \mathbf{E}Y:Y\text{ is a simple random variable and }0\leq Y\leq X\right\} $
\end_inset

.
 By the definition of supremum, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}X=\sup\left\{ \mathbf{E}Y:Y\text{ is a simple random variable and }0\leq Y\leq X\right\}  & \leq a
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
To this end, let 
\begin_inset Formula $Y$
\end_inset

 an arbitrary simple random variable satisfying 
\begin_inset Formula $0\leq Y\leq X$
\end_inset

 and suppose it takes on a finite set of values 
\begin_inset Formula $\{a_{1},\ldots,a_{m}\}$
\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
Y & =\sum_{k=1}^{m}a_{k}1_{Y(\omega)=a_{k}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Take 
\begin_inset Formula $A_{k}=\{\omega:Y(\omega)=a_{k}\}$
\end_inset

.
 Let 
\begin_inset Formula $0\leq\epsilon\leq1$
\end_inset

, and consider the random variable (a shifted step function):
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
Y_{n,\epsilon} & =(1-\epsilon)Y\cdot1_{\{(1-\epsilon)Y\leq X_{n}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
Y_{n,\epsilon} & =(1-\epsilon)Y
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
on the set 
\begin_inset Formula $A_{k}\cap\{\omega:(1-\epsilon)Y(\omega)\leq X_{n}(\omega)\}=A_{k,n,\epsilon}$
\end_inset

 and that 
\begin_inset Formula $Y_{n,\epsilon}=0$
\end_inset

 on the set 
\begin_inset Formula $\{\omega:(1-\epsilon)Y(\omega)>X_{n}(\omega)\}$
\end_inset

.
 
\end_layout

\begin_layout Proof
Clearly, 
\begin_inset Formula $Y_{n,\epsilon}\leq X_{n}$
\end_inset

 and so:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}Y_{n,\epsilon} & =\sum_{k=1}^{m}(1-\epsilon)a_{k}\mathbb{P}(A_{k,n,\epsilon})\\
 & =(1-\epsilon)\sum_{k=1}^{m}a_{k}\mathbb{P}(A_{k,n,\epsilon})\\
 & \leq\mathbf{E}X_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We will show that 
\begin_inset Formula $A_{k,n,\epsilon}$
\end_inset

 increases to 
\begin_inset Formula $A_{k}$
\end_inset

.
 Since 
\begin_inset Formula $X_{n}\leq X_{n+1}$
\end_inset

 and 
\begin_inset Formula $X_{n}\uparrow X$
\end_inset

, we conclude that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\{(1-\epsilon)Y(\omega)\leq X_{n}(\omega)\} & \subseteq\{(1-\epsilon)Y(\omega)\leq X_{n+1}(\omega)\}\subseteq\ldots\subseteq\{(1-\epsilon)Y(\omega)\leq X(\omega)\}=\Omega
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
So, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
A_{k}\cap\{(1-\epsilon)Y(\omega)\leq X_{n}(\omega)\}\subseteq A_{k}\cap\{(1-\epsilon)Y(\omega)\subseteq X_{n+1}(\omega)\}\subseteq\ldots\subseteq A_{k}
\]

\end_inset


\end_layout

\begin_layout Proof
That is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
A_{k,n,\epsilon}\subseteq A_{k,n+1,\epsilon}\subseteq\ldots\subseteq A_{k}
\]

\end_inset


\end_layout

\begin_layout Proof
So, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\bigcup_{n=1}^{\infty}A_{k,n,\epsilon} & =A_{k}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By continuity of probability:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim\mathbb{P}(A_{k,n,\epsilon}) & =\mathbb{P}(\lim A_{k,n,\epsilon})=\mathbb{P}(A_{k})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Therefore, taking limits on both sides of the expression:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim\mathbf{E}Y_{n,\epsilon} & =(1-\epsilon)\sum_{k=1}^{m}a_{k}\lim\mathbb{P}(A_{k,n,\epsilon})\\
 & =(1-\epsilon)\sum_{k=1}^{m}a_{k}\mathbb{P}(A_{k})\\
 & =(1-\epsilon)\mathbf{E}Y
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, since 
\begin_inset Formula $\mathbf{E}X_{n}\uparrow a$
\end_inset

, so 
\begin_inset Formula $\mathbf{E}X_{n}\leq a$
\end_inset

.
 And from above 
\begin_inset Formula $\mathbf{E}Y_{n,\epsilon}\leq\mathbf{E}X_{n}$
\end_inset

.
 So:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim\mathbf{E}Y_{n,\epsilon} & \leq\lim\mathbf{E}X_{n}\\
(1-\epsilon)\mathbf{E}Y & \leq a
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Letting 
\begin_inset Formula $\epsilon\to0$
\end_inset

, we have 
\begin_inset Formula $\mathbf{E}Y\leq a$
\end_inset

, which as noted earlier is sufficient to conclude that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}X & \leq a
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Then:
\end_layout

\begin_layout Proof
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}
\end_layout

\begin_layout Plain Layout

	
\backslash
draw[lightgray,thin,step=0.50] (0,0) grid (10,8);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw[->,thick] (0,0)--(10,0) node[right]{$
\backslash
omega$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw[->,thick] (0,0)--(0,8) node[above]{$X(
\backslash
omega)$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw (0,6) ..
 controls (3,8) and (7,-1) ..
 (10,4);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [blue] (0.00,6.00) -- (2.00,6.00);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [lightgray,thick,dashed] (2,6) -- (2,5);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [blue] (2,5) -- (3.5,5);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [lightgray,thick,dashed] (3.5,5) -- (3.5,4);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [blue] (3.5,4) -- (4.7,4);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [lightgray,thick,dashed] (4.7,4) -- (4.7,3);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [blue] (4.7,3) -- (6.2,3);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [lightgray,thick,dashed] (6.2,3) -- (6.2,2);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [blue] (6.2,2) -- (9.2,2);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [lightgray,thick,dashed] (9.2,2) -- (9.2,3);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [blue] (9.2,3) -- (10.00,3);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [red] (0,4.5) -- (4.2,4.5);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [lightgray,thick,dashed] (4.2,4.5) -- (4.2,2.4);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [red] (4.2,2.4) -- (10,2.4);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [magenta] (0,3.5) -- (4.2,3.5);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [lightgray,thick,dashed] (4.2,3.5) -- (4.2,1.4);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [magenta] (4.2,1.4) -- (10,1.4);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (0.00,6.00) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (2.00,6.00) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (2,5) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (3.5,5) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (3.5,4) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (4.7,4) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (4.7,3) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (6.2,3) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (6.2,2) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (9.2,2) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (9.2,3) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=blue] (10.00,3) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [blue] (0.5,5.5) node {$X_n(
\backslash
omega)$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=red] (0,4.5) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=red] (4.2,4.5) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=red] (4.2,2.4) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=red] (10,2.4) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [red] (0.5,4) node {$Y(
\backslash
omega)$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=magenta] (0,3.5) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=magenta] (4.2,3.5) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=magenta] (4.2,1.4) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [fill=magenta] (10,1.4) circle(2pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [magenta] (0.5,3) node {$Y_{n,
\backslash
epsilon}$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [magenta] (0.5,2.5) node {the shifted step function};
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Figure.
 The shifted step function $Y_{n,
\backslash
epsilon}=(1-
\backslash
epsilon)Y 
\backslash
mathbf{1}_{(1-
\backslash
epsilon)Y
\backslash
leq X_n}$.
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "th:monotone-convergence-theorem"

\end_inset

(Monotone Convergence Theorem).
 Let 
\begin_inset Formula $X_{1},X_{2},\ldots,X_{n}$
\end_inset

 be a sequence of non-negative random variables converging increasingly
 to another real valued random variable 
\begin_inset Formula $X$
\end_inset

.
 Meaning, if 
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
X_{n} & \geq0,\quad X_{n}\leq X_{n+1}
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
and 
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
X_{n}\uparrow & X
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
almost surely, then it follows that:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}\mathbb{E}X_{n} & =\mathbb{E}(\lim_{n\to\infty}X_{n})=\mathbb{E}X
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
That is, expectation preserves limits.
\end_layout

\begin_layout Proof
Using lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "existence_of_monotonic_sequence"
plural "false"
caps "false"
noprefix "false"

\end_inset

, for each 
\begin_inset Formula $n$
\end_inset

, we can choose an increasing sequence 
\begin_inset Formula $Y_{n,k}$
\end_inset

, 
\begin_inset Formula $k=1,2,3,\ldots$
\end_inset

 of positive simple random variables increasing to 
\begin_inset Formula $X_{n}$
\end_inset

 and set:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
Z_{k} & =\max_{n\leq k}Y_{n,k}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Essentially, we have these sequences of positive increasing random variables
 
\begin_inset Formula $(Y_{1,k})\to X_{1}$
\end_inset

, 
\begin_inset Formula $(Y_{2,k})\to X_{2}$
\end_inset

, 
\begin_inset Formula $\ldots$
\end_inset

, 
\begin_inset Formula $(Y_{n,k})\to X_{n}$
\end_inset

.
 And now, we construct a sequence 
\begin_inset Formula $(Z_{k})$
\end_inset

 by taking 
\begin_inset Formula $Z_{k}$
\end_inset

 as the maximum of the r.v.'s
\begin_inset Formula $\{Y_{k,1},Y_{k,2},\ldots,Y_{k,k},\}$
\end_inset

.
 Thus, 
\begin_inset Formula $(Z_{k}:k\geq1)$
\end_inset

 is a non-decreasing sequence of positive simple random variables and thus
 it has a limit 
\begin_inset Formula $Z=\lim_{k\to\infty}Z_{k}$
\end_inset

.
 Also,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
Y_{n,k}\leq Z_{k}\leq X_{k}\leq X\quad\text{almost surely }\forall n\leq k
\]

\end_inset


\end_layout

\begin_layout Proof
Hence, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\lim_{k\to\infty}Y_{n,k}\leq Z_{k}\leq X\quad\text{almost surely }
\]

\end_inset


\end_layout

\begin_layout Proof
In other words, by the Squeeze Theorem, 
\begin_inset Formula $\lim Z_{k}=Z$
\end_inset

 exists and
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
X_{n}\leq Z\leq X\quad\text{almost surely}
\]

\end_inset


\end_layout

\begin_layout Proof
Next, if we let 
\begin_inset Formula $n\to\infty$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
X & =Z\quad\text{almost surely}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since the expectation is a positive operator, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\mathbf{E}[Y_{n,k}]\leq\mathbf{E}[Z_{k}]\leq\mathbf{E}[X_{k}]\quad\text{for }n\leq k
\]

\end_inset


\end_layout

\begin_layout Proof
Fix 
\begin_inset Formula $n$
\end_inset

 and let 
\begin_inset Formula $k\to\infty$
\end_inset

.
 Taking limits on both sides of the inequality and using lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lemma:limit-of-expectations-equals-expectation-of-limits-for-positive-simple-rvs"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we obtain:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[X_{n}] & \leq\mathbf{E}[Z_{k}]\leq\lim_{k\to\infty}\mathbf{E}[X_{k}]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, let 
\begin_inset Formula $n\to\infty$
\end_inset

 on both sides to obtain:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\lim_{n\to\infty}\mathbf{E}[X_{n}]\leq\mathbf{E}[Z_{k}]\leq\lim_{k\to\infty}\mathbf{E}[X_{k}]
\]

\end_inset


\end_layout

\begin_layout Proof
By the squeeze theorem, 
\begin_inset Formula $\lim\mathbf{E}[Z_{k}$
\end_inset

] exists and 
\begin_inset Formula $\lim\mathbf{E}[Z_{k}]=\lim\mathbf{E}[X_{n}]$
\end_inset

.
 But, 
\begin_inset Formula $(Z_{k})$
\end_inset

 is a sequence of positive simple random variables and 
\begin_inset Formula $Z_{k}\uparrow X$
\end_inset

.
 So, 
\begin_inset Formula $\mathbf{E}[Z_{k}]\uparrow\mathbf{E}[X]$
\end_inset

.
 Since, 
\begin_inset Formula $\mathbf{E}[X_{n}]\leq\mathbf{E}[X_{n+1}]$
\end_inset

, it follows that 
\begin_inset Formula $\mathbf{E}[X_{n}]\uparrow\mathbf{E}[X]$
\end_inset

.
\end_layout

\begin_layout Proof

\end_layout

\begin_layout Proof
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Theorem
(Linearity of Expectations)
\begin_inset CommandInset label
LatexCommand label
name "(Linearity-of-Expectations)"

\end_inset

 Let 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 be non-negative random variables.
 Then,
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\[
\mathbb{E}(X+Y)=\mathbb{E}X+\mathbb{E}Y
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
By lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "existence_of_monotonic_sequence"
plural "false"
caps "false"
noprefix "false"

\end_inset

, there exists monotonic sequences of non-negative random variables 
\begin_inset Formula $(X_{n})_{n=1}^{\infty}$
\end_inset

 and 
\begin_inset Formula $(Y_{n})_{n=1}^{\infty}$
\end_inset

 such that 
\begin_inset Formula $(X_{n})\to X$
\end_inset

 and 
\begin_inset Formula $(Y_{n})\to Y$
\end_inset

.
 Then, the sequence 
\begin_inset Formula $X_{n}+Y_{n}$
\end_inset

 is also monotone, and by the Algebraic limit theorem for sequences, 
\begin_inset Formula $X_{n}+Y_{n}\to X+Y$
\end_inset

.
 By theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "linearity_of_expectation_of_simple_random_variables"
plural "false"
caps "false"
noprefix "false"

\end_inset

, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\mathbb{E}(X_{n}+Y_{n})=\mathbb{E}X_{n}+\mathbb{E}Y_{n}
\]

\end_inset


\end_layout

\begin_layout Proof
Passing to the limits, we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\lim\mathbb{E}(X_{n}+Y_{n})=\lim\mathbb{E}X_{n}+\lim\mathbb{E}Y_{n}
\]

\end_inset


\end_layout

\begin_layout Proof
By the Monotone convergence theorem, 
\begin_inset Formula $\mathbb{E}$
\end_inset

 preserves limits, so,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\mathbb{E}(X+Y)=\mathbb{E}X+\mathbb{E}Y
\]

\end_inset


\end_layout

\begin_layout Proof
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Subsection
Fatou's Lemma.
\end_layout

\begin_layout Theorem
(Fatou's Lemma)
\begin_inset CommandInset label
LatexCommand label
name "th:Fatou's-lemma"

\end_inset

 Let 
\begin_inset Formula $Y$
\end_inset

 be a random variable that satisfies 
\begin_inset Formula $\mathbb{E}[|Y|]<\infty.$
\end_inset

 Let 
\begin_inset Formula $(X_{n})_{n=1}^{\infty}$
\end_inset

 be a sequence of random variables.
 Then the following holds:
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $Y\leq X_{n}$
\end_inset

, for all 
\begin_inset Formula $n$
\end_inset

, then 
\begin_inset Formula $\mathbb{E}\left[\liminf_{n\to\infty}X_{n}\right]\leq\liminf_{n\to\infty}\mathbb{E}\left[X_{n}\right]$
\end_inset

.
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $Y\geq X_{n}$
\end_inset

, for all 
\begin_inset Formula $n$
\end_inset

, then 
\begin_inset Formula $\mathbb{E}\left[\limsup_{n\to\infty}X_{n}\right]\geq\limsup_{n\to\infty}\mathbb{E}\left[X_{n}\right]$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
Firstly, if 
\begin_inset Formula $X_{n}\geq Y$
\end_inset

, that is, 
\begin_inset Formula $(X_{1},X_{2},X_{3},\ldots)$
\end_inset

 is any sequence of random variables bounded below, analogous to a sequence
 of real numbers, the point-wise limit,
\begin_inset Formula $\liminf_{n\to\infty}X_{n}$
\end_inset

 always exists and therefore 
\begin_inset Formula $\liminf$
\end_inset

 random variable is defined.
 Similarly, if 
\begin_inset Formula $X_{n}\leq Y$
\end_inset

, that is, 
\begin_inset Formula $(X_{1},X_{2},X_{3},\ldots)$
\end_inset

 is any sequence of random variables bounded above, then 
\begin_inset Formula $\limsup_{n\to\infty}X_{n}$
\end_inset

 always exists and therefore 
\begin_inset Formula $\limsup$
\end_inset

 random variable is defined.
\end_layout

\begin_layout Proof
Fix some 
\begin_inset Formula $n\in\mathbf{N}$
\end_inset

.
 From the definition of infimum, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\inf_{k\geq n}X_{k}-Y & \leq X_{m}-Y,\quad\forall m\geq n
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By the monotonicity property, it follows that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[\inf_{k\geq n}X_{k}-Y\right] & \leq\mathbb{E}\left[X_{m}-Y\right]\quad\forall m\geq n
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The left-hand side is a constant real number.
 The right-hand side is indexed by 
\begin_inset Formula $m$
\end_inset

.
 So, this inequality holds for a sequence of real numbers 
\begin_inset Formula $(a_{m})$
\end_inset

, 
\begin_inset Formula $m\geq n$
\end_inset

, where 
\begin_inset Formula $a_{m}=X_{m}(\omega)-Y(\omega)$
\end_inset

.
\end_layout

\begin_layout Proof
Consider the set:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\{a_{m},a_{m+1},a_{m+2},\ldots\}
\]

\end_inset


\end_layout

\begin_layout Proof
This set is bounded below for all 
\begin_inset Formula $m\geq n$
\end_inset

.
 Hence, its infimum exists.
 I can take infimum with respect to 
\begin_inset Formula $m$
\end_inset

, on both sides.
 By the order limit theorem, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\inf_{m\geq n}\mathbb{E}\left[\inf_{k\geq n}X_{k}-Y\right]\leq\inf_{m\geq n}\mathbb{E}\left[X_{m}-Y\right]\quad\forall m\geq n
\]

\end_inset


\end_layout

\begin_layout Proof
Thus, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\mathbb{E}\left[\inf_{k\geq n}X_{k}-Y\right]\leq\inf_{m\geq n}\mathbb{E}\left[X_{m}-Y\right]\quad\forall m\geq n
\]

\end_inset


\end_layout

\begin_layout Proof
Define 
\begin_inset Formula $Z_{n}=\inf_{k\geq n}X_{k}-Y$
\end_inset

 and 
\begin_inset Formula $S_{n}=\inf_{m\geq n}\mathbb{E}\left[X_{m}-Y\right]$
\end_inset

.
 So, we can write:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\mathbb{E}Z_{n}\leq S_{n}
\]

\end_inset


\end_layout

\begin_layout Proof
Passing to the limit as 
\begin_inset Formula $n\to\infty$
\end_inset

, by the Order limit theorem, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\lim_{n\to\infty}\mathbb{E}Z_{n}\leq\lim_{n\to\infty}S_{n}
\]

\end_inset


\end_layout

\begin_layout Proof
Note that, 
\begin_inset Formula $Z_{n}\geq0$
\end_inset

, since 
\begin_inset Formula $X_{k}\geq Y$
\end_inset

.
 And 
\begin_inset Formula $Z_{n}$
\end_inset

 is a sequence of monotonically increasing random variables.
 Thus, 
\begin_inset Formula $\lim Z_{n}$
\end_inset

 exists.
 By the Monotone Convergence theorem,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\lim_{n\to\infty}\mathbb{E}Z_{n}=\mathbb{E}\left[\lim_{n\to\infty}Z_{n}\right]=\mathbb{E}\left[\liminf_{n\to\infty}X_{n}-Y\right]\leq\lim_{n\to\infty}S_{n}=\liminf_{n\to\infty}\mathbb{E}\left[X_{n}-Y\right]
\]

\end_inset


\end_layout

\begin_layout Proof
and so, it follows that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\mathbb{E}\left[\liminf_{n\to\infty}X_{n}\right]\leq\liminf_{n\to\infty}\mathbb{E}\left[X_{n}\right]
\]

\end_inset


\end_layout

\begin_layout Standard
The DCT is an important result which asserts a sufficient condition under
 which we can interchange a limit and expectation.
 
\end_layout

\begin_layout Theorem
(Dominated Convergence Theorem).
 
\begin_inset CommandInset label
LatexCommand label
name "th:dominated-convergence-theorem"

\end_inset

 Consider a sequence of random variables that converges almost surely to
 
\begin_inset Formula $X$
\end_inset

.
 Suppose that there exists a random variable 
\begin_inset Formula $Y$
\end_inset

, such that 
\begin_inset Formula $|X_{n}|\leq Y$
\end_inset

 almost surely for all 
\begin_inset Formula $n$
\end_inset

 and 
\begin_inset Formula $\mathbb{E}[Y]<\infty$
\end_inset

.
 Then, we have:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\[
\lim_{n\to\infty}\mathbb{E}[X_{n}]=\mathbb{E}[X]
\]

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $-Y\leq X_{n}\leq Y$
\end_inset

 for all 
\begin_inset Formula $n\in\mathbf{N}$
\end_inset

, we can invoke both sides of Fatou's Lemma:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\mathbb{E}\left[\liminf_{n\to\infty}X_{n}\right]\leq\liminf_{n\to\infty}\mathbb{E}X_{n}
\]

\end_inset


\end_layout

\begin_layout Proof
and 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\mathbb{E}\left[\limsup_{n\to\infty}X_{n}\right]\geq\limsup_{n\to\infty}\mathbb{E}X_{n}
\]

\end_inset


\end_layout

\begin_layout Proof
Thus,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\mathbb{E}X=\mathbb{E}\left[\liminf_{n\to\infty}X_{n}\right]\leq\liminf_{n\to\infty}\mathbb{E}X_{n}\leq\mathbb{E}X_{n}\leq\limsup_{n\to\infty}\mathbb{E}X_{n}\leq\mathbb{E}\left[\limsup_{n\to\infty n}X_{n}\right]=\mathbb{E}X
\]

\end_inset


\end_layout

\begin_layout Proof
This implies that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\liminf_{n\to\infty}\mathbb{E}X_{n}=\limsup_{n\to\infty}EX_{n}
\]

\end_inset


\end_layout

\begin_layout Proof
so 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\lim_{n\to\infty}\mathbb{E}X_{n}
\]

\end_inset

 exists and further 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\lim_{n\to\infty}\mathbb{E}X_{n}=\mathbb{E}X
\]

\end_inset


\end_layout

\begin_layout Section
Gaussian Processes.
\end_layout

\begin_layout Subsection
Random Vectors.
\end_layout

\begin_layout Standard
Consider a probability space 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 We can define several random variables on 
\begin_inset Formula $\Omega$
\end_inset

.
 A 
\begin_inset Formula $n$
\end_inset

-tuple of random variables on this space is called a random vector.
 For example, if 
\begin_inset Formula $X_{1},X_{2},\ldots,X_{n}$
\end_inset

 are random variables on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

, then the 
\begin_inset Formula $n$
\end_inset

-tuple 
\begin_inset Formula $(X_{1},X_{2},\ldots,X_{n})$
\end_inset

 is a random vector on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 The vector is said to be 
\begin_inset Formula $n$
\end_inset

-dimensional because it contains 
\begin_inset Formula $n$
\end_inset

-variables.
 We will sometimes denote a random vector by 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_layout Standard
A good point of view is to think of a random vector 
\begin_inset Formula $X=(X_{1},\ldots,X_{n})$
\end_inset

 as a random variable (point) in 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

.
 In other words, for an outcome 
\begin_inset Formula $\omega\in\Omega$
\end_inset

, 
\begin_inset Formula $X(\omega)$
\end_inset

 is a point sampled in 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

, where 
\begin_inset Formula $X_{j}(\omega)$
\end_inset

 represents the 
\begin_inset Formula $j$
\end_inset

-th coordinate of the point.
 The distribution of 
\begin_inset Formula $X$
\end_inset

, denoted 
\begin_inset Formula $\mu_{X}$
\end_inset

 is the probability on 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

defined by the events related to the values of 
\begin_inset Formula $X$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathbb{P}\{X\in A\}=\mu_{X}(A)\quad\text{for a subset }A\text{ in }\mathbf{R}^{n}
\]

\end_inset


\end_layout

\begin_layout Standard
In other words, 
\begin_inset Formula $\mathbb{P}(X\in A)=\mu_{X}(A)$
\end_inset

 is the probability that the random point 
\begin_inset Formula $X$
\end_inset

 falls in 
\begin_inset Formula $A$
\end_inset

.
 The distribution of the vector 
\begin_inset Formula $X$
\end_inset

 is also called the joint distribution of 
\begin_inset Formula $(X_{1},\ldots,X_{n})$
\end_inset

.
 
\end_layout

\begin_layout Definition
The 
\series bold
joint distribution function 
\series default
of 
\begin_inset Formula $\mathbf{X}=(X,Y)$
\end_inset

 is the function 
\begin_inset Formula $F:\mathbf{R}^{2}\to[0,1]$
\end_inset

 given by:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{equation}
F_{\mathbf{X}}(x,y)=\mathbb{P}(X\leq x,Y\leq y)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
The joint 
\series bold
PDF
\series default
 
\begin_inset Formula $f_{\mathbf{X}}(x_{1},\ldots,x_{n})$
\end_inset

 of a random vector 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is a function 
\begin_inset Formula $f_{\mathbf{X}}:\mathbf{R}^{n}\to\mathbf{R}$
\end_inset

 such that the probability that 
\begin_inset Formula $X$
\end_inset

 falls in a subset 
\begin_inset Formula $A$
\end_inset

 of 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

 and is expressed as the multiple integral of 
\begin_inset Formula $f(x_{1},x_{2,}\ldots,x_{n})$
\end_inset

 over 
\begin_inset Formula $A$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathbb{P}(X\in A)=\int_{A}f(x_{1},x_{2},\ldots,x_{n})dx_{1}dx_{2}\ldots dx_{n}
\]

\end_inset

 
\end_layout

\begin_layout Standard
Note that: we must have that the integral of 
\begin_inset Formula $f$
\end_inset

 over the whole of 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

 is 
\begin_inset Formula $1$
\end_inset

.
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $F$
\end_inset

 is differentiable at the point 
\begin_inset Formula $(x,y)$
\end_inset

, then we usually specify:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
f(x,y)=\frac{\partial^{2}}{\partial x\partial y}F(x,y)
\end{equation}

\end_inset


\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $(X,Y)$
\end_inset

 be the random variables with joint density function 
\begin_inset Formula $f_{X,Y}(x,y)$
\end_inset

.
 The marginal density function 
\begin_inset Formula $f_{X}(x)$
\end_inset

 and 
\begin_inset Formula $f_{Y}(y)$
\end_inset

 of the random variables 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 respectively is given by:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
f_{X}(x) & =\int_{-\infty}^{+\infty}f_{(X,Y)}(x,y)dy\\
f_{Y}(y) & =\int_{-\infty}^{+\infty}f_{(X,Y)}(x,y)dx
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
F_{X}(x) & =P(X\leq x)\\
 & =\int_{-\infty}^{x}\int_{y=-\infty}^{y=+\infty}f(x,y)dydx
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Differentiating both sides with respect to 
\begin_inset Formula $x$
\end_inset

,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
f_{X}(x) & =\int_{y=-\infty}^{y=+\infty}f(x,y)dydx
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
For continuous random variables 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 with the joint density function 
\begin_inset Formula $f_{(X,Y)}$
\end_inset

, the conditional density of 
\begin_inset Formula $Y$
\end_inset

 given 
\begin_inset Formula $X=x$
\end_inset

 is:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
f_{Y|X}(y|x) & =\frac{f_{(X,Y)}(x,y)}{f_{X}(x)}
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
for all 
\begin_inset Formula $x$
\end_inset

 with 
\begin_inset Formula $f_{X}(x)>0$
\end_inset

.
 This is considered as a function of 
\begin_inset Formula $y$
\end_inset

 for a fixed 
\begin_inset Formula $x$
\end_inset

.
 As a convention, in order to make 
\begin_inset Formula $f_{Y|X}(y|x)$
\end_inset

 well-defined for all real 
\begin_inset Formula $x$
\end_inset

, let 
\begin_inset Formula $f_{Y|X}(y|x)=0$
\end_inset

 for all 
\begin_inset Formula $x$
\end_inset

 with 
\begin_inset Formula $f_{X}(x)=0$
\end_inset

.
\end_layout

\begin_layout Standard
We are essentially slicing the the joint density function of 
\begin_inset Formula $f_{(X,Y)}(x,y)$
\end_inset

 by a thin plane 
\begin_inset Formula $X=x$
\end_inset

.
 How can we speak of conditioning on 
\begin_inset Formula $X=x$
\end_inset

 for 
\begin_inset Formula $X$
\end_inset

 being a continuous random variable, considering that this event has probability
 zero.
 Rigorously speaking, we are actually conditioning on the event that 
\begin_inset Formula $X$
\end_inset

 falls within a small interval containing 
\begin_inset Formula $x$
\end_inset

, say 
\begin_inset Formula $X\in(x-\epsilon,x+\epsilon)$
\end_inset

 and then taking the limit as 
\begin_inset Formula $\epsilon$
\end_inset

 approaches zero from the right.
 
\end_layout

\begin_layout Standard
We can recover the joint PDF 
\begin_inset Formula $f_{(X,Y)}$
\end_inset

 if we have the conditional PDF 
\begin_inset Formula $f_{Y|X}$
\end_inset

 and the corresponding marginal 
\begin_inset Formula $f_{X}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
f_{(X,Y)}(x,y) & =f_{Y|X}(y|x)\cdot f_{X}(x)
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
(Bayes rule and LOTP) 
\begin_inset CommandInset label
LatexCommand label
name "Bayes-rule-and-LOTP"

\end_inset

 Let 
\begin_inset Formula $(X,Y)$
\end_inset

 be continuous random variables.
 We have the following continuous form of the Bayes rule:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{equation}
f_{Y|X}(y|x)=\frac{f_{X|Y}(x|y)\cdot f_{Y}(y)}{f_{X}(x)}
\end{equation}

\end_inset


\end_layout

\begin_layout Theorem
And we have the following continuous form of the law of total probability:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
f_{X}(x) & =\int_{y=-\infty}^{y=+\infty}f_{X|Y}(x|y)\cdot f_{Y}(y)dy
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By the definition of conditional PDFs, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
f_{X|Y}(x|y)\cdot f_{Y}(y) & =f_{(X,Y)}(x,y)=f_{Y|X}(y|x)\cdot f_{X}(x)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Dividing throughout by 
\begin_inset Formula $f_{X}(x)$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
f_{Y|X}(x) & =\frac{f_{X|Y}(x|y)\cdot f_{Y}(y)}{f_{X}(x)}=\frac{f_{(X,Y)}(x,y)}{f_{X}(x)}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "Uniform-on-the-unit-circle-distribution"

\end_inset

(Sampling uniformly in the unit disc).
 Consider the random vector 
\begin_inset Formula $\mathbf{X}=(X,Y)$
\end_inset

 corresponding to a random point chosen uniformly in the unit disc 
\begin_inset Formula $\{(x,y):x^{2}+y^{2}\leq1\}$
\end_inset

.
 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is said to have uniform on the unit circle distribution.
 In this case the PDF is 
\begin_inset Formula $0$
\end_inset

 outside the disc and 
\begin_inset Formula $\frac{1}{\pi}$
\end_inset

 inside the disc:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
f(x,y) & =\frac{1}{\pi}\quad\text{ if }x^{2}+y^{2}\leq1
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The random point 
\begin_inset Formula $(X,Y)$
\end_inset

 has 
\begin_inset Formula $x$
\end_inset

-coordinate 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 coordinate 
\begin_inset Formula $Y$
\end_inset

.
 Each of these are random variables and their PDFs and CDFs can be computed.
 This is a valid PDF, because:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\int\int_{D}f(x,y)dydx & =\int_{-1}^{1}\int_{-\sqrt{1-x^{2}}}^{\sqrt{1-x^{2}}}\frac{1}{\pi}dydx\\
 & =\frac{1}{\pi}\int_{-1}^{1}\left[y\right]_{-\sqrt{1-x^{2}}}^{+\sqrt{1-x^{2}}}dx\\
 & =\frac{2}{\pi}\int_{-1}^{1}\sqrt{1-x^{2}}dx
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Substituting 
\begin_inset Formula $x=\sin\theta$
\end_inset

, we have: 
\begin_inset Formula $dx=\cos\theta d\theta$
\end_inset

 and 
\begin_inset Formula $\sqrt{1-x^{2}}=\cos\theta$
\end_inset

.
 The limits of integration are 
\begin_inset Formula $\theta=-\pi/2$
\end_inset

 to 
\begin_inset Formula $\theta=\pi/2$
\end_inset

.
 Thus,
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\int\int_{D}f(x,y)dydx & =\frac{2}{\pi}\int_{-\pi/2}^{\pi/2}\cos^{2}\theta d\theta\\
 & =\frac{1}{\pi}\int_{-\pi/2}^{\pi/2}(1+\cos2\theta)d\theta\\
 & =\frac{1}{\pi}\left[\theta+\frac{1}{2}\sin2\theta\right]_{-\pi/2}^{\pi/2}\\
 & =\frac{1}{\pi}\cdot\pi\\
 & =1
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The CDF of 
\begin_inset Formula $X$
\end_inset

 is given by:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
F_{X}(a) & =\int_{-1}^{a}\int_{-\sqrt{1-x^{2}}}^{\sqrt{1-x^{2}}}\frac{1}{\pi}dydx\\
 & =\frac{2}{\pi}\int_{-1}^{a}\sqrt{1-x^{2}}dx
\end{align*}

\end_inset


\end_layout

\begin_layout Example
I leave it in this integral form.
 The PDF of 
\begin_inset Formula $X$
\end_inset

 is obtained by differentiating the CDF, so it is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{equation}
f_{X}(x)=\frac{2}{\pi}\sqrt{1-x^{2}}\label{eq:marginal-pdf-of-X}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Let's quickly plot the density of 
\begin_inset Formula $X$
\end_inset

 over the domain of the definition 
\begin_inset Formula $-1\leq x\leq1$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[domain=-1:1]
\end_layout

\begin_layout Plain Layout


\backslash
begin{axis}[]
\end_layout

\begin_layout Plain Layout


\backslash
addplot[grid=both,
\end_layout

\begin_layout Plain Layout

		 minor tick num=5,
\end_layout

\begin_layout Plain Layout

		 grid style={line width=.1pt, draw=gray!10},     
\end_layout

\begin_layout Plain Layout

		 major grid style={line width=.2pt,draw=gray!50},
\end_layout

\begin_layout Plain Layout

         axis lines=middle,
\end_layout

\begin_layout Plain Layout

		 axis line style={latex-latex}] 
\end_layout

\begin_layout Plain Layout

	{(2/pi)*sqrt(1-x^2)};
\end_layout

\begin_layout Plain Layout


\backslash
end{axis}
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Figure.
 The PDF of the random variable $X$.
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Not suprisingly the distribution of the 
\begin_inset Formula $x$
\end_inset

-coordinate is no longer uniform! 
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $(X_{1},X_{2},\ldots,X_{n})$
\end_inset

 is a random vector, the distribution of a single coordinate, say 
\begin_inset Formula $X_{1}$
\end_inset

 is called the 
\emph on
marginal distribution
\emph default
.
 In the example 
\begin_inset CommandInset ref
LatexCommand ref
reference "Uniform-on-the-unit-circle-distribution"
plural "false"
caps "false"
noprefix "false"

\end_inset

, the marginal distribution of 
\begin_inset Formula $X$
\end_inset

 is determined by the PDF 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:marginal-pdf-of-X"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
Random variables 
\begin_inset Formula $X_{1},X_{2},\ldots,X_{n}$
\end_inset

 defined on the same probability space are said to be independent if for
 any intervals 
\begin_inset Formula $A_{1},A_{2},\ldots,A_{n}$
\end_inset

 in 
\begin_inset Formula $\mathbf{R}$
\end_inset

, the probability factors:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathbb{P}(X_{1}\in A_{1},X_{2}\in A_{2},\ldots,X_{n}\in A_{n})=\mathbb{P}(X_{1}\in A_{1})\times\mathbb{P}(X_{2}\in A_{2})\times\ldots\times\mathbb{P}(X_{n}\in A_{n})
\]

\end_inset

 We say that the random variables are independent and identically distributed
 (IID) if they are independent and their marginal distributions are the
 same.
 
\end_layout

\begin_layout Standard
When the random vector 
\begin_inset Formula $(X_{1},X_{2},\ldots,X_{n})$
\end_inset

 has a joint PDF 
\begin_inset Formula $f(x_{1},x_{2},\ldots,x_{n})$
\end_inset

, the independence of random variables is equivalent to saying that the
 joint PDF is given by the product of the marginal PDFs:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
f(x_{1},x_{2},\ldots,x_{n})=f_{1}(x_{1})\times f_{2}(x_{2})\times\ldots\times f_{n}(x_{n})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Basic Probabilistic Inequalities.
\end_layout

\begin_layout Standard
Inequalities are extremely useful tools in the theoretical development of
 probability theory.
 
\end_layout

\begin_layout Subsubsection
Jensen's inequality.
\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $g$
\end_inset

 is a convex function, and 
\begin_inset Formula $a>0$
\end_inset

, 
\begin_inset Formula $b>0$
\end_inset

, with 
\begin_inset Formula $p\in[0,1]$
\end_inset

, it follows that:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{equation}
g(pa+(1-p)b)\leq pg(a)+(1-p)g(b)
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
This directly follows from the definition of convex functions.
\end_layout

\begin_layout Subsubsection
Jensen's inequality for Random variables.
\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $g$
\end_inset

 is a convex function, then it follows that:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{equation}
\mathbb{E}(g(X))\geq g(\mathbb{E}X)
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Another way to express the idea, that a function is convex is to observe
 that the tangent line at an arbitrary point 
\begin_inset Formula $(t,g(t))$
\end_inset

 always lies below the curve.
 Let 
\begin_inset Formula $y=a+bx$
\end_inset

 be the tangent to 
\begin_inset Formula $g$
\end_inset

 at the point 
\begin_inset Formula $t$
\end_inset

.
 Then, it follows that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
a+bt & =g(t)\\
a+bx & \leq g(x)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
for all 
\begin_inset Formula $x$
\end_inset

.
\end_layout

\begin_layout Proof
Thus, it follows that, for any point 
\begin_inset Formula $t$
\end_inset

, there exists 
\begin_inset Formula $b$
\end_inset

 such that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
g(x)-g(t) & \geq b(x-t)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
for all 
\begin_inset Formula $x$
\end_inset

.
 Set 
\begin_inset Formula $t=\mathbb{E}X$
\end_inset

 and 
\begin_inset Formula $x=X$
\end_inset

.
 Then,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
g(X)-g(\mathbb{E}X) & \geq b(X-\mathbb{E}X)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Taking expectations on both sides and simplifying:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left(g(X)\right)-g(\mathbb{E}X) & \geq b(\mathbb{E}X-\mathbb{E}X)=0\\
\mathbb{E}g(X) & \geq g(\mathbb{E}X)
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection
Young's Inequality.
\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $a\geq0$
\end_inset

 and 
\series bold

\begin_inset Formula $b\geq0$
\end_inset

 
\series default
are non-negative real numbers and if 
\begin_inset Formula $p>1$
\end_inset

 and 
\begin_inset Formula $q>1$
\end_inset

 are real numbers such that 
\begin_inset Formula $\frac{1}{p}+\frac{1}{q}=1$
\end_inset

, then:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{equation}
ab\leq\frac{a^{p}}{p}+\frac{b^{q}}{q}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Consider 
\begin_inset Formula $g(x)=\log x$
\end_inset

.
 Being a concave function, Jensen's inequality can be reversed.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
g\left(\frac{1}{p}a^{p}+\frac{1}{q}b^{q}\right) & \geq\frac{1}{p}g(a^{p})+\frac{1}{q}g(b^{q})\\
\log\left(\frac{1}{p}a^{p}+\frac{1}{q}b^{q}\right) & \geq\frac{1}{p}\log(a^{p})+\frac{1}{q}\log(b^{q})\\
\log\left(\frac{1}{p}a^{p}+\frac{1}{q}b^{q}\right) & \geq\frac{1}{p}\cdot p\log(a)+\frac{1}{q}\cdot q\log(b)\\
\log\left(\frac{1}{p}a^{p}+\frac{1}{q}b^{q}\right) & \geq\log ab
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By the Monotonicity of the 
\begin_inset Formula $\log x$
\end_inset

 function, it follows that :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
ab & \leq\frac{a^{p}}{p}+\frac{b^{q}}{q}
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection
Chebyshev's inequality.
\end_layout

\begin_layout Standard
One of the simplest and very useful probabilistic inequalities is a tail
 bound by expectation: the so called Chebyshev's inequality.
\end_layout

\begin_layout Theorem
(Chebyshev's inequality) If 
\begin_inset Formula $X$
\end_inset

 is a non-negative random variable, then for every 
\begin_inset Formula $t\geq0$
\end_inset

:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{equation}
\mathbb{P}(X\geq t)\leq\frac{1}{t}\mathbb{E}X
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
t\cdot\mathbf{1}_{\{X\geq t\}} & \leq X\cdot\mathbf{1}_{\{X\geq t\}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By the monotonicity of expectations, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}\mathbf{1}_{\{X\geq t\}} & \leq\frac{1}{t}\mathbb{E}X\\
\implies\mathbb{P}\{X\geq t\} & \leq\frac{1}{t}\mathbb{E}X
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
This closes the proof.
\end_layout

\begin_layout Standard
There are several variants, easily deduced from Chebyshev's inequality using
 monotonicity of several functions.
 For a non-negative random variable 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $t>0$
\end_inset

, using the power function 
\begin_inset Formula $x^{p}$
\end_inset

, 
\begin_inset Formula $p>0$
\end_inset

, we get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbb{P}(X\geq t)=\mathbb{P}(X^{p}\geq t^{p})\leq\frac{1}{t^{p}}\mathbb{E}X^{p}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
For a real valued random variable 
\begin_inset Formula $X$
\end_inset

, every 
\begin_inset Formula $t\in\mathbf{R}$
\end_inset

, using the square function 
\begin_inset Formula $x^{2}$
\end_inset

 and variance, we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbb{P}(|X-\mathbb{E}X|\geq t)\leq\frac{1}{t^{2}}\mathbb{E}|X-\mathbb{E}X|^{2}=\frac{1}{t^{2}}Var(X)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
For a real-valued random variable 
\begin_inset Formula $X$
\end_inset

, every 
\begin_inset Formula $t\in\mathbf{R}$
\end_inset

 and 
\begin_inset Formula $\lambda>0$
\end_inset

, using the exponential function 
\begin_inset Formula $e^{\lambda x}$
\end_inset

(which is monotonic), we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbb{P}(X\geq t)=\mathbb{P}(\lambda X\geq\lambda t)=\mathbb{P}(e^{\lambda X}\geq e^{\lambda t})\leq\frac{1}{e^{\lambda t}}\mathbb{E}e^{\lambda X}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Our next inequality, the so-called Holder's inequality is a very effective
 inequality to factor out the expectation of a product.
 
\end_layout

\begin_layout Subsubsection
Holder's inequality.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $p,q\geq1$
\end_inset

 be such that 
\begin_inset Formula $\frac{1}{p}+\frac{1}{q}=1$
\end_inset

, For random variables 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

, we have:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
\mathbb{E}|XY| & \leq\left(\mathbb{E}|X^{p}|\right)^{1/p}\left(\mathbb{E}|Y^{q}|\right)^{1/q}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
From the Young's inequality, for any 
\begin_inset Formula $a,b\in\mathbf{R}$
\end_inset

, 
\begin_inset Formula $p,q\geq1$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
ab & \leq\frac{a^{p}}{p}+\frac{b^{q}}{q}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Setting 
\begin_inset Formula $a=\frac{|X|}{\left(\mathbb{E}|X^{p}|\right)^{1/p}}$
\end_inset

 and 
\begin_inset Formula $b=\frac{|Y|}{\left(\mathbb{E}|Y^{q}|\right)^{1/q}}$
\end_inset

, we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\frac{|XY|}{\left(\mathbb{E}|X^{p}|\right)^{1/p}\left(\mathbb{E}|Y^{q}|\right)^{1/q}} & \leq\frac{1}{p}\cdot\frac{|X|^{p}}{\mathbb{E}|X^{p}|}+\frac{1}{q}\cdot\frac{|Y|^{q}}{\mathbb{E}|Y^{q}|}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Taking expectations on both sides, and using the monotonicity of expectation
 property, we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\frac{\mathbb{E}|XY|}{\left(\mathbb{E}|X^{p}|\right)^{1/p}\left(\mathbb{E}|Y^{q}|\right)^{1/q}} & \leq\frac{1}{p}\cdot\frac{\mathbb{E}|X|^{p}}{\mathbb{E}|X^{p}|}+\frac{1}{q}\cdot\frac{\mathbb{E}|Y|^{q}}{\mathbb{E}|Y^{q}|}=\frac{1}{p}+\frac{1}{q}=1
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Consequently,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}|XY| & \leq\left(\mathbb{E}|X^{p}|\right)^{1/p}\left(\mathbb{E}|Y^{q}|\right)^{1/q}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $p=2$
\end_inset

 and 
\begin_inset Formula $q=2$
\end_inset

.
 Then, we get the Cauchy-Schwarz inequality:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}|XY| & \leq\left[\mathbb{E}(X^{2})\right]^{1/2}\left[\mathbb{E}(Y^{2})\right]^{1/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
In some ways, the 
\begin_inset Formula $p$
\end_inset

-th moment of a random variable can be thought of as it's length or 
\begin_inset Formula $p$
\end_inset

-norm.
\end_layout

\begin_layout Proof
Define:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\left\Vert X\right\Vert _{p}=\left(\mathbb{E}|X|^{p}\right)^{1/p}
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Minkowski's Inequality.
\end_layout

\begin_layout Theorem
For random variables 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

, and for all 
\begin_inset Formula $p\geq1$
\end_inset

 we have:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{equation}
\left\Vert X+Y\right\Vert _{p}\leq\left\Vert X\right\Vert _{p}+\left\Vert Y\right\Vert _{p}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
The basic idea of the proof is to use Holder's inequality.
 Let 
\begin_inset Formula $\frac{1}{q}=1-\frac{1}{p}$
\end_inset

 or in other words, 
\begin_inset Formula $q=\frac{p}{p-1}$
\end_inset

.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{eqnarray*}
\mathbb{E}|X||X+Y|^{p-1} & \leq\left(\mathbb{E}|X|^{p}\right)^{1/p}\left(\mathbb{E}|X+Y|^{(p-1)q}\right)^{1/q} & (a)\\
\mathbb{E}|Y||X+Y|^{p-1} & \leq\left(\mathbb{E}|Y|^{p}\right)^{1/p}\left(\mathbb{E}|X+Y|^{(p-1)q}\right)^{1/q} & (b)
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Proof
Adding the above two equations, we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}(|X+Y||X+Y|^{p-1})\leq\mathbb{E}(|X|+|Y|)(|X+Y|^{p-1}) & \leq\left\{ \left(\mathbb{E}|X|^{p}\right)^{1/p}+\left(\mathbb{E}|Y|^{p}\right)^{1/p}\right\} \left(\mathbb{E}|X+Y|^{(p-1)q}\right)^{1/q}\\
\mathbb{E}|X+Y|^{p} & \leq\left\{ \left\Vert X\right\Vert _{p}+\left\Vert Y\right\Vert _{p}\right\} \left(\mathbb{E}|X+Y|^{p}\right)^{1/q}\\
\left(\mathbb{E}|X+Y|^{p}\right)^{1/p} & \leq\left\Vert X\right\Vert _{p}+\left\Vert Y\right\Vert _{p}\\
\left\Vert X+Y\right\Vert _{p} & \leq\left\Vert X\right\Vert _{p}+\left\Vert Y\right\Vert _{p}
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
A quick refresher of linear algebra.
\end_layout

\begin_layout Standard
Many of the concepts in this chapter have very elegant interpretations,
 if we think of real-valued random variables on a probability space as vectors
 in a vector space.
 In particular, variance is related to the concept of norm and distance,
 while covariance is related to inner-products.
 These concepts can help unify some of the ideas in this chapter from a
 geometric point of view.
 Of course, real-valued random variables are simply measurable, real-valued
 functions on the abstract space 
\begin_inset Formula $\Omega.$
\end_inset

 
\end_layout

\begin_layout Definition
(Vector Space).
\end_layout

\begin_layout Definition
By a vector space, we mean a non-empty set 
\begin_inset Formula $V$
\end_inset

 with two operations:
\end_layout

\begin_layout Itemize
Vector addition: 
\begin_inset Formula $+:(\mathbf{x},\mathbf{y})\to\mathbf{x}+\mathbf{y}$
\end_inset


\end_layout

\begin_layout Itemize
Scalar multiplication: 
\begin_inset Formula $\cdot:(\alpha,\mathbf{x})\to\alpha\mathbf{x}$
\end_inset


\end_layout

\begin_layout Standard
such that the following conditions are satisfied:
\end_layout

\begin_layout Standard
(A1) Commutativity.
 
\begin_inset Formula $\mathbf{x}+\mathbf{y}=\mathbf{y}+\mathbf{x}$
\end_inset

 for all 
\begin_inset Formula $\mathbf{x},\mathbf{y}\in V$
\end_inset


\end_layout

\begin_layout Standard
(A2) Associativity: 
\begin_inset Formula $(\mathbf{x}+\mathbf{y})+\mathbf{z}=\mathbf{x}+(\mathbf{y}+\mathbf{z})$
\end_inset

 for all 
\begin_inset Formula $\mathbf{x},\mathbf{y},\mathbf{z}\in V$
\end_inset


\end_layout

\begin_layout Standard
(A3) Zero Element: There exists a zero element, denoted 
\begin_inset Formula $\mathbf{0}$
\end_inset

 in 
\begin_inset Formula $V$
\end_inset

, for all 
\begin_inset Formula $\mathbf{x}\in V$
\end_inset

, such that 
\begin_inset Formula $\mathbf{x}+\mathbf{0}=\mathbf{x}$
\end_inset

.
\end_layout

\begin_layout Standard
(A4) Additive Inverse: For all 
\begin_inset Formula $\mathbf{x}\in V$
\end_inset

, there exists an additive inverse(negative element) denoted 
\begin_inset Formula $-\mathbf{x}$
\end_inset

 in 
\begin_inset Formula $V$
\end_inset

, such that 
\begin_inset Formula $\mathbf{x}+(-\mathbf{x})=\mathbf{0}$
\end_inset

.
\end_layout

\begin_layout Standard
(M1) Scalar multiplication by identity element in 
\begin_inset Formula $F$
\end_inset

: For all 
\begin_inset Formula $\mathbf{x}\in V$
\end_inset

, 
\begin_inset Formula $1\cdot\mathbf{x}=\mathbf{x}$
\end_inset

, where 
\begin_inset Formula $1$
\end_inset

 denotes the multiplicative identity in 
\begin_inset Formula $F$
\end_inset

.
\end_layout

\begin_layout Standard
(M2) Scalar multiplication and field multiplication mix well: For all 
\begin_inset Formula $\alpha,\beta\in F$
\end_inset

 and 
\begin_inset Formula $\mathbf{v}\in V$
\end_inset

, 
\begin_inset Formula $(\alpha\beta)\mathbf{v}=\alpha(\beta\mathbf{v})$
\end_inset

.
\end_layout

\begin_layout Standard
(D1) Distribution of scalar multiplication over vector addition: For all
 
\begin_inset Formula $\alpha\in F$
\end_inset

, and 
\begin_inset Formula $\mathbf{u},\mathbf{v}\in V$
\end_inset

, 
\begin_inset Formula $\alpha(\mathbf{u}+\mathbf{v})=\alpha\mathbf{u}+\alpha\mathbf{v}$
\end_inset

.
\end_layout

\begin_layout Standard
(D2) Distribution of field addition over scalar multiplication: For all
 
\begin_inset Formula $\alpha,\beta\in F$
\end_inset

, and 
\begin_inset Formula $\mathbf{v}\in V$
\end_inset

, 
\begin_inset Formula $(\alpha+\beta)\mathbf{v}=\alpha\mathbf{v}+\beta\mathbf{v}$
\end_inset

.
\end_layout

\begin_layout Standard
As usual, our starting point is a random experiment modeled by a probability
 space 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

, so that 
\begin_inset Formula $\Omega$
\end_inset

 is the set of outcomes, 
\begin_inset Formula $\mathscr{\mathcal{F}}$
\end_inset

 is the 
\begin_inset Formula $\sigma$
\end_inset

-algebra of events and 
\begin_inset Formula $\mathbb{P}$
\end_inset

 is the probability measure on the measurable space 
\begin_inset Formula $(\Omega,\mathcal{F})$
\end_inset

.
 Our basic vector space 
\begin_inset Formula $V$
\end_inset

 consists of all real-valued random variables defined on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 We define vector addition and scalar multiplication in the usual way point-wise.
 
\end_layout

\begin_layout Itemize
Vector addition: 
\begin_inset Formula $(X+Y)(\omega)=X(\omega)+Y(\omega)$
\end_inset

.
\end_layout

\begin_layout Itemize
Scalar multiplication: 
\begin_inset Formula $(\alpha X)(\omega)=\alpha X(\omega)$
\end_inset


\end_layout

\begin_layout Standard
Clearly, any function 
\begin_inset Formula $g$
\end_inset

 of a random variable 
\begin_inset Formula $X(\omega)$
\end_inset

 is also a random variable on the same probability space and any linear
 combination of random variables on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 also define a new random variable on the same probability space.
 Thus, 
\begin_inset Formula $V$
\end_inset

 is closed under vector addition and scalar-multiplication.
 Since vector-addition and scalar multiplication is defined point-wise,
 it is easy to see that - all the axioms of a vector space (A1)-(A4), (M1-M2),
 (D1), (D2) are satisfied.
 The constantly zero random variable 
\begin_inset Formula $0(\omega)=0$
\end_inset

 and the indicator random variable 
\begin_inset Formula $I_{\Omega}(\omega)$
\end_inset

 can be thought of as the zero and identity vectors in this vector space.
\end_layout

\begin_layout Subsubsection
Inner Products.
\end_layout

\begin_layout Standard
In Euclidean geometry, the angle between two vectors is specified by their
 dot product, which is itself formalized by the abstract concept of inner
 products.
 
\end_layout

\begin_layout Definition
(Inner Product).
 An inner product on the real vector space 
\begin_inset Formula $V$
\end_inset

 is a pairing that takes two vectors 
\begin_inset Formula $\mathbf{v},\mathbf{w}\in V$
\end_inset

 and produces a real number 
\begin_inset Formula $\left\langle \mathbf{v},\mathbf{w}\right\rangle \in\mathbf{R}$
\end_inset

.
 The inner product is required to satisfy the following three axioms for
 all 
\begin_inset Formula $\mathbf{u},\mathbf{v},\mathbf{w}\in V$
\end_inset

 and scalars 
\begin_inset Formula $c,d\in\mathbf{R}$
\end_inset

.
\end_layout

\begin_layout Definition
(i) Bilinearity: 
\begin_inset Formula 
\begin{equation}
\left\langle c\mathbf{u}+d\mathbf{v},\mathbf{w}\right\rangle =c\left\langle \mathbf{u},\mathbf{w}\right\rangle +d\left\langle \mathbf{v},\mathbf{w}\right\rangle 
\end{equation}

\end_inset


\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{equation}
\left\langle \mathbf{u},c\mathbf{v}+d\mathbf{w}\right\rangle =c\left\langle \mathbf{u},\mathbf{v}\right\rangle +d\left\langle \mathbf{u},\mathbf{w}\right\rangle 
\end{equation}

\end_inset


\end_layout

\begin_layout Definition
(ii) Symmetry:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{equation}
\left\langle \mathbf{v},\mathbf{w}\right\rangle =\left\langle \mathbf{w},\mathbf{v}\right\rangle 
\end{equation}

\end_inset


\end_layout

\begin_layout Definition
(iii) Positive Definiteness:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{equation}
\left\langle \mathbf{v},\mathbf{v}\right\rangle >0\quad\text{ whenever }\mathbf{v\neq\mathbf{0}}
\end{equation}

\end_inset


\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{equation}
\left\langle \mathbf{v},\mathbf{v}\right\rangle =0\quad\text{ whenever }\mathbf{v=0}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
(Norm).
 A norm on a real vector space 
\begin_inset Formula $V$
\end_inset

 is a function 
\begin_inset Formula $\left\Vert \cdot\right\Vert :V\to\mathbf{R}$
\end_inset

 satisfying :
\end_layout

\begin_layout Definition
(i) Positive Definiteness.
 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{equation}
\left\Vert \mathbf{v}\right\Vert \geq0
\end{equation}

\end_inset


\end_layout

\begin_layout Definition
and 
\begin_inset Formula 
\begin{equation}
\left\Vert \mathbf{v}\right\Vert =0\quad\text{if and only if }\mathbf{v}=\mathbf{0}
\end{equation}

\end_inset


\end_layout

\begin_layout Definition
(ii) Scalar multiplication.
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{equation}
\left\Vert \alpha\mathbf{v}\right\Vert =|\alpha|\left\Vert \mathbf{v}\right\Vert 
\end{equation}

\end_inset


\end_layout

\begin_layout Definition
(iii) Triangle Inequality.
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{equation}
\left\Vert \mathbf{x+y}\right\Vert \leq\left\Vert \mathbf{x}\right\Vert +\left\Vert \mathbf{y}\right\Vert 
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
As mentioned earlier, we can define the 
\begin_inset Formula $p$
\end_inset

-norm of a random variable as :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left\Vert X\right\Vert _{p} & =\left(\mathbb{E}|X|^{p}\right)^{1/p}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
(i) Positive semi-definiteness: Since 
\begin_inset Formula $|X|$
\end_inset

 is a non-negative random variable, 
\begin_inset Formula $|X|^{p}\geq0$
\end_inset

 and the expectation of a non-negative random variable is also non-negative.
 Hence, 
\begin_inset Formula $(\mathbb{E}|X|^{p})^{1/p}\geq0$
\end_inset

.
 Moreover, 
\begin_inset Formula $\left\Vert X\right\Vert _{p}=0$
\end_inset

 implies that 
\begin_inset Formula $\mathbb{E}|X|^{p}=0$
\end_inset

.
 From property (iv) of expectations, 
\begin_inset Formula $X=0$
\end_inset

.
\end_layout

\begin_layout Standard
(ii) Scalar-multiplication: We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left\Vert cX\right\Vert _{p} & =\left(\mathbb{E}|cX|^{p}\right)^{1/p}\\
 & =\left(|c|^{p}\right)^{1/p}\left(\mathbb{E}|X|^{p}\right)^{1/p}\\
 & =|c|\cdot\left\Vert X\right\Vert _{p}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
(iii) Triangle Inequality.
 This followed from the Minkowski's inequality.
\end_layout

\begin_layout Standard
The space of all random variables defined on 
\begin_inset Formula $(\Omega,\mathcal{\mathcal{F}},\mathbb{P})$
\end_inset

 such that 
\begin_inset Formula $||X||_{p}<\infty$
\end_inset

 is finite is called the 
\begin_inset Formula $L^{p}$
\end_inset

 space.
 
\end_layout

\begin_layout Subsubsection
Orthogonal Matrices.
\end_layout

\begin_layout Definition
(Orthogonal Matrix).
 Let 
\begin_inset Formula $A$
\end_inset

 be an 
\begin_inset Formula $n\times n$
\end_inset

 square matrix.
 We say that the matrix 
\begin_inset Formula $A$
\end_inset

 is orthogonal, if its transpose is equal to its inverse.
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
A' & =A^{-1}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This may seem like an odd property to study, but the following theorem explains
 why it is so useful.
 Essentially, an orthogonal matrix rotates (or reflects) vectors without
 distorting angles or distances.
 
\end_layout

\begin_layout Proposition
For an 
\begin_inset Formula $n\times n$
\end_inset

 square matrix 
\begin_inset Formula $A$
\end_inset

, the following are equivalent:
\end_layout

\begin_layout Proposition
(1) 
\begin_inset Formula $A$
\end_inset

 is orthogonal.
 That is, 
\begin_inset Formula $A'A=I$
\end_inset

.
\end_layout

\begin_layout Proposition
(2) 
\begin_inset Formula $A$
\end_inset

 preserves norms.
 That is, for all 
\begin_inset Formula $\mathbf{x}$
\end_inset

,
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
\left\Vert A\mathbf{x}\right\Vert  & =\left\Vert \mathbf{x}\right\Vert 
\end{align*}

\end_inset


\end_layout

\begin_layout Proposition
(3) 
\begin_inset Formula $A$
\end_inset

 preserves inner products, that is, for every 
\begin_inset Formula $\mathbf{x}$
\end_inset

, 
\begin_inset Formula $\mathbf{y}$
\end_inset


\begin_inset Formula $\in\mathbf{R}^{n}$
\end_inset

:
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
(A\mathbf{x})\cdot(A\mathbf{y}) & =\mathbf{x}\cdot\mathbf{y}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\left\Vert A\mathbf{x}\right\Vert ^{2} & =\left(A\mathbf{x}\right)'(A\mathbf{x})\\
 & =\mathbf{x}'(A'A)\mathbf{x}\\
 & =\mathbf{x}'I\mathbf{x}\\
 & =\mathbf{x}'\mathbf{x}\\
 & =||\mathbf{x}||^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Consequently, 
\begin_inset Formula $||A\mathbf{x}||=||\mathbf{x}||$
\end_inset

.
 The matrix 
\begin_inset Formula $A$
\end_inset

 preserves norms.
 Thus, (1) implies (2).
\end_layout

\begin_layout Proof
Moreover, consider
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
||A(\mathbf{x}+\mathbf{y})||^{2} & =\left(A\mathbf{x}+A\mathbf{y}\right)\cdot\left(A\mathbf{x}+A\mathbf{y}\right)\\
 & =(A\mathbf{x})\cdot(A\mathbf{x})+(A\mathbf{x})\cdot(A\mathbf{y})+(A\mathbf{y})\cdot(A\mathbf{x})+(A\mathbf{y})\cdot(A\mathbf{y})\\
 & =||A\mathbf{x}||^{2}+2(A\mathbf{x})\cdot(A\mathbf{y})+||A\mathbf{y}||^{2} & \{\mathbf{x}\cdot\mathbf{y}=\mathbf{y}\cdot\mathbf{x}\}\\
 & =||\mathbf{x}||^{2}+2(A\mathbf{x})\cdot(A\mathbf{y})+||\mathbf{y}||^{2} & \{A\text{ preserves norms}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
But, 
\begin_inset Formula $||A(\mathbf{x}+\mathbf{y})||^{2}=||\mathbf{x}+\mathbf{y}||^{2}=||\mathbf{x}||^{2}+2\mathbf{x}\cdot\mathbf{y}+||\mathbf{y}||^{2}$
\end_inset

.
 Equating the two expressions, we have the desired result.
 Hence, (2) implies (3).
\end_layout

\begin_layout Proof
Lastly, if 
\begin_inset Formula $A$
\end_inset

 preserves inner products, we may write:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\left\langle A\mathbf{x},A\mathbf{x}\right\rangle  & =\left\langle \mathbf{x},\mathbf{x}\right\rangle \\
\left(A\mathbf{x}\right)'(A\mathbf{x}) & =\mathbf{x}'\mathbf{x}\\
\mathbf{x}'A'A\mathbf{x} & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $\mathbf{x}\neq\mathbf{0}$
\end_inset

, it must be true that 
\begin_inset Formula $\mathbf{x}'A'A-\mathbf{x}'=0$
\end_inset

.
 Again, since 
\begin_inset Formula $\mathbf{x}'\neq\mathbf{0}$
\end_inset

, it follows that 
\begin_inset Formula $A'A-I=0$
\end_inset

.
 
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "linear-independence-of-orthogonal-vectors"

\end_inset

If 
\begin_inset Formula $\mathbf{q}_{1},\mathbf{q}_{2},\ldots,\mathbf{q}_{k}\in V$
\end_inset

 be mutually orthogonal elements, such that 
\begin_inset Formula $\mathbf{q}_{i}\neq\mathbf{0}$
\end_inset

 for all 
\begin_inset Formula $i$
\end_inset

, then 
\begin_inset Formula $\mathbf{q}_{1},\mathbf{q}_{2},\ldots,\mathbf{q}_{k}$
\end_inset

 are linearly independent.
\end_layout

\begin_layout Proof
Let 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
c_{1}\mathbf{q}_{1}+c_{2}\mathbf{q}_{2}+\ldots+c_{k}\mathbf{q}_{k} & =\mathbf{0}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $\left\langle \mathbf{q}_{i},\mathbf{q}_{i}\right\rangle =1$
\end_inset

 and 
\begin_inset Formula $\left\langle \mathbf{q}_{i},\mathbf{q}_{j}\right\rangle =0$
\end_inset

 where 
\begin_inset Formula $i\neq j$
\end_inset

, we can take the inner product of the vector 
\begin_inset Formula $(c_{1}\mathbf{q}_{1}+c_{2}\mathbf{q}_{2}+\ldots+c_{i}\mathbf{q}_{i}+\ldots+c_{k}\mathbf{q}_{k})$
\end_inset

 with 
\begin_inset Formula $\mathbf{q}_{i}$
\end_inset

 for each 
\begin_inset Formula $i=1,2,3,\ldots,k$
\end_inset

.
 It results in 
\begin_inset Formula $c_{i}||\mathbf{q}_{i}||^{2}=0$
\end_inset

.
 Since 
\begin_inset Formula $\mathbf{q}_{i}\neq\mathbf{0}$
\end_inset

, 
\begin_inset Formula $||\mathbf{q}_{i}||^{2}>0$
\end_inset

.
 So, 
\begin_inset Formula $c_{i}=0$
\end_inset

.
 We conclude that 
\begin_inset Formula $c_{1}=c_{2}=\ldots=c_{k}=0$
\end_inset

.
 Consequently, 
\begin_inset Formula $\mathbf{q}_{1},\mathbf{q}_{2},\ldots,\mathbf{q}_{k}$
\end_inset

 are linearly independent.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $Q=\left[\begin{array}{cccc}
\mathbf{q}_{1} & \mathbf{q}_{2} & \ldots & \mathbf{q}_{n}\end{array}\right]$
\end_inset

 be an 
\begin_inset Formula $n\times n$
\end_inset

 orthogonal matrix.
 Then, 
\begin_inset Formula $\{\mathbf{q}_{1},\ldots,\mathbf{q}_{n}\}$
\end_inset

 form an orthonormal basis for 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

.
\end_layout

\begin_layout Proof
We have 
\begin_inset Formula $Q\mathbf{e}_{i}=\mathbf{q}_{i}$
\end_inset

.
 Consequently,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\left\langle \mathbf{q}_{i},\mathbf{q}_{i}\right\rangle  & =\mathbf{q}_{i}'\mathbf{q}_{i}\\
 & =(Q\mathbf{e}_{i})'(Q\mathbf{e}_{i})\\
 & =\mathbf{e}_{i}'Q'Q\mathbf{e}_{i}\\
 & =\mathbf{e}_{i}'I\mathbf{e}_{i}\\
 & =\mathbf{e}_{i}'\mathbf{e}_{i}\\
 & =1
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Assume that 
\begin_inset Formula $i\neq j$
\end_inset

.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\left\langle \mathbf{q}_{i},\mathbf{q}_{j}\right\rangle  & =\mathbf{q}_{i}'\mathbf{q}_{j}\\
 & =\mathbf{e}_{i}'Q'Q\mathbf{e}_{j}\\
 & =\mathbf{e}_{i}'\mathbf{e}_{j}\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
From theorem (
\begin_inset CommandInset ref
LatexCommand ref
reference "linear-independence-of-orthogonal-vectors"
plural "false"
caps "false"
noprefix "false"

\end_inset

), 
\begin_inset Formula $\{\mathbf{q}_{1},\ldots,\mathbf{q}_{n}\}$
\end_inset

 are linearly independent and hence form an orthonormal basis for 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Quadratic Forms.
\end_layout

\begin_layout Standard
An expression of the form:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathbf{x}'A\mathbf{x}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\mathbf{x}$
\end_inset

 is a 
\begin_inset Formula $n\times1$
\end_inset

 column vector and 
\begin_inset Formula $A$
\end_inset

 is an 
\begin_inset Formula $n\times n$
\end_inset

 matrix is called a quadratic form in 
\begin_inset Formula $\mathbf{x}$
\end_inset

 and 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{x}'A\mathbf{x} & =\sum_{i=1}^{n}\sum_{j=1}^{n}a_{ij}x_{i}x_{j}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
If 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 are 
\begin_inset Formula $n\times n$
\end_inset

 and 
\begin_inset Formula $\mathbf{x},\mathbf{y}$
\end_inset

 are 
\begin_inset Formula $n$
\end_inset

-vectors, then 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{x}'(A+B)\mathbf{y} & =\mathbf{x}'A\mathbf{y}+\mathbf{x}'B\mathbf{y}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The quadratic form of the matrix 
\begin_inset Formula $A$
\end_inset

 is called positive definite if:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{x}'A\mathbf{x} & >0\quad\text{whenever }\mathbf{x}\neq\mathbf{0}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
and positive semidefinite if:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{x}'A\mathbf{x} & \geq0\quad\text{whenever }\mathbf{x}\neq\mathbf{0}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Letting 
\begin_inset Formula $\mathbf{e}_{i}$
\end_inset

 be the unit vector with it's 
\begin_inset Formula $i$
\end_inset

th coordinate vector 
\begin_inset Formula $1$
\end_inset

, we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{e}_{i}'A\mathbf{e}_{i} & =\left[a_{i1}a_{i2}\ldots a_{ii}\ldots a_{in}\right]\left[\begin{array}{c}
0\\
0\\
\vdots\\
1\\
\vdots\\
0
\end{array}\right]=a_{ii}
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection
Eigenthingies and diagonalizability.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $V$
\end_inset

 and 
\begin_inset Formula $W$
\end_inset

 be finite dimensional vector spaces with 
\begin_inset Formula $dim(V)=n$
\end_inset

 and 
\begin_inset Formula $dim(W)=m$
\end_inset

.
 A linear transformation 
\begin_inset Formula $T:V\to W$
\end_inset

, is defined by its action on the basis vectors.
 Suppose:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
T(\mathbf{v}_{j}) & =\sum_{i=1}^{n}a_{ij}\mathbf{w}_{i}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
for all 
\begin_inset Formula $1\leq i\leq m$
\end_inset

.
 
\end_layout

\begin_layout Standard
Then, the matrix 
\begin_inset Formula $A=[T]_{\mathcal{B}_{V}}^{\mathcal{B}_{W}}$
\end_inset

 of the linear transformation is defined as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
A & =\left[\begin{array}{cccc}
a_{11} & a_{12} & \ldots & a_{1n}\\
a_{21} & a_{22} & \ldots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{m1} & a_{m2} & \ldots & a_{mn}
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
A linear transformation 
\begin_inset Formula $T:V\to V$
\end_inset

 is 
\series bold
diagonalizable
\series default
 if there exists an ordered basis 
\begin_inset Formula $\mathcal{B}=\{\mathbf{v}_{1},\ldots,\mathbf{v}_{n}\}$
\end_inset

 for 
\begin_inset Formula $V$
\end_inset

 so that the matrix for 
\begin_inset Formula $T$
\end_inset

 with respect to 
\begin_inset Formula $\mathcal{B}$
\end_inset

 is diagonal.
 This means precisely that, for some scalars 
\begin_inset Formula $\lambda_{1},\lambda_{2},\ldots,\lambda_{n}$
\end_inset

, we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
T(\mathbf{v}_{1}) & =\lambda_{1}\mathbf{v}_{1}\\
T(\mathbf{v}_{2}) & =\lambda_{2}\mathbf{v}_{2}\\
\vdots\\
T(\mathbf{v}_{n}) & =\lambda_{n}\mathbf{v}_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In other words, if 
\begin_inset Formula $A=[T]_{\mathcal{B}}$
\end_inset

, then we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
A\mathbf{v}_{i} & =\lambda_{i}\mathbf{v}_{i}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Thus, if we let 
\begin_inset Formula $P$
\end_inset

 be the 
\begin_inset Formula $n\times n$
\end_inset

 matrix whose columns are the vectors 
\begin_inset Formula $\mathbf{v}_{1},\mathbf{v}_{2},\ldots,\mathbf{v}_{n}$
\end_inset

 and 
\begin_inset Formula $\Lambda$
\end_inset

 be the 
\begin_inset Formula $n\times n$
\end_inset

 diagonal matrix with diagonal entries 
\begin_inset Formula $\lambda_{1},\lambda_{2},\ldots,\lambda_{n}$
\end_inset

, then we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
A\left[\begin{array}{cccc}
\mathbf{v}_{1} & \mathbf{v}_{2} & \ldots & \mathbf{v}_{n}\end{array}\right] & =\left[\begin{array}{cccc}
\mathbf{v}_{1} & \mathbf{v}_{2} & \ldots & \mathbf{v}_{n}\end{array}\right]\left[\begin{array}{cccc}
\lambda_{1}\\
 & \lambda_{2}\\
 &  & \ddots\\
 &  &  & \lambda_{n}
\end{array}\right]\\
AP & =P\Lambda\\
A & =P\Lambda P^{-1}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
There exists a large class of diagonalizable matrices - the symmetric matrices.
 A square matrix 
\begin_inset Formula $A$
\end_inset

 is symmetric, if 
\begin_inset Formula $A=A'$
\end_inset

.
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $T:V\to V$
\end_inset

 be a linear transformation.
 A 
\series bold
non-zero 
\series default
vector 
\begin_inset Formula $\mathbf{v}\in V$
\end_inset

 is called the eigenvector of 
\begin_inset Formula $T$
\end_inset

, if there is a scalar 
\begin_inset Formula $\lambda$
\end_inset

 so that 
\begin_inset Formula $T(\mathbf{v})=\lambda\mathbf{v}$
\end_inset

.
 The scalar 
\begin_inset Formula $\lambda$
\end_inset

 is called the eigenvalue of 
\begin_inset Formula $T$
\end_inset

.
\end_layout

\begin_layout Lemma
Let 
\begin_inset Formula $A$
\end_inset

 be an 
\begin_inset Formula $n\times n$
\end_inset

 matrix, and let 
\begin_inset Formula $\lambda$
\end_inset

 be any scalar.
 Then,
\end_layout

\begin_layout Lemma
\begin_inset Formula 
\begin{align*}
E(\lambda) & =\{\mathbf{x}\in\mathbf{R}^{n}:A\mathbf{x}=\lambda\mathbf{x}\}=\ker(A-\lambda I)
\end{align*}

\end_inset


\end_layout

\begin_layout Lemma
is a subspace of 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

.
 Moreover, if 
\begin_inset Formula $E(\lambda)\neq\{\mathbf{0}\}$
\end_inset

 if and only if 
\begin_inset Formula $\lambda$
\end_inset

 is an eigenvalue, in which case we call 
\begin_inset Formula $E(\lambda)$
\end_inset

 the 
\begin_inset Formula $\lambda$
\end_inset

-eigenspace of the matrix 
\begin_inset Formula $A$
\end_inset

.
\end_layout

\begin_layout Proof
We know that, 
\begin_inset Formula $E(\lambda)$
\end_inset

 is a subset of 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

.
 Moreover, if 
\begin_inset Formula $\mathbf{u},\mathbf{v}\in E(\lambda)$
\end_inset

 , then 
\begin_inset Formula $A(c_{1}\mathbf{u}+c_{2}\mathbf{v})=c_{1}A\mathbf{u}+c_{2}A\mathbf{v}=\lambda(c_{1}\mathbf{u}+c_{2}\mathbf{v})$
\end_inset

.
 Consequently, 
\begin_inset Formula $c_{1}\mathbf{u}+c_{2}\mathbf{v}\in E(\lambda)$
\end_inset

.
 Thus, 
\begin_inset Formula $E(\lambda)$
\end_inset

 is a subspace of 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

.
 
\end_layout

\begin_layout Proof
Moreover, by definition, 
\begin_inset Formula $\lambda$
\end_inset

 is an eigenvalue of 
\begin_inset Formula $A$
\end_inset

 precisely when 
\begin_inset Formula $\mathbf{x}\neq\mathbf{0}$
\end_inset

 vector in 
\begin_inset Formula $E(\lambda)$
\end_inset

.
 This closes the proof.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $A$
\end_inset

 be a 
\begin_inset Formula $n\times n$
\end_inset

 square matrix.
 If 
\begin_inset Formula $A$
\end_inset

 is a singular matrix, then 
\begin_inset Formula $\det A=0$
\end_inset

.
\end_layout

\begin_layout Proof
By definition, a square matrix is said to be non-singular, if it can be
 reduced to an upper triangular form with all non-zero elements on the diagonal
 - the pivots, by elementary row operations.
 A singular matrix is such that it's echelon form has a row of zeroes, and
 its row vectors are linearly dependent and 
\begin_inset Formula $\det A=0$
\end_inset

.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $A$
\end_inset

 be a 
\begin_inset Formula $n\times n$
\end_inset

 square matrix.
 Then, 
\begin_inset Formula $\lambda$
\end_inset

 is an eigenvalue of 
\begin_inset Formula $A$
\end_inset

 if and only if 
\begin_inset Formula $\det(A-\lambda I)=0$
\end_inset

.
\end_layout

\begin_layout Proof
\begin_inset Formula $\lambda$
\end_inset

 is an eigenvalue of 
\begin_inset Formula $A$
\end_inset

, if and only, the homogenous system of linear equations 
\begin_inset Formula $(A-\lambda I)\mathbf{x}=\mathbf{0}$
\end_inset

 has non-trivial solutions.
 Consequently, the only possibility is that there are one more free variables
 (more variables than the number of equations).
 In other words, 
\begin_inset Formula $(A-\lambda I)$
\end_inset

 must be a singular matrix and 
\begin_inset Formula $\det(A-\lambda I)=0$
\end_inset

.
\end_layout

\begin_layout Example
Let's find the eigenvalues and eigenvectors of the matrix 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
A & =\left[\begin{array}{ccc}
1 & 2 & 1\\
0 & 1 & 0\\
1 & 3 & 1
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We begin by computing 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\det(A-\lambda I) & =\left[\begin{array}{ccc}
1-\lambda & 2 & 1\\
0 & 1-\lambda & 0\\
1 & 2 & 1-\lambda
\end{array}\right]\\
 & =(1-\lambda)(1-\lambda)^{2}-(1-\lambda)\\
 & =(1-\lambda)[(1-\lambda)^{2}-1)]\\
 & =-\lambda(1-\lambda)(2-\lambda)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Thus, the eigenvalues of 
\begin_inset Formula $A$
\end_inset

 are 
\begin_inset Formula $\lambda=0$
\end_inset

, 
\begin_inset Formula $\lambda=1$
\end_inset

 and 
\begin_inset Formula $\lambda=2$
\end_inset

.
\end_layout

\begin_layout Example
We find the respective eigenspaces:
\end_layout

\begin_layout Example
1) Fix 
\begin_inset Formula $\lambda=0$
\end_inset

.
 We see that:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\left[\begin{array}{ccc}
1 & 2 & 1\\
0 & 1 & 0\\
1 & 3 & 1
\end{array}\right]\left[\begin{array}{c}
x_{1}\\
x_{2}\\
x_{3}
\end{array}\right] & =\left[\begin{array}{c}
0\\
0\\
0
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The augmented matrix 
\begin_inset Formula $[A|b]$
\end_inset

 is :
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\left[\begin{array}{ccccc}
1 & 2 & 1 & | & 0\\
0 & 1 & 0 & | & 0\\
1 & 3 & 1 & | & 0
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
\begin_inset Formula $R_{3}-R_{1}$
\end_inset

, 
\begin_inset Formula $R_{3}-R_{2}$
\end_inset

 and 
\begin_inset Formula $R_{1}-2R_{2}$
\end_inset

 leaves us with:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\left[\begin{array}{ccccc}
1 & 0 & 1 & | & 0\\
0 & 1 & 0 & | & 0\\
0 & 0 & 0 & | & 0
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
So, 
\begin_inset Formula $x_{1}+x_{3}=0$
\end_inset

 and 
\begin_inset Formula $x_{2}=0$
\end_inset

.
 Here, 
\begin_inset Formula $x_{3}$
\end_inset

 is a free variable.
 Thus, 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
E(0) & =\{\alpha(1,0,-1)|\alpha\in\mathbf{R}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
2) Fix 
\begin_inset Formula $\lambda=1$
\end_inset

.
 We see that:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\left[\begin{array}{ccc}
0 & 2 & 1\\
0 & 0 & 0\\
1 & 3 & 0
\end{array}\right]\left[\begin{array}{c}
x_{1}\\
x_{2}\\
x_{3}
\end{array}\right] & =\left[\begin{array}{c}
0\\
0\\
0
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Thus, 
\begin_inset Formula $2x_{2}+x_{3}=0$
\end_inset

 and 
\begin_inset Formula $x_{1}+3x_{2}=0$
\end_inset

.
 Here 
\begin_inset Formula $x_{3}$
\end_inset

 is a free variable.
 Let 
\begin_inset Formula $x_{3}=-2\alpha$
\end_inset

.
 Then, 
\begin_inset Formula $x_{2}=\alpha$
\end_inset

 and 
\begin_inset Formula $x_{1}=-3\alpha$
\end_inset

.
 Consequently,
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
E(1) & =\{\alpha(-3,1,-2)|\alpha\in\mathbf{R}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
3) Fix 
\begin_inset Formula $\lambda=3$
\end_inset

.
 We see that:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\left[\begin{array}{ccc}
-1 & 2 & 1\\
0 & -1 & 0\\
1 & 3 & -1
\end{array}\right]\left[\begin{array}{c}
x_{1}\\
x_{2}\\
x_{3}
\end{array}\right] & =\left[\begin{array}{c}
0\\
0\\
0
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The augmented matrix 
\begin_inset Formula $[A|b]$
\end_inset

 is :
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\left[\begin{array}{ccccc}
-1 & 2 & 1 & | & 0\\
0 & -1 & 0 & | & 0\\
1 & 3 & -1 & | & 0
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
\begin_inset Formula $R_{3}+R_{1}$
\end_inset

, 
\begin_inset Formula $R_{3}+5R_{2}$
\end_inset

 followed by 
\begin_inset Formula $R_{1}+2R_{2}$
\end_inset

 gives:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\left[\begin{array}{ccccc}
-1 & 0 & 1 & | & 0\\
0 & -1 & 0 & | & 0\\
0 & 0 & 0 & | & 0
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
Thus, 
\begin_inset Formula $x_{2}=0$
\end_inset

 and 
\begin_inset Formula $x_{1}-x_{3}=0$
\end_inset

.
 Here 
\begin_inset Formula $x_{3}$
\end_inset

 is the free variable.
 Hence, 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
E(2) & =\{\alpha(1,0,1):\alpha\in\mathbf{R}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Clearly, there exists a basis 
\begin_inset Formula $\mathcal{B}=\{(1,0,-1),(-3,1,-2),(1,0,1)\}$
\end_inset

 with respect to which the matrix of 
\begin_inset Formula $T$
\end_inset

 is diagonal.
 Hence, 
\begin_inset Formula $A$
\end_inset

 is diagonalizable.
 
\end_layout

\begin_layout Standard
Judging from the previous example, it appears that when an 
\begin_inset Formula $n\times n$
\end_inset

 square matrix has 
\begin_inset Formula $n$
\end_inset

 distinct eigen values, the corresponding eigenvectors form a linearly independe
nt set and will therefore give a 
\emph on
diagonalizing basis.
 
\emph default
Let's begin with a slightly stronger statement.
 
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $T:V\to V$
\end_inset

 be a linear transformation.
 Suppose 
\begin_inset Formula $\mathbf{v}_{1},\mathbf{v}_{2},\ldots,\mathbf{v}_{k}$
\end_inset

 are eigenvectors of 
\begin_inset Formula $T$
\end_inset

 corresponding to the distinct eigenvalues 
\begin_inset Formula $\lambda_{1},\lambda_{2},\ldots,\lambda_{k}$
\end_inset

.
 Then, 
\begin_inset Formula $\{\mathbf{v}_{1},\mathbf{v}_{2},\ldots,\mathbf{v}_{k}\}$
\end_inset

 is a linearly independent set of vectors.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $m$
\end_inset

 be the largest number between 
\begin_inset Formula $1$
\end_inset

 and 
\begin_inset Formula $k$
\end_inset

 (inclusive) so that 
\begin_inset Formula $\{\mathbf{v}_{1},\ldots,\mathbf{v}_{m}\}$
\end_inset

 is linearly independent.
 We proceed by contradiction.
 We want to see 
\begin_inset Formula $m=k$
\end_inset

.
 Assume that 
\begin_inset Formula $m<k$
\end_inset

.
 Then, we know that 
\begin_inset Formula $\{\mathbf{v}_{1},\ldots,\mathbf{v}_{m}\}$
\end_inset

 is linearly independent and 
\begin_inset Formula $\{\mathbf{v}_{1},\ldots,\mathbf{v}_{m},\mathbf{v}_{m+1}\}$
\end_inset

 is linearly dependent.
 Thus, 
\begin_inset Formula $\mathbf{v}_{m+1}=c_{1}\mathbf{v}_{1}+c_{2}\mathbf{v}_{2}+\ldots+c_{m}\mathbf{v}_{m}$
\end_inset

 such that atleast one of 
\begin_inset Formula $c_{1},c_{2},\ldots,c_{m}$
\end_inset

 are non-zero.
 Then, using repeatedly the fact that 
\begin_inset Formula $T(\mathbf{v}_{i})=\lambda_{i}\mathbf{v}_{i}$
\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{0} & =(T-\lambda_{m+1}I)\mathbf{v}_{m+1}=(T-\lambda_{m+1}I)(c_{1}\mathbf{v}_{1}+\ldots+c_{m}\mathbf{v}_{m})\\
 & =c_{1}\left(T\mathbf{v}_{1}-\lambda_{m+1}I\mathbf{v}_{1}\right)+c_{2}\left(T\mathbf{v}_{2}-\lambda_{m+1}I\mathbf{v}_{2}\right)+\ldots+c_{m}\left(T\mathbf{v}_{m}-\lambda_{m+1}I\mathbf{v}_{m}\right)\\
 & =c_{1}(\lambda_{1}-\lambda_{m+1})\mathbf{v}_{1}+c_{2}(\lambda_{2}-\lambda_{m+1})\mathbf{v}_{2}+\ldots+c_{m}(\lambda_{m}-\lambda_{m+1})\mathbf{v}_{m}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $\lambda_{i}\neq\lambda_{m+1}$
\end_inset

 for 
\begin_inset Formula $i=1,2,3,\ldots,m$
\end_inset

 and since 
\begin_inset Formula $\{\mathbf{v}_{1},\mathbf{v}_{2},\ldots\mathbf{v}_{m}\}$
\end_inset

 is linearly independent, the only other possibility is 
\begin_inset Formula $c_{1}=c_{2}=\ldots=c_{m}=0$
\end_inset

.
 But, this contradicts the fact that 
\begin_inset Formula $\mathbf{v}_{m+1}$
\end_inset

 is an eigenvector since 
\begin_inset Formula $\mathbf{v}_{m+1}\neq\mathbf{0}$
\end_inset

.
 Thus, it cannot happen that 
\begin_inset Formula $m<k$
\end_inset

.
 Consequently, 
\begin_inset Formula $m=k$
\end_inset

.
\end_layout

\begin_layout Standard
What is underlying this formal argument is the observation that: if 
\begin_inset Formula $\mathbf{v}\in E(\lambda)\cap E(\mu)$
\end_inset

, then 
\begin_inset Formula $T\mathbf{v}=\lambda\mathbf{v}$
\end_inset

 and 
\begin_inset Formula $T\mathbf{\mathbf{v}=\mu\mathbf{v}}$
\end_inset

.
 Hence, if 
\begin_inset Formula $\lambda\neq\mu$
\end_inset

, then 
\begin_inset Formula $\mathbf{v}=\mathbf{0}$
\end_inset

.
 That is, if 
\begin_inset Formula $\lambda\neq\mu$
\end_inset

, we have 
\begin_inset Formula $E(\lambda)\cap E(\mu)=\{\mathbf{0}\}$
\end_inset

.
\end_layout

\begin_layout Corollary
Suppose 
\begin_inset Formula $V$
\end_inset

 is an 
\begin_inset Formula $n$
\end_inset

-dimensional vector space and 
\begin_inset Formula $T:V\to V$
\end_inset

 has 
\begin_inset Formula $n$
\end_inset

 distinct eigenvalues.
 Then 
\begin_inset Formula $T$
\end_inset

 is diagonalizable.
 
\end_layout

\begin_layout Proof
The set of 
\begin_inset Formula $n$
\end_inset

 corresponding eigenvectors must be linearly independent and hence form
 a basis for 
\begin_inset Formula $V$
\end_inset

.
 The matrix of 
\begin_inset Formula $T$
\end_inset

 with respect to the eigenbasis is always diagonal.
\end_layout

\begin_layout Standard
The converse of this statement is not true.
 There are many diagonalizable matrices with repeated eigen-values.
 
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $\lambda$
\end_inset

 be an eigenvalue of a linear transformation.
 The algebraic multiplicity of 
\begin_inset Formula $\lambda$
\end_inset

 is its multiplicity as a root of the characteristic polynomial 
\begin_inset Formula $p(t)$
\end_inset

 that is, the highest power of 
\begin_inset Formula $t-\lambda$
\end_inset

 dividing 
\begin_inset Formula $p(t)$
\end_inset

.
 The geometric multiplicity of 
\begin_inset Formula $\lambda$
\end_inset

 is the dimension of the eigenspace 
\begin_inset Formula $E(\lambda)$
\end_inset

.
\end_layout

\begin_layout Proposition
Let 
\begin_inset Formula $\lambda$
\end_inset

 be an eigenvalue of algebraic multiplicity 
\begin_inset Formula $m$
\end_inset

 and geometric multiplicity 
\begin_inset Formula $d$
\end_inset

.
 Then, the geometric multiplicity is always bounded by the algebraic multiplicit
y, and 
\begin_inset Formula $1\leq d\leq m$
\end_inset

.
\end_layout

\begin_layout Proof
Suppose 
\begin_inset Formula $\lambda$
\end_inset

 is the eigenvalue of the linear transformation 
\begin_inset Formula $T$
\end_inset

.
 Then, 
\begin_inset Formula $d=\dim E(\lambda)\geq1$
\end_inset

 by definition.
 Now, choose a basis 
\begin_inset Formula $\{\mathbf{v}_{1},\mathbf{v}_{2},\ldots,\mathbf{v}_{d}\}$
\end_inset

 for 
\begin_inset Formula $E(\lambda)$
\end_inset

 and extend it to a basis 
\begin_inset Formula $\mathcal{B}=\{\mathbf{v}_{1},\mathbf{v}_{2},\ldots,\mathbf{v}_{n}\}$
\end_inset

 for 
\begin_inset Formula $V$
\end_inset

.
 Then, the matrix of 
\begin_inset Formula $T$
\end_inset

 with respect to 
\begin_inset Formula $\mathcal{B}$
\end_inset

 is of the form 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
A & =\left[\begin{array}{cc}
\lambda I_{d} & B\\
0_{(n-d)\times d} & C
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The characteristic polynomial 
\begin_inset Formula $p(t)$
\end_inset

 of the matrix 
\begin_inset Formula $A$
\end_inset

 is given by:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
p(t) & =\det(A-tI)\\
 & =\det((\lambda-t)I_{d})\cdot\det(C-tI)\\
 & =(\lambda-t)^{d}\cdot\det(C-tI)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since the characteristic polynomial does not depend on the choice of basis,
 the algebraic multiplicity of 
\begin_inset Formula $\lambda$
\end_inset

 is atleast 
\begin_inset Formula $d$
\end_inset

.
\end_layout

\begin_layout Lemma
(Lagrange Multipliers) Suppose 
\begin_inset Formula $f,g:\mathbf{R}^{n}\to\mathbf{R}$
\end_inset

 are scalar-valued 
\begin_inset Formula $C^{1}$
\end_inset

 functions - that is partial derivatives 
\begin_inset Formula $\partial_{x_{i}}$
\end_inset

 in all variables are continuous.
 Let 
\begin_inset Formula $S=\{\mathbf{x}\in\mathbf{R}^{n}|g(\mathbf{x})=c\}$
\end_inset

 denote the level set of 
\begin_inset Formula $g$
\end_inset

 at height 
\begin_inset Formula $c$
\end_inset

.
 Then if 
\begin_inset Formula $f|_{S}$
\end_inset

 (the restriction of 
\begin_inset Formula $f$
\end_inset

 to 
\begin_inset Formula $S$
\end_inset

) has an extremum point 
\begin_inset Formula $\mathbf{x}_{0}$
\end_inset

 in 
\begin_inset Formula $S$
\end_inset

 such that 
\begin_inset Formula $\nabla g(\mathbf{x}_{0})\neq\mathbf{0}$
\end_inset

, there exists a scalar 
\begin_inset Formula $\lambda$
\end_inset

 such that 
\end_layout

\begin_layout Lemma
\begin_inset Formula 
\begin{equation}
\nabla f(\mathbf{x}_{0})=\lambda\nabla g(\mathbf{x}_{0})
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Let's visualize the situation for the case 
\begin_inset Formula $n=3$
\end_inset

, where the constraint equation 
\begin_inset Formula $g(x,y,z)=c$
\end_inset

 defines a surface 
\begin_inset Formula $S$
\end_inset

 in 
\begin_inset Formula $\mathbf{R}^{3}$
\end_inset

.
\end_layout

\begin_layout Proof
Thus, suppose that 
\begin_inset Formula $\mathbf{x}_{0}$
\end_inset

 is an extremum of 
\begin_inset Formula $f$
\end_inset

 restricted to 
\begin_inset Formula $S$
\end_inset

.
 We consider a further restriction of 
\begin_inset Formula $f$
\end_inset

 - to a curve lying in 
\begin_inset Formula $S$
\end_inset

 and passing through 
\begin_inset Formula $\mathbf{x}_{0}$
\end_inset

.
 Let 
\begin_inset Formula $\mathbf{x}(t)=(x(t),y(t),z(t))$
\end_inset

 be the parametric equation of one such arbitrary path 
\begin_inset Formula $\mathbf{x}:I\subseteq\mathbf{R}\to\mathbf{R}^{3}$
\end_inset

 lying in 
\begin_inset Formula $S$
\end_inset

 with 
\begin_inset Formula $\mathbf{x}(t_{0})=\mathbf{x}_{0}$
\end_inset

 for some 
\begin_inset Formula $t_{0}\in I$
\end_inset

.
 Then, the restriction of 
\begin_inset Formula $f$
\end_inset

 to 
\begin_inset Formula $\mathbf{x}$
\end_inset

 can be written as a function of a single variable 
\begin_inset Formula $t$
\end_inset

.
 That is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
F(t) & :=f(\mathbf{\mathbf{x}}(t))
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Because 
\begin_inset Formula $\mathbf{x}_{0}$
\end_inset

 is an extremum of 
\begin_inset Formula $f$
\end_inset

 on the whole of 
\begin_inset Formula $S$
\end_inset

, it is also an extremum on the path 
\begin_inset Formula $\mathbf{x}$
\end_inset

.
 Since 
\begin_inset Formula $F$
\end_inset

 is a differentiable function of 
\begin_inset Formula $t$
\end_inset

, by the interior-extremum theorem, it follows that 
\begin_inset Formula $F'(t_{0})=0$
\end_inset

.
 The chain rule implies that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
F'(t) & =\nabla f(\mathbf{x})\cdot\mathbf{x}'(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Evaluating at 
\begin_inset Formula $t=t_{0}$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
F'(t_{0})=0 & =\nabla f(\mathbf{x}(t_{0}))\cdot\mathbf{x}'(t_{0})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Thus, 
\begin_inset Formula $\nabla f(\mathbf{x}(t_{0}))$
\end_inset

 is perpendicular to any curve in 
\begin_inset Formula $S$
\end_inset

 passing through 
\begin_inset Formula $\mathbf{x}_{0}$
\end_inset

; that is 
\begin_inset Formula $\nabla f(\mathbf{x}_{0})$
\end_inset

 is normal to 
\begin_inset Formula $S$
\end_inset

 at 
\begin_inset Formula $\mathbf{x}_{0}$
\end_inset

.
 We've already seen previously that the gradient vector 
\begin_inset Formula $\nabla g(\mathbf{x}_{0})$
\end_inset

 is also normal to 
\begin_inset Formula $S$
\end_inset

 at 
\begin_inset Formula $\mathbf{x}_{0}$
\end_inset

.
 Since the normal direction to the level 
\begin_inset Formula $S$
\end_inset

 is uniquely determined, we must conclude that 
\begin_inset Formula $\nabla f(\mathbf{x}_{0})$
\end_inset

 and 
\begin_inset Formula $\nabla g(\mathbf{x}_{0})$
\end_inset

 are parallel vectors.
 Therefore, there exists a scalar 
\begin_inset Formula $\lambda$
\end_inset

 such that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\nabla f(\mathbf{x}_{0}) & =\lambda\nabla g(\mathbf{x}_{0})
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection
The Gram-Schmidt Process.
\end_layout

\begin_layout Standard
The advantage of using an orthonormal basis is, that the coordinates of
 any vector are explicitly given as inner products.
 Let 
\begin_inset Formula $\{\mathbf{u}_{1},\mathbf{u}_{2},\ldots,\mathbf{u}_{n}\}$
\end_inset

 be an orthonormal basis of 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

.
 And let 
\begin_inset Formula $\mathbf{v}=c_{1}\mathbf{u}_{1}+\ldots+c_{n}\mathbf{u}_{n}$
\end_inset

 be an arbitrary vector.
 Then we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
c_{i} & =\mathbf{v}\cdot\mathbf{u}_{i}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Moreover, the magnitude (norm) of the vector is given by the Pythagorean
 formula:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left\Vert \mathbf{v}\right\Vert _{2}^{2} & =\left\langle \mathbf{v},\mathbf{v}\right\rangle \\
 & =c_{1}^{2}+c_{2}^{2}+\ldots+c_{n}^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Once we are convinced of the utility of orthogonal and orthonormal bases,
 a natural question arises: how can we construct them? A practical algorithm
 was discovered Pierre-Simon Laplace in the eighteenth century.
 Today, the algorithm is known as the 
\emph on
Gram-Schmidt process, 
\emph default
after its rediscovery by Gram and twentieth century mathematician Schmidt.
 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $W$
\end_inset

 be a finite dimensional vector space, such that 
\begin_inset Formula $\dim W=n$
\end_inset

.
 We assume that, we already know some basis 
\begin_inset Formula $\{\mathbf{w}_{1},\ldots,\mathbf{w}_{n}\}$
\end_inset

 of 
\begin_inset Formula $W$
\end_inset

, where 
\begin_inset Formula $n=\dim W$
\end_inset

.
 Our goal is to use this information to construct an orthogonal basis 
\begin_inset Formula $\mathbf{v}_{1},\mathbf{v}_{2},\ldots,\mathbf{v}_{n}$
\end_inset

.
\end_layout

\begin_layout Standard
We will construct the orthogonal basis one-by-one.
 Since initially, we are not worrying about normality, there are no conditions
 on the first orthogonal basis element 
\begin_inset Formula $\mathbf{v}_{1}$
\end_inset

, so there is no harm in choosing :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{v}_{1} & =\mathbf{w}_{1}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Note that, 
\begin_inset Formula $\mathbf{v}_{1}\neq\mathbf{0}$
\end_inset

, since 
\begin_inset Formula $\mathbf{w}_{1}$
\end_inset

 appears in the original basis.
 Starting with 
\begin_inset Formula $\mathbf{w}_{2}$
\end_inset

, the second basis vector 
\begin_inset Formula $\mathbf{v}_{2}$
\end_inset

 must be orthogonal to the first: 
\begin_inset Formula $\left\langle \mathbf{v}_{2},\mathbf{v}_{1}\right\rangle =0$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [blue,->](0,0) -- (3,0) node[anchor=north east]{$c
\backslash
boldsymbol{v}_1$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [black,->] (0,0) -- (1,0) node[anchor=south]{$
\backslash
boldsymbol{v}_1$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [black,->] (0,0) -- (3,4) node[anchor=south]{$
\backslash
boldsymbol{w}_2$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [dashed,red,->] (3,0) -- (3,4) node[midway,right]{$
\backslash
boldsymbol{w}_2 - c
\backslash
boldsymbol{v}_1$};
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Figure.
 Resolving the vector $
\backslash
mathbf{w}_2$ into two components (1) along $
\backslash
mathbf{u}_1$ and (2) perpendicular to $
\backslash
mathbf{u}_1$.
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Let us try to arrange this, by subtracting a suitable multiple of 
\begin_inset Formula $\mathbf{v}_{1}$
\end_inset

, and set:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{v}_{2} & =\mathbf{w}_{2}-c\mathbf{v}_{1}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The orthogonality condition
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
0 & =\left\langle \mathbf{v}_{2},\mathbf{v}_{1}\right\rangle \\
 & =(\mathbf{w}_{2}-c\mathbf{v}_{1})\cdot\mathbf{v}_{1}\\
 & =\mathbf{w}_{2}\cdot\mathbf{v}_{1}-c\left\Vert \mathbf{v}_{1}\right\Vert ^{2}\\
c & =\frac{\mathbf{w}_{2}\cdot\mathbf{v}_{1}}{\left\Vert \mathbf{v}_{1}\right\Vert ^{2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
and therefore
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{v}_{2} & =\mathbf{w}_{2}-\left(\frac{\mathbf{w}_{2}\cdot\mathbf{v}_{1}}{\left\Vert \mathbf{v}_{1}\right\Vert ^{2}}\right)\mathbf{v}_{1}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The linear independence of 
\begin_inset Formula $\mathbf{v}_{1}=\mathbf{w}_{1}$
\end_inset

 and 
\begin_inset Formula $\mathbf{w}_{2}$
\end_inset

 ensures that 
\begin_inset Formula $\mathbf{v}_{2}\neq\mathbf{0}$
\end_inset

.
\end_layout

\begin_layout Standard
Next, we construct:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{v}_{3} & =\mathbf{w}_{3}-c_{1}\mathbf{v}_{1}-c_{2}\mathbf{v}_{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
by subtracting suitable multiples of the first two orthogonal basis elements
 from 
\begin_inset Formula $\mathbf{w}_{3}$
\end_inset

.
 We want 
\begin_inset Formula $\mathbf{v}_{3}$
\end_inset

 to be orthogonal to both 
\begin_inset Formula $\mathbf{v}_{1}$
\end_inset

 and 
\begin_inset Formula $\mathbf{v}_{2}$
\end_inset

.
 Since we already arranged that 
\begin_inset Formula $\mathbf{v_{1}\cdot}\mathbf{v}_{2}=0$
\end_inset

, this requires:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
0=\mathbf{v}_{3}\cdot\mathbf{v}_{1} & =(\mathbf{w}_{3}\cdot\mathbf{v}_{1})-c_{1}\left\Vert \mathbf{v}_{1}\right\Vert ^{2}\\
0=\mathbf{v}_{3}\cdot\mathbf{v}_{2} & =(\mathbf{w}_{3}\cdot\mathbf{v}_{2})-c_{2}\left\Vert \mathbf{v}_{2}\right\Vert ^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
And hence:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
c_{1} & =\frac{\mathbf{w}_{3}\cdot\mathbf{v}_{1}}{\left\Vert \mathbf{v}_{1}\right\Vert ^{2}}\\
c_{2} & =\frac{\mathbf{w}_{3}\cdot\mathbf{v}_{2}}{\left\Vert \mathbf{v}_{2}\right\Vert ^{2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Therefore the next orthogonal basis vector is given by the formula:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{v}_{3} & =\mathbf{w}_{3}-\frac{\mathbf{w}_{3}\cdot\mathbf{v}_{1}}{\left\Vert \mathbf{v}_{1}\right\Vert ^{2}}\mathbf{v}_{1}-\frac{\mathbf{w}_{3}\cdot\mathbf{v}_{2}}{\left\Vert \mathbf{v}_{2}\right\Vert ^{2}}\mathbf{v}_{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $\mathbf{v}_{1}$
\end_inset

 and 
\begin_inset Formula $\mathbf{v}_{2}$
\end_inset

 are linear combinations of 
\begin_inset Formula $\mathbf{w}_{1}$
\end_inset

 and 
\begin_inset Formula $\mathbf{w}_{2}$
\end_inset

, we must have that 
\begin_inset Formula $\mathbf{v}_{3}\neq\mathbf{0}$
\end_inset

, since otherwise this would imply that 
\begin_inset Formula $\mathbf{w}_{3}$
\end_inset

 can be written as a linear combination of 
\begin_inset Formula $\mathbf{w}_{1}$
\end_inset

 and 
\begin_inset Formula $\mathbf{w}_{2}$
\end_inset

 making them linearly dependent.
 
\end_layout

\begin_layout Standard
Continuing in the same manner, suppose we have already constructed the mutually
 orthogonal vectors 
\begin_inset Formula $\mathbf{v}_{1},\ldots,\mathbf{v}_{k-1}$
\end_inset

 as linear combinations of 
\begin_inset Formula $\mathbf{w}_{1},\ldots,\mathbf{w}_{k-1}$
\end_inset

.
 The next orthogonal basis element 
\begin_inset Formula $\mathbf{v}_{k}$
\end_inset

 will be obtained from 
\begin_inset Formula $\mathbf{w}_{k}$
\end_inset

 by subtracting a suitable linear combination of the previous orthogonal
 basis elements.
 In this fashion we establish the general 
\emph on
Gram-Schmidt
\emph default
 formula - 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{v}_{k}=\mathbf{w}_{k}-\sum_{j=1}^{k-1}\frac{\mathbf{w}_{k}\cdot\mathbf{v}_{j}}{\left\Vert \mathbf{v}_{j}\right\Vert ^{2}}\mathbf{v}_{j}\label{eq:gram-schmidt-formula}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
If we are after an orthonormal basis 
\begin_inset Formula $\mathbf{u}_{1},\ldots,\mathbf{u}_{n}$
\end_inset

 we merely normalize the resulting orthogonal basis vectors, setting 
\begin_inset Formula $\mathbf{u}_{k}=\frac{\mathbf{v}_{k}}{\left\Vert \mathbf{v}_{k}\right\Vert }$
\end_inset

.
 
\end_layout

\begin_layout Subsubsection
Modifications of the Gram-Schmidt process.
\end_layout

\begin_layout Standard
With the basic Gram-Schmidt algorithm now in hand, it is worth looking at
 a couple of reformulations that have both practical and theoretical advantages.
 The first can be used to construct orthonormal basis vectors 
\begin_inset Formula $\mathbf{u}_{1},\mathbf{u}_{2},\ldots,\mathbf{u}_{n}$
\end_inset

 directly from the basis 
\begin_inset Formula $\mathbf{w}_{1},\ldots,\mathbf{w}_{n}$
\end_inset

.
\end_layout

\begin_layout Standard
We begin by replacing each orthogonal basis vector in the basic Gram-Schmidt
 formula (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:gram-schmidt-formula"
plural "false"
caps "false"
noprefix "false"

\end_inset

) by its normalized version 
\begin_inset Formula $\mathbf{u}_{j}=\mathbf{v}_{j}/\left\Vert \mathbf{v}_{j}\right\Vert $
\end_inset

.
 The original basis vectors can be expressed in terms of the orthonormal
 basis via a triangular system.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\begin{aligned}\mathbf{w}_{1} & =r_{11}\mathbf{u}_{1}\\
\mathbf{w}_{2} & =r_{12}\mathbf{u}_{1}+r_{22}\mathbf{u}_{2}\\
\mathbf{w}_{3} & =r_{13}\mathbf{u}_{1}+r_{23}\mathbf{u}_{2}+r_{33}\mathbf{u}_{3}\\
\vdots\\
\mathbf{w}_{n} & =r_{1n}\mathbf{u}_{1}+r_{2n}\mathbf{u}_{2}+r_{3n}\mathbf{u}_{3}+\ldots+r_{nn}\mathbf{u}_{n}
\end{aligned}
\label{eq:gram-schmidt-equations}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The coefficients 
\begin_inset Formula $r_{ij}$
\end_inset

 can, in fact, be computed directly from these formulas.
 Indeed taking, the inner product of the equation for 
\begin_inset Formula $\mathbf{w}_{j}$
\end_inset

 with the orthonormal basis vector 
\begin_inset Formula $\mathbf{u}_{i}$
\end_inset

 for 
\begin_inset Formula $i\leq j$
\end_inset

, we obtain in view of the orthonormality constraints:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{w}_{j}\cdot\mathbf{u}_{i} & =r_{1j}\mathbf{u}_{1}\cdot\mathbf{u}_{i}+\ldots+r_{ij}\mathbf{u}_{i}\cdot\mathbf{u}_{i}+\ldots+r_{jj}\mathbf{u}_{j}\cdot\mathbf{u}_{i}\\
 & =r_{ij}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
and hence:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
r_{ij}=\left\langle \mathbf{w}_{j},\mathbf{u}_{i}\right\rangle \label{eq:modified-gram-schmidt-eq1}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
On the other hand, we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\begin{aligned}\left\Vert \mathbf{w}_{j}\right\Vert ^{2} & =\left\Vert r_{1j}\mathbf{u}_{1}+r_{2j}\mathbf{u}_{2}+\ldots+r_{jj}\mathbf{u}_{j}\right\Vert ^{2}\\
 & =r_{1j}^{2}+r_{2j}^{2}+\ldots+r_{jj}^{2}
\end{aligned}
\label{eq:modified-gram-schmidt-eq2}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The pair of equations (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:modified-gram-schmidt-eq1"
plural "false"
caps "false"
noprefix "false"

\end_inset

) and (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:modified-gram-schmidt-eq2"
plural "false"
caps "false"
noprefix "false"

\end_inset

) can be rearranged to devise a recursive procedure to compute the orthonormal
 basis.
 We begin by setting 
\begin_inset Formula $r_{11}=\left\Vert \mathbf{w}_{1}\right\Vert $
\end_inset

 and so 
\begin_inset Formula $\mathbf{u}_{1}=\mathbf{w}_{1}/r_{11}$
\end_inset

.
 At each subsequent stage, 
\begin_inset Formula $j\geq2$
\end_inset

, we assume that we have already constructed 
\begin_inset Formula $\mathbf{u}_{1},\ldots,\mathbf{u}_{j-1}$
\end_inset

.
 We then compute 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
r_{ij}=\left\langle \mathbf{w}_{j},\mathbf{u}_{i}\right\rangle \quad\text{for each }\quad i=1,2,\ldots,j-1
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
We obtain next the orthonormal basis vector 
\begin_inset Formula $\mathbf{u}_{j}$
\end_inset

 by computing 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\begin{aligned}r_{jj} & =\sqrt{\left\Vert \mathbf{w}_{j}\right\Vert ^{2}-r_{1j}^{2}-r_{2j}^{2}-\ldots-r_{j-1,j}^{2}}\\
\mathbf{u}_{j} & =\frac{\mathbf{w}_{j}-r_{1j}\mathbf{u}_{1}-r_{2j}\mathbf{u}_{2}-\ldots-r_{j-1,j}\mathbf{u}_{j-1}}{r_{jj}}
\end{aligned}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
The QR Factorization.
\end_layout

\begin_layout Standard
The Gram-Schmidt procedure for orthonormalizing bases of 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

 can be reinterpreted as a matrix factorization.
 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\mathbf{w}_{1},\ldots,\mathbf{w}_{n}$
\end_inset

 be a basis of 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

, and let 
\begin_inset Formula $\mathbf{u}_{1},\ldots,\mathbf{u}_{n}$
\end_inset

 be the corresponding orthonormal basis that results from any one of the
 implementations of the Gram-Schmidt process.
 We assemble both sets of column vectors to form non-singular 
\begin_inset Formula $n\times n$
\end_inset

 matrices:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
A=\left[\begin{array}{cccc}
\mathbf{w}_{1} & \mathbf{w}_{2} & \ldots & \mathbf{w}_{n}\end{array}\right],\quad Q=\left[\begin{array}{cccc}
\mathbf{u}_{1} & \mathbf{u}_{2} & \ldots & \mathbf{u}_{n}\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Standard
Since the 
\begin_inset Formula $\mathbf{u}_{i}$
\end_inset

 form an orthonormal basis, 
\begin_inset Formula $Q$
\end_inset

 is an orthogonal matrix.
 In view of the matrix multiplication formula, the Gram-Schmidt equations
 (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:gram-schmidt-equations"
plural "false"
caps "false"
noprefix "false"

\end_inset

) can be recast into an equivalent matrix form:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
A & =\left[\begin{array}{cccc}
\mathbf{u}_{1} & \mathbf{u}_{2} & \ldots & \mathbf{u}_{n}\end{array}\right]\left[\begin{array}{ccccc}
r_{11} & r_{12} & r_{13} & \ldots & r_{1n}\\
 & r_{22} & r_{23} & \ldots & r_{2n}\\
 &  & r_{33} & \ldots & r_{3n}\\
 &  &  & \ddots\\
 &  &  & \ldots & r_{nn}
\end{array}\right]\\
 & =QR
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Since the Gram-Schmidt algorithm works on any basis, the only requirement
 on the matrix 
\begin_inset Formula $A$
\end_inset

 is that it's columns are linearly-independent and form a basis of 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

, and hence 
\begin_inset Formula $A$
\end_inset

 can be any non-singular matrix.
 We have therefore established the celebrated 
\begin_inset Formula $QR$
\end_inset

-factorization of non-singular matrices.
 
\end_layout

\begin_layout Theorem
Every non-singular matrix 
\begin_inset Formula $A$
\end_inset

 can be factored, 
\begin_inset Formula $A=QR$
\end_inset

 into the product of an orthogonal matrix 
\begin_inset Formula $Q$
\end_inset

 and an upper triangular matrix 
\begin_inset Formula $R$
\end_inset

.
 
\end_layout

\begin_layout Subsubsection
Numerically stable implementation of QR-Factorization.
\end_layout

\begin_layout Standard
We take a slightly different approach to generating orthogonal vectors 
\begin_inset Formula $\mathbf{u}_{1},\ldots,\mathbf{u}_{n}$
\end_inset

.
 Define:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{w}_{1}^{(1)} & =r_{11}\mathbf{u}_{1}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
and define the 
\begin_inset Formula $j$
\end_inset

th iterate of the procedure as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{w}_{k}^{(j)} & =r_{1k}\mathbf{u}_{1}+r_{2k}\mathbf{u}_{2}+\ldots+r_{jk}\mathbf{u}_{j},\quad j\leq k
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Observe that:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left\langle \mathbf{w}_{k}^{(j)},\mathbf{u}_{j}\right\rangle  & =r_{jk}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can treat all vectors simultaneously instead of sequentially and compute
 in the 
\begin_inset Formula $j=1$
\end_inset

st iteration:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{u}_{1} & =\mathbf{w}_{1}/r_{11}\\
\mathbf{w}_{2}^{(2)} & =\left(\mathbf{w}_{2}^{(1)}-\left\langle \mathbf{w}_{2}^{(1)},\mathbf{u}_{1}\right\rangle \mathbf{u}_{1}\right)\\
\mathbf{w}_{3}^{(2)} & =\left(\mathbf{w}_{3}^{(1)}-\left\langle \mathbf{w}_{3}^{(1)},\mathbf{u}_{1}\right\rangle \mathbf{u}_{1}\right)\\
\vdots\\
\mathbf{w}_{n}^{(2)} & =\left(\mathbf{w}_{n}^{(1)}-\left\langle \mathbf{w}_{n}^{(1)},\mathbf{u}_{1}\right\rangle \mathbf{u}_{1}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Note that, the updated vectors 
\begin_inset Formula $\mathbf{w}_{2}^{(2)},\mathbf{w}_{3}^{(2)},\ldots,\mathbf{w}_{n}^{(2)}$
\end_inset

 are orthogonal to 
\begin_inset Formula $\mathbf{u}_{1}$
\end_inset

.
 
\end_layout

\begin_layout Standard
In the 
\begin_inset Formula $j=2$
\end_inset

nd iteration, we compute:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{u}_{2} & =\mathbf{w}_{2}^{(2)}/r_{22}\\
\mathbf{w}_{3}^{(3)} & =\left(\mathbf{w}_{3}^{(2)}-\left\langle \mathbf{w}_{3}^{(2)},\mathbf{u}_{2}\right\rangle \mathbf{u}_{2}\right)\\
\mathbf{w}_{4}^{(3)} & =\left(\mathbf{w}_{4}^{(2)}-\left\langle \mathbf{w}_{4}^{(2)},\mathbf{u}_{2}\right\rangle \mathbf{u}_{2}\right)\\
\vdots\\
\mathbf{w}_{n}^{(3)} & =\left(\mathbf{w}_{n}^{(2)}-\left\langle \mathbf{w}_{n}^{(2)},\mathbf{u}_{2}\right\rangle \mathbf{u}_{2}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $\mathbf{w}_{2}^{(2)}$
\end_inset

 was orthogonal to 
\begin_inset Formula $\mathbf{u}_{1}$
\end_inset

, 
\begin_inset Formula $\mathbf{u}_{2}$
\end_inset

 must also be orthogonal to 
\begin_inset Formula $\mathbf{u}_{1}$
\end_inset

.
 Further, 
\begin_inset Formula $\mathbf{w}_{3}^{(3)},\ldots,\mathbf{w}_{3}^{(n)}$
\end_inset

 are orthogonal to both 
\begin_inset Formula $\mathbf{u}_{1}$
\end_inset

, 
\begin_inset Formula $\mathbf{u}_{2}$
\end_inset

.
 
\end_layout

\begin_layout Standard
In particular, in the 
\begin_inset Formula $j$
\end_inset

th iteration we compute:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{u}_{j} & =\mathbf{w}_{j}^{(j)}/r_{jj}\\
\mathbf{w}_{j+1}^{(j+1)} & =\left(\mathbf{w}_{j+1}^{(j)}-\left\langle \mathbf{w}_{j+1}^{(j)},\mathbf{u}_{j}\right\rangle \mathbf{u}_{j}\right)\\
\mathbf{w}_{j+2}^{(j+1)} & =\left(\mathbf{w}_{j+2}^{(j)}-\left\langle \mathbf{w}_{j+2}^{(j)},\mathbf{u}_{j}\right\rangle \mathbf{u}_{j}\right)\\
\vdots\\
\mathbf{w}_{n}^{(j+1)} & =\left(\mathbf{w}_{n}^{(j)}-\left\langle \mathbf{w}_{n}^{(j)},\mathbf{u}_{j}\right\rangle \mathbf{u}_{j}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can summarize the above steps as follows.
 We iterate 
\begin_inset Formula $j=1$
\end_inset

 to 
\begin_inset Formula $n$
\end_inset

.
 For 
\begin_inset Formula $j=1$
\end_inset

, we start with the initial basis 
\begin_inset Formula $\mathbf{w}_{k}^{(1)}=\mathbf{w}_{k}$
\end_inset

, and set 
\begin_inset Formula $\mathbf{u}_{1}=\mathbf{w}_{1}^{(1)}/r_{11}$
\end_inset

.
 
\end_layout

\begin_layout Standard
In the 
\begin_inset Formula $j$
\end_inset

th iteration, we set 
\begin_inset Formula $\mathbf{u}_{j}=\mathbf{w}_{j}^{(j)}/r_{jj}$
\end_inset

 and for all 
\begin_inset Formula $k=j+1$
\end_inset

 to 
\begin_inset Formula $n$
\end_inset

, we let 
\begin_inset Formula $\mathbf{w}_{k}^{(j+1)}=\mathbf{w}_{k}^{(j)}-\left\langle \mathbf{w}_{k}^{(j)},\mathbf{u}_{j}\right\rangle \mathbf{u}_{j}$
\end_inset

.
 Also, we set 
\begin_inset Formula $r_{jk}=\left\langle \mathbf{w}_{k}^{(j)},\mathbf{u}_{j}\right\rangle $
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{language=C++,backgroundcolor=
\backslash
color{backcolour},breaklines=true,commentstyle=
\backslash
color{codegreen},stringstyle=
\backslash
color{magenta},keywordstyle=
\backslash
bfseries
\backslash
color{blue!40!black},basicstyle=
\backslash
footnotesize
\backslash
ttfamily,frame=single}
\end_layout

\begin_layout Plain Layout


\backslash
begin{lstlisting}[caption=QR Factorization] 
\end_layout

\begin_layout Plain Layout

#include <iostream>
\end_layout

\begin_layout Plain Layout

#include <Eigen/Dense>
\end_layout

\begin_layout Plain Layout

#include <tuple>
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

using namespace Eigen;
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

std::pair<MatrixXd,MatrixXd> qrFactorization(MatrixXd& A)
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

    int n = A.rows();
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    // A = [w_1,w_2,...,w_n] = [u_1 u_2 ...u_n]R = QR
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    MatrixXd Q = MatrixXd::Zero(n,n);
\end_layout

\begin_layout Plain Layout

    MatrixXd R = MatrixXd::Zero(n,n);
\end_layout

\begin_layout Plain Layout

    
\end_layout

\begin_layout Plain Layout

    //We proceed iteratively and build the column vectors u_0, u_1, ...
 u_{n-1}
\end_layout

\begin_layout Plain Layout

    for (int j{ 0 }; j < n; ++j)
\end_layout

\begin_layout Plain Layout

    {
\end_layout

\begin_layout Plain Layout

        // The scalar r_jj = ||w_j^(j)||
\end_layout

\begin_layout Plain Layout

        for (int i{ 0 }; i < n; ++i)
\end_layout

\begin_layout Plain Layout

            R(j, j) += A(i, j) * A(i, j);
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        R(j, j) = sqrt(R(j, j));
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        // u_j = w_j / r_jj 
\end_layout

\begin_layout Plain Layout

        for (int i{ 0 };i < n; ++i)
\end_layout

\begin_layout Plain Layout

        {
\end_layout

\begin_layout Plain Layout

            Q(i, j) = A(i,j) / R(j, j);
\end_layout

\begin_layout Plain Layout

        }
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        for (int k{ j + 1 }; k < n; ++k)
\end_layout

\begin_layout Plain Layout

        {
\end_layout

\begin_layout Plain Layout

            // Dot product of <w_k^(j),u_j>
\end_layout

\begin_layout Plain Layout

            for (int i{ 0 }; i < n; ++i)
\end_layout

\begin_layout Plain Layout

            {
\end_layout

\begin_layout Plain Layout

                R(j,k) += A(i, k) * Q(i, j);
\end_layout

\begin_layout Plain Layout

            }
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

            // w_k^(j+1) = w_k^(j) - <w_k^(j),u_j> u_j
\end_layout

\begin_layout Plain Layout

            for (int i{ 0 }; i < n; ++i)
\end_layout

\begin_layout Plain Layout

            {
\end_layout

\begin_layout Plain Layout

                A(i, k) = A(i, k) - R(j,k) * Q(i, j);
\end_layout

\begin_layout Plain Layout

            }
\end_layout

\begin_layout Plain Layout

        }
\end_layout

\begin_layout Plain Layout

    }
\end_layout

\begin_layout Plain Layout

    return std::make_pair(Q, R);
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout


\backslash
end{lstlisting}
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Gram Matrices.
\end_layout

\begin_layout Standard
Symmetric matrices whose entries are given by the inner products of elements
 of an inner product space are called 
\emph on
Gram matrices, 
\emph default
after the Danish mathematician 
\emph on
Jorgen Gram
\emph default
.
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $V$
\end_inset

 be an inner product space, and let 
\begin_inset Formula $\mathbf{v}_{1},\ldots,\mathbf{v}_{n}\in V$
\end_inset

.
 The associated 
\emph on
Gram matrix
\emph default
 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
K & =\left[\begin{array}{cccc}
\left\langle \mathbf{v}_{1},\mathbf{v}_{1}\right\rangle  & \left\langle \mathbf{v}_{1},\mathbf{v}_{2}\right\rangle  & \ldots & \left\langle \mathbf{v}_{1},\mathbf{v}_{n}\right\rangle \\
\left\langle \mathbf{v}_{2},\mathbf{v}_{1}\right\rangle  & \left\langle \mathbf{v}_{2},\mathbf{v}_{2}\right\rangle  & \ldots & \left\langle \mathbf{v}_{2},\mathbf{v}_{n}\right\rangle \\
\vdots & \vdots & \ddots & \vdots\\
\left\langle \mathbf{v}_{n},\mathbf{v}_{1}\right\rangle  & \left\langle \mathbf{v}_{n},\mathbf{v}_{2}\right\rangle  & \ldots & \left\langle \mathbf{v}_{n},\mathbf{v}_{n}\right\rangle 
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
is the 
\begin_inset Formula $n\times n$
\end_inset

 symmetric matrix whose entries are the inner-products between the selected
 vector space elements.
 
\end_layout

\begin_layout Theorem
All Gram matrices are positive semi-definite.
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $K$
\end_inset

 be an arbitrary Gram matrix.
 To prove the positive semi-definiteness of 
\begin_inset Formula $K$
\end_inset

, we need to examine the associated quadratic form:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
q(\mathbf{x}) & =\mathbf{x}'K\mathbf{x}\\
 & =\sum_{i=1}^{n}\sum_{j=1}^{n}k_{ij}x_{i}x_{j}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
But, 
\begin_inset Formula $k_{ij}=\left\langle \mathbf{v}_{i},\mathbf{v}_{j}\right\rangle $
\end_inset

.
 Substituting the values for the matrix entries, we obtain:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
q(\mathbf{x}) & =\sum_{i=1}^{n}\sum_{j=1}^{n}\left\langle \mathbf{v}_{i},\mathbf{v}_{j}\right\rangle x_{i}x_{j}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
For intuition, let's choose 
\begin_inset Formula $n=2$
\end_inset

.
 The quadratic form becomes:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
q(\mathbf{x}) & =\left\langle \mathbf{v}_{1},\mathbf{v}_{1}\right\rangle x_{1}^{2}+\left\langle \mathbf{v}_{1},\mathbf{v}_{2}\right\rangle x_{1}x_{2}+\left\langle \mathbf{v}_{2},\mathbf{v}_{1}\right\rangle x_{2}x_{1}+\left\langle \mathbf{v}_{2},\mathbf{v}_{1}\right\rangle x_{2}^{2}\\
 & =\left\langle x_{1}\mathbf{v}_{1}+x_{2}\mathbf{v}_{2},x_{1}\mathbf{v}_{1}+x_{2}\mathbf{v}_{1}\right\rangle  & \{\text{Bi-linearity of inner products}\}\\
 & =\left\Vert x_{1}\mathbf{v}_{1}+x_{2}\mathbf{v}_{2}\right\Vert ^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Therefore, we can write the original quadratic form as a single inner product:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
q(\mathbf{x}) & =\left\langle \sum_{i=1}^{n}x_{i}\mathbf{v}_{i},\sum_{j=1}^{n}x_{j}\mathbf{v}_{j}\right\rangle \\
 & =\left\Vert \sum_{i=1}^{n}x_{i}\mathbf{v}_{i}\right\Vert ^{2}\\
 & =\left\Vert \mathbf{v}\right\Vert ^{2} & \{\text{Norm }\left\Vert \cdot\right\Vert \text{ is positive semi-definite}\}\\
 & \geq0
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection
Positive Definiteness.
\end_layout

\begin_layout Standard
Gram matrices furnish us with an almost inexhaustible supply of positive
 semi-definite matrices.
 However, we still do not know how to test whether a given symmetric matrix
 is positive definite.
 
\end_layout

\begin_layout Standard
From elementary school, we recall the algebraic technique known as 
\emph on
completing the square
\emph default
, first arising in the derivation of the formula for the solution to the
 quadratic equation
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
q(x)=ax^{2}+2bx+c=0\label{eq:quadratic_equation}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The idea is to combine the first two terms in the equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:quadratic_equation"
plural "false"
caps "false"
noprefix "false"

\end_inset

) to form a perfect square and thereby rewrite the quadratic function in
 the form :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
q(x) & =a\left[x^{2}+2\frac{b}{a}x+\frac{c}{a}\right]\\
 & =a\left[x^{2}+2x\cdot\frac{b}{a}+\left(\frac{b}{a}\right)^{2}+\frac{c}{a}-\left(\frac{b}{a}\right)^{2}\right]\\
 & =a\left[\left(x+\frac{b}{a}\right)^{2}+\frac{ac-b^{2}}{a^{2}}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
As a consequence,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left(x+\frac{b}{a}\right)^{2} & =\frac{b^{2}-ac}{a^{2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The familiar 
\emph on
quadratic formula
\emph default
:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
x & =\frac{-b\pm\sqrt{b^{2}-ac}}{a}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
follows by taking the square root on both sides and then solving for 
\begin_inset Formula $x$
\end_inset

.
 
\end_layout

\begin_layout Standard
We can perform the same kind of manipulation on a homogenous quadratic form:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
q(x_{1},x_{2})=ax_{1}^{2}+2bx_{1}x_{2}+cx_{2}^{2}\label{eq:original_quadratic_form}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
In this case, provided 
\begin_inset Formula $a\neq0$
\end_inset

, completing the square amounts to writing:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\begin{split}q(x_{1},x_{2}) & =ax_{1}^{2}+2bx_{1}x_{2}+cx_{2}^{2}\\
 & =a\left[x_{1}^{2}+2x_{1}\cdot\frac{b}{a}x_{2}+\left(\frac{b}{a}x_{2}\right)^{2}+\frac{c}{a}x_{2}^{2}-\frac{b^{2}}{a^{2}}x_{2}^{2}\right]\\
 & =a\left[\left(x_{1}+\frac{b}{a}x_{2}\right)^{2}+\frac{ac-b^{2}}{a^{2}}x_{2}^{2}\right]\\
 & =ay_{1}^{2}+\frac{ac-b^{2}}{a}y_{2}^{2}
\end{split}
\label{eq:completing_the_square}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The net result is to re-express 
\begin_inset Formula $q(x_{1},x_{2})$
\end_inset

 as a simpler sum of squares of the new variables:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
y_{1}=x_{1}+\frac{b}{a}x_{2},\quad y_{2}=x_{2}\label{eq:new_variables_quadratic_form}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
It is not hard to see that the final expression in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:completing_the_square"
plural "false"
caps "false"
noprefix "false"

\end_inset

) is positive definite, as a function of 
\begin_inset Formula $y_{1}$
\end_inset

 and 
\begin_inset Formula $y_{2}$
\end_inset

 if and only if both coefficients are positive:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
a>0,\quad\frac{ac-b^{2}}{a}>0
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Our goal is to adapt this simple idea to analyse the positive semi-definiteness
 of quadratic forms depending on more than two variables.
 To this end, let us write the quadratic form identity in the matrix form.
 The original quadratic form in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:original_quadratic_form"
plural "false"
caps "false"
noprefix "false"

\end_inset

) can be written as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
q(\mathbf{x}) & =\mathbf{x}'K\mathbf{x}\\
 & =\left[\begin{array}{cc}
x_{1} & x_{2}\end{array}\right]\left[\begin{array}{cc}
a & b\\
b & c
\end{array}\right]\left[\begin{array}{c}
x_{1}\\
x_{2}
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Similarly, the right hand side of (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:completing_the_square"
plural "false"
caps "false"
noprefix "false"

\end_inset

) can be written as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\hat{q}(\mathbf{y})=\mathbf{y}'D\mathbf{y},\quad\text{where}\quad D=\left[\begin{array}{cc}
a & 0\\
0 & \frac{ac-b^{2}}{a}
\end{array}\right],\quad\mathbf{y}=\left[\begin{array}{c}
y_{1}\\
y_{2}
\end{array}\right]\label{eq:quadratic_form_in_y}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Anticipating the final result, the equations (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:new_variables_quadratic_form"
plural "false"
caps "false"
noprefix "false"

\end_inset

) connecting 
\begin_inset Formula $\mathbf{x}$
\end_inset

 and 
\begin_inset Formula $\mathbf{y}$
\end_inset

 can themselves be written in the matrix form as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{y}=L'\mathbf{x}\quad\text{or}\quad\left[\begin{array}{c}
y_{1}\\
y_{2}
\end{array}\right]=\left[\begin{array}{c}
x_{1}+\frac{b}{a}x_{2}\\
x_{2}
\end{array}\right],\quad\text{where}\quad L'=\left[\begin{array}{cc}
1 & 0\\
b/a & 1
\end{array}\right]
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Substituting 
\begin_inset Formula $\mathbf{y}$
\end_inset

into (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:quadratic_form_in_y"
plural "false"
caps "false"
noprefix "false"

\end_inset

), we obtain:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mathbf{y}'D\mathbf{y}=(L'\mathbf{x})'D(L'\mathbf{x})=\mathbf{x}'LDL'\mathbf{x}=\mathbf{x}'K\mathbf{x},\quad\text{where }\quad K=LDL'\label{eq:ldl-transpose-factorization}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
We are thus led to the realization that completing the square is the same
 as the 
\begin_inset Formula $LDL'$
\end_inset

 factorization of a symmetric matrix 
\begin_inset Formula $K$
\end_inset

.
\end_layout

\begin_layout Standard
From basic algebra, we know that, if 
\begin_inset Formula $A$
\end_inset

 is a non-singular matrix, with all it's pivot elements 
\begin_inset Formula $a_{kk}^{(k)}$
\end_inset

 non-zero in the Gaussian elimination process, then 
\begin_inset Formula $A=LDU$
\end_inset

 where 
\begin_inset Formula $L$
\end_inset

 and 
\begin_inset Formula $U$
\end_inset

 are lower and upper uni-triangular matrices and 
\begin_inset Formula $D$
\end_inset

 is a diagonal matrix consisting of the pivots of 
\begin_inset Formula $A$
\end_inset

.
 If the matrix is symmetric, then it admits the unique factorization 
\begin_inset Formula $LDL'$
\end_inset

.
\end_layout

\begin_layout Standard
The identity (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ldl-transpose-factorization"
plural "false"
caps "false"
noprefix "false"

\end_inset

) is therefore valid for all real symmetric matrices that are non-singular
 and can be reduced to an upper triangular matrix by performing elementary
 row operations (without row interchanges).
 It also shows how to write the associated quadratic form as a sum of squares:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
q(\mathbf{x})=\mathbf{x}'K\mathbf{x}=\mathbf{y}'D\mathbf{y}=d_{1}y_{1}^{2}+d_{2}y_{2}^{2}+\ldots+d_{n}y_{n}^{2}\quad\text{where}\quad\mathbf{y}=L'\mathbf{x}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The coefficients 
\begin_inset Formula $d_{i}$
\end_inset

 are the diagonal entries of 
\begin_inset Formula $D$
\end_inset

, which are the pivots of 
\begin_inset Formula $K$
\end_inset

.
 The diagonal quadratic form is positive definite, 
\begin_inset Formula $\mathbf{y}'D\mathbf{y}>0$
\end_inset

 for all 
\begin_inset Formula $\mathbf{y}\neq\mathbf{0}$
\end_inset

 if and only if, when performing the Gaussian elimination process, all the
 pivots are positive.
 We can now add this to our list of standard results.
\end_layout

\begin_layout Theorem
(Positive Definiteness) Let 
\begin_inset Formula $K$
\end_inset

 be a 
\begin_inset Formula $n\times n$
\end_inset

 real symmetric positive definite (SPD) matrix.
 Then the following statements are equivalent.
\end_layout

\begin_layout Theorem
(i) 
\begin_inset Formula $K$
\end_inset

 is non-singular and can be reduced to an upper triangular matrix by performing
 elementary row operations (without row permutations), and it has positive
 pivot elements when performing Gaussian elimination.
\end_layout

\begin_layout Theorem
(ii) 
\begin_inset Formula $K$
\end_inset

 admits a factorization 
\begin_inset Formula $K=LDL'$
\end_inset

, where 
\begin_inset Formula $D=diag(d_{1},\ldots,d_{n})$
\end_inset

 such that 
\begin_inset Formula $d_{i}>0$
\end_inset

 for all 
\begin_inset Formula $i=1,2,3,\ldots,n$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Cholesky Factorization.
\end_layout

\begin_layout Standard
The identity (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ldl-transpose-factorization"
plural "false"
caps "false"
noprefix "false"

\end_inset

) shows us how to write an arbitrary regular quadratic form 
\begin_inset Formula $q(\mathbf{x})$
\end_inset

 as linear combination of squares.
 We can push this result slightly further in the positive definite case.
 Since each pivot 
\begin_inset Formula $d_{i}$
\end_inset

 is positive, we can write the quadratic form as a sum of squares:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
d_{1}y_{1}^{2}+d_{2}y_{2}^{2}+\ldots+d_{n}y_{n}^{2} & =(\sqrt{d_{1}}y_{1})^{2}+(\sqrt{d_{2}}y_{2})^{2}+\ldots+(\sqrt{d_{n}}y_{n})^{2}\\
 & =z_{1}^{2}+z_{2}^{2}+\ldots+z_{n}^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $z_{i}=\sqrt{d_{i}}y_{i}$
\end_inset

.
 In the matrix form, we are writing:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\hat{q}(\mathbf{y}) & =\mathbf{y}'D\mathbf{y}\\
 & =\mathbf{z}'\mathbf{z}\\
 & =\left\Vert \mathbf{z}\right\Vert ^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\mathbf{z}=S\mathbf{y}$
\end_inset

, with 
\begin_inset Formula $S=diag(\sqrt{d_{1}},\sqrt{d_{2}},\ldots,\sqrt{d_{n}})$
\end_inset

.
 Since 
\begin_inset Formula $D=S^{2}$
\end_inset

, the matrix 
\begin_inset Formula $S$
\end_inset

 can be thought of as a square root of the diagonal matrix 
\begin_inset Formula $D$
\end_inset

.
 Substituting back into the equation 
\begin_inset Formula $K=LDL'$
\end_inset

, we deduce the 
\emph on
Cholesky factorization:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
K & =LDL'\\
 & =LSS'L'\\
 & =LS(LS)'\\
 & =MM'
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
of a positive definite matrix, first proposed by the early twentieth-century
 French geographer Andrew Louis Cholesky for solving problems in geodetic
 surveying.
 Note that, 
\begin_inset Formula $M$
\end_inset

 is a lower triangular matrix with all positive diagonal entries, namely
 the square roots of the pivots: 
\begin_inset Formula $m_{ii}=\sqrt{d_{i}}$
\end_inset

.
 
\end_layout

\begin_layout Example
Let the matrix 
\begin_inset Formula $K=\left[\begin{array}{ccc}
1 & 2 & -1\\
2 & 6 & 0\\
-1 & 0 & 9
\end{array}\right]$
\end_inset

.
 Let 
\begin_inset Formula $KX=I$
\end_inset

.
 We consider the augmented matrix 
\begin_inset Formula $\left[\begin{array}{ccc}
K & | & I\end{array}\right]$
\end_inset

.
 Performing Gaussian elimination, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\left[\begin{array}{ccccccc}
1 & 2 & -1 & | & 1 & 0 & 0\\
2 & 6 & 0 & | & 0 & 1 & 0\\
-1 & 0 & 9 & | & 0 & 0 & 1
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
The pivot element 
\begin_inset Formula $a_{11}^{(1)}=1$
\end_inset

.
 Performing 
\begin_inset Formula $R_{2}=R_{2}-2R_{1}$
\end_inset

and 
\begin_inset Formula $R_{3}=R_{3}+R_{1}$
\end_inset

, the above system is row-equivalent to:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\left[\begin{array}{ccccccc}
1 & 2 & -1 & | & 1 & 0 & 0\\
0 & 2 & 2 & | & -2 & 1 & 0\\
0 & 2 & 8 & | & 1 & 0 & 1
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
The pivot element 
\begin_inset Formula $a_{22}^{(2)}=2$
\end_inset

.
 Performing 
\begin_inset Formula $R_{3}=R_{3}-R_{2}$
\end_inset

, the above system is row-equivalent to:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\left[\begin{array}{ccccccc}
1 & 2 & -1 & | & 1 & 0 & 0\\
0 & 2 & 2 & | & -2 & 1 & 0\\
0 & 0 & 6 & | & 3 & -1 & 1
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
The pivot element 
\begin_inset Formula $a_{33}^{(3)}=6$
\end_inset

.
 We have now reduced the system to the form 
\begin_inset Formula $\left[\begin{array}{ccc}
DU & | & C\end{array}\right]$
\end_inset

, where 
\begin_inset Formula $U$
\end_inset

 is an upper uni-triangular matrix.
 Thus, Gaussian Elimination produces the factors:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
L=\left[\begin{array}{ccc}
1 & 0 & 0\\
2 & 1 & 0\\
-1 & 1 & 1
\end{array}\right],\quad D=\left[\begin{array}{ccc}
1 & 0 & 0\\
0 & 2 & 0\\
0 & 0 & 6
\end{array}\right],\quad L^{T}=\left[\begin{array}{ccc}
1 & 2 & -1\\
0 & 1 & 1\\
0 & 0 & 1
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
Thus,
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
M=LS=\left[\begin{array}{ccc}
1 & 0 & 0\\
2 & 1 & 0\\
-1 & 1 & 1
\end{array}\right]\left[\begin{array}{ccc}
1 & 0 & 0\\
0 & \sqrt{2} & 0\\
0 & 0 & \sqrt{6}
\end{array}\right]=\left[\begin{array}{ccc}
1 & 0 & 0\\
2 & \sqrt{2} & 0\\
-1 & \sqrt{2} & \sqrt{6}
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
and 
\begin_inset Formula $K=MM'$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
We conclude our discussion by observing the following:
\end_layout

\begin_layout Lemma
If a square matrix 
\begin_inset Formula $K$
\end_inset

 is SPD, it admits a Cholesky factorization of the form 
\begin_inset Formula $K=MM^{T}$
\end_inset

.
\end_layout

\begin_layout Example
Prove that, if 
\begin_inset Formula $K$
\end_inset

 is real SPD(symmetric positive definite matrix), then the diagonal elements
 of 
\begin_inset Formula $K$
\end_inset

 are positive.
\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $K$
\end_inset

 is real SPD, 
\begin_inset Formula $K$
\end_inset

 admits a factorization 
\begin_inset Formula $K=LL^{T}$
\end_inset

.
 Since the diagonal element 
\begin_inset Formula $(j,j)$
\end_inset

 is the inner product of the 
\begin_inset Formula $j$
\end_inset

-th row of 
\begin_inset Formula $L$
\end_inset

 and the 
\begin_inset Formula $j$
\end_inset

-th column of 
\begin_inset Formula $L^{T}$
\end_inset

, we have:
\begin_inset Formula 
\begin{align*}
k_{jj} & =\sum_{m=1}^{n}l_{jm}l'_{mj}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
But, 
\begin_inset Formula $l_{jm}=l'_{mj}$
\end_inset

, since 
\begin_inset Formula $L=\left(L^{T}\right)^{T}$
\end_inset

 .
 Hence, 
\begin_inset Formula $k_{jj}$
\end_inset

 is a sum of squares.
 Further, since the diagonal elements of 
\begin_inset Formula $L$
\end_inset

, that is, all elements 
\begin_inset Formula $l_{jj}$
\end_inset

 are strictly positive, the sum 
\begin_inset Formula $k_{jj}=l_{j1}^{2}+\ldots+l_{jj}^{2}+\ldots+l_{jn}^{2}>0$
\end_inset

.
 Consequently, the diagonal elements of 
\begin_inset Formula $K$
\end_inset

 are positive.
\end_layout

\begin_layout Subsubsection
Cholesky Factorization Algorithm.
\end_layout

\begin_layout Standard
We adopt the commonly used notation where Greek lower-case letters refer
 to scalars, lower-case letters refer to (column) vectors and upper case
 letters refer to matrices.
 The 
\begin_inset Formula $\star$
\end_inset

 refers to a part of 
\begin_inset Formula $A$
\end_inset

 that is neither stored nor updated.
 By substituting these partitioned matrices into 
\begin_inset Formula $A=LL'$
\end_inset

 we find that:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left[\begin{array}{cc}
\alpha_{11} & a_{21}^{T}\\
a_{21} & A_{22}
\end{array}\right] & =\left[\begin{array}{cc}
\lambda_{11} & 0\\
l_{21} & L_{22}
\end{array}\right]\left[\begin{array}{cc}
\lambda_{11} & l_{21}^{T}\\
0 & L_{22}^{T}
\end{array}\right]=\left[\begin{array}{cc}
\lambda_{11}^{2} & \star\\
\lambda_{11}l_{21} & l_{21}l_{21}^{T}+L_{22}L_{22}^{T}
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
so that :
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\alpha_{11}=\lambda_{11}^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\star$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a_{21}=\lambda_{11}l_{21}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A_{22}=l_{21}l_{21}^{T}+L_{22}L_{22}^{T}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
and hence:
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\lambda_{11}=\sqrt{a_{11}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\star$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $l_{21}=a_{21}/\lambda_{11}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $L_{22}=\text{Cholesky}(A_{22}-l_{21}l_{21}^{T})$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Standard
The last equality is clever.
 Essentially, if 
\begin_inset Formula $A_{22}=l_{21}l_{21}^{T}-L_{22}L_{22}^{T}$
\end_inset

, we must have: 
\begin_inset Formula $L_{22}L_{22}^{T}=A_{22}-l_{21}l_{21}^{T}$
\end_inset

.
 So, to find 
\begin_inset Formula $L_{22}$
\end_inset

, we recursively perform the cholesky factorization of the matrix 
\begin_inset Formula $A_{22}-l_{21}l_{21}^{T}$
\end_inset

.
 These equalities motivate the following block algorithm:
\end_layout

\begin_layout Standard
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Standard
1.
 Partition 
\begin_inset Formula $A=$
\end_inset


\begin_inset space \quad{}
\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\alpha_{11}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\star$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $a_{21}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $A_{22}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset

.
\end_layout

\begin_layout Standard
2.
 Overwrite 
\begin_inset Formula $\alpha_{11}:=\lambda_{11}=\sqrt{\alpha_{11}}$
\end_inset

.
\end_layout

\begin_layout Standard
3.
 Overwrite 
\begin_inset Formula $a_{21}:=l_{21}=a_{21}/\lambda_{11}$
\end_inset

.
\end_layout

\begin_layout Standard
4.
 Overwrite 
\begin_inset Formula $A_{22}:=A_{22}-l_{21}l_{21}^{T}$
\end_inset

.
\end_layout

\begin_layout Standard
5.
 Continue with 
\begin_inset Formula $A=A_{22}$
\end_inset

.
\end_layout

\begin_layout Standard
We can also implement a serial algorithm by multiplying out the matrices:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left[\begin{array}{cccc}
a_{11} & a_{21} & a_{31} & a_{41}\\
a_{21} & a_{22} & a_{32} & a_{42}\\
a_{31} & a_{32} & a_{33} & a_{43}\\
a_{41} & a_{42} & a_{43} & a_{44}
\end{array}\right] & =\left[\begin{array}{cccc}
l_{11} & 0 & 0 & 0\\
l_{21} & l_{22} & 0 & 0\\
l_{31} & l_{32} & l_{33} & 0\\
l_{41} & l_{42} & l_{43} & l_{44}
\end{array}\right]\left[\begin{array}{cccc}
l_{11} & l_{21} & l_{31} & l_{41}\\
0 & l_{22} & l_{32} & l_{42}\\
0 & 0 & l_{33} & l_{43}\\
0 & 0 & 0 & l_{44}
\end{array}\right]\\
 & =\left[\begin{array}{cccc}
l_{11}^{2}\\
l_{21}l_{11} & l_{21}^{2}+l_{22}^{2}\\
l_{31}l_{11} & l_{31}l_{21}+l_{32}l_{22} & l_{31}^{2}+l_{32}^{2}+l_{33}^{2}\\
l_{41}l_{11} & l_{41}l_{31}+l_{42}l_{32} & l_{41}l_{31}+l_{42}l_{32}+l_{43}l_{33} & l_{41}^{2}+l_{42}^{2}+l_{43}^{2}+l_{44}^{2}
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can thus solve for the elements of the matrix 
\begin_inset Formula $L$
\end_inset

, column-by-column.
 The expressions for 
\begin_inset Formula $l_{jj}$
\end_inset

 and 
\begin_inset Formula $l_{ij}$
\end_inset

 in general, are given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
l_{jj} & =\sqrt{a_{jj}-\sum_{k=1}^{j-1}l_{jk}^{2}}\\
l_{ij} & =\frac{1}{l_{jj}}(a_{ij}-\sum_{k=1}^{j-1}l_{ik}\cdot l_{jk}),\quad\forall i>j
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{language=C++,backgroundcolor=
\backslash
color{backcolour},breaklines=true,commentstyle=
\backslash
color{codegreen},stringstyle=
\backslash
color{magenta},keywordstyle=
\backslash
bfseries
\backslash
color{blue!40!black},basicstyle=
\backslash
footnotesize
\backslash
ttfamily,frame=single}
\end_layout

\begin_layout Plain Layout


\backslash
begin{lstlisting}[caption=Cholesky Factorization] 
\end_layout

\begin_layout Plain Layout

#include <iostream>
\end_layout

\begin_layout Plain Layout

#include <Eigen/Dense>
\end_layout

\begin_layout Plain Layout

#include <cmath>
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

using Eigen::MatrixXd;
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

// Cholesky-Crout algorithm starts from the upper-left corner of the matrix
 L and proceeds 
\end_layout

\begin_layout Plain Layout

// to calculate matrix column by column
\end_layout

\begin_layout Plain Layout

MatrixXd choleskyDecomposition(const MatrixXd& A)
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

    MatrixXd L = MatrixXd::Zero(A.rows(), A.cols());
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    for (int j{ 0 }; j < A.cols(); ++j)
\end_layout

\begin_layout Plain Layout

    {
\end_layout

\begin_layout Plain Layout

        double sum{ 0.0 };
\end_layout

\begin_layout Plain Layout

        for (int k{ 0 }; k < j; ++k)
\end_layout

\begin_layout Plain Layout

        {
\end_layout

\begin_layout Plain Layout

            sum += L(j, k) * L(j, k);
\end_layout

\begin_layout Plain Layout

        }
\end_layout

\begin_layout Plain Layout

        L(j, j) = sqrt(A(j, j) - sum);
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        for (int i{ j + 1 }; i < A.rows(); ++i)
\end_layout

\begin_layout Plain Layout

        {
\end_layout

\begin_layout Plain Layout

            double sum{ 0.0 };
\end_layout

\begin_layout Plain Layout

            for (int k{ 0 }; k < j; ++k) {
\end_layout

\begin_layout Plain Layout

                sum += L(i, k) * L(j, k);
\end_layout

\begin_layout Plain Layout

            }
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

            L(i, j) = (A(i, j) - sum)/L(j,j);
\end_layout

\begin_layout Plain Layout

        }
\end_layout

\begin_layout Plain Layout

    }
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    return L;
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

int main()
\end_layout

\begin_layout Plain Layout

{
\end_layout

\begin_layout Plain Layout

    MatrixXd K(3, 3);
\end_layout

\begin_layout Plain Layout

    
\end_layout

\begin_layout Plain Layout

    K <<    4, 12, -16,
\end_layout

\begin_layout Plain Layout

            12, 37, -43,
\end_layout

\begin_layout Plain Layout

            -16, -43, 98;
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    MatrixXd L = choleskyDecomposition(K);
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    std::cout << "The SPD(Symmetric Positive Definite) matrix K is : " <<
 std::endl;
\end_layout

\begin_layout Plain Layout

    std::cout << K << std::endl;
\end_layout

\begin_layout Plain Layout

    std::cout << "The Cholesky Decomposition of K into K=LL
\backslash
' yields L :" << std::endl;
\end_layout

\begin_layout Plain Layout

    std::cout << L << std::endl;
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    return 0;
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout


\backslash
end{lstlisting}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsubsection
Eigen-decomposition of real symmetric matrices.
\end_layout

\begin_layout Standard
We review couple of lemmas from basic algebra, which we shall need in the
 main result.
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lemma:extending_linearly_independent_seq_to_a_basis"

\end_inset

Every linearly independent sequence can be extended to a basis.
\end_layout

\begin_layout Lemma
Let 
\begin_inset Formula $V$
\end_inset

 be a finite-dimensional vector space and let 
\begin_inset Formula $\mathbf{l}_{1},\mathbf{l}_{2},\ldots,\mathbf{l}_{n}$
\end_inset

be linearly independent.
 Then, there exists a basis of 
\begin_inset Formula $V$
\end_inset

 containing 
\begin_inset Formula $\mathbf{l}_{1},\mathbf{l}_{2},\ldots,\mathbf{l}_{n}$
\end_inset

.
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $\mathscr{L}=\mathbf{l}_{1},\mathbf{l}_{2},\ldots,\mathbf{l}_{n}$
\end_inset

.
 Since 
\begin_inset Formula $V$
\end_inset

 is finite-dimensional, there exist elements 
\begin_inset Formula $\mathbf{v}_{1},\mathbf{v}_{2},\ldots,\mathbf{v}_{m}$
\end_inset

 of 
\begin_inset Formula $V$
\end_inset

 such that they span 
\begin_inset Formula $V$
\end_inset

.
\end_layout

\begin_layout Proof
Define a sequence of sequences of the elements of 
\begin_inset Formula $V$
\end_inset

 as follows.
 Set 
\begin_inset Formula $\mathscr{L}_{0}=\mathscr{L}$
\end_inset

 and for 
\begin_inset Formula $i\geq0$
\end_inset

, define:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathscr{L}_{i+1} & =\begin{cases}
\mathscr{L}_{i} & \text{if }\mathbf{v}_{i}\in\text{span}(\mathscr{L}_{i})\\
\mathscr{L}_{i},\mathbf{v}_{i+1} & \text{otherwise }
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Here, 
\begin_inset Formula $\mathscr{L}_{i},\mathbf{v}_{i+1}$
\end_inset

 just means take the sequence 
\begin_inset Formula $\mathscr{L}_{i}$
\end_inset

 and add 
\begin_inset Formula $\mathbf{v}_{i+1}$
\end_inset

 on to the end.
 
\end_layout

\begin_layout Proof
Note that in either case, 
\begin_inset Formula $\mathbf{v}_{i+1}\in\text{span}(\mathscr{L}_{i+1})$
\end_inset

 and also that 
\begin_inset Formula $\mathscr{L}_{0}\subseteq\mathscr{L}_{1}\subseteq\ldots\subseteq\mathscr{L}_{m}$
\end_inset

.
 
\end_layout

\begin_layout Proof
By construction, each sequence 
\begin_inset Formula $\mathscr{L}_{i}$
\end_inset

 is linearly independent and in particular 
\begin_inset Formula $\mathscr{L}_{m}$
\end_inset

 is linearly independent.
 Furthermore, 
\begin_inset Formula $\text{span}(\mathscr{L}_{m})$
\end_inset

 contains 
\begin_inset Formula $\{\mathbf{v}_{1},\ldots,\mathbf{v}_{m}\}$
\end_inset

 and therefore contains 
\begin_inset Formula $\text{span}(\mathscr{L}_{m})=V$
\end_inset

.
 Therefore, 
\begin_inset Formula $\mathscr{L}_{m}$
\end_inset

 is a basis for 
\begin_inset Formula $V$
\end_inset

 containing 
\begin_inset Formula $\mathscr{L}.$
\end_inset

 This completes the proof.
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lemma:EMHE"

\end_inset

(EMHE) Every matrix has an (atleast one) eigenvalue, and a corresponding
 eigenvector.
\end_layout

\begin_layout Proof
This is just the Fundamental Theorem of Algebra(FTA), but it's still worth
 enumerating as a theorem.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $A\subseteq\mathbf{C}^{n\times n}$
\end_inset

 and the scalar field 
\begin_inset Formula $\mathbf{F}=\mathbf{C}$
\end_inset

.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $\mathbf{v}$
\end_inset

 be any non-zero vector in 
\begin_inset Formula $\mathbf{C}^{n}$
\end_inset

.
 Consider the list 
\begin_inset Formula $\mathscr{L}=\mathbf{v},A\mathbf{v},A^{2}\mathbf{v},\ldots,A^{n}\mathbf{v}$
\end_inset

.
 There are 
\begin_inset Formula $n+1$
\end_inset

 vectors in the list, so they must be linearly dependent.
 There exists scalars 
\begin_inset Formula $a_{0},a_{1},\ldots,a_{n}$
\end_inset

 from 
\begin_inset Formula $\mathbf{C}$
\end_inset

 not all zero, such that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
a_{0}\mathbf{v}+a_{1}A\mathbf{v}+a_{2}A^{2}\mathbf{v}+\ldots+a_{n}A^{n}\mathbf{v} & =\mathbf{0}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By FTA, the polynomial equation of degree 
\begin_inset Formula $n$
\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
p(x) & =a_{0}+a_{1}x+a_{2}x^{2}+\ldots+a_{n}x^{n}=0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
has 
\begin_inset Formula $n$
\end_inset

 linear factors 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
p(x)=(x-\lambda_{1})(x-\lambda_{2})\cdots(x-\lambda_{n}) & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
where 
\begin_inset Formula $\lambda_{i}\in\mathbf{C}$
\end_inset

, 
\begin_inset Formula $i=1,2,\ldots,n$
\end_inset

.
\end_layout

\begin_layout Proof
Putting it all together,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
p(A)\mathbf{v}=\mathbf{0} & =a_{0}\mathbf{v}+a_{1}A\mathbf{v}+a_{2}A^{2}\mathbf{v}+\ldots+a_{n}A^{n}\mathbf{v}\\
 & =(a_{0}+a_{1}A+a_{2}A^{2}+\ldots+a_{n}A^{n})\mathbf{v}\\
 & =(A-\lambda_{1}I)(A-\lambda_{2}I)\cdots(A-\lambda_{n}I)\mathbf{v}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
This shows that the composition of the factors has a non-trivial nullspace.
 
\begin_inset Formula $\ker((A-\lambda_{1}I)(A-\lambda_{2}I)\cdots(A-\lambda_{n}I))\neq\{\mathbf{0}\}$
\end_inset

.
 So, atleast one of the factors must fail to be injective.
 There exists 
\begin_inset Formula $\lambda_{i}$
\end_inset

, such that 
\begin_inset Formula $(A-\lambda_{i})\mathbf{v}=\mathbf{0}$
\end_inset

 such that 
\begin_inset Formula $\mathbf{v}\neq\mathbf{0}$
\end_inset

.
 Thus, 
\begin_inset Formula $A$
\end_inset

 has atleast one eigenvalue and a corresponding eigenvector.
\end_layout

\begin_layout Theorem
(Spectral Theorem) Every real symmetric matrix is diagonalizable.
 
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $A$
\end_inset

 be a symmetric 
\begin_inset Formula $n\times n$
\end_inset

 real matrix.
 Then,
\end_layout

\begin_layout Theorem
1) The eigenvalues of 
\begin_inset Formula $A$
\end_inset

 are real.
\end_layout

\begin_layout Theorem
2) There exists an orthonormal basis 
\begin_inset Formula $\{\mathbf{q}_{1},\mathbf{q}_{2},\ldots,\mathbf{q}_{n}\}$
\end_inset

 for 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

 consisting of the eigenvectors of 
\begin_inset Formula $A$
\end_inset

.
 That is, there is an orthogonal matrix 
\begin_inset Formula $Q$
\end_inset

 so that 
\begin_inset Formula $Q^{-1}AQ=\Lambda$
\end_inset

 is diagonal.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
(I) Before we get to the proof, note that for any square matrix 
\begin_inset Formula $A$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\left\langle A\mathbf{x},\mathbf{y}\right\rangle  & =\mathbf{x}'A'\mathbf{y}\\
 & =\left\langle \mathbf{x},A'\mathbf{y}\right\rangle 
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since for a symmetric matrix 
\begin_inset Formula $A$
\end_inset

, we have, 
\begin_inset Formula $A=A'$
\end_inset

, it follows that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\left\langle A\mathbf{x},\mathbf{y}\right\rangle  & =\left\langle \mathbf{x},A\mathbf{y}\right\rangle 
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Or using the dot-product notation, we could write:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
(A\mathbf{x})\cdot\mathbf{y} & =\mathbf{x}\cdot(A\mathbf{y})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Suppose 
\begin_inset Formula $\mathbf{v}\neq\mathbf{0}$
\end_inset

 be a non-zero vector in 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

 such that there exists a complex scalar 
\begin_inset Formula $\lambda$
\end_inset

, satisfying:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
A\mathbf{v}=\lambda\mathbf{v}\label{eq:eigen_value_equation}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
We can therefore write:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
(A\mathbf{v})\cdot\mathbf{v}=(\lambda\mathbf{v})\cdot\mathbf{v}=\lambda(\mathbf{v}\cdot\mathbf{v})\label{eq:eigenvalue-eq-1}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Alternatively,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
(A\mathbf{v})\cdot\mathbf{v}=\mathbf{v}\cdot(A\mathbf{v})\label{eq:eigen-value-eq-2}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
We can now take the complex conjugate of the (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:eigen_value_equation"
plural "false"
caps "false"
noprefix "false"

\end_inset

) equation.
 Remember that 
\begin_inset Formula $A$
\end_inset

 is a real matrix so 
\begin_inset Formula $\overline{A}=A$
\end_inset

.
 Thus, we have the conjugated version of the eigen-value equation:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\overline{\left(A\mathbf{v}\right)}=\overline{A}\overline{\mathbf{v}}=A\overline{\mathbf{v}} & =\overline{(\lambda\mathbf{v})}=\overline{\lambda}\overline{\mathbf{v}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
In equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:eigenvalue-eq-1"
plural "false"
caps "false"
noprefix "false"

\end_inset

), if we replace the second vector 
\begin_inset Formula $\mathbf{v}$
\end_inset

 with its conjugate, 
\begin_inset Formula $\overline{\mathbf{v}}$
\end_inset

, we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
(A\mathbf{v})\cdot\overline{\mathbf{v}}=\lambda(\mathbf{v}\cdot\overline{\mathbf{v}})
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
In equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:eigen-value-eq-2"
plural "false"
caps "false"
noprefix "false"

\end_inset

), if we replace the second vector 
\begin_inset Formula $\mathbf{v}$
\end_inset

 with its conjugate, 
\begin_inset Formula $\overline{\mathbf{v}}$
\end_inset

, we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
(A\mathbf{v})\cdot\overline{\mathbf{v}}=\mathbf{v}\cdot(A\overline{\mathbf{v}})=\mathbf{v}\cdot(\overline{\lambda}\overline{\mathbf{v}})=\overline{\lambda}(\mathbf{v}\cdot\overline{\mathbf{v}})
\end{equation}

\end_inset

Now, since 
\begin_inset Formula $\mathbf{v}$
\end_inset

 is an eigenvector, it cannot be the zero vector.
 
\end_layout

\begin_layout Proof
Without loss of generality, if 
\begin_inset Formula $\mathbf{v}=(v_{1},\ldots,v_{n})$
\end_inset

, then 
\begin_inset Formula $\mathbf{v}\cdot\overline{\mathbf{v}}=|v_{1}|^{2}+\ldots+|v_{n}|^{2}\neq0$
\end_inset

, so 
\begin_inset Formula $\mathbf{v}\cdot\overline{\mathbf{v}}\neq0$
\end_inset

.
 
\end_layout

\begin_layout Proof
The two expressions for 
\begin_inset Formula $(A\mathbf{v})\cdot\overline{\mathbf{v}}$
\end_inset

 are equal, so 
\begin_inset Formula $(\lambda-\overline{\lambda})(\mathbf{v}\cdot\overline{\mathbf{v}})=0$
\end_inset

.
 But, 
\begin_inset Formula $(\mathbf{v}\cdot\overline{\mathbf{v}})\neq0$
\end_inset

, so 
\begin_inset Formula $\lambda=\overline{\lambda}$
\end_inset

.
 Therefore, 
\begin_inset Formula $\lambda\in\mathbf{R}$
\end_inset

.
 
\end_layout

\begin_layout Proof
(II) We proceed by mathematical induction on 
\begin_inset Formula $n$
\end_inset

.
 
\end_layout

\begin_layout Proof
For 
\begin_inset Formula $n=1$
\end_inset

, any 
\begin_inset Formula $1\times1$
\end_inset

 symmetric matrix is already diagonal.
 Since 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $v\in V$
\end_inset

 are both scalars, 
\begin_inset Formula $Av=\lambda v$
\end_inset

 where 
\begin_inset Formula $\lambda=A$
\end_inset

.
 Thus, we can pick any non-zero scalar 
\begin_inset Formula $v$
\end_inset

 to form a basis of 
\begin_inset Formula $\mathbf{R}$
\end_inset

.
 And we can write, 
\begin_inset Formula $A=P^{-1}\Lambda P$
\end_inset

, where 
\begin_inset Formula $P=I$
\end_inset

 and 
\begin_inset Formula $\Lambda=A$
\end_inset

.
\end_layout

\begin_layout Proof

\emph on
Induction hypothesis
\emph default
: Every 
\begin_inset Formula $k\times k$
\end_inset

 symmetric matrix is diagonalizable for 
\begin_inset Formula $k=1,2,3,\ldots,n-1$
\end_inset

.
 If 
\begin_inset Formula $C$
\end_inset

 is a real symmetric matrix of size 
\begin_inset Formula $k\times k$
\end_inset

, then there exists an orthogonal matrix 
\begin_inset Formula $R$
\end_inset

 such that 
\begin_inset Formula $R^{-1}CR$
\end_inset

 is diagonal.
\end_layout

\begin_layout Proof
By lemma (
\begin_inset CommandInset ref
LatexCommand ref
reference "lemma:EMHE"
plural "false"
caps "false"
noprefix "false"

\end_inset

), the square matrix 
\begin_inset Formula $A$
\end_inset

 has atleast one eigenvalue.
 Suppose 
\begin_inset Formula $\lambda_{1}$
\end_inset

 is an eigenvalue of the matrix 
\begin_inset Formula $A$
\end_inset

.
 By part (I), we know that 
\begin_inset Formula $\lambda_{1}\in\mathbf{R}$
\end_inset

.
 Choose a unit vector 
\begin_inset Formula $\mathbf{q}_{1}$
\end_inset

 that is an eigenvector with eigenvalue 
\begin_inset Formula $\lambda_{1}$
\end_inset

.
 (Obviously, this is no problem.
 We can pick an eigenvector and then make it a unit vector by dividing by
 it's length.) 
\end_layout

\begin_layout Proof
By lemma (
\begin_inset CommandInset ref
LatexCommand ref
reference "lemma:extending_linearly_independent_seq_to_a_basis"
plural "false"
caps "false"
noprefix "false"

\end_inset

), we can extend this to a basis 
\begin_inset Formula $\{\mathbf{q}_{1},\mathbf{w}_{2},\ldots,\mathbf{w}_{n}\}$
\end_inset

 of 
\begin_inset Formula $V$
\end_inset

.
 By the Gram-Schmidt orthogonalization algorithm, given the basis 
\begin_inset Formula $\{\mathbf{q}_{1},\mathbf{w}_{2},\ldots,\mathbf{w}_{n}\}$
\end_inset

, we can find a corresponding orthonormal basis 
\begin_inset Formula $\{\mathbf{q}_{1},\mathbf{q}_{2},\ldots,\mathbf{q}_{n}\}$
\end_inset

 of 
\begin_inset Formula $V$
\end_inset

.
\end_layout

\begin_layout Proof
Now, we huddle these basis vectors together as column-vectors of a matrix
 and formulate the matrix 
\begin_inset Formula $P$
\end_inset

.
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
P & =\left[\begin{array}{cccc}
\mathbf{\mathbf{q}_{1}} & \mathbf{q}_{2} & \ldots & \mathbf{q}_{n}\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By definition, 
\begin_inset Formula $P$
\end_inset

 is an orthogonal matrix.
 
\end_layout

\begin_layout Proof
Let 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
B & =P^{-1}AP
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We are interested to show that 
\begin_inset Formula $B$
\end_inset

 is diagonal.
\end_layout

\begin_layout Proof

\emph on
Step
\emph default
 I.
 
\begin_inset Formula $B$
\end_inset

 is symmetric.
\end_layout

\begin_layout Proof
We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
B^{T} & =(P^{-1}AP)^{T}\\
 & =(P^{T}AP)^{T} & \{P^{-1}=P^{T}\}\\
 & =P^{T}A^{T}(P^{T})^{T}\\
 & =P^{T}A^{T}P\\
 & =P^{T}AP & \{A\text{ is symmetric}\}\\
 & =B
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We are now going to try and write 
\begin_inset Formula $B$
\end_inset

 in the block form to try to see the structure that this matrix must have
 and hope that it looks like, it is going to be diagonal.
 
\end_layout

\begin_layout Proof

\emph on
Step II.
 
\emph default
The structure of 
\begin_inset Formula $B$
\end_inset

.
 
\end_layout

\begin_layout Proof
The way we do this, is to consider the matrix 
\begin_inset Formula $B$
\end_inset

 post-multiplied by 
\begin_inset Formula $\mathbf{e}_{1}$
\end_inset

.
 Consider 
\begin_inset Formula $B\mathbf{e}_{1}$
\end_inset

.
 This should actually give us the first column of 
\begin_inset Formula $B$
\end_inset

.
 Now, we also know that 
\begin_inset Formula $B=P^{T}AP$
\end_inset

.
 So, we could actually say, well, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
P^{T}AP\mathbf{e}_{1} & =P^{T}A\mathbf{q}_{1}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, remember that 
\begin_inset Formula $\mathbf{q}_{1}$
\end_inset

 is the normalized eigenvector corresponding to the eigenvalue 
\begin_inset Formula $\lambda_{1}$
\end_inset

.
 So, 
\begin_inset Formula $A\mathbf{q}_{1}=\lambda_{1}\mathbf{q}_{1}$
\end_inset

.
 That means, this is equal to:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
P^{T}A\mathbf{q}_{1} & =P^{T}\lambda_{1}\mathbf{q}_{1}\\
 & =\lambda_{1}P^{t}\mathbf{q}_{1}\\
 & =\lambda_{1}\left[\begin{array}{c}
\mathbf{q}_{1}^{T}\\
\mathbf{q}_{2}^{T}\\
\vdots\\
\mathbf{q}_{n}^{T}
\end{array}\right]\mathbf{q}_{1}\\
 & =\lambda_{1}\left[\begin{array}{c}
\mathbf{q}_{1}^{T}\mathbf{q}_{1}\\
\mathbf{q}_{2}^{T}\mathbf{q}_{1}\\
\vdots\\
\mathbf{q}_{n}^{T}\mathbf{q}_{1}
\end{array}\right]\\
 & =\lambda_{1}\left[\begin{array}{c}
1\\
0\\
\vdots\\
0
\end{array}\right]\\
 & =\left[\begin{array}{c}
\lambda_{1}\\
0\\
0\\
0
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
This is the first column of the matrix 
\begin_inset Formula $B$
\end_inset

.
 Since 
\begin_inset Formula $B=B^{T}$
\end_inset

, the first row should also be 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\left[\begin{array}{cccc}
\lambda_{1} & 0 & 0 & 0\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Proof
So, we can write the matrix 
\begin_inset Formula $B$
\end_inset

 in the form:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
B & =\left[\begin{array}{cc}
\lambda_{1} & O\\
O & C
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The first row and the first column are satisying the need to be diagonal.
 
\end_layout

\begin_layout Proof

\emph on
Step III.
\end_layout

\begin_layout Proof
We know that 
\begin_inset Formula $C$
\end_inset

 is a 
\begin_inset Formula $n-1\times n-1$
\end_inset

 symmetric matrix.
 By the inductive hypothesis, 
\begin_inset Formula $C$
\end_inset

 is diagonalizable and further there exists an orthogonal matrix 
\begin_inset Formula $R$
\end_inset

, such that 
\begin_inset Formula $R^{-1}CR=D$
\end_inset

 where 
\begin_inset Formula $D$
\end_inset

 is diagonal.
 
\end_layout

\begin_layout Proof
Define the matrix 
\begin_inset Formula $Q$
\end_inset

 as:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
Q:=P\left[\begin{array}{cc}
1 & 0_{1\times n-1}\\
0_{n-1\times1} & R
\end{array}\right]
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Our claim is that 
\begin_inset Formula $Q$
\end_inset

 is orthogonal and 
\begin_inset Formula $Q^{-1}AQ$
\end_inset

 is diagonal.
\end_layout

\begin_layout Proof
(i) We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
Q^{-1} & =\left[\begin{array}{cc}
1 & 0_{1\times n-1}\\
0_{n-1\times1} & R^{-1}
\end{array}\right]P^{-1} & \{\text{Reverse order law}\}\\
 & =\left[\begin{array}{cc}
1 & 0_{1\times n-1}\\
0_{n-1\times1} & R^{T}
\end{array}\right]P^{T} & \{P\text{ and }R\text{ are orthogonal}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
But, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
Q^{T} & =\left[\begin{array}{cc}
1 & 0_{1\times n-1}\\
0_{n-1\times1} & R^{T}
\end{array}\right]P^{T}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
So, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
Q^{T} & =Q^{-1}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Thus, 
\begin_inset Formula $Q$
\end_inset

 is orthogonal.
\end_layout

\begin_layout Proof
(ii) Well, let's compute 
\begin_inset Formula $Q^{-1}AQ$
\end_inset

.
 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
Q^{-1}AQ & =Q^{T}AQ & \{Q\text{ is orthogonal}\}\\
 & =\left[\begin{array}{cc}
1 & 0_{1\times n-1}\\
0_{n-1\times1} & R^{T}
\end{array}\right]P^{T}AP\left[\begin{array}{cc}
1 & 0_{1\times n-1}\\
0_{n-1\times1} & R
\end{array}\right]\\
 & =\left[\begin{array}{cc}
1 & 0_{1\times n-1}\\
0_{n-1\times1} & R^{T}
\end{array}\right]B\left[\begin{array}{cc}
1 & 0_{1\times n-1}\\
0_{n-1\times1} & R
\end{array}\right]\\
 & =\left[\begin{array}{cc}
1 & 0_{1\times n-1}\\
0_{n-1\times1} & R^{T}
\end{array}\right]\left[\begin{array}{cc}
\lambda_{1} & 0_{1\times n-1}\\
0_{n-1\times1} & C
\end{array}\right]\left[\begin{array}{cc}
1 & 0_{1\times n-1}\\
0_{n-1\times1} & R
\end{array}\right]\\
 & =\left[\begin{array}{cc}
\lambda_{1} & 0_{1\times n-1}\\
0_{n-1\times1} & R^{T}C
\end{array}\right]\left[\begin{array}{cc}
1 & 0_{1\times n-1}\\
0_{n-1\times1} & R
\end{array}\right]\\
 & =\left[\begin{array}{cc}
\lambda_{1} & 0_{1\times n-1}\\
0_{n-1\times1} & R^{T}CR
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $R^{T}CR$
\end_inset

 is diagonal, it follows that 
\begin_inset Formula $Q^{-1}AQ$
\end_inset

 is diagonal.
 This closes the proof.
\end_layout

\begin_layout Subsection
Covariance and MGF of random variables.
\end_layout

\begin_layout Definition
If 
\begin_inset Formula $(X,Y)$
\end_inset

 is a random vector, then the covariance of 
\begin_inset Formula $(X,Y)$
\end_inset

 is given by: 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{equation}
\text{Cov}(X,Y)=\mathbb{E}\left[\left(X-\mathbb{E}X\right)\left(Y-\mathbb{E}Y\right)\right]=\mathbb{E}\left[XY\right]-\mathbb{E}\left[X\right]\cdot\mathbb{E}\left[Y\right]
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Expected value of a random matrix.
\end_layout

\begin_layout Standard
Suppose our random experiment is modeled by the probability space 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 We can define the expected value of a random matrix in a component-wise
 manner.
 
\end_layout

\begin_layout Standard
Suppose that 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is an 
\begin_inset Formula $m\times n$
\end_inset

 matrix of real-valued random variables, whose 
\begin_inset Formula $(i,j)$
\end_inset

 entry is denoted by 
\begin_inset Formula $X_{ij}$
\end_inset

.
 Equivalently, 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is a random 
\begin_inset Formula $m\times n$
\end_inset

 matrix.
 The expected value 
\begin_inset Formula $\mathbb{E}(\mathbf{X})$
\end_inset

 is defined to be the 
\begin_inset Formula $m\times n$
\end_inset

 matrix whose 
\begin_inset Formula $(i,j)$
\end_inset

 entry is 
\begin_inset Formula $\mathbb{E}X_{ij}$
\end_inset

, the expected value of 
\begin_inset Formula $X_{ij}$
\end_inset

.
\end_layout

\begin_layout Standard
Many of the basic properties of expected value of random variables have
 analogous results for expected values of random matrices/vectors.
 If 
\begin_inset Formula $\mathbf{X}$
\end_inset

 and 
\begin_inset Formula $\mathbf{Y}$
\end_inset

are random 
\begin_inset Formula $m\times n$
\end_inset

 matrices, the linearity property holds: 
\begin_inset Formula $\mathbb{E}(\mathbf{X}+\mathbf{Y})=\mathbb{E}\mathbf{X}+\mathbb{E}\mathbf{Y}$
\end_inset

.
 Similarly, if 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is a 
\begin_inset Formula $n\times p$
\end_inset

 random matrix and 
\begin_inset Formula $\mathbf{a}$
\end_inset

 is a constant 
\begin_inset Formula $m\times n$
\end_inset

 matrix, th of the expectation.
 
\begin_inset Formula $\mathbb{E}\left[\mathbf{a}\mathbf{X}\right]=\mathbf{a}\mathbb{E}\left[\mathbf{X}\right]$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Covariance Matrices.
\end_layout

\begin_layout Definition
Suppose that 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is a random vector in 
\begin_inset Formula $\mathbf{R}^{m}$
\end_inset

 and 
\begin_inset Formula $\mathbf{Y}$
\end_inset

 is a random vector in 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

.
 The covariance matrix of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 and 
\begin_inset Formula $\mathbf{Y}$
\end_inset

 is the 
\begin_inset Formula $m\times n$
\end_inset

 matrix 
\begin_inset Formula $\text{Cov}(\mathbf{X},\mathbf{Y})$
\end_inset

 whose 
\begin_inset Formula $(i,j)$
\end_inset

 entry is 
\begin_inset Formula $\text{Cov}(X_{i},Y_{j})$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $\mathbf{X}=(X_{1},\ldots,X_{n})$
\end_inset

 be a random vector in 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

.
 Then the covariance matrix of 
\begin_inset Formula $\mathbf{X}$
\end_inset

, denoted by 
\begin_inset Formula $\Sigma$
\end_inset

 is the 
\begin_inset Formula $n\times n$
\end_inset

 matrix, whose 
\begin_inset Formula $(i,j)$
\end_inset

 entry is 
\begin_inset Formula $\text{Cov}(X_{i},X_{j})$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $(X,Y)$
\end_inset

 be random variables.
 
\begin_inset Formula $\text{Cov}(X,Y)$
\end_inset

 has the following properties:
\end_layout

\begin_layout Theorem
(i) 
\begin_inset Formula $Cov(X,X)=Var(X)$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Theorem
(ii) 
\begin_inset Formula $Cov(X,Y)=Cov(Y,X)$
\end_inset


\end_layout

\begin_layout Theorem
(iii) 
\begin_inset Formula $Cov(X,c)=0$
\end_inset


\end_layout

\begin_layout Theorem
(iv) Scaling property: 
\begin_inset Formula $Cov(aX,Y)=aCov(X,Y)$
\end_inset


\end_layout

\begin_layout Theorem
(v) Bi-linearity:
\end_layout

\begin_layout Theorem
\begin_inset Formula $Cov(aX+bY,Z)=aCov(X,Z)+bCov(Y,Z)$
\end_inset


\end_layout

\begin_layout Theorem
\begin_inset Formula $Cov(X,cY+dZ)=cCov(X,Y)+dCov(X,Z)$
\end_inset


\end_layout

\begin_layout Theorem
(vi) 
\begin_inset Formula $Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)$
\end_inset


\end_layout

\begin_layout Theorem
Since 
\begin_inset Formula $Cov(X,-Y)=-Cov(X,Y)$
\end_inset

, it follows that 
\begin_inset Formula $Var(X-Y)=Var(X)+Var(-Y)+2Cov(X,-Y)=Var(X)+Var(Y)-2Cov(X,Y)$
\end_inset


\end_layout

\begin_layout Theorem
\begin_inset Formula $Var(X_{1}+X_{2}+\ldots+X_{n})=\sum_{i=1}^{n}Var(X_{i})+\sum_{i=1}^{n}\sum_{j=1}^{n}Cov(X_{i},X_{j})$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $\mathbf{X}=(X_{1},X_{2},\ldots,X_{n})$
\end_inset

 be a random vector with mean vector 
\begin_inset Formula $\boldsymbol{\mathbf{\mu}}=(\mu_{1},\mu_{2},\ldots,\mu_{n})$
\end_inset

 and 
\begin_inset Formula $n\times n$
\end_inset

 covariance matrix 
\begin_inset Formula $\Sigma$
\end_inset

.
 Then, 
\begin_inset Formula $\Sigma$
\end_inset

 is positive semi-definite.
\end_layout

\begin_layout Proof
We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\Sigma & =\left[\begin{array}{cccc}
\mathbb{E}(X_{1}-\mu_{1})(X_{1}-\mu_{1}) & \mathbb{E}(X_{1}-\mu_{1})(X_{2}-\mu_{2}) & \ldots & \mathbb{E}(X_{1}-\mu_{1})(X_{n}-\mu_{n})\\
\mathbb{E}(X_{2}-\mu_{2})(X_{1}-\mu_{1}) & \mathbb{E}(X_{2}-\mu_{2})(X_{2}-\mu_{2}) & \ldots & \mathbb{E}(X_{2}-\mu_{2})(X_{n}-\mu_{n})\\
\vdots & \vdots & \ddots & \vdots\\
\mathbb{E}(X_{n}-\mu_{n})(X_{1}-\mu_{1}) & (X_{n}-\mu_{n})(X_{2}-\mu_{2}) & \ldots & (X_{n}-\mu_{n})(X_{n}-\mu_{n})
\end{array}\right]\\
 & =\mathbb{E}\left[\left[\begin{array}{c}
X_{1}-\mu_{1}\\
X_{2}-\mu_{2}\\
\vdots\\
X_{n}-\mu_{n}
\end{array}\right]\left[\begin{array}{cccc}
X_{1}-\mu_{1} & X_{2}-\mu_{2} & \ldots & X_{n}-\mu_{n}\end{array}\right]\right]\\
 & =\mathbb{E}\left[(\mathbf{X}-\boldsymbol{\mu})(\mathbf{X}-\boldsymbol{\mu})'\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $\mathbf{a}$
\end_inset

 be an arbitrary(not random) vector in 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

.
 Then,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{a}'\Sigma\mathbf{a} & =\mathbf{a}'\mathbb{E}\left[(\mathbf{X}-\boldsymbol{\mu})(\mathbf{X}-\boldsymbol{\mu})'\right]\mathbf{a}\\
 & =\mathbb{E}\left[\mathbf{a}'(\mathbf{X}-\boldsymbol{\mu})(\mathbf{X}-\boldsymbol{\mu})'\mathbf{a}\right]\\
 & =\mathbb{E}\left[\left((\mathbf{X}-\boldsymbol{\mu})'\mathbf{a}\right)'\left((\mathbf{X}-\boldsymbol{\mu})'\mathbf{a}\right)\right]\\
 & =\mathbb{E}[(\mathbf{X}-\boldsymbol{\mu})'\mathbf{a}]^{2}\\
 & \geq0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Consequently, 
\begin_inset Formula $\Sigma$
\end_inset

 is a positive semi-definite matrix.
\end_layout

\begin_layout Definition
The MGF of a random variable 
\begin_inset Formula $X$
\end_inset

 on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 is the function on 
\begin_inset Formula $\mathbf{R}$
\end_inset

 defined by:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
M_{X}(t) & =\mathbb{E}\left[e^{tX}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The MGF of a standard Gaussian random variable given by:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
M_{Z}(t) & =\mathbb{E}\left[e^{tZ}\right]\\
 & =\int_{-\infty}^{\infty}e^{tz}\phi(z)dz\\
 & =\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{tz}e^{-z^{2}/2}dz
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We can complete the square in the exponent as follows:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\exp\left(tz-\frac{z^{2}}{2}\right) & =\exp\left[-\frac{1}{2}\left(z^{2}-2tz+t^{2}-t^{2}\right)\right]\\
 & =\exp\left[-\frac{1}{2}\left(z-t\right)^{2}+\frac{t^{2}}{2}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
So, 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
M_{Z}(t) & =\frac{e^{t^{2}/2}}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-(z-t)^{2}/2}dz\\
 & =\frac{e^{t^{2}/2}}{\sqrt{2\pi}}\sqrt{2\pi}\\
 & =e^{t^{2}/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Differentiating with respect to 
\begin_inset Formula $t$
\end_inset

, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
M_{Z}'(t) & =te^{t^{2}/2}\\
M_{Z}''(t) & =e^{t^{2}/2}+t^{2}e^{t^{2}/2}\\
M_{Z}^{(3)}(t) & =3te^{t^{2}/2}+t^{3}e^{t^{2}/2}\\
M_{Z}^{(4)}(t) & =3e^{t^{2}/2}+6t^{2}e^{t^{2}/2}+t^{4}e^{t^{2}/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
So, the mean of the standard gaussian random variable is 
\begin_inset Formula $M_{Z}'(0)=0$
\end_inset

, the second moment and variance of a standard gaussian random variable
 is 
\begin_inset Formula $M_{Z}''(0)=1$
\end_inset

.
 The skewness of the standard gaussian random variable is 
\begin_inset Formula $M_{Z}^{(3)}(0)=0$
\end_inset

, while the kurtosis of a standard gaussian random variable is 
\begin_inset Formula $M_{Z}^{(4)}(t)=3$
\end_inset

.
\end_layout

\begin_layout Definition
(
\emph on
Joint Moment Generating Function (MGF)
\emph default
).
 The joint MGF of a random vector 
\begin_inset Formula $\mathbf{X}=(X_{1},X_{2},\ldots,X_{n})$
\end_inset

 on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 is the function defined on 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

 by:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{equation}
M_{\mathbf{X}}(\mathbf{t})=\mathbb{E}\left[\exp\left(\mathbf{t}^{T}\mathbf{X}\right)\right]=\mathbb{E}\left[\exp\left(t_{1}X_{1}+t_{2}X_{2}+\ldots+t_{n}X_{n}\right)\right]
\end{equation}

\end_inset


\end_layout

\begin_layout Definition
The following result will be stated without proof.
 It will be useful when studying Gaussian vectors.
 
\end_layout

\begin_layout Proposition
Let 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 be a probability space.
 Two random vectors 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 that have the same moment generating function have the same distribution.
 
\end_layout

\begin_layout Example
Consider 
\begin_inset Formula $(X,Y)$
\end_inset

 a random vector with value in 
\begin_inset Formula $\mathbf{R}^{2}$
\end_inset

 such that 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are IID with standard Gaussian distribution.
 Then, the joint PDF is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
f(x,y) & =\frac{1}{\sqrt{2\pi}}e^{-x^{2}/2}\times\frac{1}{\sqrt{2\pi}}e^{-y^{2}/2}=\frac{1}{\sqrt{2\pi}}e^{-(x^{2}+y^{2})/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The moment generating function is obtained by independence:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
M_{(X,Y)}(t_{1},t_{2}) & =\mathbb{E}[e^{t_{1}X+t_{2}Y}]\\
 & =\mathbb{E}\left[e^{t_{1}X}\cdot e^{t_{2}Y}\right]\\
 & =\mathbb{E}\left[e^{t_{1}X}\right]\cdot\mathbb{E}\left[e^{t_{2}X}\right]\\
 & =e^{t_{1}^{2}/2}\cdot e^{t_{2}^{2}/2}\\
 & =e^{(t_{1}^{2}+t_{2}^{2})/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
More generally, we can consider 
\begin_inset Formula $n$
\end_inset

 IID random variables with standard Gaussian distribution.
 We then have the joint PDF:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
f(x_{1},x_{2},\ldots,x_{n}) & =\frac{e^{-(x_{1}^{2}+x_{2}^{2}+\ldots+x_{n}^{2})/2}}{(2\pi)^{n/2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In order to work with random vectors, we frequently use the change-of-variables
 theorem from vector calculus.
\end_layout

\begin_layout Theorem
(Change of Variables theorem for double integrals).
 If 
\begin_inset Formula $f:\mathbf{R}^{2}\to\mathbf{R}$
\end_inset

 and 
\begin_inset Formula $\mathbf{T}$
\end_inset

 is a linear transformation such that 
\begin_inset Formula $D=\mathbf{T}(D^{*})$
\end_inset

, and 
\begin_inset Formula $\mathbf{x}=T\mathbf{y}$
\end_inset

, then by the change of variables formula, we have:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
\int\int_{D}f(x_{1},x_{2})dx_{1}dx_{2} & =\int\int_{D^{*}}f(\mathbf{T}(y_{1},y_{2}))\left|J(y_{1},y_{2})\right|dy_{1}dy_{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
where 
\begin_inset Formula $J(y_{1},y_{2})=\frac{\partial(x_{1},x_{2})}{\partial(y_{1},y_{2})}$
\end_inset

.
 In particular, if 
\begin_inset Formula $T(\mathbf{y})=A\mathbf{y}$
\end_inset

 is a linear transformation which is one-to-one and onto, then it can be
 easily shown that any parallelogram with unit area in 
\begin_inset Formula $D^{*}$
\end_inset

 is scaled by a factor 
\begin_inset Formula $|\det A|$
\end_inset

 in 
\begin_inset Formula $D$
\end_inset

.
 Hence, 
\begin_inset Formula $J(y_{1},y_{2})=\frac{1}{|\det A|}$
\end_inset

.
 
\end_layout

\begin_layout Corollary
If 
\begin_inset Formula $X_{1},X_{2}$
\end_inset

 have the joint density function 
\begin_inset Formula $f$
\end_inset

, and 
\begin_inset Formula $T$
\end_inset

 is any linear transformation, then the pair 
\begin_inset Formula $(Y_{1},Y_{2})=T(X_{1},X_{2})$
\end_inset

 has the density function:
\end_layout

\begin_layout Corollary
\begin_inset Formula 
\begin{align*}
f_{(Y_{1},Y_{2})}(y_{1},y_{2}) & =f(x_{1}(y_{1},y_{2}),x_{2}(y_{1},y_{2}))\left|\frac{\partial(x_{1},x_{2})}{\partial(y_{1},y_{2})}\right|
\end{align*}

\end_inset


\end_layout

\begin_layout Example
(
\emph on
Computations with random vectors
\emph default
).
 Let 
\begin_inset Formula $(X,Y)$
\end_inset

 be two IID standard Gaussian random variables.
 We can think of 
\begin_inset Formula $(X,Y)$
\end_inset

 as the random point in 
\begin_inset Formula $\mathbf{R}^{2}$
\end_inset

 with 
\begin_inset Formula $x$
\end_inset

-coordinate 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $y$
\end_inset

-coordinate 
\begin_inset Formula $Y$
\end_inset

.
 
\end_layout

\begin_layout Example
First off, let's compute the probability that the point 
\begin_inset Formula $(X,Y)$
\end_inset

 is in the unit disc 
\begin_inset Formula $D=\{(x,y)|x^{2}+y^{2}=1\}$
\end_inset

.
 The probability is given by the double integral:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
P((X,Y)\in D) & =\int\int_{D}\frac{1}{2\pi}e^{-(x^{2}+y^{2})/2}dxdy\\
 & =\int_{-1}^{+1}\int_{-\sqrt{1-x^{2}}}^{+\sqrt{1-x^{2}}}\frac{1}{2\pi}e^{-(x^{2}+y^{2})/2}dxdy
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We apply the linear transformation:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
r & =\sqrt{x^{2}+y^{2}}\\
\tan\theta & =\frac{y}{x}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The inverse map is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
x & =r\cos\theta\\
y & =r\sin\theta
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The Jacobian 
\begin_inset Formula $\frac{\partial(x,y)}{\partial(r,\theta)}$
\end_inset

 is given by:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\frac{\partial(x,y)}{\partial(r,\theta)} & =\det\left[\begin{array}{cc}
\frac{\partial x}{\partial r} & \frac{\partial x}{\partial\theta}\\
\frac{\partial y}{\partial r} & \frac{\partial y}{\partial\theta}
\end{array}\right]\\
 & =\left|\begin{array}{cc}
\cos\theta & -r\sin\theta\\
\sin\theta & r\cos\theta
\end{array}\right|\\
 & =r(\cos^{2}\theta+\sin^{2}\theta)\\
 & =r
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We need to identify the region 
\begin_inset Formula $D^{*}$
\end_inset

 that 
\begin_inset Formula $T$
\end_inset

 maps in a one-to-one fashion to 
\begin_inset Formula $D$
\end_inset

.
 We have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
D^{*} & =\{(\theta,r)|0\leq\theta\leq2\pi,0\leq r\leq1\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Thus, 
\begin_inset Formula $D^{*}$
\end_inset

 is a rectangular region.
 We can write our double integral as:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
P((X,Y)\in D) & =\frac{1}{2\pi}\int_{0}^{2\pi}\int_{0}^{1}e^{-r^{2}/2}rdrd\theta\\
 & =\frac{1}{2\pi}\int_{0}^{2\pi}\int_{0}^{1/2}e^{-u}dud\theta\\
 & =\frac{1}{2\pi}\int_{0}^{2\pi}-\left[e^{-u}\right]_{0}^{1/2}d\theta\\
 & =\frac{1}{2\pi}\int_{0}^{2\pi}(1-e^{-1/2})d\theta\\
 & =(1-e^{-1/2})\frac{1}{2\pi}\int_{0}^{2\pi}d\theta\\
 & =(1-e^{-1/2})
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We are given that 
\begin_inset Formula $X,Y$
\end_inset

 are IID Gaussian random variables.
 Consider now the random variable 
\begin_inset Formula $R=(X^{2}+Y^{2})$
\end_inset

 giving the distance of the point to the origin.
 Let's compute 
\begin_inset Formula $\mathbb{E}[R]$
\end_inset

.
 Now, 
\begin_inset Formula $R$
\end_inset

 is a function of the random variables 
\begin_inset Formula $(X,Y)$
\end_inset

.
 Hence, by LOTUS, we must have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[R\right] & =\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}(x^{2}+y^{2})^{1/2}f_{(X,Y)}(x,y)dxdy\\
 & =\frac{1}{2\pi}\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}(x^{2}+y^{2})^{1/2}e^{-(x^{2}+y^{2})/2}dxdy
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Again by transforming to the polar coordinates, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[R\right] & =\frac{1}{2\pi}\int_{0}^{2\pi}\int_{0}^{\infty}re^{-r^{2}/2}rdrd\theta\\
 & =\frac{1}{2\pi}\int_{0}^{2\pi}\int_{0}^{\infty}r^{2}e^{-r^{2}/2}drd\theta
\end{align*}

\end_inset


\end_layout

\begin_layout Example
By the product rule, the inner integral can be simplified as follows:
\end_layout

\begin_layout Example
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $u$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dv$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $r$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $re^{-r^{2}/2}dr$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $-e^{-r^{2}/2}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Example
We have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\int_{0}^{\infty}udv & =\left.uv\right|_{0}^{\infty}-\int_{0}^{\infty}vdu\\
 & =\left.-re^{-r^{2}/2}\right|_{0}^{\infty}+\int_{0}^{\infty}e^{-r^{2}/2}dr\\
 & =0+\frac{\sqrt{2\pi}}{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
So, the desired expectation is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}[R] & =\frac{\sqrt{2\pi}}{2}\cdot\frac{1}{2\pi}\int_{0}^{2\pi}d\theta=\sqrt{\frac{\pi}{2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Consider the joint PDF 
\begin_inset Formula $f_{(R,\Theta)}(r,\theta)$
\end_inset

 of 
\begin_inset Formula $R$
\end_inset

, the distance to the origin and 
\begin_inset Formula $\Theta$
\end_inset

, the angle made with the positive 
\begin_inset Formula $x$
\end_inset

-axis.
 By the change-of-variables theorem, this is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
f_{(R,\Theta)}(r,\theta) & =f_{X,Y}(x(r,\theta),y(r,\theta))\left|\frac{\partial(x,y)}{\partial(r,\theta)}\right|\\
 & =\frac{1}{2\pi}re^{-r^{2}/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The joint CDF of 
\begin_inset Formula $(R,\Theta)$
\end_inset

 is :
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
F_{(R,\theta)}(r,\theta) & =\frac{1}{2\pi}\int_{0}^{\theta}\int_{0}^{r}re^{-r^{2}/2}drd\theta\\
 & =\frac{1}{2\pi}\int_{0}^{\theta}\int_{0}^{r^{2}/2}e^{-u}dud\theta\\
 & =\frac{1}{2\pi}\int_{0}^{\theta}\left[\frac{e^{-u}}{-1}\right]_{0}^{r^{2}/2}d\theta\\
 & =\frac{1}{2\pi}\int_{0}^{\theta}\left[\frac{e^{-u}}{-1}\right]_{0}^{r^{2}/2}d\theta\\
 & =\frac{1}{2\pi}\int_{0}^{\theta}(1-e^{-r^{2}/2})d\theta\\
 & =\frac{\theta}{2\pi}(1-e^{-r^{2}/2})
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In particular, the variables 
\begin_inset Formula $(R,\Theta)$
\end_inset

 are independent since the joint PDF is the product of the marginals.
 
\begin_inset Formula $\Theta$
\end_inset

 is uniformly distributed on 
\begin_inset Formula $[0,2\pi]$
\end_inset

 and has PDF 
\begin_inset Formula $f_{\Theta}(\theta)=\frac{1}{2\pi}$
\end_inset

.
 
\end_layout

\begin_layout Subsubsection
The Box-Mueller Method.
\end_layout

\begin_layout Standard
The above example gives an interesting method to generate a pair of IID
 standard Gaussian random variables.
 This is called the Box-Mueller method.
 Let 
\begin_inset Formula $U_{1}$
\end_inset

 and 
\begin_inset Formula $U_{2}$
\end_inset

be two independent uniform random variables on 
\begin_inset Formula $[0,1]$
\end_inset

.
 Define the random variables 
\begin_inset Formula $(Z_{1},Z_{2})$
\end_inset

 as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Z_{1} & =\sqrt{-2\log U_{1}}\cos(2\pi U_{2})\\
Z_{2} & =\sqrt{-2\log U_{1}}\sin(2\pi U_{2})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The CDF of the random variable 
\begin_inset Formula $R$
\end_inset

 defined in the previous section is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
F_{R}(r) & =1-e^{-r^{2}/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The inverse CDF is obtained by expressing 
\begin_inset Formula $r$
\end_inset

 in terms of 
\begin_inset Formula $u$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
e^{-r^{2}/2} & =1-u\\
\frac{-r^{2}}{2} & =\log(1-u)\\
r^{2} & =-2\log(1-u)\\
r & =\sqrt{-2\log(1-u)}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
By probability integral transform, we know that if 
\begin_inset Formula $U_{1}'$
\end_inset

 is a 
\begin_inset Formula $\text{Uniform}[0,1]$
\end_inset

 random variable, then the random variable 
\begin_inset Formula $F_{X}^{-1}(U_{1}')$
\end_inset

 has the CDF 
\begin_inset Formula $F_{X}$
\end_inset

.
 By symmetry, 
\begin_inset Formula $U_{1}:=1-U_{1}'$
\end_inset

 is also uniformly distributed on 
\begin_inset Formula $[0,1]$
\end_inset

.
 Thus, the random variable 
\begin_inset Formula $\sqrt{-2\log U_{1}}$
\end_inset

 has the same distribution as 
\begin_inset Formula $R$
\end_inset

.
 
\end_layout

\begin_layout Standard
The CDF of the random variable 
\begin_inset Formula $\Theta$
\end_inset

 defined above is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
F_{\Theta}(\theta) & =\frac{\theta}{2\pi}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
So, if 
\begin_inset Formula $U_{2}$
\end_inset

 is a uniform random variable, then the random variable 
\begin_inset Formula $2\pi U_{2}$
\end_inset

 has the same distribution as 
\begin_inset Formula $\Theta$
\end_inset

 in the discussion above.
 
\end_layout

\begin_layout Standard
As seen in the example above, if 
\begin_inset Formula $R$
\end_inset

 and 
\begin_inset Formula $\Theta$
\end_inset

 are independent and their marginal CDFs are 
\begin_inset Formula $F_{R}(r)=1-e^{-r^{2}/2}$
\end_inset

 and 
\begin_inset Formula $F_{\Theta}(\theta)=\frac{\theta}{2\pi}$
\end_inset

, we know that the random variables defined by 
\begin_inset Formula $X=R\cos\Theta$
\end_inset

 and 
\begin_inset Formula $Y=R\sin\Theta$
\end_inset

 are IID standard normal random variables.
 
\end_layout

\begin_layout Standard
More formally, we are making the transformation 
\begin_inset Formula $T:(R,\Theta)\mapsto(X,Y)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
T(R,\Theta) & =(R\cos\Theta,R\sin\Theta)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The inverse map is 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
R & =\sqrt{X^{2}+Y^{2}}\\
\Theta & =\arctan\frac{Y}{X}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
So, the density function of the pair 
\begin_inset Formula $(X,Y)$
\end_inset

 is given :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
f_{(X,Y)}(x,y) & =f_{(R,\Theta)}(\sqrt{x^{2}+y^{2}},\arctan(y/x))\cdot\left|\begin{array}{cc}
\frac{\partial r}{\partial x} & \frac{\partial r}{\partial y}\\
\frac{\partial\theta}{\partial x} & \frac{\partial\theta}{\partial y}
\end{array}\right|\\
 & =\frac{1}{2\pi}re^{-r^{2}/2}\left|\begin{array}{cc}
\frac{x}{\sqrt{x^{2}+y^{2}}} & \frac{y}{\sqrt{x^{2}+y^{2}}}\\
\frac{-y}{x^{2}+y^{2}} & \frac{x}{x^{2}+y^{2}}
\end{array}\right|\\
 & =\frac{1}{2\pi}\sqrt{x^{2}+y^{2}}\cdot e^{-(x^{2}+y^{2})/2}\cdot\frac{1}{\sqrt{x^{2}+y^{2}}}\\
 & =\frac{1}{2\pi}e^{-(x^{2}+y^{2})/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Hence, 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are IID standard Gaussian random variables.
\end_layout

\begin_layout Problem
Find the PDF of 
\begin_inset Formula $e^{-X}$
\end_inset

 for 
\begin_inset Formula $X\sim Expo(1)$
\end_inset

.
 
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
By change of variables, 
\begin_inset Formula $Y=e^{-X}$
\end_inset

, 
\begin_inset Formula $X=-\log Y$
\end_inset

.
 
\begin_inset Formula $\frac{\partial x}{\partial y}=-\frac{1}{y}$
\end_inset

.
 The PDF of 
\begin_inset Formula $Y$
\end_inset

 is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
f_{Y}(y) & =f_{X}(-\log y)\cdot\left|\frac{\partial x}{\partial y}\right|\\
 & =y\times\frac{1}{y}\\
 & =1
\end{align*}

\end_inset


\end_layout

\begin_layout Problem
Find the PDF of 
\begin_inset Formula $X^{7}$
\end_inset

 for 
\begin_inset Formula $X\sim\text{Expo}(\lambda)$
\end_inset

.
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
By change of variables, 
\begin_inset Formula $Y=X^{7}$
\end_inset

, 
\begin_inset Formula $X=Y^{1/7}$
\end_inset

.
 The PDF of 
\begin_inset Formula $Y$
\end_inset

 is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
f_{Y}(y) & =f_{X}(y^{1/7})\cdot\left|\frac{\partial x}{\partial y}\right|\\
 & =\lambda e^{-\lambda y^{1/7}}\times\frac{1}{7}\frac{1}{y^{6/7}}\\
 & =\frac{\lambda e^{-\lambda y^{1/7}}}{7y^{6/7}}
\end{align*}

\end_inset


\end_layout

\begin_layout Problem
Find the PDF of 
\begin_inset Formula $Z^{3}$
\end_inset

 for 
\begin_inset Formula $Z\sim\mathcal{N}(0,1)$
\end_inset

.
 
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
By change of variables, 
\begin_inset Formula $Y=Z^{3}$
\end_inset

, 
\begin_inset Formula $Z=Y^{1/3}$
\end_inset

.
 The PDF of 
\begin_inset Formula $Y$
\end_inset

 is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
f_{Y}(y) & =f_{Z}(y^{1/3})\cdot\left|\frac{\partial x}{\partial y}\right|\\
 & =\frac{1}{\sqrt{2\pi}}\exp\left[-\frac{y^{2/3}}{2}\right]\times\frac{1}{3}y^{-2/3}
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Gaussian Vectors.
\end_layout

\begin_layout Definition
A 
\begin_inset Formula $n$
\end_inset

-dimensional random vector 
\begin_inset Formula $\mathbf{X}=(X_{1},X_{2},\ldots,X_{n})$
\end_inset

 is said to be jointly Gaussian if and only if for all real vectors 
\begin_inset Formula $\mathbf{t}=(t_{1},\ldots,t_{n})$
\end_inset

, the linear combination 
\begin_inset Formula $\mathbf{t}^{T}\mathbf{X}=t_{1}X_{1}+t_{2}X_{2}+\ldots+t_{n}X_{n}$
\end_inset

 of 
\begin_inset Formula $(X_{1},X_{2},\ldots,X_{n})$
\end_inset

 is a Gaussian random variable.
 
\end_layout

\begin_layout Standard
As a simple consequence of the above definition, if 
\begin_inset Formula $(X_{1},\ldots,X_{n})$
\end_inset

 is Gaussian, then setting 
\begin_inset Formula $t_{i}=1$
\end_inset

 and 
\begin_inset Formula $t_{j}=0$
\end_inset

 for all 
\begin_inset Formula $i\neq j$
\end_inset

, we have that each 
\begin_inset Formula $X_{i}$
\end_inset

 is also Gaussian.
\end_layout

\begin_layout Standard
An equivalent definition can also be stated in terms of the joint MGF since
 an MGF uniquely characterizes the distribution of a random variable.
 Before introducing the second definition, we first make two important observati
ons about the mean and variance of a linear combination of random variables.
 
\end_layout

\begin_layout Standard
First, the mean of a linear combination of random variables is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}[a_{1}X_{1}+a_{2}X_{2}+\ldots+a_{n}X_{n}] & =a_{1}\mathbb{E}X_{1}+\ldots+a_{n}\mathbb{E}X_{n}=\mathbf{a}^{T}\mathbb{E}\mathbf{X}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\mathbb{E}\mathbf{X}$
\end_inset

 is the mean vector.
 The variance is obtained with a short calculation using the linearity of
 expectations:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Var(a_{1}X_{1}+\ldots+a_{n}X_{n}) & =\sum_{i=1}^{n}\sum_{j=1}^{n}a_{i}a_{j}Cov(X_{i},X_{j})\\
 & =\mathbf{a}^{T}\Sigma\mathbf{a}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\Sigma$
\end_inset

 is the covariance matrix of 
\begin_inset Formula $\mathbf{X}$
\end_inset

.
\end_layout

\begin_layout Proposition
A random vector 
\begin_inset Formula $\mathbf{X}=(X_{1},X_{2},\ldots,X_{n})$
\end_inset

 is Gaussian if and only if the moment generating function of 
\begin_inset Formula $X$
\end_inset

 is:
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{equation}
\mathbb{E}\left[\exp\left\{ \mathbf{t}^{T}\mathbf{X}\right\} \right]=\exp\left[\mathbf{t}^{T}\boldsymbol{\mu}+\frac{1}{2}\mathbf{t}^{T}\Sigma\mathbf{t}\right]
\end{equation}

\end_inset


\end_layout

\begin_layout Proposition
where 
\begin_inset Formula $\boldsymbol{\mu}$
\end_inset

 is the mean vector and 
\begin_inset Formula $\Sigma$
\end_inset

 is the covariance matrix of 
\begin_inset Formula $\mathbf{X}$
\end_inset

.
\end_layout

\begin_layout Proof
By the definition of joint MGF:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
M_{\mathbf{X}}(\mathbf{t})=\mathbb{E}\left[\exp\left\{ \mathbf{t}^{T}\mathbf{X}\right\} \right]=\mathbb{E}\left[\exp\left\{ t_{1}X_{1}+\ldots+t_{n}X_{n}\right\} \right]\label{eq:joint-mgf_definition-exp}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
But, we know that 
\begin_inset Formula $t_{1}X_{1}+\ldots+t_{n}X_{n}$
\end_inset

 is a Gaussian random variable with mean 
\begin_inset Formula $\mu=\mathbf{t}^{T}\boldsymbol{\mu}$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}=\mathbf{t}^{T}\Sigma\mathbf{t}$
\end_inset

.
 
\end_layout

\begin_layout Proof
The MGF of a univariate Gaussian random variable is :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
M_{X}(s)=\mathbb{E}[\exp(sX)] & =\exp(\mu s+\frac{\sigma^{2}s^{2}}{2})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
At 
\begin_inset Formula $s=1$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
M_{X}(1)=\mathbb{E}[\exp(X)]=\exp(\mu+\frac{\sigma^{2}}{2})
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Thus, if 
\begin_inset Formula $X=t_{1}X_{1}+\ldots+t_{n}X_{n}$
\end_inset

 then it follows that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[\exp\left(t_{1}X_{1}+\ldots+t_{n}X_{n}\right)\right] & =\exp\left[\mathbf{t}^{T}\boldsymbol{\mu}+\frac{1}{2}\mathbf{t}^{T}\Sigma\mathbf{t}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
But from (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:joint-mgf_definition-exp"
plural "false"
caps "false"
noprefix "false"

\end_inset

), this is the joint MGF of 
\begin_inset Formula $\mathbf{X}$
\end_inset

.
 This closes the proof.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:diagonal-cov-matrix-implies-independence-of-gaussians"

\end_inset

Let 
\begin_inset Formula $\mathbf{X}=(X_{1},\ldots,X_{n})$
\end_inset

 be a Gaussian vector.
 Then, the covariance matrix is diagonal, if and only if the random variables
 are independent.
 
\end_layout

\begin_layout Proof
(
\begin_inset Formula $\Longrightarrow$
\end_inset

) direction.
\end_layout

\begin_layout Proof
We are given that the covariance matrix is diagonal.
 Our proposition is that the random variables are independent.
 
\end_layout

\begin_layout Proof
Remember, that if 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

 are independent random variables, 
\begin_inset Formula $Cov(X_{1},X_{2})=0$
\end_inset

.
 But, the converse is not true.
 We use the MGF of the random vector 
\begin_inset Formula $\mathbf{X}$
\end_inset

, to prove this claim.
\end_layout

\begin_layout Proof
We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
M_{\mathbf{X}}(\mathbf{t}) & =\exp\left[\mathbf{t}^{T}\boldsymbol{\mu}+\frac{1}{2}\mathbf{t}^{T}\Sigma\mathbf{t}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $\Sigma=Diag(\sigma_{1}^{2},\ldots,\sigma_{n}^{2})$
\end_inset

, we can express:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{t}^{T}\Sigma\mathbf{t} & =t_{1}^{2}\sigma_{1}^{2}+t_{2}^{2}\sigma_{2}^{2}+\ldots+t_{n}^{2}\sigma_{n}^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
So:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
M_{\mathbf{X}}(\mathbf{t}) & =\exp\left[t_{1}\mu_{1}+\frac{\sigma_{1}^{2}t_{1}^{2}}{2}\right]\cdots\exp\left[t_{n}\mu_{n}+\frac{\sigma_{n}^{2}t_{n}^{2}}{2}\right]\\
 & =M_{X_{1}}(t_{1})\cdots M_{X_{n}}(t_{n})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Consequently, the MGF can factored into a product of the MGFs of 
\begin_inset Formula $X_{1},\ldots,X_{n}$
\end_inset

.
 Thus, 
\begin_inset Formula $X_{1},X_{2},\ldots,X_{n}$
\end_inset

 are independent random variables.
\end_layout

\begin_layout Proof
(
\begin_inset Formula $\Longleftarrow$
\end_inset

) direction.
\end_layout

\begin_layout Proof
This direction is trivial.
 We are given that the random variables are independent.
 Then, 
\begin_inset Formula $Cov(X_{i},X_{j})=0$
\end_inset

 for all 
\begin_inset Formula $i\neq j$
\end_inset

.
 So, the covariance matrix is diagonal.
\end_layout

\begin_layout Standard
Before writing the joint PDF of a Gaussian vector in terms of the mean vector
 and the covariance matrix, we need to introduce the important notion of
 degenerate vector.
 We say a Gaussian vector is 
\emph on
degenerate
\emph default
 if its covariance matrix 
\begin_inset Formula $\Sigma$
\end_inset

 is singular, 
\begin_inset Formula $\det\Sigma=0$
\end_inset

.
\end_layout

\begin_layout Example
Consider 
\begin_inset Formula $(Z_{1},Z_{2},Z_{3})$
\end_inset

 IID standard Gaussian random variables.
 We define 
\begin_inset Formula $X=Z_{1}+Z_{2}+Z_{3}$
\end_inset

, 
\begin_inset Formula $Y=Z_{1}+Z_{2}$
\end_inset

 and 
\begin_inset Formula $W=Z_{3}$
\end_inset

.
 Clearly, 
\begin_inset Formula $(X,Y,W)$
\end_inset

 is a Gaussian vector.
 It has 
\begin_inset Formula $0$
\end_inset

 mean and covariance:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\left[\begin{array}{ccc}
3 & 2 & 1\\
2 & 2 & 0\\
1 & 0 & 1
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
It is easy to check that 
\begin_inset Formula $\det\Sigma=3\cdot2-2\cdot2+1\cdot(-2)=0$
\end_inset

.
 Thus, 
\begin_inset Formula $(X,Y,W)$
\end_inset

 is a degenerate Gaussian vector.
 
\end_layout

\begin_layout Standard
The above example is helpful to illustrate the notion.
 Note that we have the linear relation 
\begin_inset Formula $X-Y-W=0$
\end_inset

 between the random variables.
 Therefore, the random variables are linearly dependent.
 In other words, one vector is redundant, say 
\begin_inset Formula $X$
\end_inset

, in the sense that its value can be recovered from others for any outcome.
 The relation between degeneracy and linear dependence is general.
 
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lemma:linear-dependence-lemma"

\end_inset

Let 
\begin_inset Formula $\mathbf{X}=(X_{1},X_{2},\ldots,X_{n})$
\end_inset

 be a Gaussian vector.
 Then, 
\begin_inset Formula $X$
\end_inset

 is degenerate if and only if the coordinates are linearly dependent.
 That is, there exists 
\begin_inset Formula $c_{1},c_{2},\ldots,c_{n}$
\end_inset

, not all zero, such that 
\begin_inset Formula $c_{1}X_{1}+c_{2}X_{2}+\ldots+c_{n}X_{n}=0$
\end_inset

 with probability one.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
(
\begin_inset Formula $\Longrightarrow$
\end_inset

) direction.
\end_layout

\begin_layout Proof
We are given that the vector 
\begin_inset Formula $X$
\end_inset

 is degenerate.
 This implies that 
\begin_inset Formula $\det\Sigma=0$
\end_inset

 and the columns of 
\begin_inset Formula $\Sigma$
\end_inset

 are linearly dependent.
 
\begin_inset Formula $\Sigma$
\end_inset

 is non-singular.
 
\end_layout

\begin_layout Proof
TODO.
\end_layout

\begin_layout Standard
We are now ready to state the form of the PDF of Gaussian vectors.
 
\end_layout

\begin_layout Definition
(Joint PDF of Gaussian vectors).
 
\begin_inset CommandInset label
LatexCommand label
name "prop:multivariate-gaussian"

\end_inset

 Let 
\begin_inset Formula $\mathbf{X}=(X_{1},X_{2},\ldots,X_{n})$
\end_inset

 be a non-degenerate Gaussian vector with mean vector 
\begin_inset Formula $\boldsymbol{\mu}$
\end_inset

 and covariance matrix 
\begin_inset Formula $\Sigma$
\end_inset

, written 
\begin_inset Formula $N(\boldsymbol{\mu},\boldsymbol{\Sigma})$
\end_inset

.
 Then the joint density of 
\begin_inset Formula $X$
\end_inset

 is given by the PDF:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{equation}
f(x_{1},\ldots,x_{n})=\frac{1}{\sqrt{(2\pi)^{n}|\det\Sigma|}}\exp\left(-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^{T}\Sigma^{-1}(\mathbf{x}-\boldsymbol{\mu})\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Definition
where 
\begin_inset Formula $\mathbf{x}\in\mathbf{R}^{n}$
\end_inset

 and 
\begin_inset Formula $\Sigma$
\end_inset

 is PSD (Positive symmetric definite).
\end_layout

\begin_layout Example
Consider a Gaussian vector 
\begin_inset Formula $(X_{1},X_{2})$
\end_inset

 of mean 
\begin_inset Formula $0$
\end_inset

 and covariance matrix 
\begin_inset Formula $\Sigma=\left[\begin{array}{cc}
2 & 1\\
1 & 2
\end{array}\right]$
\end_inset

.
 The inverse of 
\begin_inset Formula $\Sigma$
\end_inset

 can be found out as follows.
\end_layout

\begin_layout Example
We consider the augmented matrix 
\begin_inset Formula $[\Sigma|I]$
\end_inset

.
 
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\left[\begin{array}{ccccc}
2 & 1 & | & 1 & 0\\
1 & 2 & | & 0 & 1
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
Performing 
\begin_inset Formula $R_{1}=1/2R_{1}$
\end_inset

, the above system is row equivalent to:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\left[\begin{array}{ccccc}
1 & \frac{1}{2} & | & \frac{1}{2} & 0\\
1 & 2 & | & 0 & 1
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
Performing 
\begin_inset Formula $R_{2}=R_{2}-R_{1}$
\end_inset

, the above system is row equivalent to:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\left[\begin{array}{ccccc}
1 & \frac{1}{2} & | & \frac{1}{2} & 0\\
0 & \frac{3}{2} & | & -\frac{1}{2} & 1
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
Peforming 
\begin_inset Formula $R_{2}=\frac{2}{3}R_{2}$
\end_inset

, the above system is row equivalent to:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\left[\begin{array}{ccccc}
1 & \frac{1}{2} & | & \frac{1}{2} & 0\\
0 & 1 & | & -\frac{1}{3} & \frac{2}{3}
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
Performing 
\begin_inset Formula $R_{1}=R_{1}-\frac{1}{2}R_{2}$
\end_inset

, the above system is row equivalent to
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\left[\begin{array}{ccccc}
1 & 0 & | & \frac{2}{3} & -\frac{1}{3}\\
0 & 1 & | & -\frac{1}{3} & \frac{2}{3}
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
So, 
\begin_inset Formula $\Sigma^{-1}=\left[\begin{array}{cc}
2/3 & -1/3\\
-1/3 & 2/3
\end{array}\right]$
\end_inset

 and 
\begin_inset Formula $\det C=3$
\end_inset

.
 By doing matrix operations, the joint PDF of 
\begin_inset Formula $(X_{1},X_{2})$
\end_inset

 is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
f_{(X_{1},X_{2})}(x_{1},x_{2}) & =\frac{1}{\sqrt{(2\pi)^{2}\cdot3}}\exp\left(-\frac{1}{2}\left[\begin{array}{cc}
x_{1} & x_{2}\end{array}\right]\left[\begin{array}{cc}
2/3 & -1/3\\
-1/3 & 2/3
\end{array}\right]\left[\begin{array}{c}
x_{1}\\
x_{2}
\end{array}\right]\right)\\
 & =\frac{1}{2\pi\sqrt{3}}\exp\left(-\frac{1}{2}\left[\begin{array}{cc}
2/3x_{1}-1/3x_{2} & -1/3x_{1}+2/3x_{2}\end{array}\right]\left[\begin{array}{c}
x_{1}\\
x_{2}
\end{array}\right]\right)\\
 & =\frac{1}{2\pi\sqrt{3}}\exp\left(-\frac{1}{3}x_{1}^{2}+\frac{1}{3}x_{1}x_{2}-\frac{1}{3}x_{2}^{2}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We will not prove proposition (
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:multivariate-gaussian"
plural "false"
caps "false"
noprefix "false"

\end_inset

) yet.
 Instead, we will take a short detour and derive it from a powerful decompositio
n of Gaussian vectors as a linear combination of IID Gaussians.
 The decomposition is the generalization of making a random variable 
\emph on
standard
\emph default
.
 Suppose 
\begin_inset Formula $X$
\end_inset

 is Gaussian with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

.Then, we can write it as 
\begin_inset Formula $X=\sigma Z$
\end_inset

, where 
\begin_inset Formula $Z$
\end_inset

 is a standard normal random variable.
 (This makes sense even when 
\begin_inset Formula $X$
\end_inset

 is degenerate that is 
\begin_inset Formula $\sigma^{2}=0$
\end_inset

).
 If 
\begin_inset Formula $\sigma^{2}\neq0$
\end_inset

, then we can reverse the relation to get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Z & =\frac{X}{\sigma}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We generalize this procedure to Gaussian vectors.
 
\end_layout

\begin_layout Proposition
(Decomposition into IID).
 
\begin_inset CommandInset label
LatexCommand label
name "prop:decomposition-into-IID-gaussians"

\end_inset

 Let 
\begin_inset Formula $\mathbf{X}=(X_{1},X_{2},\ldots,X_{n})$
\end_inset

 be a Gaussian vector of mean 
\begin_inset Formula $0$
\end_inset

 and 
\begin_inset Formula $n\times n$
\end_inset

 covariance matrix 
\begin_inset Formula $C$
\end_inset

.
 If 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is non-degenerate, there exists 
\begin_inset Formula $n$
\end_inset

 IID gaussian random variables 
\begin_inset Formula $Z_{1},Z_{2},\ldots,Z_{n}$
\end_inset

 and an invertible 
\begin_inset Formula $n\times n$
\end_inset

 matrix 
\begin_inset Formula $A$
\end_inset

 such that:
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{equation}
\mathbf{X}=AZ,\quad Z=A^{-1}\mathbf{X}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The choice of 
\begin_inset Formula $Z$
\end_inset

s and thus the matrix 
\begin_inset Formula $A$
\end_inset

 is generally not unique as the following simple example shows:
\end_layout

\begin_layout Example
Consider the Gaussian vector 
\begin_inset Formula $(X_{1},X_{2})$
\end_inset

 given by:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
X_{1} & =Z_{1}+Z_{2}\\
X_{2} & =Z_{1}-Z_{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
where 
\begin_inset Formula $Z_{1},Z_{2}$
\end_inset

 are IID standard gaussians.
\end_layout

\begin_layout Example
The matrix 
\begin_inset Formula $A=\left[\begin{array}{cc}
1 & 1\\
1 & -1
\end{array}\right]$
\end_inset

.
 The covariance matrix of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is 
\begin_inset Formula $\left[\begin{array}{cc}
2 & 0\\
0 & 2
\end{array}\right]$
\end_inset

.
 Since, the covariance matrix is diagonal, by proposition (
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:diagonal-cov-matrix-implies-independence-of-gaussians"
plural "false"
caps "false"
noprefix "false"

\end_inset

), the random variables 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

 are independent.
 
\end_layout

\begin_layout Example
Another choice of decomposition is simply 
\begin_inset Formula $W_{1}=X_{1}/\sqrt{2}$
\end_inset

 and 
\begin_inset Formula $W_{2}=X_{2}/\sqrt{2}$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Proof of proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:decomposition-into-IID-gaussians"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Proof
This is done using the same Gram-Schmidt procedure as for 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

.
 The idea is to take the variables one-by-one and subtract the components
 in the directions of the previous ones using covariance.
 The lemma (
\begin_inset CommandInset ref
LatexCommand ref
reference "lemma:linear-dependence-lemma"
plural "false"
caps "false"
noprefix "false"

\end_inset

) ensures that no random variables are linear combinations of the others.
 
\end_layout

\begin_layout Proof
To start, we take 
\begin_inset Formula $Z_{1}=\frac{X_{1}}{\sqrt{C_{11}}}$
\end_inset

.
 Clearly, 
\begin_inset Formula $Z_{1}$
\end_inset

 is a standard normal random variable.
\end_layout

\begin_layout Proof
Then, we define 
\begin_inset Formula $Z_{2}'$
\end_inset

 as:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
Z_{2}' & =X_{2}-\mathbb{E}\left[X_{2}Z_{1}\right]Z_{1}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
And let 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
Z_{2} & =\frac{Z_{2}'}{\sqrt{Var(Z_{2}')}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Firstly, since 
\begin_inset Formula $(X_{1},X_{2})$
\end_inset

 is Gaussian, any linear combination of 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

 must be a Gaussian random variable.
 It follows that 
\begin_inset Formula $Z_{2}'$
\end_inset

 is also a Gaussian random variable.
 Moreover, 
\begin_inset Formula $\mathbb{E}[Z_{2}]=\frac{1}{\sqrt{Var(Z_{2}')}}\cdot\mathbb{E}[X_{2}]=0$
\end_inset

 and 
\begin_inset Formula $Var(Z_{2})=1$
\end_inset

.
 Further:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
Cov(Z_{1},Z_{2}') & =Cov(Z_{1},X_{2}-\mathbb{E}\left[X_{2}Z_{1}\right]Z_{1})\\
 & =Cov(Z_{1},X_{2})-\mathbb{E}\left[X_{2}Z_{1}\right]Var(Z_{1})\\
 & =\mathbb{E}\left[X_{2}Z_{1}\right]-\mathbb{E}\left[X_{2}Z_{1}\right](1)\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Thus, 
\begin_inset Formula $Z_{2}$
\end_inset

 is independent Gaussian with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $1$
\end_inset

.
\end_layout

\begin_layout Proof
In the same way, we take 
\begin_inset Formula $Z_{3}$
\end_inset

 to be:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
Z_{3}' & =X_{3}-\mathbb{E}(X_{3}Z_{2})Z_{2}-E(X_{3}Z_{1})Z_{1}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
and 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
Z_{3} & =\frac{Z_{3}'}{\sqrt{Var(Z_{3}')}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Again, its easy to check that 
\begin_inset Formula $Z_{3}'$
\end_inset

 is independent of 
\begin_inset Formula $Z_{2}$
\end_inset

 and 
\begin_inset Formula $Z_{1}$
\end_inset

.
 As above, we define 
\begin_inset Formula $Z_{3}$
\end_inset

 to be 
\begin_inset Formula $Z_{3}'$
\end_inset

 divided by the square root of variance.
 
\end_layout

\begin_layout Proof
Also, 
\begin_inset Formula $Z_{2}$
\end_inset

 is a linear combination of 
\begin_inset Formula $X_{2}$
\end_inset

and 
\begin_inset Formula $Z_{1}$
\end_inset

 and in turn, 
\begin_inset Formula $Z_{1}$
\end_inset

 is a linear combination of 
\begin_inset Formula $X_{1}$
\end_inset

.
 So, effectively, 
\begin_inset Formula $Z_{3}'$
\end_inset

 is a linear combination of 
\begin_inset Formula $X_{1},X_{2},X_{3}$
\end_inset

.
 Since 
\begin_inset Formula $(X_{1},X_{2},X_{3})$
\end_inset

 is a Gaussian vector, every linear combination is Gaussian.
 So, 
\begin_inset Formula $Z_{3}'$
\end_inset

 is Gaussian.
\end_layout

\begin_layout Proof
This procedure is carried on until we run out variables.
 Not that since 
\begin_inset Formula $C$
\end_inset

 is non-degenerate, none of the variances of the 
\begin_inset Formula $Z_{i}'$
\end_inset

 will be zero, and therefore they can be standardized.
\end_layout

\begin_layout Standard
The covariance matrix 
\begin_inset Formula $C$
\end_inset

 of the Gaussian vector 
\begin_inset Formula $\mathbf{X}$
\end_inset

 with mean vector 
\begin_inset Formula $\boldsymbol{\mu}=\mathbf{0}$
\end_inset

 can be written in terms of 
\begin_inset Formula $A$
\end_inset

.
 Write 
\begin_inset Formula $A=(a_{ij})$
\end_inset

 for the 
\begin_inset Formula $(i,j)$
\end_inset

th entry of the matrix 
\begin_inset Formula $A$
\end_inset

.
 By the relation 
\begin_inset Formula $X=AZ$
\end_inset

, we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Cov(X_{i},X_{j}) & =\mathbb{E}(X_{i}X_{j})\\
 & =\mathbb{E}\left[\left(\sum_{k=1}^{n}a_{ik}Z_{k}\right)\left(\sum_{l=1}^{n}a_{jl}Z_{l}\right)\right]\\
 & =\mathbb{E}\left[\sum_{k=1}^{n}a_{ik}a_{jk}Z_{k}^{2}+\sum_{k\neq l}a_{ik}a_{jl}Z_{k}Z_{l}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Now, we know that: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}(Z_{k}\cdot Z_{l}) & =\begin{cases}
1 & \text{if }k=l\\
0 & \text{otherwise}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
So, the expectation simplifies to:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Cov(X_{i},X_{j}) & =\mathbb{E}\left[\sum_{k=1}^{n}a_{ik}a_{jk}Z_{k}^{2}\right]\\
 & =\sum_{k=1}^{n}a_{ik}a_{jk}\\
 & =(AA^{T})_{ij}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Thus, we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
C & =AA^{T}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Thus, the covariance matrix 
\begin_inset Formula $C$
\end_inset

 of a Gaussian vector 
\begin_inset Formula $\mathbf{X}$
\end_inset

 admits a Cholesky Factorization of the form, 
\begin_inset Formula $C=AA^{T}$
\end_inset

 and therefore, 
\begin_inset Formula $C$
\end_inset

 is SPD(symmetric positive definite).
 For applications and numerical simulations, it is important to get the
 matrix 
\begin_inset Formula $A$
\end_inset

 from the covariance matrix 
\begin_inset Formula $C$
\end_inset

.
 This decomposition is an exact analogue of the decomposition of a vector
 in 
\begin_inset Formula $\mathbf{R}^{3}$
\end_inset

 written as a sum of orthonormal basis vectors.
 In particular, the condition of being non-degenerate is equivalent to linear
 independence.
 
\end_layout

\begin_layout Standard

\series bold
Proof of proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:multivariate-gaussian"
plural "false"
caps "false"
noprefix "false"

\end_inset


\end_layout

\begin_layout Proof
Without the loss of generality assume that 
\begin_inset Formula $\boldsymbol{\mu}=(0,\ldots,0)$
\end_inset

.
 Otherwise, we just need to subtract it from 
\begin_inset Formula $\mathbf{X}$
\end_inset

.
 We use the decomposition in proposition 
\series bold
(
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:decomposition-into-IID-gaussians"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 
\series default
First note that, since 
\begin_inset Formula $C=AA^{T}$
\end_inset

, the determinant of 
\begin_inset Formula $C$
\end_inset

 is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
C & =AA^{T}
\end{align*}

\end_inset

 so the determinant of 
\begin_inset Formula $C$
\end_inset

 is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\det C & =\det A\cdot\det A^{T}\\
 & =\det A\cdot\det A\\
 & =\left(\det A\right)^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
In particular, since 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is non-degenerate, we have that 
\begin_inset Formula $\det C\neq0$
\end_inset

, so 
\begin_inset Formula $\det A\neq0$
\end_inset

.
 Thus, 
\begin_inset Formula $A$
\end_inset

 is invertible.
 We also have by the decomposition that there exist IID Gausian random variables
 
\begin_inset Formula $Z$
\end_inset

 such that 
\begin_inset Formula $\mathbf{X}=AZ$
\end_inset

.
 Now, the event 
\begin_inset Formula $\{\mathbf{X}\in B\}=\{AZ\in B\}=\{Z\in A^{-1}B\}$
\end_inset

.
 So,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
P(X\in B) & =P(Z\in A^{-1}B)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
But we know the joint density of 
\begin_inset Formula $n$
\end_inset

 IID standard normal random variables 
\begin_inset Formula $Z_{1},Z_{2},\ldots,Z_{n}$
\end_inset

.
 Consequently, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
P(X\in B) & =\int\ldots\int_{A^{-1}B}\frac{1}{(2\pi)^{n/2}}\exp\left[-\frac{1}{2}\mathbf{z}^{T}\mathbf{z}\right]dz_{1}\cdots dz_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
because 
\begin_inset Formula $\mathbf{z}=(z_{1},\ldots,z_{n})$
\end_inset

 and 
\begin_inset Formula $\mathbf{z}^{T}\mathbf{z}=z_{1}^{2}+\ldots+z_{n}^{2}$
\end_inset

.
 It remains to do the change of variable 
\begin_inset Formula $\mathbf{x}=A\mathbf{z}$
\end_inset

.
\end_layout

\begin_layout Proof
Let us define the map 
\begin_inset Formula $T$
\end_inset

 as:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{x} & =A\mathbf{z}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Then, the inverse map 
\begin_inset Formula $T^{-1}$
\end_inset

 is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{z} & =A^{-1}\mathbf{x}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is non-degenerate, 
\begin_inset Formula $A^{-1}$
\end_inset

 exists and the right-hand side vector is well-defined.
 The Jacobian 
\begin_inset Formula $\frac{\partial(z_{1},\ldots,z_{n})}{\partial(x_{1},\ldots,x_{n})}$
\end_inset

 is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\frac{\partial(z_{1},\ldots,z_{n})}{\partial(x_{1},\ldots,x_{n})} & =|\det(A^{-1})|=\frac{1}{|\det A|}=\frac{1}{\sqrt{|\det C|}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Moreover, 
\begin_inset Formula $\mathbf{z}\in A^{-1}B$
\end_inset

 is equivalent to 
\begin_inset Formula $\mathbf{x}\in B$
\end_inset

.
 Further, 
\begin_inset Formula $\mathbf{z}^{T}\mathbf{z}=(A^{-1}\mathbf{x})^{T}(A^{-1}\mathbf{x})=\mathbf{x}^{T}(A^{-1})^{T}(A^{-1})\mathbf{x}$
\end_inset

.
 Now, note that if 
\begin_inset Formula $C=AA^{T}$
\end_inset

, by the reverse order law, 
\begin_inset Formula $C^{-1}=(A^{T})^{-1}(A^{-1})=(A^{-1})^{T}(A^{-1})$
\end_inset

.
 Consequently, 
\begin_inset Formula $\mathbf{z}^{T}\mathbf{z}=\mathbf{x}^{T}C^{-1}\mathbf{x}$
\end_inset

.
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
P(X\in B) & =\int\ldots\int_{B}\frac{1}{\sqrt{(2\pi)^{n}|\det C|}}\exp\left[-\frac{1}{2}\mathbf{x}^{T}C^{-1}\mathbf{x}\right]dx_{1}\cdots dx_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Consequently, the joint density function of 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
f_{\mathbf{X}}(\mathbf{x}) & =\frac{1}{\sqrt{(2\pi)^{n}|\det C|}}\exp\left[-\frac{1}{2}\mathbf{x}^{T}C^{-1}\mathbf{x}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
If 
\begin_inset Formula $\mathbf{X}$
\end_inset

 has a non-zero mean vector 
\begin_inset Formula $\mathbf{\boldsymbol{\mu}}$
\end_inset

, then 
\begin_inset Formula $\mathbf{X}'=\mathbf{X}-\boldsymbol{\mu}$
\end_inset

 has a mean vector zero.
 Thus, the joint density function becomes:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
f_{\mathbf{X}}(\mathbf{x}) & =\frac{1}{\sqrt{(2\pi)^{n}|\det C|}}\exp\left[-\frac{1}{2}(\mathbf{x-\boldsymbol{\mu}})^{T}C^{-1}(\mathbf{x-\boldsymbol{\mu}})\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We now explore three ways to find the matrix 
\begin_inset Formula $A$
\end_inset

 in the decomposition of Gaussian vectors of proposition (
\series bold

\begin_inset CommandInset ref
LatexCommand ref
reference "prop:decomposition-into-IID-gaussians"
plural "false"
caps "false"
noprefix "false"

\end_inset


\series default
).
 We proceed by example:
\end_layout

\begin_layout Example
(Cholesky by Gram-Schmidt).
 This is the method suggested by the proof of proposition 
\series bold

\begin_inset CommandInset ref
LatexCommand ref
reference "prop:decomposition-into-IID-gaussians"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 
\series default
It suffices to successively go through the 
\begin_inset Formula $X$
\end_inset

's by subtracting the projection of a given 
\begin_inset Formula $X_{i}$
\end_inset

 onto the previous random variables.
 Consider the random vector 
\begin_inset Formula $\mathbf{X}=(X_{1},X_{2})$
\end_inset

 with mean 
\begin_inset Formula $0$
\end_inset

 and covariance matrix :
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
C & =\left[\begin{array}{cc}
2 & 1\\
1 & 2
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
It is easy to check that 
\begin_inset Formula $X$
\end_inset

 is non-degenerate, 
\begin_inset Formula $\det C=3$
\end_inset

.
 Take:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Z_{1} & =\frac{X_{1}}{\sqrt{2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
This is obviously a standard Gaussian random variable.
 For 
\begin_inset Formula $Z_{2}$
\end_inset

, first consider:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Z_{2}' & =X_{2}-\mathbb{E}(X_{2}Z_{1})Z_{1}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
It is straightforward to check that 
\begin_inset Formula $Z_{1}$
\end_inset

 and 
\begin_inset Formula $Z_{2}'$
\end_inset

 are jointly Gaussian.
 
\begin_inset Formula $Z_{2}'$
\end_inset

 is a linear combination of 
\begin_inset Formula $Z_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

, so 
\begin_inset Formula $Z_{2}'$
\end_inset

 is Gaussian.
 Since all linear combinations of 
\begin_inset Formula $Z_{2}'$
\end_inset

 and 
\begin_inset Formula $Z_{1}$
\end_inset

 are Gaussian, by definition, 
\begin_inset Formula $(Z_{1},Z_{2}')$
\end_inset

 is jointly Gaussian.
 They are also independent, because:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}(Z_{1}Z_{2}') & =\mathbb{E}[Z_{1}(X_{2}-\mathbb{E}(X_{2}Z_{1})Z_{1})]\\
 & =\mathbb{E}[Z_{1}X_{2}]-\mathbb{E}(X_{2}Z_{1})\mathbb{E}(Z_{1}^{2})\\
 & =\mathbb{E}[Z_{1}X_{2}]-\mathbb{E}(X_{2}Z_{1})\cdot1\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Note that:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Z_{2}' & =X_{2}-\mathbb{E}[X_{2}Z_{1}]Z_{1}\\
 & =X_{2}-\mathbb{E}\left[X_{2}\frac{X_{1}}{\sqrt{2}}\right]\frac{X_{1}}{\sqrt{2}}\\
 & =X_{2}-\frac{1}{2}\mathbb{E}[X_{1}X_{2}]X_{1}\\
 & =X_{2}-\frac{1}{2}X_{1}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In particular, we have by linearity of expectations:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}[(Z_{2}')^{2}] & =\mathbb{E}[X_{2}^{2}-X_{1}X_{2}+\frac{1}{4}X_{1}^{2}]\\
 & =\mathbb{E}(X_{2}^{2})-\mathbb{E}(X_{1}X_{2})+\frac{1}{4}\mathbb{E}(X_{1}^{2})\\
 & =2-1+\frac{1}{4}\cdot2\\
 & =\frac{3}{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
To get a random variable of variance 
\begin_inset Formula $1$
\end_inset

, that is a multiple of 
\begin_inset Formula $Z_{2}'$
\end_inset

, we take 
\begin_inset Formula $Z_{2}=\frac{Z_{2}'}{\sqrt{3/2}}=\sqrt{\frac{2}{3}}Z_{2}=\sqrt{\frac{2}{3}}X_{2}-\frac{1}{\sqrt{6}}X_{1}$
\end_inset

.
 Altogether, we get :
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Z_{1} & =\frac{X_{1}}{\sqrt{2}}\\
Z_{2} & =-\frac{1}{\sqrt{6}}X_{1}+\sqrt{\frac{2}{3}}X_{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We thus constructed two standard IID Gaussians from 
\begin_inset Formula $(X_{1},X_{2})$
\end_inset

.
 In particular we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
A^{-1}=\left[\begin{array}{cc}
\frac{1}{\sqrt{2}} & 0\\
-\frac{1}{\sqrt{6}} & \sqrt{\frac{2}{3}}
\end{array}\right],\quad A=\left[\begin{array}{cc}
\sqrt{2} & 0\\
\frac{1}{\sqrt{2}} & \sqrt{\frac{3}{2}}
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Example
We can check that :
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
AA^{T} & =\left[\begin{array}{cc}
\sqrt{2} & 0\\
\frac{1}{\sqrt{2}} & \sqrt{\frac{3}{2}}
\end{array}\right]\left[\begin{array}{cc}
\sqrt{2} & \frac{1}{\sqrt{2}}\\
0 & \sqrt{\frac{3}{2}}
\end{array}\right]\\
 & =\left[\begin{array}{cc}
2 & 1\\
1 & 2
\end{array}\right]\\
 & =C
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The probability of the event 
\begin_inset Formula $P(X_{1}>2,X_{2}<3)$
\end_inset

 can be computed as follows:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
P(X_{1}>2,X_{2}<3) & =P\left(\sqrt{2}Z_{1}>2,\frac{1}{\sqrt{2}}Z_{1}+\sqrt{\frac{3}{2}}Z_{2}<3\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(Cholesky by solving a system of equations).
 Consider the same example as above.
 Write 
\begin_inset Formula $A=\left[\begin{array}{cc}
a & b\\
c & d
\end{array}\right]$
\end_inset

.
 Then the relation 
\begin_inset Formula $C=AA^{T}$
\end_inset

 yields:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\left[\begin{array}{cc}
a & b\\
c & d
\end{array}\right]\left[\begin{array}{cc}
a & c\\
b & d
\end{array}\right] & =\left[\begin{array}{cc}
a^{2}+b^{2} & ac+bd\\
ac+bd & c^{2}+d^{2}
\end{array}\right]=\left[\begin{array}{cc}
2 & 1\\
1 & 2
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
and so we have the three equations:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
a^{2}+b^{2} & =2\\
ac+bd & =1\\
c^{2}+d^{2} & =2
\end{align*}

\end_inset


\end_layout

\begin_layout Example
There are several solutions.
 One of them is 
\begin_inset Formula $a=\sqrt{2}$
\end_inset

, 
\begin_inset Formula $b=0$
\end_inset

, 
\begin_inset Formula $c=\frac{1}{\sqrt{2}}$
\end_inset

 and 
\begin_inset Formula $d=\sqrt{\frac{3}{2}}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(
\emph on
Cholesky by diagonalization
\emph default
) This method takes advantage of the symmetry of the covariance matrix.
 From the spectral theorem, we know that, if 
\begin_inset Formula $C$
\end_inset

 is a symmetric matrix, it is diagonalizable, it admits a factorization
 of the form 
\begin_inset Formula $Q\Lambda Q^{-1}$
\end_inset

 where 
\begin_inset Formula $Q$
\end_inset

 is an orthogonal matrix.
 The entries of 
\begin_inset Formula $\Lambda$
\end_inset

 are the eigenvalues of 
\begin_inset Formula $C$
\end_inset

.
 Furthermore, the eigenvectors are orthogonal to each other.
 
\end_layout

\begin_layout Example
Since 
\begin_inset Formula $C=AA^{T}$
\end_inset

, we get:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
C & =Q\Lambda Q^{T}\\
\Longleftrightarrow AA^{T} & =Q\Lambda Q^{T}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
It suffices to take:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
A & =Q\Lambda^{1/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
where 
\begin_inset Formula $Q$
\end_inset

 is the matrix with the columns given by the eigenvectors of 
\begin_inset Formula $C$
\end_inset

 and 
\begin_inset Formula $\Lambda^{1/2}$
\end_inset

 is the diagonal matrix with the square root of the eigenvalues on the diagonal.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(IID Decomposition).
 Let 
\begin_inset Formula $X=(X_{1},X_{2},X_{3})$
\end_inset

 be a Gaussian vector with mean 
\begin_inset Formula $0$
\end_inset

 and covariance matrix:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
C & =\left[\begin{array}{ccc}
1 & 1 & 1\\
1 & 2 & 2\\
1 & 2 & 3
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Let's find a matrix 
\begin_inset Formula $A$
\end_inset

 such that 
\begin_inset Formula $X=AZ$
\end_inset

 for 
\begin_inset Formula $Z=(Z_{1},Z_{2},Z_{3})$
\end_inset

 IID standard gaussians.
 The vector is not degenerate since 
\begin_inset Formula $\det C=1\cdot(2-1)=1$
\end_inset

.
 If we do a Gram-Schmidt procedure, we get:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Z_{1} & =X_{1}\\
Z_{2} & =(X_{2}-X_{1})\\
Z_{3} & =X_{3}-(X_{2}-X_{1})-X_{1}\\
 & =X_{3}-X_{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Consequently, 
\begin_inset Formula $X_{1}=Z_{1}$
\end_inset

, 
\begin_inset Formula $X_{2}=Z_{1}+Z_{2}$
\end_inset

 and 
\begin_inset Formula $X_{3}=Z_{1}+Z_{2}+Z_{3}$
\end_inset

.
 So, the matrix 
\begin_inset Formula $A$
\end_inset

 is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
A & =\left[\begin{array}{ccc}
1 & 0 & 0\\
1 & 1 & 0\\
1 & 1 & 1
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
As we will see in the next section, this random vector corresponds to the
 position of the Brownian motion at time 
\begin_inset Formula $1$
\end_inset

, 
\begin_inset Formula $2$
\end_inset

 and 
\begin_inset Formula $3$
\end_inset

.
\end_layout

\begin_layout Subsection
Gaussian Processes.
 
\end_layout

\begin_layout Standard
In general, a 
\emph on
stochastic process
\emph default
 is an infinite collection of random variables on a probability space 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 The collection can be countable or uncountable.
 We are mostly interested in the case, where the variables are indexed by
 time; for example
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
X & =(X_{t},t\in\mathcal{J})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\mathcal{J}$
\end_inset

 can be a finite set, 
\begin_inset Formula $\mathbf{N}$
\end_inset

 or some uncountable set such as the closed interval 
\begin_inset Formula $[0,T]$
\end_inset

 or 
\begin_inset Formula $[0,\infty)$
\end_inset

.
\end_layout

\begin_layout Standard
In the case where 
\begin_inset Formula $\mathcal{J}=[0,\infty)$
\end_inset

 or 
\begin_inset Formula $[0,T]$
\end_inset

, the realization of the process 
\begin_inset Formula $X(\omega)$
\end_inset

 can be thought of as a function of time for each outcome 
\begin_inset Formula $\omega$
\end_inset

.
 This function 
\begin_inset Formula $t\mapsto X_{t}(\omega)$
\end_inset

 is sometimes called a 
\emph on
path
\emph default
 or the 
\emph on
trajectory
\emph default
 of the process.
 With this in mind, we can think of the process 
\begin_inset Formula $(X)_{t\geq0}$
\end_inset

 as a function-valued random variable as each outcome 
\begin_inset Formula $\omega$
\end_inset

 produces a function.
\end_layout

\begin_layout Standard
(a) For each 
\begin_inset Formula $t$
\end_inset

, 
\begin_inset Formula $X(t,\cdot)$
\end_inset

 is a random variable.
 
\end_layout

\begin_layout Standard
(b) For each 
\begin_inset Formula $\omega$
\end_inset

, 
\begin_inset Formula $X(\cdot,\omega)$
\end_inset

 is a 
\emph on
function
\emph default
 (called a 
\emph on
sample path
\emph default
)
\end_layout

\begin_layout Standard
For convenience, the random variable 
\begin_inset Formula $X(t,\cdot)$
\end_inset

 will be written as 
\begin_inset Formula $X(t)$
\end_inset

 or 
\begin_inset Formula $X_{t}$
\end_inset

.
 Thus a stochastic process 
\begin_inset Formula $X(t,\omega)$
\end_inset

 can also be expressed as 
\begin_inset Formula $(X(t))_{t\geq0}$
\end_inset

 or simply 
\begin_inset Formula $X(t)$
\end_inset

.
\end_layout

\begin_layout Standard
How can we compute the probabilities for a stochastic process? In other
 words, what object captures it's distribution? The most common way (there
 are others) is to use finite dimensional distributions.
 The idea here is to describe the probabilities related to any finite set
 of time.
 More precisely, the finite-dimensional distributions are given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathbb{P}(X_{t_{1}}\in B_{1},X_{t_{2}}\in B_{2},\ldots,X_{t_{n}}\in B_{n})
\]

\end_inset


\end_layout

\begin_layout Standard
for any 
\begin_inset Formula $n\in\mathbf{N}$
\end_inset

, any choice of 
\begin_inset Formula $t_{1},\ldots,t_{n}\in\mathcal{J}$
\end_inset

, and any events 
\begin_inset Formula $B_{1},\ldots,B_{n}$
\end_inset

 in 
\begin_inset Formula $\mathbf{R}$
\end_inset

.
 Of course, for any fixed choice of 
\begin_inset Formula $t$
\end_inset

's 
\begin_inset Formula $(X_{t_{1}},\ldots,X_{t_{n}})$
\end_inset

 is a random vector as seen in the previous section.
 The fact that we can control the probabilities for the whole random function
 comes from the fact that we have the distributions of these vectors for
 any 
\begin_inset Formula $n$
\end_inset

 and any choice of 
\begin_inset Formula $t$
\end_inset

's.
\end_layout

\begin_layout Standard
Some important types of stochastic processes include Markov processes, martingal
es and Gaussian processes.
 We will encounter them along the way.
 Let's start with Gaussian processes.
\end_layout

\begin_layout Definition
A 
\emph on
Gaussian process
\emph default
 
\begin_inset Formula $(X_{t})_{t\geq0}$
\end_inset

 is a stochastic process whose finite dimensional distributions are jointly
 Gaussian.
 In other words, for any 
\begin_inset Formula $n\in\mathbf{N}$
\end_inset

 and any choice of 
\begin_inset Formula $t_{1}<\ldots<t_{n}$
\end_inset

 we have that 
\begin_inset Formula $(X_{t_{1}},X_{t_{2}},\ldots,X_{t_{n}})$
\end_inset

 is a Gaussian vector.
 In particular, its distribution is defined by the mean function 
\begin_inset Formula $m(t)=\mathbb{E}(X_{t})$
\end_inset

 and the covariance function 
\begin_inset Formula $C(s,t)=Cov(X_{t},X_{s})$
\end_inset

.
\end_layout

\begin_layout Standard
As before, linear combinations of Gaussian processes remain Gaussian.
 
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lemma:linear-combination-of-gaussian-processes"

\end_inset

Let 
\begin_inset Formula $X^{(1)},X^{(2)},\ldots,X^{(m)}$
\end_inset

 be 
\begin_inset Formula $m$
\end_inset

 Gaussian processes on 
\begin_inset Formula $[0,\infty)$
\end_inset

 defined on the same probability space.
 Then, any process constructed by taking linear combinations is also a Gaussian
 process:
\end_layout

\begin_layout Lemma
\begin_inset Formula 
\begin{align*}
a_{1}X^{(1)}+\ldots+a_{m}X^{(m)} & =\left(a_{1}X_{t}^{(1)}+\ldots+a_{m}X_{t}^{(m)},t\geq0\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
It suffices to take a finite set of times 
\begin_inset Formula $t_{1}<t_{2}<\ldots<t_{n}$
\end_inset

.
 Consider the vector:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\mathbf{Y}=\left[\begin{array}{c}
a_{1}X_{t_{1}}^{(1)}+\ldots+a_{m}X_{t_{1}}^{(m)}\\
a_{1}X_{t_{2}}^{(1)}+\ldots+a_{m}X_{t_{2}}^{(m)}\\
\vdots\\
a_{1}X_{t_{n}}^{(1)}+\ldots+a_{m}X_{t_{n}}^{(m)}
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Proof
Consider any linear combination of these random variables:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\beta_{1}Y_{1}+\ldots\beta_{n}Y_{n} & =\beta_{1}\sum_{j=1}^{m}a_{j}X_{t_{1}}^{(j)}+\ldots+\beta_{n}\sum_{j=1}^{m}a_{j}X_{t_{n}}^{(j)}\\
 & =a_{1}\sum_{i=1}^{n}\beta_{i}X_{t_{i}}^{(1)}+\ldots+a_{n}\sum_{i=1}^{n}\beta_{i}X_{t_{i}}^{(m)}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $(X_{t_{1}}^{(j)},\ldots,X_{t_{n}}^{(j)})$
\end_inset

 is a Gaussian vector, any linear combination 
\begin_inset Formula $\sum\beta_{i}X_{t_{i}}^{(j)}$
\end_inset

 is Gaussian.
 Moreover, since 
\end_layout

\begin_layout Standard
The most important example of a Gaussian process is a Brownian motion.
 
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:standard-brownian-motion"

\end_inset

(
\emph on
Standard Brownian motion or Wiener process
\emph default
).
 A stochastic process 
\begin_inset Formula $B(t,\omega)$
\end_inset

 is called a Brownian motion if it satisfies the following conditions:
\end_layout

\begin_layout Itemize
\begin_inset Formula $\mathbb{P}\{\omega:B(0,\omega)=0\}=1$
\end_inset

.
\end_layout

\begin_layout Itemize
For any 
\begin_inset Formula $0\leq s<t$
\end_inset

, the random variable 
\begin_inset Formula $B(t)-B(s)$
\end_inset

 is normally distributed with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $t-s$
\end_inset

.
 That is for any 
\begin_inset Formula $a<b$
\end_inset

:
\begin_inset Formula 
\begin{align*}
\mathbb{P}\{a\leq B(t)-B(s)\leq b\} & =\frac{1}{\sqrt{2\pi(t-s)}}\int_{a}^{b}e^{-\frac{x^{2}}{2(t-s)}}dx
\end{align*}

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $B(t,\omega)$
\end_inset

 has independent increments, i.e.
 for any 
\begin_inset Formula $0\leq t_{1}<t_{2}<\ldots<t_{n}$
\end_inset

, the random variables :
\begin_inset Formula 
\[
B(t_{1}),B(t_{2})-B(t_{1}),B(t_{3})-B(t_{2}),\ldots,B(t_{n})-B(t_{n-1})
\]

\end_inset

 are independent.
 
\end_layout

\begin_layout Itemize
Almost all sample paths of 
\begin_inset Formula $B(t,\omega)$
\end_inset

 are continuous functions, that is,
\begin_inset Formula 
\[
P(\omega\hspace{1em}|\hspace{1em}B(\cdot,\omega)\text{ is continuous})=1
\]

\end_inset


\end_layout

\begin_layout Proposition
The standard Brownian motion 
\begin_inset Formula $(B_{t},t\geq0)$
\end_inset

 is a Gaussian process.
\end_layout

\begin_layout Standard

\emph on
Proof.
\end_layout

\begin_layout Standard
Consider any finite set of times 
\begin_inset Formula $0\leq t_{1}\leq t_{2}\leq\ldots\leq t_{n}$
\end_inset

.
 Our claim is that the vector 
\begin_inset Formula $(B_{t_{1}},\ldots,B_{t_{n}})$
\end_inset

 is Gaussian.
 
\end_layout

\begin_layout Standard
First consider 
\begin_inset Formula $n=1$
\end_inset

.
 
\begin_inset Formula $B(t_{1})$
\end_inset

 is a Gaussian random variable centered at 
\begin_inset Formula $0$
\end_inset

.
 Any scalar multiple 
\begin_inset Formula $\alpha_{1}B_{t_{1}}$
\end_inset

 is also Gaussian.
\end_layout

\begin_layout Standard
Next, consider 
\begin_inset Formula $n=2$
\end_inset

.
 We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\alpha_{1}B_{t_{1}}+\alpha_{2}B_{t_{2}} & =(\alpha_{1}+\alpha_{2})B_{t_{1}}+\alpha_{2}(B_{t_{2}}-B_{t_{1}})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Now, 
\begin_inset Formula $B_{t_{1}}$
\end_inset

 is a Gaussian random variable and it is 
\begin_inset Formula $\mathcal{F}_{t_{1}}$
\end_inset

 measurable.
 
\begin_inset Formula $(B_{t_{2}}-B_{t_{1}})$
\end_inset

 is also Gaussian and independent of 
\begin_inset Formula $\mathcal{F}_{t_{1}}$
\end_inset

.
 Hence, 
\begin_inset Formula $\alpha_{1}B_{t_{1}}+\alpha_{2}B_{t_{2}}$
\end_inset

 is Gaussian.
\end_layout

\begin_layout Standard
Assume that 
\begin_inset Formula $\alpha_{1}B_{t_{1}}+\ldots+\alpha_{k}B_{t_{k}}$
\end_inset

 is Gaussian for all 
\begin_inset Formula $\alpha_{1},\ldots,\alpha_{k}\in\mathbf{R}$
\end_inset

.
 Our claim is that 
\begin_inset Formula $\alpha_{1}B_{t_{1}}+\ldots+\alpha_{k}B_{t_{k}}+\alpha_{k+1}B_{t_{k+1}}$
\end_inset

 is Gaussian.
\end_layout

\begin_layout Standard
We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\alpha_{1}B_{t_{1}}+\ldots+\alpha_{k}B_{t_{k}}+\alpha_{k+1}B_{t_{k+1}} & =(\alpha_{1}B_{t_{1}}+\ldots+(\alpha_{k}+\alpha_{k+1})B_{t_{k}})+\alpha_{k+1}(B_{t_{k+1}}-B_{t_{k}})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Now, from our inductive assumption 
\begin_inset Formula $\alpha_{1}B_{t_{1}}+\ldots+(\alpha_{k}+\alpha_{k+1})B_{t_{k}}$
\end_inset

is Gaussian and 
\begin_inset Formula $\mathcal{F}_{t_{k}}$
\end_inset

 measurable.
 Also, 
\begin_inset Formula $(B_{t_{k+1}}-B_{t_{k}})$
\end_inset

 is Gaussian and independent of 
\begin_inset Formula $\mathcal{F}_{t_{k}}$
\end_inset

.
\end_layout

\begin_layout Example
(Sampling a Gaussian process using Cholesky decomposition).
 The IID decomposition of proposition 
\series bold

\begin_inset CommandInset ref
LatexCommand ref
reference "prop:decomposition-into-IID-gaussians"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\series default
is useful for generating a sample of the Gaussian process.
 
\begin_inset Formula $(X_{t})_{t\in[0,T]}$
\end_inset

.
 First, we need to fix the discretization or step-size.
 Take for example, a step size of 
\begin_inset Formula $0.01$
\end_inset

, meaning we approximate the process by evaluating the position at every
 
\begin_inset Formula $0.01$
\end_inset

.
 This is given by the Gaussian vector:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
(X_{\frac{j}{100},} & j=1,2,3,\ldots,100T)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
This Gaussian vector has covariance matrix 
\begin_inset Formula $C$
\end_inset

 and a matrix 
\begin_inset Formula $A$
\end_inset

 from the IID decomposition.
 Note that, we start with the vector at 
\begin_inset Formula $0.01$
\end_inset

 and not 
\begin_inset Formula $0$
\end_inset

.
 This is because in some cases (like the standard Brownian motion) the value
 at time 
\begin_inset Formula $0$
\end_inset

 is 
\begin_inset Formula $0$
\end_inset

.
 Including it in the covariance matrix would result in a degenerate covariance
 matrix.
 You can always add position 
\begin_inset Formula $0$
\end_inset

 at time 
\begin_inset Formula $0$
\end_inset

 after performing the cholesky decomposition.
 It then suffices to sample 
\begin_inset Formula $100T$
\end_inset

 IID standard Gaussian random variable 
\begin_inset Formula $Z=(Z_{1},Z_{2},\ldots,Z_{100T})$
\end_inset

 and to apply the deterministic matrix 
\begin_inset Formula $A$
\end_inset

 to the sample vector to get :
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
(X_{\frac{j}{100}},j=1,2,\ldots,100T) & =AZ
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example

\series bold
Simulating Brownian Motion
\series default
.

\series bold
 
\series default
The goal of this project is to simulate 
\begin_inset Formula $100$
\end_inset

 paths of Brownian motion on 
\begin_inset Formula $[0,1]$
\end_inset

 using a step-size of 
\begin_inset Formula $0.01$
\end_inset

 using the Cholesky decomposition.
 
\end_layout

\begin_layout Example
(a) Construct the covariance matrix of 
\begin_inset Formula $(B_{j/100})_{1\leq j\leq100}$
\end_inset

 using a for-loop.
 Recall that for a Brownian motion 
\begin_inset Formula $C(s,t)=s\land t$
\end_inset

 with mean 
\begin_inset Formula $0$
\end_inset

.
\end_layout

\begin_layout Example
(b) The command 
\begin_inset Formula $\texttt{numpy.linalg.cholesky}$
\end_inset

 in Python gives the Cholesky decomposition of the covariance matrix 
\begin_inset Formula $C$
\end_inset

.
 Use this to find the matrix 
\begin_inset Formula $A$
\end_inset

.
\end_layout

\begin_layout Example
(c) Define a function whose output is a sample of 
\begin_inset Formula $N$
\end_inset

 standard Gaussian random variables and whose input is 
\begin_inset Formula $N$
\end_inset

.
\end_layout

\begin_layout Example
(d) Use the above to plot 
\begin_inset Formula $n=100$
\end_inset

 paths of the Brownian motion on 
\begin_inset Formula $[0,1]$
\end_inset

 with a step size of 
\begin_inset Formula $0.01$
\end_inset

.
 Do not forget 
\begin_inset Formula $B_{0}$
\end_inset

!
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{language=Python,backgroundcolor=
\backslash
color{backcolour},breaklines=true,commentstyle=
\backslash
color{codegreen},stringstyle=
\backslash
color{magenta},keywordstyle=
\backslash
bfseries
\backslash
color{blue!40!black},basicstyle=
\backslash
footnotesize
\backslash
ttfamily,frame=single}
\end_layout

\begin_layout Plain Layout


\backslash
begin{lstlisting}[caption=Generating 100 paths of a standard brownian motion]
\end_layout

\begin_layout Plain Layout

import numpy as np
\end_layout

\begin_layout Plain Layout

import seaborn as sns
\end_layout

\begin_layout Plain Layout

import matplotlib.pyplot as plt
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

sns.set_style("whitegrid")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# A generator for N standard gaussian random variables
\end_layout

\begin_layout Plain Layout

def standardNormalGenerator(N):
\end_layout

\begin_layout Plain Layout

    return np.random.standard_normal(N)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# Produces 1 sample (path) of a gaussian process
\end_layout

\begin_layout Plain Layout

# N : Number of time-steps
\end_layout

\begin_layout Plain Layout

# A : The transformation that maps IID gaussians (Z_1,Z_2,...,Z_N) to a gaussian
 vector (X_1,X_2,...,X_N)
\end_layout

\begin_layout Plain Layout

# with covariance matrix C = AA'
\end_layout

\begin_layout Plain Layout

def sampleGaussianProcess(A,N):
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    Z = standardNormalGenerator(N)
\end_layout

\begin_layout Plain Layout

    X = np.matmul(A,Z)
\end_layout

\begin_layout Plain Layout

    return X
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# Produces `numOfPaths` paths of a standard brownian motion
\end_layout

\begin_layout Plain Layout

# N : Number of time-steps, 1/N : step-size
\end_layout

\begin_layout Plain Layout

def standardBrownianMotion(numOfPaths,N):
\end_layout

\begin_layout Plain Layout

    C = np.zeros((N,N))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    for i in range(N):
\end_layout

\begin_layout Plain Layout

        for j in range(N):
\end_layout

\begin_layout Plain Layout

            s = (i+1)/N
\end_layout

\begin_layout Plain Layout

            t = (j+1)/N
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

            C[i][j] = np.min([s,t])
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    A = np.linalg.cholesky(C)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    B = []
\end_layout

\begin_layout Plain Layout

    for i in range(numOfPaths):
\end_layout

\begin_layout Plain Layout

        X = sampleGaussianProcess(A,N)
\end_layout

\begin_layout Plain Layout

        X = np.concatenate(([0], X), axis=0)
\end_layout

\begin_layout Plain Layout

        B.append(X)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    return B
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

if __name__ == "__main__":
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    T = 1.0
\end_layout

\begin_layout Plain Layout

    N = 100
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    C = covarMatrix(N)
\end_layout

\begin_layout Plain Layout

    B = standardBrownianMotion(numOfPaths=100,covarianceMatrix=C,N=100)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    plt.xlabel(r'$t$')
\end_layout

\begin_layout Plain Layout

    plt.ylabel(r'$B(t,
\backslash
omega)$')
\end_layout

\begin_layout Plain Layout

    plt.grid(True)
\end_layout

\begin_layout Plain Layout

    plt.title(r'$100$ sample paths of a standard brownian motion')
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    t = np.linspace(start=0,stop=1.0,num=101)
\end_layout

\begin_layout Plain Layout

    for n in range(100):
\end_layout

\begin_layout Plain Layout

        plt.plot(t,B[n])
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    plt.show()
\end_layout

\begin_layout Plain Layout


\backslash
end{lstlisting}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/standard_brownian_motion.tex"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(
\emph on
Brownian motion with a drift
\emph default
.) For 
\begin_inset Formula $\sigma>0$
\end_inset

 (called the volatility or diffusion coefficient) and 
\begin_inset Formula $\mu\in\mathbf{R}$
\end_inset

 (called the drift), we define the process:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
X_{t} & =\sigma B_{t}+\mu t
\end{align*}

\end_inset


\end_layout

\begin_layout Example
where 
\begin_inset Formula $(B_{t})_{t\geq0}$
\end_inset

 is a standard brownian motion.
 This is a Gaussian process, because it is a linear transformation of a
 brownian motion, which is itself a Gaussian process by lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lemma:linear-combination-of-gaussian-processes"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Example
A straightfoward computation shows that:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}[X_{t}] & =\sigma\mathbb{E}[B_{t}]+\mathbb{E}[\mu t]\\
 & =\mu t
\end{align*}

\end_inset


\end_layout

\begin_layout Example
and if 
\begin_inset Formula $0\leq s\leq t$
\end_inset

,
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}[X_{s}X_{t}] & =\mathbb{E}[(\sigma B_{s}+\mu s)(\sigma B_{t}+\mu t)]\\
 & =\mathbb{E}[\sigma^{2}B_{s}B_{t}+\mu tB_{s}+\mu s\sigma B_{t}+\mu^{2}st]\\
 & =\sigma^{2}s+\mu^{2}st
\end{align*}

\end_inset


\end_layout

\begin_layout Example
so,
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Cov(X_{s},X_{t}) & =\sigma^{2}s
\end{align*}

\end_inset


\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{language=Python,backgroundcolor=
\backslash
color{backcolour},breaklines=true,commentstyle=
\backslash
color{codegreen},stringstyle=
\backslash
color{magenta},keywordstyle=
\backslash
bfseries
\backslash
color{blue!40!black},basicstyle=
\backslash
footnotesize
\backslash
ttfamily,frame=single}
\end_layout

\begin_layout Plain Layout


\backslash
begin{lstlisting}[caption=Brownian motion with a drift]
\end_layout

\begin_layout Plain Layout

# Given a standard brownian motion, this function produces a
\end_layout

\begin_layout Plain Layout

# brownian motion with drift = mu and diffusion coefficient=sigma
\end_layout

\begin_layout Plain Layout

def brownianMotionWithDrift(mu,sigma,B_t):
\end_layout

\begin_layout Plain Layout

    numOfPaths = len(B_t)
\end_layout

\begin_layout Plain Layout

    N = len(B_t[0])
\end_layout

\begin_layout Plain Layout

    t = np.linspace(start=0,stop=1.0,num=N)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    Y = []
\end_layout

\begin_layout Plain Layout

    for omega_i in range(numOfPaths):
\end_layout

\begin_layout Plain Layout

        X_t = sigma * B_t[omega_i] + mu * t
\end_layout

\begin_layout Plain Layout

        Y.append(X_t)
\end_layout

\begin_layout Plain Layout


\backslash
end{lstlisting}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/brownian_motion_with_drift.tex"

\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "example:brownian-bridge"

\end_inset

(
\emph on
Brownian Bridge
\emph default
).
 The Brownian bridge is a Gaussian process 
\begin_inset Formula $(Z_{t})_{t\in[0,1]}$
\end_inset

 defined by the mean 
\begin_inset Formula $\mathbb{E}[Z_{t}]=0$
\end_inset

 and covariance 
\begin_inset Formula $Cov(Z_{t},Z_{s})=s(1-t)$
\end_inset

 if 
\begin_inset Formula $0\leq s\leq t$
\end_inset

.
 Note that by construction, 
\begin_inset Formula $Z_{0}=Z_{1}=0$
\end_inset

.
 It turns out that if 
\begin_inset Formula $(B_{t})_{t\in[0,1]}$
\end_inset

 is a standard brownian motion on 
\begin_inset Formula $[0,1]$
\end_inset

, then the process 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Z_{t} & =B_{t}-tB_{1},\quad t\in[0,1]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
has the distribution of a Brownian bridge.
\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{language=Python,backgroundcolor=
\backslash
color{backcolour},breaklines=true,commentstyle=
\backslash
color{codegreen},stringstyle=
\backslash
color{magenta},keywordstyle=
\backslash
bfseries
\backslash
color{blue!40!black},basicstyle=
\backslash
footnotesize
\backslash
ttfamily,frame=single}
\end_layout

\begin_layout Plain Layout


\backslash
begin{lstlisting}[caption=Brownian bridge]
\end_layout

\begin_layout Plain Layout

def brownianBridge(B_t):
\end_layout

\begin_layout Plain Layout

    numOfPaths = len(B_t)
\end_layout

\begin_layout Plain Layout

    N = len(B_t[0])
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    t = np.linspace(start=0, stop=1.0, num=N)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    Z = []
\end_layout

\begin_layout Plain Layout

    for omega_i in range(numOfPaths):
\end_layout

\begin_layout Plain Layout

        X = B_t[omega_i] - B_t[omega_i][N-1]* t
\end_layout

\begin_layout Plain Layout

        Z.append(X)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    return Z
\end_layout

\begin_layout Plain Layout


\backslash
end{lstlisting}
\end_layout

\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/brownian_bridge.tex"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(
\emph on
Fractional Brownian Motion
\emph default
).
 The fractional Brownian motion 
\begin_inset Formula $(B_{t}^{(H)})_{t\geq0}$
\end_inset

 with index 
\begin_inset Formula $0<H<1$
\end_inset

 (called the Hurst Index), is the Gaussian process with mean 
\begin_inset Formula $0$
\end_inset

 and covariance 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Cov(Y_{s},Y_{t}) & =\mathbb{E}[B_{t}^{(H)},B_{s}^{(H)}]=\frac{1}{2}(t^{2H}+s^{2H}-|t-s|^{2H})
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The case of 
\begin_inset Formula $H=1/2$
\end_inset

 corresponds to the Brownian motion.
 
\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{language=Python,backgroundcolor=
\backslash
color{backcolour},breaklines=true,commentstyle=
\backslash
color{codegreen},stringstyle=
\backslash
color{magenta},keywordstyle=
\backslash
bfseries
\backslash
color{blue!40!black},basicstyle=
\backslash
footnotesize
\backslash
ttfamily,frame=single}
\end_layout

\begin_layout Plain Layout


\backslash
begin{lstlisting}[caption=Fractional Brownian Motion]
\end_layout

\begin_layout Plain Layout

def fBM(H,numOfPaths,N):
\end_layout

\begin_layout Plain Layout

    # Initialize the covariance matrix
\end_layout

\begin_layout Plain Layout

    C = np.zeros((N,N))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    for i in range(N):
\end_layout

\begin_layout Plain Layout

        for j in range(N):
\end_layout

\begin_layout Plain Layout

            s = (i+1)/N
\end_layout

\begin_layout Plain Layout

            t = (j+1)/N
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

            C[i][j] = 0.50 * (s**(2*H) + t**(2*H) - (np.abs(t - s))**(2*H))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    A = np.linalg.cholesky(C)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    Y = []
\end_layout

\begin_layout Plain Layout

    for i in range(numOfPaths):
\end_layout

\begin_layout Plain Layout

        X = sampleGaussianProcess(A, N)
\end_layout

\begin_layout Plain Layout

        X = np.concatenate(([0], X), axis=0)
\end_layout

\begin_layout Plain Layout

        Y.append(X)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    return Y
\end_layout

\begin_layout Plain Layout


\backslash
end{lstlisting}
\end_layout

\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/fractional_brownian_motion_1.tex"

\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/fractional_brownian_motion_2.tex"

\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/fractional_brownian_motion_3.tex"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(Ornstein-Uhlenbeck process).
 The Ornstein-Uhlenbeck process 
\begin_inset Formula $(Y_{t})_{t\geq0}$
\end_inset

 starting at 
\begin_inset Formula $Y_{0}=0$
\end_inset

 is the Gaussian process with mean 
\begin_inset Formula $\mathbb{E}[Y_{t}]=0$
\end_inset

 and covariance:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Cov(Y_{s},Y_{t}) & =\frac{e^{-2(t-s)}}{2}(1-e^{-2s}),\quad\text{ for }s\leq t
\end{align*}

\end_inset


\end_layout

\begin_layout Example
If the starting point 
\begin_inset Formula $Y_{0}$
\end_inset

 is random, specifically Gaussian with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $1/2$
\end_inset

, then we have: 
\begin_inset Formula $\mathbb{E}Y_{t}=0$
\end_inset

 and 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Cov(Y_{s},Y_{t}) & =\frac{e^{-2(t-s)}}{2},\quad\text{ for }s\leq t
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The covariance only depends on the difference of the time! This means that
 the process 
\begin_inset Formula $(Y_{t})_{t\geq0}$
\end_inset

 has the same distribution if we shift time by an amount 
\begin_inset Formula $a$
\end_inset

 for any 
\begin_inset Formula $a\geq0$
\end_inset

: 
\begin_inset Formula $(Y_{t+a})_{t\geq0}$
\end_inset

.
 Processes with this property are called 
\emph on
stationary
\emph default
.
 As can be observed from the figure below, the statistics of stationary
 processes do not change over time.
 
\end_layout

\begin_layout Subsection
A Geometric Point of View.
\end_layout

\begin_layout Standard
Before turning to Gaussian processes in more detail, it is worthwhile to
 spend some time to further explore the analogy between random variables
 in 
\begin_inset Formula $L^{2}(\Omega)$
\end_inset

 and vectors in
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

.
 We've already seen earlier, how the space of all random variables form
 a vector space.
 We shall now observe that 
\begin_inset Formula $L^{2}$
\end_inset

 is a subspace of this vector space.
\end_layout

\begin_layout Definition
For a given probability space 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

, the space 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 consists of all random variables defined on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 such that:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
\left[\mathbb{E}(X^{2})\right] & <\infty
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
Such random variables are called square integrable.
 
\end_layout

\begin_layout Standard
In the same spirit, the space of integrable random variables is denoted
 by 
\begin_inset Formula $L^{1}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 We will see that any square-integrable random variable must be integrable.
 In other words, 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 is a subset of 
\begin_inset Formula $L^{1}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 In particular, square integrable random variables have a well-defined expectati
on.
 This means that, we can think of 
\begin_inset Formula $L^{2}$
\end_inset

 as the set of all random variables on a given probability space with finite
 variance.
 Clearly, random variables on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 with the Gaussian distribution are in 
\begin_inset Formula $L^{2}$
\end_inset

.
\end_layout

\begin_layout Standard
The space 
\begin_inset Formula $L^{2}$
\end_inset

 is a vector space.
\end_layout

\begin_layout Standard
1) If 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are two random variables in 
\begin_inset Formula $L^{2}$
\end_inset

, then the linear combination 
\begin_inset Formula $aX+bY$
\end_inset

 is also a random variable in 
\begin_inset Formula $L^{2}$
\end_inset

.
 If 
\begin_inset Formula $u,v\in\mathbf{R}$
\end_inset

, we know that :
\begin_inset Formula 
\begin{align*}
(u-v)^{2} & \geq0\\
u^{2}-2uv+v^{2} & \geq0\\
2uv & \leq u^{2}+v^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Setting 
\begin_inset Formula $u=aX$
\end_inset

 and 
\begin_inset Formula $v=bY$
\end_inset

, we get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
2abXY & \leq a^{2}X^{2}+b^{2}Y^{2}\\
2ab\mathbb{E}(XY) & \leq a^{2}\mathbb{E}X^{2}+b^{2}\mathbb{E}Y^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Having established this upper bound for 
\begin_inset Formula $2ab\mathbb{E}(XY)$
\end_inset

, we now proceed to show that 
\begin_inset Formula $aX+bY$
\end_inset

 belongs to 
\begin_inset Formula $L^{2}$
\end_inset

.
 We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}[(aX+bY)^{2}] & =\mathbb{E}(a^{2}X^{2}+b^{2}Y^{2}+2abXY)\\
 & =a^{2}\mathbb{E}X^{2}+b^{2}\mathbb{E}Y^{2}+2ab\mathbb{E}(XY)\\
 & \leq a^{2}\mathbb{E}X^{2}+b^{2}\mathbb{E}Y^{2}+a^{2}\mathbb{E}X^{2}+b^{2}\mathbb{E}Y^{2}\\
 & =2a^{2}\mathbb{E}X^{2}+2b^{2}\mathbb{E}Y^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $X,Y\in L^{2}$
\end_inset

, 
\begin_inset Formula $\mathbb{E}X^{2}<\infty$
\end_inset

 and 
\begin_inset Formula $\mathbb{E}Y^{2}<\infty$
\end_inset

.
 Hence, 
\begin_inset Formula $\mathbb{E}[(aX+bY)^{2}]$
\end_inset

 is bounded.
 
\end_layout

\begin_layout Standard
2) The zero element of the linear space 
\begin_inset Formula $L^{2}$
\end_inset

 is the constantly zero random variable 
\begin_inset Formula $X=0$
\end_inset

 (with probability one).
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "ex:example-of-l2-space"

\end_inset

Consider 
\begin_inset Formula $(\Omega,\mathcal{P}(\Omega),\mathbb{P})$
\end_inset

 where 
\begin_inset Formula $\Omega=\{0,1\}\times\{0,1\}$
\end_inset

, 
\begin_inset Formula $\mathbb{P}$
\end_inset

 is the equiprobability and 
\begin_inset Formula $\mathcal{P}(\Omega)$
\end_inset

 is the power set of 
\begin_inset Formula $\Omega$
\end_inset

 i.e.
 all the subsets of 
\begin_inset Formula $\Omega$
\end_inset

.
 An example of a random variable is 
\begin_inset Formula $X=2\mathbf{1}_{\{(0,0)\}}$
\end_inset

 where 
\begin_inset Formula $\mathbf{1}_{\{(0,0)\}}$
\end_inset

 is the indicator function of the event 
\begin_inset Formula $\{(0,0)\}$
\end_inset

.
 In other words, 
\begin_inset Formula $X$
\end_inset

 takes the value 
\begin_inset Formula $2$
\end_inset

 on the outcome 
\begin_inset Formula $(0,0)$
\end_inset

 and 
\begin_inset Formula $0$
\end_inset

 for the other outcomes.
 Of course, we can generalize this construction by taking a linear combination
 of multiples of indicator random functions.
 Namely, consider the random variable:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
X & =a\mathbf{1}_{\{(0,0)\}}+b\mathbf{1}_{\{(1,0)\}}+c\mathbf{1}_{\{(0,1)\}}+d\mathbf{1}_{\{(1,1)\}}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
for some fixed 
\begin_inset Formula $a,b,c,d\in\mathbf{R}$
\end_inset

.
 Clearly, any random variable on this probability space can be written in
 this form.
 Moreover, any random variable of this form will have a finite variance.
 Therefore, the space 
\begin_inset Formula $L^{2}$
\end_inset

 in this example consists of random variables of the above form.
 This linear space has dimension 
\begin_inset Formula $4$
\end_inset

, since we can write any random variables as the finite linear combination
 of the four indicator functions.
 In general, if 
\begin_inset Formula $\Omega$
\end_inset

 is finite, the space 
\begin_inset Formula $L^{2}$
\end_inset

 is finite dimensional as a linear space, if 
\begin_inset Formula $\Omega$
\end_inset

 is infinite, the space 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 might be infinite dimensional.
 
\end_layout

\begin_layout Subsubsection
Norm in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
\end_layout

\begin_layout Standard
Similar to 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

, the space 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 has a norm or a length: for a random variable 
\begin_inset Formula $X$
\end_inset

 in 
\begin_inset Formula $L^{2}$
\end_inset

, its norm 
\begin_inset Formula $\left\Vert X\right\Vert _{2}$
\end_inset

 is given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\left\Vert X\right\Vert _{2}=\left[\mathbb{E}X^{2}\right]^{1/2}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Note that this is very close in spirit to the length for the vector 
\begin_inset Formula $\left\Vert \mathbf{x}\right\Vert _{2}=\sqrt{x_{1}^{2}+\ldots+x_{n}^{2}}$
\end_inset

 in 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

, since the expectation is heuristically a sum over the outcomes.
 We have already seen that this definition satisfies the properties of a
 norm.
\end_layout

\begin_layout Standard
1) 
\emph on
Positive Semi-Definite
\emph default
: 
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $X$
\end_inset

 is a random variable, then 
\begin_inset Formula $X^{2}\geq0$
\end_inset

.
 By monotonicity of expectations, 
\begin_inset Formula $\mathbb{E}X^{2}\geq0$
\end_inset

.
 Moreover, if 
\begin_inset Formula $\mathbb{E}X^{2}=0$
\end_inset

, then since 
\begin_inset Formula $X^{2}$
\end_inset

 is a non-negative random variable, 
\begin_inset Formula $X^{2}=0$
\end_inset

 almost surely.
 It implies that 
\begin_inset Formula $X=0$
\end_inset

 a.s.
\end_layout

\begin_layout Standard
2) 
\emph on
Scalar multiplication
\emph default
.
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $X$
\end_inset

 is a random variable in 
\begin_inset Formula $L^{2}$
\end_inset

, we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left\Vert aX\right\Vert _{2} & =\left(\mathbb{E}[(aX)^{2}]\right)^{1/2}\\
 & =\left(\mathbb{E}a^{2}X^{2}\right)^{1/2}\\
 & =|a|\left(\mathbb{E}X^{2}\right)^{1/2}\\
 & =|a|\left\Vert X\right\Vert _{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
3) 
\emph on
Triangle Inequality
\emph default
.
\end_layout

\begin_layout Standard
We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left\Vert X+Y\right\Vert _{2}^{2} & =\mathbb{E}[(X+Y)^{2}]\\
 & =\mathbb{E}X^{2}+\mathbb{E}Y^{2}+2\mathbb{E}XY\\
 & =\left\Vert X\right\Vert _{2}^{2}+\left\Vert Y\right\Vert _{2}^{2}+2\mathbb{E}XY\\
 & \leq\left\Vert X\right\Vert _{2}^{2}+\left\Vert Y\right\Vert _{2}^{2}+2\mathbb{E}|XY| & \{\because XY\leq|XY|\}\\
 & \leq\left\Vert X\right\Vert _{2}^{2}+\left\Vert Y\right\Vert _{2}^{2}+2\left(\mathbb{E}X^{2}\right)^{1/2}\left(\mathbb{E}Y^{2}\right)^{1/2} & \{\text{Cauchy-Schwarz inequality}\}\\
 & =\left\Vert X\right\Vert _{2}^{2}+\left\Vert Y\right\Vert _{2}^{2}+2\left\Vert X\right\Vert _{2}\left\Vert Y\right\Vert _{2}\\
 & =\left(\left\Vert X\right\Vert _{2}+\left\Vert Y\right\Vert _{2}\right)^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Thus, 
\begin_inset Formula $\left\Vert X+Y\right\Vert _{2}\leq\left\Vert X\right\Vert _{2}+\left\Vert Y\right\Vert _{2}$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Inner-product in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
\end_layout

\begin_layout Standard
Like 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

, the space 
\begin_inset Formula $L^{2}$
\end_inset

 has a dot-product or scalar product between two elements 
\begin_inset Formula $X,Y$
\end_inset

 of the space.
 It is given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left\langle X,Y\right\rangle  & =\mathbb{E}(XY)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
More generally, this operation is called the inner-product.
 It has the same properties as the dot product in 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

.
\end_layout

\begin_layout Standard
1) 
\emph on
Symmetric
\emph default
:
\end_layout

\begin_layout Standard
We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}(XY) & =\mathbb{E}(YX)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
2) 
\emph on
Linearity
\emph default
:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}((aX+bY)Z) & =a\mathbb{E}(XZ)+b\mathbb{E}(YZ)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
3) 
\emph on
Positive semi-definite
\emph default
:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left\langle X,X\right\rangle  & =\mathbb{E}X^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $X^{2}$
\end_inset

 is a non-negative random variable, 
\begin_inset Formula $X^{2}\geq0$
\end_inset

 and by the monotonicity of expectations 
\begin_inset Formula $\mathbb{E}X^{2}\geq0$
\end_inset

.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $X,Y\in L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 and define 
\begin_inset Formula $\hat{X}=X-\mathbb{E}X$
\end_inset

, 
\begin_inset Formula $\hat{Y}=Y-\mathbb{E}Y$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
|\mathbb{E}(\hat{X}\hat{Y})|\leq\mathbb{E}|\hat{X}\hat{Y}| & \leq\left(\mathbb{E}\hat{X}^{2}\right)^{1/2}\left(\mathbb{E}\hat{Y}^{2}\right)^{1/2}\\
|\mathbb{E}(X-\mathbb{E}X)(Y-\mathbb{E}Y)| & \leq\left[\mathbb{E}(X-EX)^{2}\right]^{1/2}\left[\mathbb{E}(Y-EY)^{2}\right]^{1/2}\\
|Cov(X,Y)| & \leq\sqrt{Var(X)}\cdot\sqrt{Var(Y)}\\
|Corr(X,Y)| & \leq1
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection
Projection of a random variable 
\begin_inset Formula $X$
\end_inset

 on 
\begin_inset Formula $Y$
\end_inset

.
\end_layout

\begin_layout Standard
Consider the random variable 
\begin_inset Formula 
\begin{align*}
X^{\perp} & =X-\frac{\left\langle X,Y\right\rangle }{\left\Vert Y\right\Vert _{2}^{2}}Y\\
 & =X-\frac{\mathbb{E}(XY)}{\mathbb{E}Y^{2}}Y
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This random variable is uncorrelated to 
\begin_inset Formula $Y$
\end_inset

 or orthogonal to 
\begin_inset Formula $Y$
\end_inset

, in the sense that it's inner product with 
\begin_inset Formula $Y$
\end_inset

 is zero.
 We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left\langle X^{\perp},Y\right\rangle  & =\mathbb{E}(X^{\perp}Y)\\
 & =\mathbb{E}\left[XY-\frac{\mathbb{E}(XY)}{\mathbb{E}Y^{2}}Y^{2}\right]\\
 & =\mathbb{E}XY-\frac{\mathbb{E}(XY)}{\mathbb{E}Y^{2}}\cdot\mathbb{E}Y^{2}\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [black,->,-latex](0,0) -- (8,0) node[anchor=north east]{$Y$};
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (0,0) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (8,0) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (4,0) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [line width=2pt,black,->,-latex] (0,0) -- (4,0) node[anchor=north]{$
\backslash
frac{
\backslash
boldsymbol{E}[XY]}{
\backslash
boldsymbol{E}[Y^2]}Y$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [black,->] (0,0) -- (4,4) node[anchor=south]{$X$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [dashed,blue,->,-latex] (4,0) -- (4,4) node[midway,right]{$X^{
\backslash
perp}$};
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Figure.
 A representation of the decomposition of the random variable $X$ in terms
 of its projection on $Y$ and the component $X^{
\backslash
perp}$ orthogonal to $Y$.
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The random variable 
\begin_inset Formula $\frac{\mathbb{E}[XY]}{\mathbb{E}[Y^{2}]}Y$
\end_inset

 is the random variable of the form 
\begin_inset Formula $tY$
\end_inset

, 
\begin_inset Formula $t\in\mathbf{R}$
\end_inset

, that is closest to 
\begin_inset Formula $X$
\end_inset

 in the 
\begin_inset Formula $L^{2}$
\end_inset

-sense.
 We will make this more precise when we define the conditional expectation
 of a random variable shortly ahead.
 For now, we simply note that these considerations imply the decomposition
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
X & =X^{\perp}+\frac{\mathbb{E}[XY]}{\mathbb{E}[Y^{2}]}Y
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The random variable 
\begin_inset Formula $X^{\perp}=X-\frac{\mathbb{E}[XY]}{\mathbb{E}[Y^{2}]}Y$
\end_inset

 is the component of 
\begin_inset Formula $X$
\end_inset

 
\emph on
orthogonal 
\emph default
to 
\begin_inset Formula $Y$
\end_inset

.
 The random variable:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\text{Proj}{}_{Y}(X) & =\frac{\mathbb{E}[XY]}{\mathbb{E}[Y^{2}]}Y
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
is called the orthogonal projection of the random variable 
\begin_inset Formula $X$
\end_inset

 onto 
\begin_inset Formula $Y$
\end_inset

.
 Put another way, this is the component of 
\begin_inset Formula $X$
\end_inset

 in the direction of 
\begin_inset Formula $Y$
\end_inset

.
 This is the equivalent of the orthogonal projection of 
\begin_inset Formula $\mathbf{R}^{n}$
\end_inset

 of a vector 
\begin_inset Formula $\mathbf{w}$
\end_inset

 in the direction of 
\begin_inset Formula $\mathbf{v}$
\end_inset

, given by 
\begin_inset Formula $\frac{\left\langle \mathbf{w},\mathbf{v}\right\rangle }{\left\Vert \mathbf{v}\right\Vert ^{2}}\mathbf{v}$
\end_inset

.
\end_layout

\begin_layout Example
Going back to example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:example-of-l2-space"
plural "false"
caps "false"
noprefix "false"

\end_inset

, let's define the random variables 
\begin_inset Formula $Y=2\mathbf{1}_{\{(0,0)\}}+\mathbf{1}_{\{(1,0)\}}$
\end_inset

and 
\begin_inset Formula $W=\mathbf{1}_{\{(0,0)\}}$
\end_inset

.
 Then the orthogonal projection of 
\begin_inset Formula $Y$
\end_inset

 onto 
\begin_inset Formula $W$
\end_inset

 is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\frac{\mathbb{E}(YW)}{\mathbb{E}W^{2}}W & =\frac{2\mathbb{P}(\{0,0\}}{\mathbb{P}(\{0,0\})}W\\
 & =\frac{2\cdot\frac{1}{4}}{\frac{1}{4}}W\\
 & =2W
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The orthogonal decomposition of 
\begin_inset Formula $Y$
\end_inset

 is simply :
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Y & =2W+(Y-2W)
\end{align*}

\end_inset

The notion of norm induces a notion of distance between the random variables
 in 
\begin_inset Formula $L^{2}$
\end_inset

 given by 
\begin_inset Formula $\left\Vert X-Y\right\Vert _{2}=\mathbb{E}[(X-Y)^{2}]^{1/2}$
\end_inset

.
 In particular, we see that the orthogonal projection of 
\begin_inset Formula $X$
\end_inset

 onto 
\begin_inset Formula $Y$
\end_inset

 is the closest point from 
\begin_inset Formula $X$
\end_inset

 amongst all multiples of 
\begin_inset Formula $Y$
\end_inset

.
 This is what the proof of Cauchy-Schwarz inequality does.
 The 
\begin_inset Formula $L^{2}$
\end_inset

 distance also gives rise to a notion of convergence.
\end_layout

\begin_layout Subsubsection
Borel-Cantelli Lemmas.
\end_layout

\begin_layout Lemma
(Borel-Cantelli Lemmas) 
\begin_inset CommandInset label
LatexCommand label
name "lemma:borel-cantelli-lemma"

\end_inset

 
\end_layout

\begin_layout Lemma
(a) (First Borel-Cantelli Lemma) Let 
\begin_inset Formula $\{A_{n}\}$
\end_inset

 be a sequence of events such that the series 
\begin_inset Formula $\sum_{n}\mathbb{P}(A_{n})$
\end_inset

 converges to a finite value 
\begin_inset Formula $L$
\end_inset

.
 Then, almost surely, only finitely many 
\begin_inset Formula $A_{n}$
\end_inset

's will occur.
\end_layout

\begin_layout Lemma
(b) (Second Borel-Cantelli Lemma) Let 
\begin_inset Formula $\{A_{n}\}$
\end_inset

 be a sequence of independent events such that 
\begin_inset Formula $\sum_{n}\mathbb{P}(A_{n})$
\end_inset

 diverges to 
\begin_inset Formula $\infty$
\end_inset

.
 Then, almost surely, infinitely many 
\begin_inset Formula $A_{n}$
\end_inset

's will occur.
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
Fix a probability space 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Let 
\begin_inset Formula $A_{1},A_{2},A_{3},\ldots$
\end_inset

 be an infinite sequence of events belonging to 
\begin_inset Formula $\mathcal{F}$
\end_inset

.
 We shall often be interested in finding out how many of the 
\begin_inset Formula $A_{n}$
\end_inset

 occur.
 
\end_layout

\begin_layout Standard
The event 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $A_{n}$
\end_inset

 occurs infinitely often (
\begin_inset Formula $A_{n}\:i.o.$
\end_inset

) is the set of all 
\begin_inset Formula $\omega$
\end_inset

 that belong to infinitely many 
\begin_inset Formula $A_{n}$
\end_inset

's.
 
\end_layout

\begin_layout Standard
Imagine that an infinite number of 
\begin_inset Formula $A_{n}$
\end_inset

's occur.
 That is, 
\begin_inset Formula $(\forall n)(\exists m\geq n)(\text{s.t.}A_{m}\text{ occurs})$
\end_inset

.
 In other words:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\{A_{n}\text{ infinitely often }\}\triangleq\bigcap_{n=1}^{\infty}\underbrace{\bigcup_{m=n}^{\infty}A_{m}}_{B_{n}}\label{eq:infinitely-often}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Here, 
\begin_inset Formula $B_{n}$
\end_inset

 is the event that atleast one of 
\begin_inset Formula $A_{n},A_{n+1},\ldots$
\end_inset

 occur.
 For that reason, 
\begin_inset Formula $B_{n}$
\end_inset

 is sometimes referred to as the 
\begin_inset Formula $n$
\end_inset

-th tail event.
 
\begin_inset Formula $\{A_{n}\text{ infinitely often }\}$
\end_inset

 is the intersection of all the 
\begin_inset Formula $B_{n}$
\end_inset

's, so it is the event that all the 
\begin_inset Formula $B_{n}$
\end_inset

's occur.
 Therefore, no matter how far I go, no matter how big my 
\begin_inset Formula $n_{0}$
\end_inset

 is, beyond that 
\begin_inset Formula $n_{0}$
\end_inset

, atleast one of 
\begin_inset Formula $A_{n_{0}},A_{n_{0}+1},\ldots$
\end_inset

 occurs.
\end_layout

\begin_layout Standard
Taking the complement of both sides in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:infinitely-often"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we get the expression for the event that 
\begin_inset Formula $A_{n}$
\end_inset

 occurs finitely often.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\{A_{n}\text{ finitely often }\}\triangleq\bigcup_{n=1}^{\infty}\underbrace{\bigcap_{m=n}^{\infty}A_{m}^{C}}\label{eq:finitely-often}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
It means there exists an 
\begin_inset Formula $n$
\end_inset

, such that each of the further 
\begin_inset Formula $A_{i}$
\end_inset

's fail to occur.
 
\end_layout

\begin_layout Standard
In order to prove the Borel-Cantelli lemmas, we require the following lemma.
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lemma:limit-of-the-product-series"

\end_inset

If 
\begin_inset Formula $\sum_{i=1}^{\infty}p_{i}=\infty$
\end_inset

, then 
\begin_inset Formula $\lim_{n\to\infty}\prod_{i=1}^{n}(1-p_{i})=0$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
We know that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\ln(1+x) & \leq x
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
So,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\ln(1-p_{i}) & \leq-p_{i}\\
\sum_{i=1}^{n}\ln(1-p_{i}) & \leq-\sum_{i=1}^{n}p_{i}\\
0\leq\prod_{i=1}^{n}(1-p_{i}) & \leq e^{-\sum_{i=1}^{n}p_{i}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Passing to the limit on both sides, as 
\begin_inset Formula $n\to\infty$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
0\leq\lim_{n\to\infty}\prod_{i=1}^{n}(1-p_{i})\leq\lim e^{-\sum_{i=1}^{n}p_{i}}=0
\]

\end_inset


\end_layout

\begin_layout Proof
By the squeeze theorem, the limit 
\begin_inset Formula $\lim_{n\to\infty}\prod_{i=1}^{n}(1-p_{i})$
\end_inset

 exists and is equal to 
\begin_inset Formula $0$
\end_inset

.
\end_layout

\begin_layout Proof
Consequently, the product series 
\begin_inset Formula $\prod_{i=1}^{n}(1-p_{i})$
\end_inset

 converges to 
\begin_inset Formula $0$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
(
\series bold
First Borel-Cantelli Lemma
\series default
)
\end_layout

\begin_layout Proof
Our claim is that 
\begin_inset Formula $\mathbb{P}(\bigcap_{n=1}^{\infty}B_{n})=0$
\end_inset

.
 
\end_layout

\begin_layout Proof
Whenever we see something like 
\begin_inset Formula $\bigcap_{n=1}^{\infty}B_{n}$
\end_inset

, we can think of invoking continuity of probability.
 It turns out that, 
\begin_inset Formula $B_{n}=\bigcup_{m\geq n}A_{m}$
\end_inset

.
 So, 
\begin_inset Formula $B_{1}\supseteq B_{2}\supseteq B_{3}\supseteq\ldots$
\end_inset

, that is the 
\begin_inset Formula $B_{n}$
\end_inset

's are nested decreasing sequence of sets.
 So, 
\begin_inset Formula $\lim B_{n}=\bigcap_{n=1}^{\infty}B_{n}$
\end_inset

.
 So, by continuity of probability measure:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}(\bigcap_{n=1}^{\infty}B_{n}) & =\lim_{n\to\infty}\mathbb{P}(B_{n})\\
 & =\lim_{n\to\infty}\mathbb{P}(\bigcup_{m\geq n}^{\infty}A_{m})\\
 & \leq\lim_{n\to\infty}\left[\mathbb{P}(A_{n})+\mathbb{P}(A_{n+1})+\ldots\right]\\
 & \qquad\{\text{ Union bound on probability}\}\\
 & =\lim_{n\to\infty}\sum_{i=n}^{\infty}\mathbb{P}(A_{i})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We know that, 
\begin_inset Formula $\sum_{n=1}^{\infty}\mathbb{P}(A_{n})$
\end_inset

 converges to some finite value 
\begin_inset Formula $L$
\end_inset

, and the above expression is the tail sum of a convergent series.
 The sequence of tail sums of a convergent series always converges to 
\begin_inset Formula $0$
\end_inset

.
 Thus,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
0\leq\mathbb{P}(\bigcap_{n=1}^{\infty}B_{n})\leq0
\]

\end_inset


\end_layout

\begin_layout Proof
so it follows that 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\mathbb{P}\{A_{n}\:i.o.\}=0
\]

\end_inset


\end_layout

\begin_layout Proof
(
\series bold
Second Borel-Cantelli Lemma
\series default
)
\end_layout

\begin_layout Proof
Our claim is 
\begin_inset Formula $\mathbb{P}\{A_{n}\:i.o.\}=1$
\end_inset

.
 We must therefore prove that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\bigcap_{n=1}^{\infty}B_{n}\right) & =1\\
\Longleftrightarrow\mathbb{P}\left(\bigcup_{n=1}^{\infty}B_{n}^{C}\right) & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\bigcup_{n=1}^{\infty}B_{n}^{C}\right) & \le\sum_{n=1}^{\infty}\mathbb{P}(B_{n}^{C})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
I want to prove that the above sum is zero.
 It means that each of these 
\begin_inset Formula $B_{n}^{C}$
\end_inset

 events should have 
\begin_inset Formula $0$
\end_inset

 probability.
 We will show that 
\begin_inset Formula $\mathbb{P}(B_{n}^{C})=0$
\end_inset

 for all 
\begin_inset Formula $n\geq1$
\end_inset

.
 
\end_layout

\begin_layout Proof
Indeed fix 
\begin_inset Formula $n$
\end_inset

 and 
\begin_inset Formula $k\geq n$
\end_inset

.
 Consider 
\begin_inset Formula $\mathbb{P}\left(\bigcap_{i=n}^{k}A_{i}^{C}\right)$
\end_inset

.
 That is I am taking finite intersection of 
\begin_inset Formula $A_{i}^{C}$
\end_inset

.
 I want to prove that 
\begin_inset Formula $B_{n}^{C}$
\end_inset

 has probability zero.
 
\end_layout

\begin_layout Proof
If you look at 
\begin_inset Formula $A_{i}^{C}$
\end_inset

, these are independent events.
 So, 
\begin_inset Formula $\mathbb{P}(\bigcap_{i=n}^{k}A_{i}^{C})=\prod_{i=n}^{k}\mathbb{P}(A_{i}^{C})=\prod_{i=n}^{k}\left[1-\mathbb{P}(A_{i})\right]$
\end_inset

.
 Passing to the limit as 
\begin_inset Formula $k\to\infty$
\end_inset

,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim_{k\to\infty}\mathbb{P}(\bigcap_{i=n}^{k}A_{i}^{C}) & =\lim_{k\to\infty}\prod_{i=n}^{k}\left[1-\mathbb{P}(A_{i})\right]\\
\mathbb{P}\left(\bigcap_{i=n}^{\infty}A_{i}^{C}\right) & =\lim_{k\to\infty}\prod_{i=n}^{k}\left[1-\mathbb{P}(A_{i})\right]\\
\mathbb{P}(B_{n}^{C}) & =\lim_{k\to\infty}\prod_{i=n}^{k}\left[1-\mathbb{P}(A_{i})\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since, 
\begin_inset Formula $\sum_{i=n}^{\infty}\mathbb{P}(A_{i})$
\end_inset

 diverges to 
\begin_inset Formula $\infty$
\end_inset

, it follows from lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lemma:limit-of-the-product-series"
plural "false"
caps "false"
noprefix "false"

\end_inset

, that 
\begin_inset Formula $\prod_{i=n}^{\infty}\left[1-\mathbb{P}(A_{i})\right]=0$
\end_inset

.
 Hence, 
\begin_inset Formula $\mathbb{P}(B_{n}^{C})=0$
\end_inset

 for all 
\begin_inset Formula $n\in\mathbf{N}$
\end_inset

.
 So, 
\begin_inset Formula $0\leq\mathbb{P}\left(\bigcup_{n=1}^{\infty}B_{n}^{C}\right)\leq0$
\end_inset

.
 Therefore, 
\begin_inset Formula $\mathbb{P}\left(\bigcup_{n=1}^{\infty}B_{n}^{C}\right)=0$
\end_inset

, or equivalently, 
\begin_inset Formula $\mathbb{P}\left(\bigcap_{n=1}^{\infty}B_{n}\right)=1$
\end_inset

.
 The event 
\begin_inset Formula $\{A_{n}\:i.o.\}$
\end_inset

 occurs almost surely.
 
\end_layout

\begin_layout Subsection
Convergence of random variables.
\end_layout

\begin_layout Standard
Fix a probability space 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 once for all.
 On this probability space, we will have a sequence 
\begin_inset Formula $(X_{1},X_{2},X_{3},\ldots)$
\end_inset

 of random variables defined on it.
 
\end_layout

\begin_layout Definition
(
\emph on
Point-wise convergence
\emph default
.) A sequence of random variables 
\begin_inset Formula $(X_{n})_{n=1}^{\infty}$
\end_inset

 on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 is said to converge point-wise to 
\begin_inset Formula $X$
\end_inset

, if and if, for all 
\begin_inset Formula $\epsilon>0$
\end_inset

, and for all 
\begin_inset Formula $\omega\in\Omega$
\end_inset

, there exists 
\begin_inset Formula $N(\epsilon,\omega)\in\mathbf{N}$
\end_inset

 such that for all 
\begin_inset Formula $n\geq N$
\end_inset

, we have 
\begin_inset Formula $|X_{n}(\omega)-X(\omega)|<\epsilon$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
It would be natural to say, that, for all 
\begin_inset Formula $\omega\in\Omega$
\end_inset

, 
\begin_inset Formula $X_{n}(\omega)\to X(\omega)$
\end_inset

.
 But, this is too demanding.
 So, we will weaken this convergence.
 
\end_layout

\begin_layout Definition
(
\emph on
Almost-sure convergence
\emph default
.) A sequence of random variables 
\begin_inset Formula $(X_{n})_{n=1}^{\infty}$
\end_inset

 on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 is said to converge almost-surely to 
\begin_inset Formula $X$
\end_inset

, written 
\begin_inset Formula $X_{n}\xrightarrow{a.s.}X$
\end_inset

, if and only if, there exists a set 
\begin_inset Formula $A\in\mathcal{F}$
\end_inset

, such that 
\begin_inset Formula $\mathbb{P}[A]=1$
\end_inset

 and for all 
\begin_inset Formula $\omega\in A$
\end_inset

, 
\begin_inset Formula $X_{n}(\omega)\to X(\omega)$
\end_inset

.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "th:sufficient-condition-for-almost-sure-convergence"

\end_inset

(Sufficient condition for almost-sure convergence.) If 
\begin_inset Formula $(\forall\epsilon>0)$
\end_inset

, 
\begin_inset Formula $\sum_{n=1}^{\infty}\mathbb{P}(|X_{n}-X|>\epsilon)<\infty$
\end_inset

, then 
\begin_inset Formula $X_{n}\stackrel{a.s.}{\to}X$
\end_inset

.
\end_layout

\begin_layout Remark*
If you notice just the object 
\begin_inset Formula $\mathbb{P}(|X_{n}-X|>\epsilon)$
\end_inset

; if this term goes to zero, then it is convergence in probability.
 So, if the term 
\begin_inset Formula $\mathbb{P}(|X_{n}-X|>\epsilon)$
\end_inset

 goes to zero, we have convergence in probability.
 The condition 
\begin_inset Formula $\sum_{n=1}^{\infty}\mathbb{P}(|X_{n}-X|>\epsilon)<\infty$
\end_inset

 is a little bit stronger, it says a little bit more.
 As 
\begin_inset Formula $n$
\end_inset

 tends to infinity, not only do the terms 
\begin_inset Formula $a_{n}=\mathbb{P}(|X_{n}-X|>\epsilon)$
\end_inset

 go to zero, for every 
\begin_inset Formula $\epsilon$
\end_inset

; it goes to zero fast enough that the sum converges.
 For example, if this probability 
\begin_inset Formula $\mathbb{P}(|X_{n}-X|>\epsilon)$
\end_inset

 were to go to zero, as 
\begin_inset Formula $\frac{1}{n}$
\end_inset

, then you have convergence in probability, but 
\begin_inset Formula $\sum\frac{1}{n}$
\end_inset

 diverges.
 So, if the term 
\begin_inset Formula $a_{n}$
\end_inset

 goes to zero fast enough to keep the summation finite, then we have convergence
 almost surely.
 For instance, if 
\begin_inset Formula $a_{n}\approx\frac{1}{n^{2}}$
\end_inset

, then we would have almost sure convergence.
 
\end_layout

\begin_layout Remark*
This is just a sufficient condition.
 If it holds, we are guaranteed almost sure convergence, but even if it
 doesn't hold, sometimes we may have almost sure convergence.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $A_{n}(\epsilon)$
\end_inset

 be the event 
\begin_inset Formula $\{|X_{n}-X|>\epsilon\}$
\end_inset

.
 We are given that, for all 
\begin_inset Formula $\epsilon>0$
\end_inset

, 
\begin_inset Formula $\sum_{n=1}^{\infty}\mathbb{P}(A_{n}(\epsilon))<\infty$
\end_inset

.
 Using BCL1 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lemma:borel-cantelli-lemma"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we see that that, for any 
\begin_inset Formula $\epsilon>0$
\end_inset

, only finitely many 
\begin_inset Formula $A_{n}(\epsilon)$
\end_inset

 occur with probability 
\begin_inset Formula $1$
\end_inset

.
 Thus, there exists an 
\begin_inset Formula $n_{0}$
\end_inset

, such that for all 
\begin_inset Formula $n\geq n_{0}$
\end_inset

, 
\begin_inset Formula $A_{n}^{C}(\epsilon)=\{|X_{n}-X|\leq\epsilon\}$
\end_inset

 occurs with probability 
\begin_inset Formula $1$
\end_inset

.
 So, 
\begin_inset Formula $X_{n}$
\end_inset

 converges to 
\begin_inset Formula $X$
\end_inset

 with probability 
\begin_inset Formula $1$
\end_inset

.
 
\end_layout

\begin_layout Remark*
If we plot the distance between the random variables, 
\begin_inset Formula $X_{n}-X$
\end_inset

, there may be some excursions.
 But, essentially, BCL1 says that, with probability 
\begin_inset Formula $1$
\end_inset

, there must be an 
\begin_inset Formula $n_{0}$
\end_inset

, beyond which the sequence 
\begin_inset Formula $X_{n}$
\end_inset

 settles within an 
\begin_inset Formula $\epsilon$
\end_inset

-band of 
\begin_inset Formula $X$
\end_inset

, and these excursions never occur.
 Because, only finitely many excursions occur.
 And this is true for every 
\begin_inset Formula $\epsilon>0$
\end_inset

.
 So, with probability 
\begin_inset Formula $1$
\end_inset

, 
\begin_inset Formula $X_{n}\to X$
\end_inset

.
 Thus, 
\begin_inset Formula $X_{n}\stackrel{a.s.}{\to}X$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [black,->,-latex](0,0) -- (10,0) node[anchor=north east]{$n$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [black,->,-latex](0,-5) -- (0,5) node[anchor=north east]{$X_n-X$};
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (1/2,-1*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (2/2,1/2*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (3/2,-1/3*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (4/2,1/4*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (5/2,-1/5*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (6/2,1/6*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (7/2,-1/7*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (8/2,1/8*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (9/2,-1/9*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (10/2,1/10*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (11/2,-1/11*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (12/2,1/12*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (13/2,-1/13*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (14/2,1/14*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (15/2,-1/15*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (16/2,1/16*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (17/2,-1/17*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (18/2,1/18*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
filldraw[black] (19/2,-1/19*5) circle (3pt);
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [dashed,blue] (0,1/2) -- (10,1/2) node[left,anchor=north east]{$
\backslash
epsilon$};
\end_layout

\begin_layout Plain Layout

	
\backslash
draw [dashed,blue] (0,-1/2) -- (10,-1/2) node[left,anchor=north east]{$-
\backslash
epsilon$};
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Figure.
 Convergence of $X_n$ to $X$.
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
The converse of the theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:sufficient-condition-for-almost-sure-convergence"
plural "false"
caps "false"
noprefix "false"

\end_inset

 does not hold.
 Consider the sequence of random variables:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
X_{n} & =\begin{cases}
1 & \text{with probability }\frac{1}{n}\\
0 & \text{with probability }1-\frac{1}{n}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Then, for all 
\begin_inset Formula $\epsilon>0$
\end_inset

, 
\begin_inset Formula $\mathbb{P}(|X_{n}|<\epsilon)=1-\frac{1}{n}$
\end_inset

.
 So, for all 
\begin_inset Formula $\epsilon>0$
\end_inset

, 
\begin_inset Formula $\lim\mathbb{P}(|X_{n}|<\epsilon)=1$
\end_inset

.
 Thus, the sequence 
\begin_inset Formula $(X_{n})$
\end_inset

 converges 
\begin_inset Formula $0$
\end_inset

 with probability 
\begin_inset Formula $1$
\end_inset

.
 So, 
\begin_inset Formula $X_{n}\stackrel{a.s.}{\to}0$
\end_inset

.
 However, 
\begin_inset Formula $\sum\mathbb{P}(|X_{n}|>\epsilon)=\sum\frac{1}{n}=\infty$
\end_inset

.
 
\end_layout

\begin_layout Theorem
(Necessary and sufficient condition for almost-sure convergence.) 
\begin_inset CommandInset label
LatexCommand label
name "th:necessary-and-sufficient-condition-for-almost-sure-convergence"

\end_inset

 Let 
\begin_inset Formula $A_{n}(\epsilon)$
\end_inset

 be the event that the excursion 
\begin_inset Formula $\{|X_{n}-X|>\epsilon\}$
\end_inset

 happens and define:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
B_{m}(\epsilon) & =\bigcup_{n\geq m}A_{n}(\epsilon)
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
Then, 
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\[
X_{n}\stackrel{a.s.}{\to}X\quad\text{if and only if }\quad\lim\mathbb{P}(B_{m}(\epsilon))=0\quad\forall\epsilon>0
\]

\end_inset


\end_layout

\begin_layout Remark*
Note that, 
\begin_inset Formula $\mathbb{P}(A_{n}(\epsilon))$
\end_inset

 going to 
\begin_inset Formula $0$
\end_inset

 is convergence in probability.
 I am saying a little more.
 In words, 
\begin_inset Formula $A_{n}(\epsilon)$
\end_inset

 is the event that an excursion occurs at the 
\begin_inset Formula $n$
\end_inset

th term.
 In words, 
\begin_inset Formula $B_{m}(\epsilon)$
\end_inset

 is the event that atleast one of 
\begin_inset Formula $A_{m}$
\end_inset

, 
\begin_inset Formula $A_{m+1}$
\end_inset

, 
\begin_inset Formula $A_{m+2}$
\end_inset

, 
\begin_inset Formula $\ldots$
\end_inset

 occurs, which means that atleast one excursion occurs 
\begin_inset Formula $m$
\end_inset

 or after.
 What this theorem says is, if the probability of this event goes to 
\begin_inset Formula $0$
\end_inset

, then you have almost sure convergence.
 In other words, if you find some 
\begin_inset Formula $m$
\end_inset

; this 
\begin_inset Formula $m$
\end_inset

 can be very large, but if you find some 
\begin_inset Formula $m$
\end_inset

 beyond which no excursions ever occur, then you have almost sure convergence
 (and vice versa).
\end_layout

\begin_layout Proof
(
\begin_inset Formula $\Longrightarrow$
\end_inset

 direction.) 
\end_layout

\begin_layout Proof
We are given that 
\begin_inset Formula $X_{n}\stackrel{a.s.}{\to}X$
\end_inset

.
 Our claim is 
\begin_inset Formula $\lim_{m\to\infty}\mathbb{P}(B_{m}(\epsilon))=0$
\end_inset

.
\end_layout

\begin_layout Proof
Now, if 
\begin_inset Formula $X_{n}\to X$
\end_inset

 almost surely, then clearly, 
\begin_inset Formula $(\forall\epsilon>0)$
\end_inset

, the event 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\bigcup_{m\geq1}\bigcap_{n\geq m}\{|X_{n}-X|<\epsilon\}
\]

\end_inset


\end_layout

\begin_layout Proof
occurs with probability 
\begin_inset Formula $1$
\end_inset

.
 
\end_layout

\begin_layout Proof
So, for all 
\begin_inset Formula $\epsilon>0$
\end_inset

, the event 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\bigcap_{m\geq1}\bigcup_{n\geq m}\{|X_{n}-X|\geq\epsilon\}=\bigcap_{m\geq1}B_{m}
\]

\end_inset


\end_layout

\begin_layout Proof
occurs with probability 
\begin_inset Formula $0$
\end_inset

.
 An excursion happens only finitely many times.
 
\end_layout

\begin_layout Proof
Now, the sequence events 
\begin_inset Formula $B_{1}(\epsilon)$
\end_inset

, 
\begin_inset Formula $B_{2}(\epsilon)$
\end_inset

, 
\begin_inset Formula $B_{3}(\epsilon)$
\end_inset

, 
\begin_inset Formula $\ldots$
\end_inset

 are nested decreasing.
 They are like Russian dolls.
 By continuity of probability measure, 
\begin_inset Formula $\mathbb{P}\left(\bigcap_{m=1}^{\infty}B_{m}\right)=\lim_{m\to\infty}\mathbb{P}(B_{m})$
\end_inset

.
 Consequently, it follows that 
\begin_inset Formula $\lim_{m\to\infty}\mathbb{P}(B_{m})=0$
\end_inset

.
 
\end_layout

\begin_layout Proof
(
\begin_inset Formula $\Longleftarrow$
\end_inset

direction.)
\end_layout

\begin_layout Proof
We are given that, for all 
\begin_inset Formula $\epsilon>0$
\end_inset

, 
\begin_inset Formula $\lim_{m\to\infty}\mathbb{P}\left(B_{m}(\epsilon)\right)=0$
\end_inset

.
 We are interested to prove that 
\begin_inset Formula $X_{n}\stackrel{a.s.}{\to}X$
\end_inset

.
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $C$
\end_inset

 be the event:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
C= & \{\omega|X_{n}(\omega)\to X(\omega)\}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Define the event:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
A(\epsilon) & =\bigcap_{m\geq1}\bigcup_{n\geq m}\{|X_{n}-X|\geq\epsilon\}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
I would like to prove that 
\begin_inset Formula $\mathbb{P}(C)=1$
\end_inset

.
 What we will prove is that 
\begin_inset Formula $\mathbb{P}(C^{C})=0$
\end_inset

.
 
\end_layout

\begin_layout Proof
\begin_inset Formula $C^{C}$
\end_inset

 is the event that, no matter how big an 
\begin_inset Formula $n$
\end_inset

 you look at, there is some excursion.
 That is there are infinitely many excursions.
\end_layout

\begin_layout Proof
This means, there must be some 
\begin_inset Formula $\epsilon_{0}>0$
\end_inset

 for which 
\begin_inset Formula $A(\epsilon)$
\end_inset

 occurs.
 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}(C^{C}) & =\mathbb{P}\left(\bigcup_{\epsilon>0}A(\epsilon)\right)\\
 & =\mathbb{P}\left(\bigcup_{k=0}^{\infty}A(\frac{1}{k})\right)\\
 & \leq\sum_{k=0}^{\infty}\mathbb{P}\left(A(\frac{1}{k})\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim_{m\to\infty}\mathbb{P}(B_{m}(\frac{1}{k})) & =\mathbb{P}\left(\bigcap_{m=1}^{\infty}B_{m}(\frac{1}{k})\right)\\
 & \quad\{\text{ Continuity of probability measure }\}\\
 & =\mathbb{P}\left(A(\frac{1}{k})\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
So, 
\begin_inset Formula $\mathbb{P}\left(A(1/k)\right)=0$
\end_inset

.
 Consequently, 
\begin_inset Formula $\mathbb{P}(C^{C})=0$
\end_inset

 and 
\begin_inset Formula $\mathbb{P}(C)=1$
\end_inset

.
 Thus, 
\begin_inset Formula $X_{n}\stackrel{a.s.}{\to}X$
\end_inset

.
\end_layout

\begin_layout Remark*
Therein, lies the difference between convergence in probability and convergence
 almost surely.
 Convergence in probability just says the probability of 
\begin_inset Formula $A_{n}(\epsilon)$
\end_inset

 (an excursion occurs at 
\begin_inset Formula $n$
\end_inset

) goes to zero.
 It just looks at one 
\begin_inset Formula $n$
\end_inset

; it forgets about the rest of the sequence.
 
\end_layout

\begin_layout Remark*
For convergence almost surely, you are not looking at a particular 
\begin_inset Formula $n$
\end_inset

.
 You fix a particular 
\begin_inset Formula $m$
\end_inset

 and you're saying that the probability that beyond 
\begin_inset Formula $m$
\end_inset

 an excursion occurs goes to zero.
 
\end_layout

\begin_layout Remark*
This should convince you intuitively, that almost sure convergence implies
 convergence in probability.
\end_layout

\begin_layout Definition
(
\emph on
Convergence in Probability
\emph default
.) A sequence of random variables 
\begin_inset Formula $(X_{n})_{n=1}^{\infty}$
\end_inset

 on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 is said to converge in probability to 
\begin_inset Formula $X$
\end_inset

, written 
\begin_inset Formula $X_{n}\xrightarrow{P.}X$
\end_inset

, if and only if 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
\forall\epsilon>0,\quad\lim_{n\to\infty}\mathbb{P}(|X_{n}-X|\geq\epsilon)=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
(
\emph on
Convergence in 
\begin_inset Formula $L^{p}$
\end_inset


\emph default
) A sequence of random variables 
\begin_inset Formula $(X_{n})_{n=1}^{\infty}$
\end_inset

 on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 is said to converge in the 
\begin_inset Formula $p$
\end_inset

th mean to 
\begin_inset Formula $X$
\end_inset

, if and only if 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
\lim_{n\to\infty}\mathbb{E}\left[\left|X_{n}-X\right|{}^{p}\right]=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
(
\emph on
Convergence in Distribution
\emph default
.) A sequence of random variables 
\begin_inset Formula $(X_{n})_{n=1}^{\infty}$
\end_inset

 on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 is said to converge in distribution to 
\begin_inset Formula $X$
\end_inset

, if and only if:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
\mathbb{P}(X_{n}\leq X)\to\mathbb{P}(X\leq x)
\]

\end_inset


\end_layout

\begin_layout Standard
For example, let 
\begin_inset Formula $\Omega=\{1,2\}$
\end_inset

 and 
\begin_inset Formula $\mathbb{P}(1)=\mathbb{P}(2)=\frac{1}{2}$
\end_inset

, 
\begin_inset Formula $X_{n}(1)=\frac{-1}{n}$
\end_inset

 and 
\begin_inset Formula $X_{n}(2)=\frac{1}{n}$
\end_inset

.
 We have:
\end_layout

\begin_layout Standard
1) 
\begin_inset Formula $X_{n}\stackrel{a.s.}{\longrightarrow}0$
\end_inset

 because 
\begin_inset Formula $X_{n}(\omega)\to0$
\end_inset

 for all 
\begin_inset Formula $\omega\in\Omega$
\end_inset

.
\end_layout

\begin_layout Standard
2) 
\begin_inset Formula $X_{n}\stackrel{L^{2}}{\longrightarrow}0$
\end_inset

 because 
\begin_inset Formula $\mathbb{E}(X_{n}^{2})=\frac{1}{n^{2}}\to0$
\end_inset

.
\end_layout

\begin_layout Standard
3) 
\begin_inset Formula $X_{n}\stackrel{P}{\longrightarrow}0$
\end_inset

 because 
\begin_inset Formula $P(|X_{n}|>\epsilon)=\mathbb{P}\left(\frac{1}{n}>\epsilon\right)=0$
\end_inset

.
\end_layout

\begin_layout Theorem
(Hierarchy of Convergence) The following implications hold:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
(X_{n}\stackrel{a.s.}{\longrightarrow}X)\\
\Downarrow\\
(X_{n}\stackrel{P}{\longrightarrow}X) & \implies(X_{n}\stackrel{D}{\longrightarrow}X)\\
\Uparrow\\
(X_{n}\stackrel{L^{p}}{\longrightarrow}X)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(i) 
\emph on
Claim
\emph default
.
 
\begin_inset Formula $X_{n}\stackrel{L^{p}}{\to}X$
\end_inset

 implies 
\begin_inset Formula $X_{n}\stackrel{P}{\to}X$
\end_inset

.
\end_layout

\begin_layout Proof
This is a very easy proposition to prove.
 By definition, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\lim_{n\to\infty}\mathbb{E}\left[\left|X_{n}-X\right|{}^{p}\right]=0
\]

\end_inset


\end_layout

\begin_layout Proof
By Markov's inequality:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
0\leq\mathbb{P}(|X_{n}-X|>\epsilon) & =\mathbb{P}(|X_{n}-X|^{p}>\epsilon^{p})\\
 & \leq\frac{1}{\epsilon^{p}}\mathbb{E}\left[\left|X_{n}-X\right|{}^{p}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Passing to the limit on both sides, as 
\begin_inset Formula $n\to\infty$
\end_inset

, by the squeeze limit theorem, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty} & \mathbb{P}(|X_{n}-X|>\epsilon)=0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(ii) 
\emph on
Claim
\emph default
.
 
\begin_inset Formula $X_{n}\stackrel{P}{\to}X$
\end_inset

 implies that 
\begin_inset Formula $X_{n}\stackrel{D}{\to}X$
\end_inset

.
\end_layout

\begin_layout Proof
Fix an 
\begin_inset Formula $\epsilon>0$
\end_inset

.
\end_layout

\begin_layout Proof
We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
F_{X_{n}}(x) & =\mathbb{P}(X_{n}\leq x)\\
 & =\mathbb{P}(X_{n}\leq x,X\leq x+\epsilon)\\
 & +\mathbb{P}(X_{n}\leq x,X>x+\epsilon)\\
 & \leq\mathbb{P}(X\leq x+\epsilon)+\mathbb{P}(|X_{n}-X|>\epsilon)\\
 & \quad\because\{X_{n}\leq x,X\leq x+\epsilon\}\subseteq\{X\leq x+\epsilon\}\\
 & =F_{X}(x+\epsilon)+\mathbb{P}(|X_{n}-X|>\epsilon)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Similarly, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
F_{X}(x-\epsilon) & =\mathbb{P}(X\leq x-\epsilon)\\
 & =\mathbb{P}(X\leq x-\epsilon,X_{n}\leq x)+\mathbb{P}(X\leq x-\epsilon,X_{n}>x)\\
 & \leq\mathbb{P}(X_{n}\leq x)+\mathbb{P}(|X_{n}-x|>\epsilon)\\
 & =F_{X_{n}}(x)+\mathbb{P}(|X_{n}-X|>\epsilon)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Thus, we have the inequality:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\forall\epsilon>0,\quad F_{X}(x-\epsilon)-\mathbb{P}(|X_{n}-X|>\epsilon)\leq F_{X_{n}}(x)\leq F_{X}(x+\epsilon)+\mathbb{P}(|X_{n}-X|>\epsilon)
\]

\end_inset


\end_layout

\begin_layout Proof
We assume that 
\begin_inset Formula $F_{X}$
\end_inset

 is continous for all 
\begin_inset Formula $x$
\end_inset

.
 Pick 
\begin_inset Formula $\epsilon=\frac{1}{n}$
\end_inset

 and passing to the limit as 
\begin_inset Formula $n\to\infty$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim F_{X}(x-\epsilon) & \leq\lim F_{X_{n}}(x)\leq\lim F_{X}(x+\epsilon)\\
F_{X}(x) & \leq\lim F_{X_{n}}(x)\leq F_{X}(x)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By the Squeeze Theorem, the limit 
\begin_inset Formula $F_{X_{n}}(x)$
\end_inset

 exists and 
\begin_inset Formula $\lim F_{X_{n}}(x)=F_{X}(x)$
\end_inset

.
\end_layout

\begin_layout Proof
(iii) 
\series bold
Counterexample
\series default
.
 (Convergence in distribution does not imply convergence in probability).
\end_layout

\begin_layout Proof
Convergence in distribution simply means that only the CDFs are converging;
 it doesn't mean that 
\begin_inset Formula $X_{n}$
\end_inset

 and 
\begin_inset Formula $X$
\end_inset

 are getting closer in any sense.
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $X_{1}$
\end_inset

, 
\begin_inset Formula $X_{2}$
\end_inset

, 
\begin_inset Formula $X_{3}$
\end_inset

, 
\begin_inset Formula $\ldots$
\end_inset

 be such that 
\begin_inset Formula $X_{i}=X$
\end_inset

 for all 
\begin_inset Formula $i\geq1$
\end_inset

 and 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
X & =\begin{cases}
0 & \text{ with probability }\frac{1}{2}\\
1 & \text{ with probability }\frac{1}{2}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The entire sequence is just 
\begin_inset Formula $(X,X,X,\ldots)$
\end_inset

.
 Let 
\begin_inset Formula $Y=1-X$
\end_inset

.
 By definition, 
\begin_inset Formula $Y\sim Bernoulli(1/2)$
\end_inset

.
 We have: 
\begin_inset Formula $X_{n}\stackrel{D}{\to}Y$
\end_inset

 in distribution, but 
\begin_inset Formula $|X_{n}-Y|=1$
\end_inset

, we could choose 
\begin_inset Formula $\epsilon_{0}=\frac{1}{2}$
\end_inset

 and we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{\mathbb{P}}(|X_{n}-Y|>\frac{1}{2}) & =1
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
so 
\begin_inset Formula $(X_{n})$
\end_inset

 does not converge to 
\begin_inset Formula $Y$
\end_inset

 in probability.
\end_layout

\begin_layout Proof
(iv) 
\series bold
Counterexample
\series default
.
 (Convergence in probability does not imply convergence in the mean square
 sense).
\end_layout

\begin_layout Proof
Consider 
\begin_inset Formula 
\begin{align*}
X_{n} & =\begin{cases}
n^{2} & \text{with probability }n^{-2}\\
0 & \text{with probability }1-n^{-2}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Then,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\mathbb{P}(|X_{n}|>\epsilon)=\frac{1}{n^{2}}
\]

\end_inset


\end_layout

\begin_layout Proof
and as 
\begin_inset Formula $n\to\infty$
\end_inset

, 
\begin_inset Formula $\frac{1}{n^{2}}\to0$
\end_inset

.
 So, 
\begin_inset Formula $X_{n}\stackrel{P}{\to}0$
\end_inset

.
\end_layout

\begin_layout Proof
But,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\mathbb{E}(X_{n}^{2})=n^{2}
\]

\end_inset


\end_layout

\begin_layout Proof
and as 
\begin_inset Formula $n\to\infty$
\end_inset

, 
\begin_inset Formula $n^{2}\to\infty$
\end_inset

.
 Hence, 
\begin_inset Formula $X_{n}\stackrel{L^{2}}{\cancel{\to}}0$
\end_inset

.
\end_layout

\begin_layout Proof
(v) 
\series bold
Counterexample
\series default
.
 (Convergence in probability does not imply convergence almost surely).
 
\end_layout

\begin_layout Proof
Consider 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
X_{n} & =\begin{cases}
1 & \text{ with probability}\frac{1}{n}\\
0 & \text{with probability }1-\frac{1}{n}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
and 
\begin_inset Formula $X_{i}$
\end_inset

's are independent.
 The larger the value of 
\begin_inset Formula $n$
\end_inset

, the more likely that 
\begin_inset Formula $X_{n}$
\end_inset

 takes the value 
\begin_inset Formula $0$
\end_inset

.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}(|X_{n}|>\epsilon) & =\frac{1}{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
So, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}\mathbb{P}(|X_{n}|>\epsilon) & =\lim\frac{1}{n}=0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Our claim is that 
\begin_inset Formula $X_{n}$
\end_inset

 does not converge to 
\begin_inset Formula $0$
\end_inset

 almost surely.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $A_{n}$
\end_inset

 be the event that 
\begin_inset Formula $\{X_{n}=1\}$
\end_inset

.
 Then, 
\begin_inset Formula $A_{n}$
\end_inset

's are independent.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sum_{i=1}^{\infty}\mathbb{P}(A_{n}) & =0+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\ldots
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The harmonic series 
\begin_inset Formula $\sum_{n=1}^{\infty}\frac{1}{n}$
\end_inset

 diverges to 
\begin_inset Formula $\infty$
\end_inset

.
 
\end_layout

\begin_layout Proof
By the BCL2 (Borell-Cantelli Lemma 2) 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lemma:borel-cantelli-lemma"
plural "false"
caps "false"
noprefix "false"

\end_inset

, it follows that, with probability 
\begin_inset Formula $1$
\end_inset

, infinitely many 
\begin_inset Formula $A_{n}$
\end_inset

's will occur.
 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}\{X_{n}=1\:i.o.\} & =1
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
So, 
\begin_inset Formula $X_{n}\stackrel{a.s.}{\cancel{\to}}0$
\end_inset

.
 
\end_layout

\begin_layout Proof
Imagine a coin-tossing experiment, where 
\begin_inset Formula $X_{n}$
\end_inset

 represents the outcome of the 
\begin_inset Formula $n$
\end_inset

th coin-toss, and the probability of the 
\begin_inset Formula $n$
\end_inset

th coin toss falling heads is 
\begin_inset Formula $\frac{1}{n}$
\end_inset

.
 Then, no matter how far out you go in the sequence, BCL2 says that, there
 will some occasional head 
\begin_inset Formula $(X_{n}=1)$
\end_inset

 popping off at some-time.
 Which means that 
\begin_inset Formula $X_{n}$
\end_inset

 does not converge to zero.
 
\end_layout

\begin_layout Proof
(vi) 
\series bold
Claim
\series default
.
 
\begin_inset Formula $X_{n}\stackrel{a.s.}{\to}X$
\end_inset

 implies 
\begin_inset Formula $X_{n}\stackrel{P}{\to}X$
\end_inset

.
\end_layout

\begin_layout Proof
By the necessary and sufficient condition of almost sure convergence, 
\begin_inset Formula $X_{n}\stackrel{a.s.}{\to}X$
\end_inset

 is equivalent to saying that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim_{m\to\infty}\mathbb{P}(B_{m}(\epsilon)) & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
But, 
\begin_inset Formula $B_{m}(\epsilon)=\bigcup_{n\geq m}A_{n}(\epsilon)$
\end_inset

.
 Thus, 
\begin_inset Formula $A_{m}(\epsilon)\subseteq B_{m}(\epsilon)$
\end_inset

.
 So, 
\begin_inset Formula $(\forall\epsilon>0)$
\end_inset

, 
\begin_inset Formula $0\leq\mathbb{P}(A_{m}(\epsilon))\leq\mathbb{P}(B_{m}(\epsilon))$
\end_inset

.
 Passing to the limit on both sides, 
\begin_inset Formula $0\leq\mathbb{P}(A_{m}(\epsilon))\leq\lim\mathbb{P}(B_{m}(\epsilon))=0$
\end_inset

.
 By the squeeze theorem, 
\begin_inset Formula $\lim\mathbb{P}(A_{m}(\epsilon))=0$
\end_inset

.
 Consequently, 
\begin_inset Formula $X_{n}\stackrel{P}{\to}X$
\end_inset

.
\end_layout

\begin_layout Proof
(vii) 
\series bold
Counterexample
\series default
.

\series bold
 
\series default
(Convergence almost surely does not imply convergence in mean square)
\end_layout

\begin_layout Proof
Let 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
X_{n}(\omega) & =\begin{cases}
n & \omega\in[0,\frac{1}{n}]\\
0 & \text{ otherwise }
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $A_{n}(\epsilon)$
\end_inset

 be the event that an excursion occurs at 
\begin_inset Formula $n$
\end_inset

, 
\begin_inset Formula $\{|X_{n}|>\epsilon\}$
\end_inset

.
 Now, 
\begin_inset Formula $\mathbb{P}(B_{m}(\epsilon))=\mathbb{P}(\bigcup_{n\geq m}A_{n}(\epsilon))\leq\mathbb{P}(A_{m}(\epsilon))=\frac{1}{m}$
\end_inset

.
 So, 
\begin_inset Formula $\lim_{m\to\infty}\mathbb{P}(B_{m}(\epsilon))=0$
\end_inset

.
 Thus, 
\begin_inset Formula $X_{n}\stackrel{a.s.}{\to}0$
\end_inset

.
 But, 
\begin_inset Formula $\mathbb{E}[X_{n}^{2}]=n$
\end_inset

.
 Thus, 
\begin_inset Formula $X_{n}\stackrel{L^{2}}{\cancel{\to}}0$
\end_inset

.
\end_layout

\begin_layout Proof
(viii) 
\series bold
Counterexample.
 
\series default
(Convergence in mean square does not imply convergence almost surely)
\end_layout

\begin_layout Proof
Let 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
X_{n} & =\begin{cases}
1 & \text{with probability }1/n\\
0 & \text{with probability }1-1/n
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
where the 
\begin_inset Formula $X_{n}$
\end_inset

's are independent.
 
\end_layout

\begin_layout Proof
Now, 
\begin_inset Formula $\mathbb{E}[X_{n}^{2}]=\frac{1}{n}$
\end_inset

 so 
\begin_inset Formula $\lim\mathbb{E}[X_{n}^{2}]=0$
\end_inset

.
 Thus, 
\begin_inset Formula $X_{n}\stackrel{L^{2}}{\to}0$
\end_inset

.
 Define 
\begin_inset Formula $A_{n}=\{|X_{n}|\geq\epsilon\}$
\end_inset

.
 But, by BCL2, 
\begin_inset Formula $\sum_{n}\mathbb{P}(A_{n})=\infty$
\end_inset

 and the events 
\begin_inset Formula $A_{n}$
\end_inset

 are independent.
 Then, 
\begin_inset Formula $A_{n}$
\end_inset

 occurs infinitely often.
 In other words, 
\begin_inset Formula $X_{n}$
\end_inset

 does not converge to 
\begin_inset Formula $0$
\end_inset

 almost surely.
 
\end_layout

\begin_layout Theorem
If a sequence 
\begin_inset Formula $(X_{n})$
\end_inset

 of random variables converges in probability to 
\begin_inset Formula $X$
\end_inset

, then there exists a subsequence 
\begin_inset Formula $(X_{n_{k}})_{k}$
\end_inset

 which converges to 
\begin_inset Formula $X$
\end_inset

 almost surely.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $X_{n}\stackrel{P}{\to}X$
\end_inset

 it follows that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\forall\epsilon>0\quad\lim\mathbb{P}(|X_{n}-X|>\epsilon)=0
\]

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $\epsilon=1/m$
\end_inset

.
 In words, for all 
\begin_inset Formula $m>0$
\end_inset

 and for all 
\begin_inset Formula $k>0$
\end_inset

, there exists 
\begin_inset Formula $N(m,k)\in\mathbf{N}$
\end_inset

, such that for all 
\begin_inset Formula $n\geq N$
\end_inset

, the following condition is satisfied:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(|X_{n}-X|>\frac{1}{m}\right) & <\frac{1}{k}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By the definition of the limit of a sequence, there exists 
\begin_inset Formula $n_{1}$
\end_inset

 such that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(|X_{n_{1}}-X|>1\right) & <1
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
There exists 
\begin_inset Formula $n_{2}\geq n_{1}$
\end_inset

 such that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(|X_{n_{2}}-X|>\frac{1}{2}\right) & <\frac{1}{2^{2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
There exists 
\begin_inset Formula $n_{3}\geq n_{2}$
\end_inset

 such that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(|X_{n_{3}}-X|>\frac{1}{3}\right) & <\frac{1}{3^{2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
In general, there exists a positive integer 
\begin_inset Formula $n_{i}\geq n_{i-1}$
\end_inset

 such that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(|X_{n_{i}}-X|>\frac{1}{i}\right) & <\frac{1}{i^{2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By the sufficient condition for almost sure convergence 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:sufficient-condition-for-almost-sure-convergence"
plural "false"
caps "false"
noprefix "false"

\end_inset

, 
\begin_inset Formula $\sum_{n=1}^{\infty}\mathbb{P}(A_{n})<\sum_{n=1}^{\infty}\frac{1}{n^{2}}$
\end_inset

 which converges to a finite value.
 Hence, 
\begin_inset Formula $X_{n_{i}}\stackrel{a.s.}{\to}X$
\end_inset

.
\end_layout

\begin_layout Standard
Consider a sequence of random variables 
\begin_inset Formula $(X_{n})$
\end_inset

, such that 
\begin_inset Formula $X_{n}\stackrel{L^{2}}{\to}X$
\end_inset

.
 it turns out that the limit random variable 
\begin_inset Formula $X$
\end_inset

 of the convergent sequence in 
\begin_inset Formula $L^{2}$
\end_inset

 is guaranteed to be in 
\begin_inset Formula $L^{2}$
\end_inset

.
 This is because 
\begin_inset Formula $L^{2}$
\end_inset

 is complete.
 We will prove this very important result further ahead.
 This property is crucial for the construction of the Ito integral.
\end_layout

\begin_layout Example
(A version of the weak law of large numbers.) Consider a sequence of random
 variables 
\begin_inset Formula $X_{1},X_{2},\ldots,X_{n}$
\end_inset

 in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 such that 
\begin_inset Formula $\mathbb{E}[X_{i}]=0$
\end_inset

, 
\begin_inset Formula $\mathbb{E}[X_{i}^{2}]=\sigma^{2}<\infty$
\end_inset

 for all 
\begin_inset Formula $i\geq1$
\end_inset

 and that they are orthogonal to each other, that is, 
\begin_inset Formula $\mathbb{E}[X_{i}X_{j}]=0$
\end_inset

 for all 
\begin_inset Formula $i\neq j$
\end_inset

.
 We show that the empirical mean
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\frac{1}{n}S_{n} & =\frac{1}{n}(X_{1}+X_{2}+\ldots+X_{n})
\end{align*}

\end_inset


\end_layout

\begin_layout Example
converges to zero in the 
\begin_inset Formula $L^{2}$
\end_inset

 sense.
 
\end_layout

\begin_layout Example
Clearly, 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[\frac{S_{n}^{2}}{n^{2}}\right] & =\lim_{n\to\infty}\frac{1}{n^{2}}\sum_{i=1}^{n}\mathbb{E}[X_{i}^{2}]\\
 & =\lim_{n\to\infty}\frac{1}{n^{2}}\cdot n\sigma^{2}\\
 & =\lim_{n\to\infty}\frac{\sigma^{2}}{n}\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Consequently, the empirical mean 
\begin_inset Formula $\frac{S_{n}}{n}$
\end_inset

 converges to 
\begin_inset Formula $0$
\end_inset

 in the mean square sense.
\end_layout

\begin_layout Exercise
(
\series bold
Ornstein-Uhlenbeck Process
\series default
.) Generate 
\begin_inset Formula $100$
\end_inset

 paths with step size = 
\begin_inset Formula $0.01$
\end_inset

 of the following processes on 
\begin_inset Formula $[0,1]$
\end_inset

:
\end_layout

\begin_layout Exercise
(a) Ornstein Uhlenbeck process: 
\begin_inset Formula $C(s,t)=\frac{e^{-2(t-s)}}{2}(1-e^{-2s})$
\end_inset

 for 
\begin_inset Formula $s\leq t$
\end_inset

.
 with mean 
\begin_inset Formula $0$
\end_inset

 (so that 
\begin_inset Formula $Y_{0}=0$
\end_inset

).
\end_layout

\begin_layout Exercise
(b) Stationary Ornstein-Uhlenbeck process: 
\begin_inset Formula $C(s,t)=\frac{e^{-2(t-s)}}{2}$
\end_inset

 for 
\begin_inset Formula $s\leq t$
\end_inset

 with mean 
\begin_inset Formula $0$
\end_inset

 (so 
\begin_inset Formula $Y_{0}$
\end_inset

 is a Gaussian random variable of mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $1/2$
\end_inset

).
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{language=Python,backgroundcolor=
\backslash
color{backcolour},breaklines=true,commentstyle=
\backslash
color{codegreen},stringstyle=
\backslash
color{magenta},keywordstyle=
\backslash
bfseries
\backslash
color{blue!40!black},basicstyle=
\backslash
footnotesize
\backslash
ttfamily,frame=single}
\end_layout

\begin_layout Plain Layout


\backslash
begin{lstlisting}[caption=Orsntein-Uhlenbech(OU) process]
\end_layout

\begin_layout Plain Layout

def ornsteinUhlenbeck(numOfPaths,N):
\end_layout

\begin_layout Plain Layout

    C = np.zeros((N,N))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    for i in range(N):
\end_layout

\begin_layout Plain Layout

        for j in range(N):
\end_layout

\begin_layout Plain Layout

            s = (i + 1)/N
\end_layout

\begin_layout Plain Layout

            t = (j + 1)/N
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

            if s > t:
\end_layout

\begin_layout Plain Layout

                s,t = t,s
\end_layout

\begin_layout Plain Layout

            C[i][j] = np.exp(-2*(t-s))/2 * (1 - np.exp(-2*s))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    A = np.linalg.cholesky(C)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    Y =[]
\end_layout

\begin_layout Plain Layout

    for i in range(numOfPaths):
\end_layout

\begin_layout Plain Layout

        X = sampleGaussianProcess(A,N)
\end_layout

\begin_layout Plain Layout

        X = np.concatenate(([0],X),axis=0)
\end_layout

\begin_layout Plain Layout

        Y.append(X)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    return Y
\end_layout

\begin_layout Plain Layout


\backslash
end{lstlisting}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/ornstein_uhlenbeck.tex"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/stationaryOU.tex"

\end_inset


\end_layout

\begin_layout Section
Properties of Brownian Motion.
\end_layout

\begin_layout Subsection
Properties of Brownian Motion.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $B(t)$
\end_inset

 be a fixed Brownian motion.
 We give below some simple properties that follow directly from the definition
 of the Brownian Motion.
\end_layout

\begin_layout Proposition
For any 
\begin_inset Formula $t\geq0$
\end_inset

, 
\begin_inset Formula $B(t)$
\end_inset

 is normally distributed with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $t$
\end_inset

.
 For any 
\begin_inset Formula $s,t\geq0$
\end_inset

 we have 
\begin_inset Formula $\mathbb{E}(B_{s}B_{t})=\min\{s,t\}$
\end_inset

.
 
\end_layout

\begin_layout Proof
From condition (1), we have that 
\begin_inset Formula $B_{0}=0$
\end_inset

.
 From condition (2), 
\begin_inset Formula $B_{t}-B_{0}=B_{t}$
\end_inset

 is normally distributed with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Proof
Assume that 
\begin_inset Formula $s<t$
\end_inset

.
\end_layout

\begin_layout Proof
We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}(B_{s}B_{t}) & =\mathbb{E}\left[B_{s}(B_{t}-B_{s}+B_{s})\right] & \{\text{Write }B_{t}=B_{t}-B_{s}+B_{s}\}\\
 & =\mathbb{E}[B_{s}(B_{t}-B_{s})]+\mathbb{E}[B_{s}^{2}] & \{\text{Linearity of expectations}\}\\
 & =\mathbb{E}[B_{s}]\mathbb{E}(B_{t}-B_{s})+s & \{B_{s},(B_{t}-B_{s})\text{ are independent}\}\\
 & =0\cdot0+s\\
 & =s
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
This closes the proof.
\end_layout

\begin_layout Proposition
(Translation Invariance) For fixed 
\begin_inset Formula $t_{0}\geq0$
\end_inset

, the stochastic process 
\begin_inset Formula $\tilde{B}(t)=B(t+t_{0})-B(t_{0})$
\end_inset

 is also a Brownian motion.
\end_layout

\begin_layout Proof
Firstly, the stochastic process 
\begin_inset Formula $\tilde{B}(t)$
\end_inset

 is such that:
\end_layout

\begin_layout Proof
(1) 
\begin_inset Formula $\tilde{B}(0)=B(t_{0})-B(t_{0})=0$
\end_inset

.
 Hence, it satisfies condition (1).
\end_layout

\begin_layout Proof
(2) Let 
\begin_inset Formula $s<t$
\end_inset

.
 We have: 
\begin_inset Formula $\tilde{B}(t)-\tilde{B}(s)=B(t+t_{0})-B(s+t_{0})$
\end_inset

 which a Gaussian random variable with mean 0 and variance 
\begin_inset Formula $t-s$
\end_inset

.
 Hence, for 
\begin_inset Formula $a\leq b$
\end_inset

,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}\{a\leq & \tilde{B}(t)\leq b\}=\frac{1}{\sqrt{2\pi(t-s)}}\int_{a}^{b}e^{-\frac{x^{2}}{2(t-s)}}dx
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Hence, it satisfies condition (2).
\end_layout

\begin_layout Proof
(3) To check condition (3) for 
\begin_inset Formula $\tilde{B}(t)$
\end_inset

, we may assume 
\begin_inset Formula $t_{0}>0$
\end_inset

.
 Then, for any 
\begin_inset Formula $0\leq t_{1}\leq t_{2}\leq\ldots\leq t_{n}$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
0<t_{0}\leq t_{0}+t_{1}\leq t_{0}+t_{2}\leq\ldots\leq t_{0}+t_{n}
\]

\end_inset


\end_layout

\begin_layout Proof
So, 
\begin_inset Formula $B(t_{1}+t_{0})-B(t_{0})$
\end_inset

, 
\begin_inset Formula $B(t_{2}+t_{0})-B(t_{1}+t_{0})$
\end_inset

, 
\begin_inset Formula $\ldots$
\end_inset

, 
\begin_inset Formula $B(t_{k}+t_{0})-B(t_{k-1}+t_{0})$
\end_inset

, 
\begin_inset Formula $\ldots$
\end_inset

, 
\begin_inset Formula $B(t_{n}+t_{0})-B(t_{n-1}+t_{0})$
\end_inset

 are independent random variables.
 Consequently, 
\begin_inset Formula $\tilde{B}(t)$
\end_inset

 satisfies condition (3).
\end_layout

\begin_layout Proof
This closes the proof.
\end_layout

\begin_layout Standard
The above translation invariance property says that a Brownian motion starts
 afresh at any moment as a new Brownian motion.
 
\end_layout

\begin_layout Proposition
(Scaling Invariance) For any real number 
\begin_inset Formula $\lambda>0$
\end_inset

, the stochastic process 
\begin_inset Formula $\tilde{B}(t)=B(\lambda t)/\sqrt{\lambda}$
\end_inset

 is also a Brownian motion.
 
\end_layout

\begin_layout Proof
The scaled stochastic process 
\begin_inset Formula $\tilde{B}(t)$
\end_inset

 is such that:
\end_layout

\begin_layout Proof
(1) 
\begin_inset Formula $\tilde{B}(0)=0$
\end_inset

.
 Hence it satisfies condition (1).
\end_layout

\begin_layout Proof
(2) Let 
\begin_inset Formula $s<t$
\end_inset

.
 Then, 
\begin_inset Formula $\lambda s<\lambda t$
\end_inset

.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\tilde{B}(t)-\tilde{B}(s) & =\frac{1}{\sqrt{\lambda}}(B(\lambda t)-B(\lambda s))
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, 
\begin_inset Formula $B(\lambda t)-B(\lambda s)$
\end_inset

 is a Gaussian random variable with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $\lambda(t-s)$
\end_inset

.
 We know that, if 
\begin_inset Formula $X$
\end_inset

 is a random variable with mean 
\begin_inset Formula $\mu$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

, 
\begin_inset Formula $Z=\left(\frac{X-\mu}{\sigma}\right)$
\end_inset

 has mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $1$
\end_inset

.
 Consequently, 
\begin_inset Formula $\frac{B(\lambda t)-B(\lambda s)}{\sqrt{\lambda}}$
\end_inset

 is a Gaussian random variable with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $(t-s)$
\end_inset

.
\end_layout

\begin_layout Proof
Hence, 
\begin_inset Formula $\tilde{B}(t)-\tilde{B}(s)$
\end_inset

 is normal distributed with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $t-s$
\end_inset

 and it satisfies condition (2).
\end_layout

\begin_layout Proof
(3) To check condition (3) for 
\begin_inset Formula $\tilde{B}(t)$
\end_inset

, we may assume 
\begin_inset Formula $t_{0}>0$
\end_inset

.
 Then, for any 
\begin_inset Formula $0\leq t_{1}\leq t_{2}\leq\ldots\leq t_{n}$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
0\leq\lambda t_{1}\leq\lambda t_{2}\leq\ldots\leq\lambda t_{n}
\]

\end_inset


\end_layout

\begin_layout Proof
Consequently, the random variables 
\begin_inset Formula $B(\lambda t_{k})-B(\lambda t_{k-1})$
\end_inset

, 
\begin_inset Formula $k=1,2,3,\ldots,n$
\end_inset

 are independent.
 Hence it follows that 
\begin_inset Formula $\frac{1}{\sqrt{\lambda}}[B(\lambda t_{k})-B(\lambda t_{k-1})]$
\end_inset

 for 
\begin_inset Formula $k=1,2,\ldots,n$
\end_inset

 are also independent random variables.
 
\end_layout

\begin_layout Proof
This closes the proof.
\end_layout

\begin_layout Standard
It follows from the scaling invariance property that for any 
\begin_inset Formula $\lambda>0$
\end_inset

 and 
\begin_inset Formula $0\leq t_{1}\leq t_{2}\leq\ldots\leq t_{n}$
\end_inset

, the random vectors:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
(B(\lambda t_{1}),B(\lambda t_{2}),\ldots,B(\lambda t_{n}))\quad(\sqrt{\lambda}B(t_{1}),\sqrt{\lambda}B(t_{1}),\ldots,\sqrt{\lambda}B(t_{n}))
\]

\end_inset


\end_layout

\begin_layout Standard
have the same distribution.
\end_layout

\begin_layout Standard
The scaling property shows that Brownian motion is 
\emph on
self-similar
\emph default
, much like a fractal.
 To see this, suppose we zoom into a Brownian motion path very close to
 zero, say on the interval 
\begin_inset Formula $[0,10^{-6}]$
\end_inset

.
 If the Brownian motion path were smooth and differentiable, the closer
 we zoom in around the origin, the flatter the function will look.
 In the limit, we would essentially see a straight line given by the derivative
 at 
\begin_inset Formula $0$
\end_inset

.
 However, what we see with the Brownian motion is very different.
 The scaling property means that for 
\begin_inset Formula $a=10^{-6}$
\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
(B_{10^{-6}t,}t\in[0,1]) & \stackrel{\text{distrib.}}{=}(10^{-3}B_{t},t\in[0,1])
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\stackrel{\text{distrib.}}{=}$
\end_inset

 means equality of the distribution of the two processes.
 In other words, Brownian motion on 
\begin_inset Formula $[0,10^{-6}]$
\end_inset

 looks like a Browian motion on 
\begin_inset Formula $[0,1]$
\end_inset

, but with its amplitude multiplied by a factor of 
\begin_inset Formula $10^{-3}$
\end_inset

.
 In particular, it will remain rugged as we zoom in, unlike a smooth function.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:brownian-motion-symmetry-of-reflection-at-time-s"

\end_inset

(Reflection at time 
\begin_inset Formula $s$
\end_inset

) The process 
\begin_inset Formula $(-B_{t},t\geq0)$
\end_inset

 is a Brownian motion.
 More generally, for any 
\begin_inset Formula $s\geq0$
\end_inset

, the process 
\begin_inset Formula $(\tilde{B}(t),t\geq0)$
\end_inset

 defined by:
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align}
\tilde{B}(t) & =\begin{cases}
B_{t} & \text{if }t\leq s\\
B_{s}-(B_{t}-B_{s}) & \text{if }t>s
\end{cases}\label{eq:reflection-property}
\end{align}

\end_inset


\end_layout

\begin_layout Proposition
is a Brownian motion.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
(a) Consider the process 
\begin_inset Formula $\tilde{B}(t)=(-B_{t},t\geq0)$
\end_inset

.
\end_layout

\begin_layout Proof
(1) 
\begin_inset Formula $\tilde{B}(0)=0$
\end_inset

.
\end_layout

\begin_layout Proof
(2) If 
\begin_inset Formula $X$
\end_inset

 is a Gaussian random variable with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $t-s$
\end_inset

, 
\begin_inset Formula $-X$
\end_inset

 is also Gaussian with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $t-s$
\end_inset

.
 Thus, 
\begin_inset Formula $\tilde{B}(t)-\tilde{B}(s)=-(B(t)-B(s))$
\end_inset

 is also Gaussian with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $(t-s)$
\end_inset

.
 Hence condition (2) is satisfied.
\end_layout

\begin_layout Proof
(3) Assume that 
\begin_inset Formula $0\leq t_{0}\leq t_{1}\leq\ldots\leq t_{n}$
\end_inset

.
 Then, the random variables 
\begin_inset Formula $-(B(t_{k})-B(t_{k-1}))$
\end_inset

 are independent for 
\begin_inset Formula $k=1,2,3,\ldots,n$
\end_inset

.
 Hence, condition (3) is satisfied.
\end_layout

\begin_layout Proof
(b) Consider the process 
\begin_inset Formula $\tilde{B}(t)$
\end_inset

 as defined in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:reflection-property"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Proof
Fix an 
\begin_inset Formula $s\geq0$
\end_inset

.
 
\end_layout

\begin_layout Proof
(1) Let 
\begin_inset Formula $t=0$
\end_inset

.
 Then, 
\begin_inset Formula $t\leq s$
\end_inset

.
 
\begin_inset Formula $\tilde{B}(t)=\tilde{B}(0)=B(0)=0$
\end_inset

.
\end_layout

\begin_layout Proof
(2) Let 
\begin_inset Formula $t_{1}<t_{2}\leq s$
\end_inset

.
 Then, 
\begin_inset Formula $\tilde{B}(t_{2})-\tilde{B}(t_{1})=B(t_{2})-B(t_{1})$
\end_inset

.
 This is a Gaussian random variable with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $t_{2}-t_{1}$
\end_inset

.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $t_{1}<s<t_{2}$
\end_inset

.
 Then, 
\begin_inset Formula $\tilde{B}(t_{2})-\tilde{B}(t_{1})=B(s)-(B(t_{2})-B(s))-B(t_{1})=(B(s)-B(t_{1}))-(B(t_{2})-B(s))$
\end_inset

.
 Since, 
\begin_inset Formula $B(s)-B(t_{1})$
\end_inset

 and 
\begin_inset Formula $B(t_{2})-B(s)$
\end_inset

 are independent Gaussian random variables, any linear combination of these
 is Gaussian.
 Moreover, its mean is zero.
 The variance is given by:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
Var[\tilde{B}(t_{2})-\tilde{B}(t_{1})] & =Var[B(s)-B(t_{1})]+Var[B(t_{2})-B(s)]\\
 & =(s-t_{1})+(t_{2}-s)\\
 & =t_{2}-t_{1}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $s<t_{1}<t_{2}$
\end_inset

.
 Then, 
\begin_inset Formula 
\begin{align*}
\tilde{B}(t_{2})-\tilde{B}(t_{1}) & =B_{s}-(B_{t_{2}}-B_{s})-(B_{s}-(B_{t_{1}}-B_{s}))\\
 & =\cancel{B_{s}}-(B_{t_{2}}-\cancel{B_{s}})-(\cancel{B_{s}}-(B_{t_{1}}-\cancel{B_{s}}))\\
 & =-(B_{t_{2}}-B_{t_{1}})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Hence, 
\begin_inset Formula $\tilde{B}(t_{2})-\tilde{B}(t_{1})$
\end_inset

 is again a Gaussian random variable with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $t_{2}-t_{1}$
\end_inset

.
 Hence, condition (3) is satisfied.
\end_layout

\begin_layout Proof
(3) Assume that 
\begin_inset Formula $0\leq t_{1}\leq\ldots\leq t_{k-1}\leq s\leq t_{k}\leq\ldots\leq t_{n}$
\end_inset

.
 From the above discussion, the increments 
\begin_inset Formula $\tilde{B}(t_{2})-\tilde{B}(t_{1})$
\end_inset

, 
\begin_inset Formula $\ldots$
\end_inset

, 
\begin_inset Formula $\tilde{B}(s)-\tilde{B}(t_{k-1})$
\end_inset

, 
\begin_inset Formula $\tilde{B}(t_{k})-\tilde{B}(s)$
\end_inset

, 
\begin_inset Formula $\ldots$
\end_inset

, 
\begin_inset Formula $\tilde{B}(t_{n})-\tilde{B}(t_{n-1})$
\end_inset

 are independent increments.
 The increment 
\begin_inset Formula $\tilde{B}(t_{k})-\tilde{B}(t_{k-1})$
\end_inset

 only depends on the random variables 
\begin_inset Formula $\tilde{B}(s)-\tilde{B}(t_{k-1})$
\end_inset

 and 
\begin_inset Formula $\tilde{B}(t_{k})-\tilde{B}(s)$
\end_inset

.
 Thus, 
\begin_inset Formula $\tilde{B}(t_{2})-\tilde{B}(t_{1})$
\end_inset

, 
\begin_inset Formula $\ldots$
\end_inset

, 
\begin_inset Formula $\tilde{B}(t_{k})-\tilde{B}(t_{k-1})$
\end_inset

, 
\begin_inset Formula $\ldots$
\end_inset

, 
\begin_inset Formula $\tilde{B}(t_{n})-\tilde{B}(t_{n-1})$
\end_inset

 are independent.
\end_layout

\begin_layout Proposition
(Time Reversal).
 Let 
\begin_inset Formula $(B_{t},t\geq0)$
\end_inset

 be a Brownian motion.
 Show that the process 
\begin_inset Formula $(B_{1}-B_{1-t},t\in[0,1])$
\end_inset

 has the distribution of a standard brownian motion on 
\begin_inset Formula $[0,1]$
\end_inset

.
 
\end_layout

\begin_layout Proof
(1) At 
\begin_inset Formula $t=0$
\end_inset

, 
\begin_inset Formula $B(1)-B(1-t)=B(1)-B(1)=0$
\end_inset

.
\end_layout

\begin_layout Proof
(2) Let 
\begin_inset Formula $s<t$
\end_inset

.
 Then, 
\begin_inset Formula $1-t<1-s$
\end_inset

.
 So, the increment :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
(B(1)-B(1-t))-(B(1)-B(1-s)) & =B(1-s)-B(1-t)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
has a Gaussian distribution.
 It's mean is 
\begin_inset Formula $0$
\end_inset

 and variance is 
\begin_inset Formula $(1-s)-(1-t)=t-s$
\end_inset

.
\end_layout

\begin_layout Proof
(3) Let 
\begin_inset Formula $0\leq t_{1}\leq t_{2}\leq\ldots\leq t_{n}$
\end_inset

.
 Then:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
1-t_{n}\leq\ldots\leq1-t_{k}\leq1-t_{k-1}\leq\ldots\leq1-t_{2}\leq1-t_{1}
\]

\end_inset


\end_layout

\begin_layout Proof
Consider the increments of the process for 
\begin_inset Formula $k=1,2,\ldots,n$
\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
(B(1)-B(1-t_{k}))-(B(1)-B(1-t_{k-1})) & =B(1-t_{k-1})-B(1-t_{k})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
They are independent random variables.
 Hence, condition (3) is satisfied.
\end_layout

\begin_layout Example
(Evaluating Brownian Probabilities).
 Let's compute the probability that 
\begin_inset Formula $B_{1}>0$
\end_inset

 and 
\begin_inset Formula $B_{2}>0$
\end_inset

.
 We know from the definition that 
\begin_inset Formula $(B_{1},B_{2})$
\end_inset

 is a Gaussian vector with mean 
\begin_inset Formula $0$
\end_inset

 and covariance matrix:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
C & =\left[\begin{array}{cc}
1 & 1\\
1 & 2
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The determinant of 
\begin_inset Formula $C$
\end_inset

 is 
\begin_inset Formula $1$
\end_inset

.
 By performing row operations on the augmented matrix 
\begin_inset Formula $[C|I]$
\end_inset

 we find that:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
C^{-1} & =\left[\begin{array}{cc}
2 & -1\\
-1 & 1
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Thus, the probability 
\begin_inset Formula $\mathbb{P}(B_{1}>0,B_{2}>0)$
\end_inset

 can be expressed as:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{P}(B_{1}>0,B_{2}>0) & =\frac{1}{\sqrt{(2\pi)^{2}}}\int_{0}^{\infty}\int_{0}^{\infty}\exp\left[-\frac{1}{2}(2x_{1}^{2}-2x_{1}x_{2}+x_{2}^{2}\right]dx_{2}dx_{1}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
This integral can be evaluated using a calculator or software and is equal
 to 
\begin_inset Formula $3/8$
\end_inset

.
 The probability can also be computed using the independence of increments.
 The increments 
\begin_inset Formula $(B_{1},B_{2}-B_{1})$
\end_inset

 are IID standard Gaussians.
 We know their joint PDF.
 It remains to integrate over the correct region of 
\begin_inset Formula $\mathbf{R}^{2}$
\end_inset

 which in this case will be:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
D^{*} & =\{(z_{1},z_{2}):(z_{1}>0,z_{1}+z_{2}>0)\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{P}(B_{1}>0,B_{2}>0) & =\frac{1}{2\pi}\int_{0}^{\infty}\int_{z_{2}=-z_{1}}^{z_{2}=\infty}e^{-(z_{1}^{2}+z_{2}^{2})/2}dz_{2}dz_{1}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
It turns out that this integral can be evaluated exactly.
 Indeed by writing 
\begin_inset Formula $B_{1}=Z_{1}$
\end_inset

 and 
\begin_inset Formula $Z_{2}=B_{2}-B_{1}$
\end_inset

 and splitting the probability on the event 
\begin_inset Formula $\{Z_{2}\geq0\}$
\end_inset

 and its complement, we have that 
\begin_inset Formula $\mathbb{P}(B_{1}\geq0,B_{2}\geq0)$
\end_inset

 equals:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{P}(B_{1}\geq0,B_{2}\geq0) & =\mathbb{P}(Z_{1}\geq0,Z_{1}+Z_{2}>0,Z_{2}\geq0)+\mathbb{P}(Z_{1}\geq0,Z_{1}+Z_{2}>0,Z_{2}<0)\\
 & =\mathbb{P}(Z_{1}\geq0,Z_{2}\geq0)+\mathbb{P}(Z_{1}\geq0,Z_{1}>-Z_{2},-Z_{2}>0)\\
 & =\mathbb{P}(Z_{1}\geq0,Z_{2}\geq0)+\mathbb{P}(Z_{1}\geq0,Z_{1}>Z_{2},Z_{2}>0)\\
 & =\frac{1}{4}+\frac{1}{8}\\
 & =\frac{3}{8}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Note that, by symmetry, 
\begin_inset Formula $\mathbb{P}(Z_{1}\geq0,Z_{1}>Z_{2},Z_{2}>0)=\mathbb{P}(Z_{1}\geq0,Z_{1}\leq Z_{2},Z_{2}>0)=\frac{1}{8}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(Another look at Ornstein Uhlenbeck process.) Consider the process 
\begin_inset Formula $(X_{t},t\in\mathbf{R})$
\end_inset

 defined by :
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
X_{t} & =\frac{e^{-2t}}{\sqrt{2}}B(e^{4t}),\quad t\in\mathbf{R}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Here the process 
\begin_inset Formula $(B_{e^{4t}},t\ge0)$
\end_inset

 is called a time change of Brownian motion, since the time is now quantitfied
 by an increasing function of 
\begin_inset Formula $t$
\end_inset

 namely 
\begin_inset Formula $e^{4t}$
\end_inset

.
 The example 
\begin_inset Formula $(B(\lambda t),t\geq0)$
\end_inset

 in the scaling property is another example of time change.
 
\end_layout

\begin_layout Standard
It turns out that 
\begin_inset Formula $(X_{t},t\in\mathbf{R})$
\end_inset

 is a stationary Ornstein-Uhlenbeck process.
 (Here the index of time is 
\begin_inset Formula $\mathbf{R}$
\end_inset

 instead of 
\begin_inset Formula $[0,\infty)$
\end_inset

, but the definition also applies as the process is stationary.
 Since the original brownian motion 
\begin_inset Formula $B(t)$
\end_inset

 is a Gaussian process, any finite dimensional vector 
\begin_inset Formula $(B(t_{1}),\ldots,B(t_{n}))$
\end_inset

 is Gaussian.
 It follows that:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
(B(T_{1}),\ldots,B(T_{n}))=\frac{1}{\sqrt{2}}(e^{-2t_{1}}B(e^{4t_{1}}),\ldots,e^{-2t_{n}}B(e^{4t_{n}}))
\]

\end_inset


\end_layout

\begin_layout Standard
is also a Gaussian vector.
 (Note, once we fix 
\begin_inset Formula $t_{1},t_{2},\ldots,t_{n}$
\end_inset

, 
\begin_inset Formula $e^{-4t_{1}},\ldots,e^{-4t_{n}}$
\end_inset

 are constants.) Hence, 
\begin_inset Formula $(X_{t},t\in\mathbf{R})$
\end_inset

 is a Gaussian process.
 
\end_layout

\begin_layout Standard
The mean of 
\begin_inset Formula $(X_{t},t\in\mathbf{R})$
\end_inset

 is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}[X_{t}] & =\frac{e^{-2t}}{\sqrt{2}}\mathbb{E}[B(e^{4t})]=0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
And if 
\begin_inset Formula $s<t$
\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}[X_{s}X_{t}] & =\frac{e^{-2(s+t)}}{2}\mathbb{E}[B(e^{4s})B(e^{4t})]\\
 & =\frac{e^{-2(s+t)}}{2}e^{4s}\\
 & =\frac{e^{-2(t-s)}}{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Two Gaussian processes having the same mean and covariance have the same
 distribution.
 Hence, it proves the claim that 
\begin_inset Formula $(X_{t})$
\end_inset

 is a stationary OU process.
\end_layout

\begin_layout Subsection
Properties of the paths.
\end_layout

\begin_layout Standard
First we review the definitions of the Riemann integral and the Riemann-Stieljte
s integral in Calculus.
\end_layout

\begin_layout Definition
A partition 
\begin_inset Formula $P$
\end_inset

 of 
\begin_inset Formula $[a,b]$
\end_inset

 is a 
\emph on
finite
\emph default
 set of points from 
\begin_inset Formula $[a,b]$
\end_inset

 that includes both 
\begin_inset Formula $[a,b].$
\end_inset

The notational convention is to always list the points of a partition 
\begin_inset Formula $P=\{a=x_{0},x_{1},x_{2},\ldots,x_{n}=b\}$
\end_inset

 in increasing order.
 Thus:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
a=x_{0}<x_{1}<\ldots<x_{k-1}<x_{k}<\ldots<x_{n}=b
\]

\end_inset


\end_layout

\begin_layout Standard
For each subinterval 
\begin_inset Formula $[x_{k-1},x_{k}]$
\end_inset

 of 
\begin_inset Formula $P$
\end_inset

, let 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
m_{k} & =\inf\{f(x):x\in[x_{k-1},x_{k}]\}\\
M_{k} & =\sup\{f(x):x\in[x_{k-1},x_{k}]\}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The lower sum of 
\begin_inset Formula $f$
\end_inset

 with respect to 
\begin_inset Formula $P$
\end_inset

 is given by :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
L(f,P) & =\sum_{k=1}^{n}m_{k}(x_{k}-x_{k-1})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The upper sum of 
\begin_inset Formula $f$
\end_inset

 with respect to 
\begin_inset Formula $P$
\end_inset

 is given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
U(f,P) & =\sum_{k=1}^{n}M_{k}(x_{k}-x_{k-1})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
For a particular partition 
\begin_inset Formula $P$
\end_inset

, it is clear that 
\begin_inset Formula $U(f,P)\geq L(f,P)$
\end_inset

 because 
\begin_inset Formula $M_{k}\geq m_{k}$
\end_inset

 for all 
\begin_inset Formula $k=0,1,2,\ldots,n$
\end_inset

.
 
\end_layout

\begin_layout Definition
A partition 
\begin_inset Formula $Q$
\end_inset

 is called a 
\emph on
refinement 
\emph default
of 
\begin_inset Formula $P$
\end_inset

 if 
\begin_inset Formula $Q$
\end_inset

 contains all of the points of 
\begin_inset Formula $P$
\end_inset

; that is 
\begin_inset Formula $Q\subseteq P$
\end_inset

.
\end_layout

\begin_layout Lemma
If 
\begin_inset Formula $P\subseteq Q$
\end_inset

, then 
\begin_inset Formula $L(f,P)\leq L(f,Q)$
\end_inset

 and 
\begin_inset Formula $U(f,Q)\leq U(f,P)$
\end_inset

.
\end_layout

\begin_layout Proof
Consider what happens when we refine 
\begin_inset Formula $P$
\end_inset

 by adding a single point 
\begin_inset Formula $z$
\end_inset

 to some subinterval 
\begin_inset Formula $[x_{k-1},x_{k}]$
\end_inset

 of 
\begin_inset Formula $P$
\end_inset

.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
m_{k}(x_{k}-x_{k-1}) & =m_{k}(x_{k}-z)+m_{k}(z-x_{k-1})\\
 & \leq m_{k}'(x_{k}-z)+m_{k}''(z-x_{k-1})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
where 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
m_{k}' & =\inf\{f(x):x\in[z,x_{k}]\}\\
m_{k}'' & =\inf\{f(x):x\in[x_{k-1},z]\}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By induction we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
L(f,P) & \leq L(f,Q)\\
U(f,Q) & \leq U(f,P)
\end{align*}

\end_inset


\end_layout

\begin_layout Lemma
If 
\begin_inset Formula $P_{1}$
\end_inset

 and 
\begin_inset Formula $P_{2}$
\end_inset

 are any two partitions of 
\begin_inset Formula $[a,b]$
\end_inset

, then 
\begin_inset Formula $L(f,P_{1})\leq U(f,P_{2})$
\end_inset

.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $Q=P_{1}\cup P_{2}$
\end_inset

.
 Then, 
\begin_inset Formula $P_{1}\subseteq Q$
\end_inset

 and 
\begin_inset Formula $P_{2}\subseteq Q$
\end_inset

.
 Thus, 
\begin_inset Formula $L(f,P_{1})\leq L(f,Q)\leq U(f,Q)\leq L(f,P_{2})$
\end_inset

.
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $\mathcal{P}$
\end_inset

 be the collection of all possible partitions of the interval 
\begin_inset Formula $[a,b]$
\end_inset

.
 The upper integral of 
\begin_inset Formula $f$
\end_inset

 is defined to be:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
U(f) & =\inf\{U(f,P):P\in\mathcal{P}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
The lower integral of 
\begin_inset Formula $f$
\end_inset

 is defined by:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
L(f) & =\sup\{L(f,P):P\in\mathcal{P}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Consider the set of all upper sums of 
\begin_inset Formula $f$
\end_inset

 - 
\begin_inset Formula $\{U(f,P):P\in\mathcal{P}\}$
\end_inset

.
 Take an arbitrary partition 
\begin_inset Formula $P'\in\mathcal{P}$
\end_inset

.
 Since 
\begin_inset Formula $L(f,P')\leq U(f,P)$
\end_inset

 for all 
\begin_inset Formula $P\in\mathcal{P}$
\end_inset

, by the Axiom of Completeness(AoC), 
\begin_inset Formula $\inf\{U(f,P):P\in\mathcal{P}\}$
\end_inset

 exists.We can similarly argue for the supremum of all lower Riemann sums.
\end_layout

\begin_layout Lemma
For any bounded function 
\begin_inset Formula $f$
\end_inset

 on 
\begin_inset Formula $[a,b]$
\end_inset

, it is always the case that 
\begin_inset Formula $U(f)\geq L(f)$
\end_inset

.
\end_layout

\begin_layout Proof
By the properties of the infimum of a set, 
\begin_inset Formula $(\forall\epsilon>0)$
\end_inset

, 
\begin_inset Formula $\exists P(\epsilon)$
\end_inset

 such that 
\begin_inset Formula $U(f)<U(f,P(\epsilon))<U(f)+\epsilon$
\end_inset

.
 Pick 
\begin_inset Formula $\epsilon=1,\frac{1}{2},\frac{1}{3}\ldots,\frac{1}{n},\ldots$
\end_inset

.
 Thus, we can produce a sequence of partitions 
\begin_inset Formula $P_{n}$
\end_inset

 such that :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
U(f)<\ldots<U(f,P_{n})<U(f)+\frac{1}{n}
\]

\end_inset


\end_layout

\begin_layout Proof
Consequently, 
\begin_inset Formula $\lim U(f,P_{n})=U(f)$
\end_inset

.
 Similarly, we can produce a sequence of partitions 
\begin_inset Formula $(Q_{m})$
\end_inset

 such that :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
L(f)-\frac{1}{m}<\ldots<L(f,Q_{m})<L(f)
\]

\end_inset


\end_layout

\begin_layout Proof
We know that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
L(f,Q_{m}) & \leq U(f,P_{n})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Keeping 
\begin_inset Formula $m$
\end_inset

 fixed and passing to the limit, as 
\begin_inset Formula $n\to\infty$
\end_inset

 on both sides, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}L(f,Q_{m}) & \leq\lim_{n\to\infty}U(f,P_{n})\quad\left\{ \text{Order Limit Theorem}\right\} \\
L(f,Q_{m}) & \leq U(f)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, passing to the limit, as 
\begin_inset Formula $m\to\infty$
\end_inset

 on both sides, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim_{m\to\infty}L(f,Q_{m}) & \leq\lim_{m\to\infty}U(f)\quad\left\{ \text{Order Limit Theorem}\right\} \\
L(f) & \leq U(f)
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
(Riemann Integrability).
 A bounded function 
\begin_inset Formula $f$
\end_inset

 on the interval 
\begin_inset Formula $[a,b]$
\end_inset

 is said to be Riemann integrable if 
\begin_inset Formula $U(f)=L(f)$
\end_inset

.
 In this case, we define 
\begin_inset Formula $\int_{a}^{b}f$
\end_inset

 or 
\begin_inset Formula $\int_{a}^{b}f(x)dx$
\end_inset

 to be the common value:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
\int_{a}^{b}f(x)dx & =U(f)=L(f)
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
(Integrability Criterion) A bounded function 
\begin_inset Formula $f$
\end_inset

 is integrable on 
\begin_inset Formula $[a,b]$
\end_inset

 if and only if, for every 
\begin_inset Formula $\epsilon>0$
\end_inset

, there exists a partition 
\begin_inset Formula $P_{\epsilon}$
\end_inset

 of 
\begin_inset Formula $[a,b]$
\end_inset

 such that:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
U(f,P_{\epsilon})-L(f,P_{\epsilon}) & <\epsilon
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(
\begin_inset Formula $\Longleftarrow$
\end_inset

 direction.) Let 
\begin_inset Formula $\epsilon>0$
\end_inset

.
 If such a partition 
\begin_inset Formula $P_{\epsilon}$
\end_inset

 exists, then:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
U(f)-L(f)\leq U(f,P_{\epsilon})-L(f,P_{\epsilon})<\epsilon
\]

\end_inset


\end_layout

\begin_layout Proof
Because 
\begin_inset Formula $\epsilon$
\end_inset

 is arbitrary, it follows that 
\begin_inset Formula $U(f)=L(f)$
\end_inset

 and hence 
\begin_inset Formula $f$
\end_inset

 is Riemann integrable.
\end_layout

\begin_layout Proof
(
\begin_inset Formula $\Longrightarrow$
\end_inset

 direction.) Let 
\begin_inset Formula $f$
\end_inset

 be a bounded function on 
\begin_inset Formula $[a,b]$
\end_inset

 such that 
\begin_inset Formula $f$
\end_inset

 is Riemann integrable.
 
\end_layout

\begin_layout Proof
Pick an arbitrary 
\begin_inset Formula $\epsilon>0$
\end_inset

.
 
\end_layout

\begin_layout Proof
Then, since 
\begin_inset Formula $U(f)=\inf\{U(f,P):P\in\mathcal{P}\}$
\end_inset

, there exists 
\begin_inset Formula $P_{\epsilon}\in\mathcal{P}$
\end_inset

, such that 
\begin_inset Formula $U(f)<U(f,P_{\epsilon})<U(f)+\frac{\epsilon}{2}$
\end_inset

.
 Since 
\begin_inset Formula $L(f)=\sup\{L(f,P):P\in\mathcal{P}\}$
\end_inset

, there exists 
\begin_inset Formula $P_{\epsilon}\in\mathcal{P}$
\end_inset

, such that 
\begin_inset Formula $L(f)-\frac{\epsilon}{2}<L(f,P_{\epsilon})<L(f)$
\end_inset

.
 Consequently, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
U(f,P_{\epsilon})-L(f,P_{\epsilon}) & <U(f)+\frac{\epsilon}{2}-\left(L(f)-\frac{\epsilon}{2}\right)\\
 & =U(f)-L(f)+\epsilon\\
 & =\epsilon
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection
Functions considered in Stochastic Calculus.
\end_layout

\begin_layout Definition
A point 
\begin_inset Formula $c$
\end_inset

 is called a discontinuity of the first kind or jump point if both limits
 
\begin_inset Formula $g(c+)=\lim_{t\uparrow c}g(t)$
\end_inset

 and 
\begin_inset Formula $g(c-)=\lim_{t\downarrow c}g(t)$
\end_inset

 exist and are not equal.
 The jump at 
\begin_inset Formula $c$
\end_inset

 is defined as 
\begin_inset Formula $\Delta g(c)=g(c+)-g(c-)$
\end_inset

.
 Any other discontinuity is said to be of the second kind.
 
\end_layout

\begin_layout Example
Consider the function 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
f(x) & =\sin\left(\frac{1}{x}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $x_{n}=\frac{1}{2n\pi}$
\end_inset

.
 Then, 
\begin_inset Formula $f(x_{n})=(0,0,0,\ldots)$
\end_inset

.
 Next, consider 
\begin_inset Formula $y_{n}=\frac{1}{\pi/2+2n\pi}$
\end_inset

.
 Then, 
\begin_inset Formula $f(y_{n})=(1,1,1,\ldots)$
\end_inset

.
 Consequently, 
\begin_inset Formula $f$
\end_inset

 is not continuous at 
\begin_inset Formula $0$
\end_inset

.
 Hence, limits from the left or right don't exist.
 Consequently, this is a discontinuity of the second kind.
 
\end_layout

\begin_layout Standard
Functions in stochastic calculus are functions without discontinuities of
 the second kind, that is functions have both left and right hand limits
 at any point of the domain and have one-sided limits at the boundary.
 These functions are called 
\emph on
regular 
\emph default
functions.
 It is often agreed to identify functions if they have the same right and
 left limits at any point.
\end_layout

\begin_layout Standard
The class 
\begin_inset Formula $D=D[0,T]$
\end_inset

 of right-continuous functions on 
\begin_inset Formula $[0,T]$
\end_inset

 with left limits has a special name, 
\emph on
cadlag 
\emph default
functions (which is the abbreviation of right continuous with left limits
 in French).
 Sometimes these processes are called R.R.C.
 for regular right continuous.
 Notice that this class of processes includes 
\begin_inset Formula $C$
\end_inset

, the class of continuous functions.
 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $g\in D$
\end_inset

 be a cadlag function, then, by definition, all the discontinuities of 
\begin_inset Formula $g$
\end_inset

 are jumps.
 An important result in analysis is that, a function can have no more than
 a countable number of discontinuities.
 
\end_layout

\begin_layout Subsubsection
Variation of a function.
 
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $g$
\end_inset

 is a function of a real variable, its variation over the interval 
\begin_inset Formula $[a,b]$
\end_inset

 is defined as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
V_{g}([a,b]) & =\sup\left\{ \sum_{i=1}^{n}\left|g(t_{i})-g(t_{i-1})\right|\right\} \label{eq:total-variation-of-a-function}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
where the supremum is taken over all partitions 
\begin_inset Formula $P\in\mathcal{P}$
\end_inset

.
\end_layout

\begin_layout Standard
Clearly, by the Triangle Inequality, the sums in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:total-variation-of-a-function"
plural "false"
caps "false"
noprefix "false"

\end_inset

 increase as new points are added to the partitions.
 Therefore, the variation of 
\begin_inset Formula $g$
\end_inset

 is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
V_{g}([a,b]) & =\lim_{||\Delta_{n}||\to0}\sum_{i=1}^{n}\left|g(t_{i})-g(t_{i-1})\right|
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $||\Delta_{n}||=\max_{1\leq i\leq n}(t_{i}-t_{i-1})$
\end_inset

.
 If 
\begin_inset Formula $V_{g}([a,b])$
\end_inset

 is finite, then 
\begin_inset Formula $g$
\end_inset

 is said to be a function of finite variation on 
\begin_inset Formula $[a,b]$
\end_inset

.
 If 
\begin_inset Formula $g$
\end_inset

 is a function of 
\begin_inset Formula $t\geq0$
\end_inset

, then the variation of 
\begin_inset Formula $g$
\end_inset

 as a function of 
\begin_inset Formula $t$
\end_inset

 is defined by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
V_{g}(t) & =V_{g}([0,t])
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Clearly, 
\begin_inset Formula $V_{g}(t)$
\end_inset

 is an increasing function of 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Definition
\begin_inset Formula $g$
\end_inset

 is a function of finite variation if 
\begin_inset Formula $V_{g}(t)<\infty$
\end_inset

 for all 
\begin_inset Formula $t\in[0,\infty)$
\end_inset

.
 
\begin_inset Formula $g$
\end_inset

 is of bounded variation if 
\begin_inset Formula $\sup_{t}V_{g}(t)<\infty$
\end_inset

, in other words there exists 
\begin_inset Formula $C$
\end_inset

, for all 
\begin_inset Formula $t$
\end_inset

, such that 
\begin_inset Formula $V_{g}(t)<C$
\end_inset

.
 Here 
\begin_inset Formula $C$
\end_inset

 is independent of 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Example
(1) If 
\begin_inset Formula $g(t)$
\end_inset

 is increasing then for any 
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $g(t_{i})\geq g(t_{i-1})$
\end_inset

, resulting in a telescopic sum, where all terms excluding the first and
 the last cancel out, leaving 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
V_{g}(t) & =g(t)-g(0)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
(2) If 
\begin_inset Formula $g(t)$
\end_inset

 is decreasing, then similarly, 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
V_{g}(t) & =g(0)-g(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
If 
\begin_inset Formula $g(t)$
\end_inset

 is differentiable with continuous derivative 
\begin_inset Formula $g'(t)$
\end_inset

, 
\begin_inset Formula $g(t)=\int_{0}^{t}g'(s)ds$
\end_inset

 then
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
V_{g}(t) & =\int_{0}^{t}|g'(s)|ds
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By definition,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
V_{g}(t) & =\lim_{||\Delta_{n}\to0||}\sum_{i=1}^{n}|g(t_{i})-g(t_{i-1})|
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $g$
\end_inset

 is continuous and differentiable on 
\begin_inset Formula $[t_{i-1},t_{i}]$
\end_inset

, there exists 
\begin_inset Formula $z_{i}\in(t_{i-1},t_{i})$
\end_inset

 such, that 
\begin_inset Formula $g(t_{i})-g(t_{i-1})=g'(z_{i})(t_{i}-t_{i-1})$
\end_inset

.
 Therefore, we can write:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{alignat*}{1}
V_{g}(t) & =\lim_{||\Delta_{n}\to0||}\sum_{i=1}^{n}|g'(z_{i})|(t_{i}-t_{i-1})\\
 & =\int_{0}^{t}|g'(s)|ds
\end{alignat*}

\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $g$
\end_inset

 is continuous, 
\begin_inset Formula $g'$
\end_inset

 exists and 
\begin_inset Formula $\int_{0}^{t}|g'(s)|ds$
\end_inset

 is finite, then 
\begin_inset Formula $g$
\end_inset

 is of finite variation.
 
\end_layout

\begin_layout Example
The function 
\begin_inset Formula $g(t)=t\sin(1/t)$
\end_inset

 for 
\begin_inset Formula $t>0$
\end_inset

 and 
\begin_inset Formula $g(0)=0$
\end_inset

 is continuous on 
\begin_inset Formula $[0,1]$
\end_inset

 and differentiable at all points except zero, but is not of bounded variation
 on any interval that includes 
\begin_inset Formula $0$
\end_inset

.
 Consider the partition 
\begin_inset Formula $\{x_{n}\}=\left\{ \frac{1}{\pi/2+n\pi}\right\} $
\end_inset

.
 Thus,
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\sin(\frac{1}{x_{n}}) & =\begin{cases}
1 & \text{if }n\text{ is even}\\
-1 & \text{if }n\text{ is odd}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Thus,
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
f(x_{n}) & =\begin{cases}
x_{n} & n\text{ is even}\\
-x_{n} & n\text{ is odd}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Therefore, 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\sum_{n=1}^{m}|f(x_{n})-f(x_{n-1})| & =\sum_{n=1}^{m}(x_{n}+x_{n-1})\\
 & =x_{0}+x_{n}+2\sum_{n=1}^{m-1}x_{n}\\
 & \geq\sum_{n=1}^{m-1}x_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
This is the lower bound on the variation of 
\begin_inset Formula $g$
\end_inset

 on the partition 
\begin_inset Formula $\{0,x_{m},\ldots,x_{1},x_{0},1\}$
\end_inset

.
 Now, passing to the limit as 
\begin_inset Formula $m$
\end_inset

 approaches infinity, 
\begin_inset Formula $\sum\frac{1}{\pi/2+n\pi}$
\end_inset

 is a divergent series.
 Consequently, 
\begin_inset Formula $V_{g}([0,1])$
\end_inset

 has unbounded variation.
\end_layout

\begin_layout Subsubsection
Jordan Decomposition.
\end_layout

\begin_layout Theorem
Any function 
\begin_inset Formula $g:[0,\infty)\to\mathbf{R}$
\end_inset

 is of bounded variation if and only if it can be expressed as the difference
 of two increasing functions:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
g(t) & =a(t)-b(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(
\begin_inset Formula $\Longrightarrow$
\end_inset

direction).
 If 
\begin_inset Formula $g$
\end_inset

 is of finite variation, 
\begin_inset Formula $V_{g}(t)<\infty$
\end_inset

 for all 
\begin_inset Formula $t$
\end_inset

, and we can write:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
g(t) & =V_{g}(t)-(V_{g}(t)-g(t))
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $a(t)=V_{g}(t)$
\end_inset

 and 
\begin_inset Formula $b(t)=V_{g}(t)-g(t)$
\end_inset

.
 Clearly, both 
\begin_inset Formula $a(t)$
\end_inset

 and 
\begin_inset Formula $b(t)$
\end_inset

 are increasing functions.
\end_layout

\begin_layout Proof
(
\begin_inset Formula $\Longleftarrow$
\end_inset

direction).
 Suppose a function 
\begin_inset Formula $g$
\end_inset

 can be expressed as a difference of two bounded increasing functions.
 Then,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
V_{g}(t) & =\lim_{||\Delta_{n}||\to0}\sum_{i=1}^{n}|(a(t_{i})-b(t_{i}))-(a(t_{i-1})-b(t_{i-1})|\\
 & \quad\{\text{ Telescoping sum }\}\\
 & =a(t)-b(t)-(a(0)-b(0))
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since both 
\begin_inset Formula $a(t)$
\end_inset

 and 
\begin_inset Formula $b(t)$
\end_inset

 are bounded, 
\begin_inset Formula $g$
\end_inset

 has bounded variation.
\end_layout

\begin_layout Subsubsection
Riemann-Stieltjes Integral.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $g$
\end_inset

 be a montonically increasing function on a finite closed interval 
\begin_inset Formula $[a,b]$
\end_inset

.
 A bounded function 
\begin_inset Formula $f$
\end_inset

 defined on 
\begin_inset Formula $[a,b]$
\end_inset

 is said to 
\emph on
Riemann-Stieltjes integrable 
\emph default
with respect to 
\begin_inset Formula $g$
\end_inset

 if the following limit exists:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\int_{a}^{b}f(t)dg(t) & =\lim_{||\Delta_{n}||\to0}\sum_{i=1}^{n}f(\tau_{i})(g(t_{i})-g(t_{i-1}))\label{eq:riemann-stieltjes-integral}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\tau_{i}$
\end_inset

 is an evaluation point in the interval 
\begin_inset Formula $[t_{i-1},t_{i}]$
\end_inset

.
 It is a well-known fact that continuous functions are Riemann integrable
 and Riemann-Stieltjes integrable with respect to any monotonically increasing
 function on 
\begin_inset Formula $[a,b]$
\end_inset

.
\end_layout

\begin_layout Standard
We ask the following question.
 For any continuous functions 
\begin_inset Formula $f$
\end_inset

 and 
\begin_inset Formula $g$
\end_inset

 on 
\begin_inset Formula $[a,b]$
\end_inset

, can we define the integral 
\begin_inset Formula $\int_{a}^{b}f(t)dg(t)$
\end_inset

 by Equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:riemann-stieltjes-integral"
plural "false"
caps "false"
noprefix "false"

\end_inset

? 
\end_layout

\begin_layout Standard
Consider the special case 
\begin_inset Formula $f=g$
\end_inset

, namely, the integral:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\int_{a}^{b}f(t)df(t)
\]

\end_inset


\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\Delta_{n}=\{a=t_{0},t_{1},\ldots,t_{n}=b\}$
\end_inset

 be a partition of 
\begin_inset Formula $[a,b]$
\end_inset

.
 Let 
\begin_inset Formula $L_{n}$
\end_inset

 and 
\begin_inset Formula $R_{n}$
\end_inset

 denote the corresponding Riemann sums with the evaluation points 
\begin_inset Formula $\tau_{i}=t_{i-1}$
\end_inset

 and 
\begin_inset Formula $\tau_{i}=t_{i}$
\end_inset

, respectively, namely,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
L_{n} & =\sum_{i=1}^{n}f(t_{i-1})(f(t_{i})-f(t_{i-1}))\label{eq:left-riemann-sum}\\
R_{n} & =\sum_{i=1}^{n}f(t_{i})(f(t_{i})-f(t_{i-1}))\label{eq:right-riemann-sum}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Is it true that, 
\begin_inset Formula $\lim L_{n}=\lim R_{n}$
\end_inset

 as 
\begin_inset Formula $||\Delta_{n}||\to0$
\end_inset

? Observe that:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
R_{n}-L_{n}=\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\label{eq:quadratic-variation}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
R_{n}+L_{n}=\sum_{i=1}^{n}(f(t_{i})^{2}-f(t_{i-1})^{2})=f(b)^{2}-f(a)^{2}\label{eq:sum-of-left-and-right-riemann-sums}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Therefore, 
\begin_inset Formula $R_{n}$
\end_inset

 and 
\begin_inset Formula $L_{n}$
\end_inset

 are given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
R_{n}=\frac{1}{2}\left(f(b)^{2}-f(a)^{2}+\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
L_{n}=\frac{1}{2}\left(f(b)^{2}-f(a)^{2}-\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The limit of the right-hand side of equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:quadratic-variation"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is called the 
\emph on
quadratic variation
\emph default
 of the function 
\begin_inset Formula $f$
\end_inset

 on 
\begin_inset Formula $[a,b]$
\end_inset

.
 Obviously, 
\begin_inset Formula $\lim_{||\Delta_{n}||\to0}R_{n}\neq\lim_{||\Delta_{n}||\to0}L_{n}$
\end_inset

 if and only the quadratic variation of the function 
\begin_inset Formula $f$
\end_inset

 is non-zero.
 
\end_layout

\begin_layout Example
Let 
\begin_inset Formula $f$
\end_inset

 be a 
\begin_inset Formula $C^{1}$
\end_inset

-function that is 
\begin_inset Formula $f'(t)$
\end_inset

 is a continuous function.
 Then, by the mean value theorem:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
|R_{n}-L_{n}| & =\sum_{i=1}^{n}(f(t_{i})-f(t_{i-1}))^{2}\\
 & =\sum_{i=1}^{n}(f'(t_{i}^{*})(t_{i}-t_{i-1}))^{2}\\
 & \quad\{\text{Mean Value Theorem}\}\\
 & \leq\sum_{i=1}^{n}\left\Vert f'\right\Vert _{\infty}^{2}(t_{i}-t_{i-1})^{2}\\
 & \quad\{\text{ Interior Extremum Theorem }\}\\
 & \leq\left\Vert f'\right\Vert _{\infty}^{2}\left\Vert \Delta_{n}\right\Vert \sum_{i=1}^{n}(t_{i}-t_{i-1})\\
 & =\left\Vert f'\right\Vert _{\infty}^{2}\left\Vert \Delta_{n}\right\Vert (b-a)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
where 
\begin_inset Formula $\left\Vert f'\right\Vert _{\infty}=\sup_{x\in[a,b]}f(x)$
\end_inset

.
 Thus, the limit as 
\begin_inset Formula $\left\Vert \Delta_{n}\right\Vert \to0$
\end_inset

 of the distance 
\begin_inset Formula $|R_{n}-L_{n}|$
\end_inset

 also approaches zero.
 Thus, 
\begin_inset Formula $\lim L_{n}=\lim R_{n}$
\end_inset

 as 
\begin_inset Formula $\left\Vert \Delta_{n}\right\Vert \to0$
\end_inset

 and the Riemann-Stieltjes integral exists.
 By equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sum-of-left-and-right-riemann-sums"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{equation}
\lim_{\left\Vert \Delta_{n}\right\Vert \to0}L_{n}=\lim_{\left\Vert \Delta_{n}\right\Vert \to0}R_{n}=\frac{1}{2}(f(b)^{2}-f(a)^{2})
\end{equation}

\end_inset


\end_layout

\begin_layout Example
On the other hand, for such a 
\begin_inset Formula $C^{1}$
\end_inset

-function 
\begin_inset Formula $f$
\end_inset

, we may simply define the integral 
\begin_inset Formula $\int_{a}^{b}f(t)df(t)$
\end_inset

 by:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\int_{a}^{b}f(t)df(t) & =\int_{a}^{b}f(t)f'(t)dt
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Then, by the fundamental theorem of Calculus:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\int_{a}^{b}f(t)df(t)=\int_{a}^{b}f(t)f'(t)dt=\frac{1}{2}f(t)^{2}|_{a}^{b}=\frac{1}{2}(f(b)^{2}-f(a)^{2})
\]

\end_inset


\end_layout

\begin_layout Remark*
There is a very close relationship between functions with bounded variation
 and functions for which the classical integral makes sense.
 For the Ito integral, the quadratic variation plays a similar role.
 The quadratic variation of a smooth fuction 
\begin_inset Formula $f\in C^{1}([0,t])$
\end_inset

 is zero.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "ex:non-zero-quadratic-variation-example"

\end_inset

Suppose 
\begin_inset Formula $f$
\end_inset

 is a continuous function satisfying the condition
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
|f(t)-f(s)| & \leq C|t-s|^{1/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
where 
\begin_inset Formula $0<C<1$
\end_inset

.
\end_layout

\begin_layout Example
In this case we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
0\leq|R_{n}-L_{n}|\leq C^{2}\sum_{i=1}^{n}(t_{i}-t_{i-1})=C^{2}(b-a)
\]

\end_inset


\end_layout

\begin_layout Example
Hence, 
\begin_inset Formula $\lim R_{n}\neq\lim L_{n}$
\end_inset

 as 
\begin_inset Formula $\left\Vert \Delta_{n}\right\Vert \to0$
\end_inset

 when 
\begin_inset Formula $a\neq b$
\end_inset

.
 Consequently, the integral 
\begin_inset Formula $\int_{a}^{b}f(t)df(t)$
\end_inset

 cannot be defined for such a function 
\begin_inset Formula $f$
\end_inset

.
 Observe that the quandratic variation of the function is 
\begin_inset Formula $b-a$
\end_inset

 (non-zero).
\end_layout

\begin_layout Standard
We see from the above examples, that definining the integral 
\begin_inset Formula $\int_{a}^{b}f(t)dg(t)$
\end_inset

 even when 
\begin_inset Formula $f=g$
\end_inset

 is a non-trivial problem.
 Consider the question posed earlier - if 
\begin_inset Formula $f$
\end_inset

 and 
\begin_inset Formula $g$
\end_inset

 are continuous functions on 
\begin_inset Formula $[a,b]$
\end_inset

, can we define the integral 
\begin_inset Formula $\int_{a}^{b}f(t)dg(t)$
\end_inset

? There is no simple answer to this question.
 But then in view of example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:non-zero-quadratic-variation-example"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we can ask another question:
\end_layout

\begin_layout Standard

\emph on
Question
\emph default
.
 Are there continuous functions 
\begin_inset Formula $f$
\end_inset

 satisfying the condition 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
|f(t)-f(s)| & \leq C|t-s|^{1/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection
Brownian motion as the limit of a symmetric random walk.
\end_layout

\begin_layout Standard
Consider a random walk starting at 
\begin_inset Formula $0$
\end_inset

 with jumps 
\begin_inset Formula $h$
\end_inset

 and 
\begin_inset Formula $-h$
\end_inset

 equally at times 
\begin_inset Formula $\delta$
\end_inset

, 
\begin_inset Formula $2\delta$
\end_inset

, 
\begin_inset Formula $\ldots$
\end_inset

 where 
\begin_inset Formula $h$
\end_inset

 and 
\begin_inset Formula $\delta$
\end_inset

 are positive numbers.
 More precisely, let 
\begin_inset Formula $\{X_{n}\}_{n=1}^{\infty}$
\end_inset

 be a sequence of independent and identically distributed random variables
 with :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{P}\{X_{j}=h\} & =\mathbb{P}\{X_{j}=-h\}=\frac{1}{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $Y_{\delta,h}(0)=0$
\end_inset

 and put:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Y_{\delta,h}(n\delta) & =X_{1}+X_{2}+\ldots+X_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
For 
\begin_inset Formula $t>0$
\end_inset

, define 
\begin_inset Formula $Y_{\delta,h}(t)$
\end_inset

 by linearization that is, for 
\begin_inset Formula $n\delta<t<(n+1)\delta$
\end_inset

, define:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Y_{\delta,h}(t) & =\frac{(n+1)\delta-t}{\delta}Y_{\delta,h}(n\delta)+\frac{t-n\delta}{\delta}Y_{\delta,h}((n+1)\delta)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can think of 
\begin_inset Formula $Y_{\delta,h}(t)$
\end_inset

 as the position of the random walk at time 
\begin_inset Formula $t$
\end_inset

.
 In particular, 
\begin_inset Formula $X_{1}+X_{2}+\ldots+X_{n}$
\end_inset

 is the position of this random walk at time 
\begin_inset Formula $n\delta$
\end_inset

.
\end_layout

\begin_layout Standard

\emph on
Question
\emph default
.
 What is the limit of the random walk 
\begin_inset Formula $Y_{\delta,h}$
\end_inset

 as 
\begin_inset Formula $\delta,h\to0$
\end_inset

?
\end_layout

\begin_layout Standard
Recall that the characteristic function of a random variable 
\begin_inset Formula $X$
\end_inset

 is 
\begin_inset Formula $\phi_{X}(\lambda)=\mathbb{E}\exp[i\lambda X]$
\end_inset

.
 In order to find out the answer, let us compute the following limit of
 the characteristic function of 
\begin_inset Formula $Y_{\delta,h}(t)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\lim_{\delta,h\to0}\mathbb{E}\exp\left[i\lambda Y_{\delta,h}(t)\right]
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\lambda\in\mathbf{R}$
\end_inset

is fixed.
 For heuristic derivation, let 
\begin_inset Formula $t=n\delta$
\end_inset

 and so 
\begin_inset Formula $n=t/\delta$
\end_inset

.
 Then we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}\exp\left[i\lambda Y_{\delta,h}(t)\right] & =\prod_{j=1}^{n}\mathbb{E}e^{i\lambda X_{j}}\\
 & =\prod_{j=1}^{n}\left(\frac{1}{2}e^{i\lambda h}+\frac{1}{2}e^{-i\lambda h}\right)\\
 & =\left(\frac{1}{2}e^{i\lambda h}+\frac{1}{2}e^{-i\lambda h}\right)^{n}\\
 & =\left(\cos\lambda h\right)^{n}\\
 & =\left(\cos\lambda h\right)^{t/\delta}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
For fixed 
\begin_inset Formula $t$
\end_inset

 and 
\begin_inset Formula $\lambda$
\end_inset

, when 
\begin_inset Formula $\delta$
\end_inset

 and 
\begin_inset Formula $h$
\end_inset

 independently approach 
\begin_inset Formula $0$
\end_inset

, the limit of 
\begin_inset Formula $\mathbb{E}\exp\left[i\lambda Y_{\delta,h}(t)\right]$
\end_inset

 may not exist.
 For example, holding 
\begin_inset Formula $h$
\end_inset

 constant, letting 
\begin_inset Formula $\delta\to0$
\end_inset

, since 
\begin_inset Formula $-1\leq\cos\theta\leq1$
\end_inset

, the function 
\begin_inset Formula $\left(\cos\lambda h\right)^{t/\delta}\to0$
\end_inset

.
 Holding 
\begin_inset Formula $\delta$
\end_inset

 constant, letting 
\begin_inset Formula $h\to0$
\end_inset

, the function 
\begin_inset Formula $\left(\cos\lambda h\right)^{t/\delta}\to1$
\end_inset

.
 In order for the limit to exist, we impose a certain relationship between
 
\begin_inset Formula $\delta$
\end_inset

 and 
\begin_inset Formula $h$
\end_inset

.
 However, depending on the relationship, we may obtain different limits.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $u=\cos(\lambda h)^{1/\delta}$
\end_inset

.
 Then 
\begin_inset Formula $\ln u=\frac{1}{\delta}\ln\cos(\lambda h)$
\end_inset

.
 Note that:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\cos(\lambda h) & \approx1-\frac{1}{2}\lambda^{2}h^{2}
\end{align*}

\end_inset

 
\end_layout

\begin_layout Standard
And 
\begin_inset Formula $\ln(1+x)\approx x$
\end_inset

.
 Hence,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\ln\cos(\lambda h)\approx\ln\left(1-\frac{1}{2}\lambda^{2}h^{2}\right)\approx-\frac{1}{2}\lambda^{2}h^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
Therefore for small 
\begin_inset Formula $\lambda$
\end_inset

 and 
\begin_inset Formula $h$
\end_inset

, we have 
\begin_inset Formula $\ln u\approx-\frac{1}{2\delta}\lambda^{2}h^{2}$
\end_inset

 and so:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
u & \approx\exp\left[-\frac{1}{2\delta}\lambda^{2}h^{2}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In particular, if 
\begin_inset Formula $\delta$
\end_inset

 and 
\begin_inset Formula $h$
\end_inset

 are related by 
\begin_inset Formula $h^{2}=\delta$
\end_inset

, then 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\lim_{\delta\to0}\mathbb{E}\exp\left[i\lambda Y_{\delta,h}(t)\right] & =e^{-\frac{1}{2}\lambda^{2}t}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
But, 
\begin_inset Formula $e^{-\frac{1}{2}\lambda^{2}t}$
\end_inset

 is the characteristic function of a Gaussian random variable with mean
 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $t$
\end_inset

.
 Thus, we have derived the following theorem about the limit of the random
 walk 
\begin_inset Formula $Y_{\delta,h}$
\end_inset

 as 
\begin_inset Formula $\delta,h\to0$
\end_inset

 in such a way that 
\begin_inset Formula $h^{2}=\delta$
\end_inset

.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $Y_{\delta,h}(t)$
\end_inset

 be the random walk starting at 
\begin_inset Formula $0$
\end_inset

 with jumps 
\begin_inset Formula $h$
\end_inset

 and 
\begin_inset Formula $-h$
\end_inset

 equally likely at times 
\begin_inset Formula $\delta$
\end_inset

, 
\begin_inset Formula $2\delta$
\end_inset

, 
\begin_inset Formula $3\delta$
\end_inset

, 
\begin_inset Formula $\ldots$
\end_inset

.
 Assume that 
\begin_inset Formula $h^{2}=\delta$
\end_inset

.
 Then, for each 
\begin_inset Formula $t\geq0$
\end_inset

, the limit:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
\lim_{\delta\to0}Y_{\delta,h}(t) & =B(t)
\end{align*}

\end_inset

exists in distribution.
 Moreover, we have:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
\mathbb{E}e^{i\lambda B(t)} & =e^{-\frac{1}{2}\lambda^{2}t}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "th:quadratic-variation-of-bm-approaches-t-in-mean-square"

\end_inset

(Quadratic Variation of a Brownian motion).
 Let 
\begin_inset Formula $(B_{t},t\ge0)$
\end_inset

 be a standard brownian motion.
 Then, for any sequence of partitions 
\begin_inset Formula $(t_{j},j\leq n)$
\end_inset

 of 
\begin_inset Formula $[0,t]$
\end_inset

 we have:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
\left\langle B\right\rangle _{t} & =\sum_{j=1}^{n}(B_{t_{j+1}}-B_{t_{j}})^{2}\stackrel{L^{2}}{\to}t
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
where the convergence is in the 
\begin_inset Formula $L^{2}$
\end_inset

 sense.
\end_layout

\begin_layout Remark*
It is reasonable to have some sort of convergence as we are dealing with
 a sum of independent random variables.
 However, the conclusion would not hold if the increments were not squared.
 So there is something more at play here.
\end_layout

\begin_layout Proof
We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[\left(\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\right)^{2}\right] & =\mathbb{E}\left[\left(\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-\sum_{j=0}^{n-1}(t_{j+1}-t_{j})\right)^{2}\right]\\
 & =\mathbb{E}\left[\left(\sum_{j=0}^{n-1}\left\{ (B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})\right\} \right)^{2}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
For simplicity, we define the variables 
\begin_inset Formula $X_{j}=(B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})$
\end_inset

.
 Then, we may write:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[\left(\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\right)^{2}\right] & =\mathbb{E}\left[\left(\sum_{j=0}^{n-1}X_{j}\right)^{2}\right]\\
 & =\mathbb{E}\left[\sum_{i=0}^{n-1}\sum_{j=0}^{n-1}X_{i}X_{j}\right]\\
 & =\sum_{i=0}^{n-1}\sum_{j=0}^{n-1}\mathbb{E}[X_{i}X_{j}]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, the random variables 
\begin_inset Formula $X_{j}$
\end_inset

 are independent.
 
\end_layout

\begin_layout Proof
The expectation of 
\begin_inset Formula $X_{j}$
\end_inset

 is 
\begin_inset Formula $\mathbb{E}[X_{j}]=\mathbb{E}(B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})=0$
\end_inset

.
 
\end_layout

\begin_layout Proof
Since, 
\begin_inset Formula $X_{i}$
\end_inset

 and 
\begin_inset Formula $X_{j}$
\end_inset

 are independent, for 
\begin_inset Formula $i\neq j$
\end_inset

, 
\begin_inset Formula $\mathbb{E}[X_{i}X_{j}]=\mathbb{E}X_{i}\cdot\mathbb{E}X_{j}=0$
\end_inset

.
\end_layout

\begin_layout Proof
Hence, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[\left(\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\right)^{2}\right] & =\sum_{i=0}^{n-1}\mathbb{E}[X_{i}^{2}]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We now develop the expectation of the square of 
\begin_inset Formula $X_{i}$
\end_inset

.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}[X_{i}^{2}] & =\mathbb{E}\left[\left((B(t_{i+1})-B(t_{i}))^{2}-(t_{i+1}-t_{i})\right)^{2}\right]\\
 & =\mathbb{E}\left[((B(t_{i+1})-B(t_{i}))^{4}-2(B(t_{i+1})-B(t_{i}))^{2}(t_{i+1}-t_{i})+(t_{i+1}-t_{i})^{2}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The MGF of the random variable 
\begin_inset Formula $B(t_{i+1})-B(t_{i})$
\end_inset

 is :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\phi(\lambda) & =\exp\left[\frac{\lambda^{2}(t_{i+1}-t_{i})}{2}\right]\\
\phi'(\lambda) & =\lambda(t_{i+1}-t_{i})\exp\left[\frac{\lambda^{2}(t_{i+1}-t_{i})}{2}\right]\\
\phi''(\lambda) & =\left[(t_{i+1}-t_{i})+\lambda^{2}(t_{i+1}-t_{i})^{2}\right]\exp\left[\frac{\lambda^{2}(t_{i+1}-t_{i})}{2}\right]\\
\phi^{(3)}(\lambda) & =\left[3\lambda(t_{i+1}-t_{i})^{2}+\lambda^{3}(t_{i+1}-t_{i})^{3}\right]\exp\left[\frac{\lambda^{2}(t_{i+1}-t_{i})}{2}\right]\\
\phi^{(4)}(\lambda) & =\left[3(t_{i+1}-t_{i})^{2}+6\lambda^{2}(t_{i+1}-t_{i})^{3}+\lambda^{4}(t_{i+1}-t_{i})^{4}\right]\exp\left[\frac{\lambda^{2}(t_{i+1}-t_{i})}{2}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Thus, 
\begin_inset Formula $\mathbb{E}[(B(t_{i+1})-B(t_{i}))^{4}]=3(t_{i+1}-t_{i})^{2}$
\end_inset

.
 Consequently,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}[X_{i}^{2}] & =\mathbb{E}[(B(t_{i+1})-B(t_{i}))^{4}]-2(t_{i+1}-t_{i})\mathbb{E}[(B(t_{i+1})-B(t_{i}))^{2}]+(t_{i+1}-t_{i})^{2}\\
 & =3(t_{i+1}-t_{i})^{2}-2(t_{i+1}-t_{i})^{2}+(t_{i+1}-t_{i})^{2}\\
 & =2(t_{i+1}-t_{i})^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Putting all this together, we finally have that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
\mathbb{E}\left[\left(\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\right)^{2}\right] & =2\sum_{i=0}^{n-1}(t_{i+1}-t_{i})^{2}\label{eq:second-moment-of-qv}\\
 & \leq2\left\Vert \Delta_{n}\right\Vert \sum_{i=0}^{n-1}(t_{i+1}-t_{i})\nonumber \\
 & =2\left\Vert \Delta_{n}\right\Vert \cdot t\nonumber 
\end{align}

\end_inset


\end_layout

\begin_layout Proof
As 
\begin_inset Formula $n\to\infty$
\end_inset

, 
\begin_inset Formula $\left\Vert \Delta_{n}\right\Vert \to0$
\end_inset

.
 Hence, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}\mathbb{E}\left[\left(\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2}-t\right)^{2}\right] & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Hence, the sequence of random variables 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sum_{j=0}^{n-1}(B(t_{j+1})-B(t_{j}))^{2} & \stackrel{L^{2}}{\to}t
\end{align*}

\end_inset


\end_layout

\begin_layout Corollary
(Quadratic Variation of a Brownian Motion Path).
 Let 
\begin_inset Formula $(B_{s},s\geq0)$
\end_inset

 be a Brownian motion.
 For every 
\begin_inset Formula $n\in\mathbf{N}$
\end_inset

, consider the dyadic partition 
\begin_inset Formula $(t_{j},j\leq2^{n})$
\end_inset

 of 
\begin_inset Formula $[0,t]$
\end_inset

 where 
\begin_inset Formula $t_{j}=\frac{j}{2^{n}}t$
\end_inset

.
 Then we have that:
\end_layout

\begin_layout Corollary
\begin_inset Formula 
\begin{align*}
\left\langle B\right\rangle _{t} & =\sum_{j=1}^{2^{n}-1}(B_{t_{j+1}}-B_{t_{j}})^{2}\stackrel{a.s.}{\to}t
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
We have 
\begin_inset Formula $(t_{i+1}-t_{i})=\frac{t}{2^{n}}.$
\end_inset

 Borrowing equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:second-moment-of-qv"
plural "false"
caps "false"
noprefix "false"

\end_inset

 from the proof of theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:quadratic-variation-of-bm-approaches-t-in-mean-square"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we have that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[\left(\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\right)^{2}\right] & =2\sum_{i=0}^{2^{n}-1}\left(\frac{t}{2^{n}}\right)^{2}\\
 & =2\cdot(2^{n})\cdot\frac{t^{2}}{2^{2n}}\\
 & =\frac{2t^{2}}{2^{n}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By Chebyshev's inequality, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\left|\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\right|>\epsilon\right) & \leq\frac{1}{\epsilon^{2}}\mathbb{E}\left[\left(\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\right)^{2}\right]\\
 & \leq\frac{1}{\epsilon^{2}}\cdot\frac{2t^{2}}{2^{n}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Define 
\begin_inset Formula $A_{n}:=\left\{ \left|\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2}-t\right|>\epsilon\right\} $
\end_inset

.
 Since, 
\begin_inset Formula $\sum\frac{1}{2^{n}}$
\end_inset

 is a convergent series, any multiple of it, 
\begin_inset Formula $(2t^{2}/\epsilon^{2})\sum\frac{1}{2^{n}}$
\end_inset

 also converges.
 Now, 
\begin_inset Formula $0\leq\mathbb{P}(A_{n})\leq\frac{(2t^{2}/\epsilon^{2})}{2^{n}}$
\end_inset

.
 By the comparison test, 
\begin_inset Formula $\sum\mathbb{P}(A_{n})$
\end_inset

 converges to a finite value.
 By Theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:sufficient-condition-for-almost-sure-convergence"
plural "false"
caps "false"
noprefix "false"

\end_inset

, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sum_{j=0}^{2^{n}-1}(B(t_{j+1})-B(t_{j}))^{2} & \stackrel{a.s.}{\to}t
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We are now ready to show that every Brownian motion path has infinite variation.
 
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $g$
\end_inset

 is a 
\begin_inset Formula $C^{1}$
\end_inset

 function,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\int_{0}^{t}|g'(t)|dt & =\int_{0}^{t}\sqrt{g'(t)^{2}}dt\\
 & \leq\int_{0}^{t}\sqrt{1+g'(t)^{2}}dt\\
 & =l_{g}(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $l_{g}(t)$
\end_inset

 is the arclength of the function 
\begin_inset Formula $g$
\end_inset

 between 
\begin_inset Formula $[0,t]$
\end_inset

.
 So, 
\begin_inset Formula $V_{g}(t)\leq l_{g}(t)$
\end_inset

 and further:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
l_{g}(t) & =\int_{0}^{t}\sqrt{1+g'(t)^{2}}dt\\
 & \leq\int_{0}^{t}\left(1+\sqrt{g'(t)^{2}}\right)dt\\
 & \leq t+V_{g}(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Consequently, 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
V_{g}(t) & \leq l_{g}(t)\leq t+V_{g}(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The total variation of the function is finite if and only if it's arclength
 is.
\end_layout

\begin_layout Standard
Hence, intuitively, our claim is that a Brownian motion path on 
\begin_inset Formula $[0,T]$
\end_inset

 has infinite arc-length.
 Since 
\begin_inset Formula $g\in C^{1}([a,b])\Longrightarrow(V_{g}(t)<\infty)$
\end_inset

, it follows that 
\begin_inset Formula $(V_{g}(t)\to\infty)\Longrightarrow g\notin C^{1}$
\end_inset

.
 
\end_layout

\begin_layout Corollary
(Brownian Motion paths have unbounded total variation.) 
\begin_inset CommandInset label
LatexCommand label
name "th:bm-paths-have-unbounded-total-variation"

\end_inset

 Let 
\begin_inset Formula $(B_{s},s\geq0)$
\end_inset

 be a Brownian motion.
 Then, the random functions 
\begin_inset Formula $B(s,\omega)$
\end_inset

 on the interval 
\begin_inset Formula $[0,t]$
\end_inset

 have unbounded variation almost surely.
\end_layout

\begin_layout Proof
Take the sequence of dyadic partitions of 
\begin_inset Formula $[0,t]$
\end_inset

: 
\begin_inset Formula $t_{j}=\frac{j}{2^{n}}t$
\end_inset

, 
\begin_inset Formula $n\in\mathbf{N}$
\end_inset

, 
\begin_inset Formula $j\leq2^{n}$
\end_inset

.
 By pulling out the worst increment, we have the trivial bound for every
 
\begin_inset Formula $\omega$
\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
\sum_{j=0}^{2^{n}-1}(B_{t_{j+1}}(\omega)-B_{t_{j}}(\omega))^{2} & \leq\max_{0\leq j\leq2^{n}}\left|B_{t_{j+1}}(\omega)-B_{t_{j}}(\omega)\right|\cdot\sum_{j=0}^{2^{n}-1}(B_{t_{j+1}}(\omega)-B_{t_{j}}(\omega))\label{eq:trivial-upper-bound-on-quadratic-variation}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
We proceed by contradiction.
 Let 
\begin_inset Formula $A'$
\end_inset

 be the set of all 
\begin_inset Formula $\omega$
\end_inset

, for which the Brownian motion paths have bounded total variation.
 Let 
\begin_inset Formula $A$
\end_inset

 be event that the Brownian motion paths have unbounded variation.
\end_layout

\begin_layout Proof
By the definition of total variation, that would imply, 
\begin_inset Formula $\exists M\in\mathbf{N}$
\end_inset

 :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
(\forall\omega\in A')\quad\lim_{n\to\infty}\sum_{j=0}^{2^{n}-1}\left|(B_{t_{j+1}}(\omega)-B_{t_{j}}(\omega))\right| & <M
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since Brownian Motion paths are continuous on the compact set 
\begin_inset Formula $[\frac{j}{2^{n}}t,\frac{j+1}{2^{n}}t]$
\end_inset

, they are uniformly continuous.
 So, as 
\begin_inset Formula $n\to\infty$
\end_inset

, 
\begin_inset Formula $|t_{j+1}-t_{j}|\to0$
\end_inset

 and therefore 
\begin_inset Formula $|B_{t_{j+1}}(\omega)-B_{t_{j}}(\omega)|\to0$
\end_inset

.
 And consequently, 
\begin_inset Formula $\max_{0\leq j\leq2^{n}}\left|B_{t_{j+1}}(\omega)-B_{t_{j}}(\omega)\right|\to0$
\end_inset

.
 
\end_layout

\begin_layout Proof
Thus, for every 
\begin_inset Formula $\omega\in A'$
\end_inset

, the right hand side of the inequality 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:trivial-upper-bound-on-quadratic-variation"
plural "false"
caps "false"
noprefix "false"

\end_inset

, converges to 
\begin_inset Formula $0$
\end_inset

 and therefore the left hand side converges to 
\begin_inset Formula $0$
\end_inset

.
 But, this contradicts the fact that 
\begin_inset Formula $\left\langle B\right\rangle _{t}\stackrel{a.s.}{\to}t$
\end_inset

.
 So, 
\begin_inset Formula $A'$
\end_inset

 is a null set, and 
\begin_inset Formula $\mathbb{P}(A')=0$
\end_inset

 and 
\begin_inset Formula $\mathbb{P}(A)=1$
\end_inset

.
 This closes the proof.
\end_layout

\begin_layout Subsection
What exactly is 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 in mathematical finance?
\end_layout

\begin_layout Standard
If we make the simplifying assumption that the process paths are continuous,
 we obtain the set of all continuous functions on 
\begin_inset Formula $[0,T]$
\end_inset

, denoted by 
\begin_inset Formula $C[0,T]$
\end_inset

.
 This is a very rich space.
 In a more general model, it is assumed that the process paths are right
 continuous with left limits (regular right-continuous RRC, cadlag) functions.
 
\end_layout

\begin_layout Standard
Let the sample space 
\begin_inset Formula $\Omega=D[0,T]$
\end_inset

 be the set of all RRC functions on 
\begin_inset Formula $[0,T]$
\end_inset

.
 An element of this set is a RRC function from 
\begin_inset Formula $[0,T]$
\end_inset

 into 
\begin_inset Formula $\mathbf{R}$
\end_inset

.
 First we must decide what kind of sets of these functions are measurable?
 The simplest set for which we would like to calculate the probabilities
 are sets of the form 
\begin_inset Formula $\{a\leq S(t_{1})\leq b\}$
\end_inset

 for some 
\begin_inset Formula $t_{1}$
\end_inset

.
 If 
\begin_inset Formula $S(t)$
\end_inset

 represents the price of a stock at time 
\begin_inset Formula $t$
\end_inset

, then the probability of such a set gives the probability that the stock
 price at time 
\begin_inset Formula $t_{1}$
\end_inset

 is between 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

.
 We are also interested in how the price of the stock at time 
\begin_inset Formula $t_{1}$
\end_inset

 affects the price at another time 
\begin_inset Formula $t_{2}$
\end_inset

.
 Thus, we need to talk about the joint distribution of stock prices 
\begin_inset Formula $S(t_{1})$
\end_inset

 and 
\begin_inset Formula $S(t_{2})$
\end_inset

.
 This means that we need to define probability on the sets of the form 
\begin_inset Formula $\{S(t_{1})\in B_{1},S(t_{2})\in B_{2}\}$
\end_inset

 where 
\begin_inset Formula $B_{1}$
\end_inset

 and 
\begin_inset Formula $B_{2}$
\end_inset

 are intervals on the line.
 More generally, we would like to have all the finite-dimensional distributions
 of the process 
\begin_inset Formula $S(t)$
\end_inset

, that is, the probabilities of the sets: 
\begin_inset Formula $\{S(t_{1})\in B_{1},S(t_{2})\in B_{2},\ldots,S(t_{n})\in B_{n}\}$
\end_inset

 for any choice of 
\begin_inset Formula $0\leq t_{1}\leq\ldots\leq t_{n}\leq T$
\end_inset

.
 
\end_layout

\begin_layout Standard
The sets of the form 
\begin_inset Formula $A=\{\omega(\cdot)\in D[0,T]:\omega(t_{1})\in B_{1},\ldots,\omega(t_{n})\in B_{n}\}$
\end_inset

, where 
\begin_inset Formula $B_{i}$
\end_inset

's are borel subsets of 
\begin_inset Formula $\mathbf{R}$
\end_inset

, are called cylinder sets or finite-dimensional rectangles.
 
\end_layout

\begin_layout Standard
The stochastic process 
\begin_inset Formula $S(t)$
\end_inset

 is just a (function-valued) random variable on this sample space, which
 takes some value 
\begin_inset Formula $\omega(t)$
\end_inset

 - the value of the function 
\begin_inset Formula $\omega$
\end_inset

 at 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\mathcal{R}$
\end_inset

 be the colllection of all cylindrical subsets of 
\begin_inset Formula $D[0,1]$
\end_inset

.
 Obviously 
\begin_inset Formula $\mathcal{R}$
\end_inset

 is not a 
\begin_inset Formula $\sigma$
\end_inset

-field.
\end_layout

\begin_layout Standard
Probability is first defined by on the elements of 
\begin_inset Formula $\mathcal{R}$
\end_inset

.
 Let 
\begin_inset Formula $A\subseteq\mathcal{R}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{P}(A) & =\int_{B_{1}}\cdots\int_{B_{n}}\prod_{i=1}^{n}\frac{1}{\sqrt{(2\pi)(t_{i}-t_{i-1})}}\exp\left[-\frac{(u_{i}-u_{i-1})^{2}}{2(t_{i}-t_{i-1})}\right]du_{1}\cdots du_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
and then extended to the 
\begin_inset Formula $\sigma$
\end_inset

-field generated by taking unions, complements and intersections of cylinders.
 We take the smallest 
\begin_inset Formula $\sigma$
\end_inset

-algebra containing all the cylindrical subsets of 
\begin_inset Formula $D[0,1]$
\end_inset

.
 Thus, 
\begin_inset Formula $\mathcal{F}=\mathcal{B}(D[0,1])$
\end_inset

.
 
\end_layout

\begin_layout Standard
Hence, 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})=(D[0,1],\mathcal{B}(D[0,1]),\mathbb{P})$
\end_inset

 is a probability space.
 It is called the 
\emph on
Wiener space
\emph default
 and 
\begin_inset Formula $\mathbb{P}$
\end_inset

 here is called the 
\emph on
Wiener measure
\emph default
.
\end_layout

\begin_layout Subsection
Continuity and Regularity of paths.
\end_layout

\begin_layout Standard
As discussed in the previous section, a stochastic process is determined
 by its finite-dimensional distribution.
 In studying stochastic processes, it is often natural to think of them
 as function-valued random variables in 
\begin_inset Formula $t$
\end_inset

.
 Let 
\begin_inset Formula $S(t)$
\end_inset

 be defined for 
\begin_inset Formula $0\leq t\leq T$
\end_inset

, then for a fixed 
\begin_inset Formula $\omega$
\end_inset

, it is a function in 
\begin_inset Formula $t$
\end_inset

, called the sample path or a realization of 
\begin_inset Formula $S$
\end_inset

.
 Finite-dimensional distributions do not determine the continuity property
 of sample paths.
 The following example illustrates this.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "ex:modifications-of-a-stochastic-process"

\end_inset

Let 
\begin_inset Formula $X(t)=0$
\end_inset

 for all 
\begin_inset Formula $t$
\end_inset

, 
\begin_inset Formula $0\leq t\leq1$
\end_inset

 and 
\begin_inset Formula $\tau$
\end_inset

 be a uniformly distributed random variable on 
\begin_inset Formula $[0,1]$
\end_inset

.
 Let 
\begin_inset Formula $Y(t)=0$
\end_inset

 for 
\begin_inset Formula $t\neq\tau$
\end_inset

 and 
\begin_inset Formula $Y(t)=1$
\end_inset

 if 
\begin_inset Formula $t=\tau.$
\end_inset

 Then, for any fixed 
\begin_inset Formula $t$
\end_inset

, 
\begin_inset Formula $\mathbb{P}(Y(t)\neq0)=\mathbb{P}(\tau=t)=0$
\end_inset

, and hence 
\begin_inset Formula $\mathbb{P}(Y(t)=0)=1$
\end_inset

.
 So, that all one-dimensional distributions of 
\begin_inset Formula $X(t)$
\end_inset

 and 
\begin_inset Formula $Y(t)$
\end_inset

 are the same.
 Similarly, all finite-dimensional distributions of 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are the same.
 However, the sample paths of the process 
\begin_inset Formula $X$
\end_inset

, that is, the functions 
\begin_inset Formula $X(t)_{0\leq t\leq1}$
\end_inset

 are continuous in 
\begin_inset Formula $t$
\end_inset

, whereas every sample path 
\begin_inset Formula $Y(t)_{0\leq t\leq1}$
\end_inset

 has a jump at the (random) point 
\begin_inset Formula $\tau$
\end_inset

.
 Notice that, 
\begin_inset Formula $\mathbb{P}(X(t)=Y(t))=1$
\end_inset

 for all 
\begin_inset Formula $t$
\end_inset

, 
\begin_inset Formula $0\leq t\leq1$
\end_inset

.
\end_layout

\begin_layout Definition
Two stochastic processes are called 
\emph on
versions 
\emph default
(modifications) of one another if
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
\mathbb{P}(X(t)=Y(t))=1\quad\text{for all }0\leq t\leq T
\]

\end_inset


\end_layout

\begin_layout Standard
Thus, the two processes in the example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:modifications-of-a-stochastic-process"
plural "false"
caps "false"
noprefix "false"

\end_inset

 are versions of one another, one has continuous sample paths, the other
 does not.
 If we agree to pick any version of the process we want, then we can pick
 the continous version when it exists.
 In general, we choose the smoothest possible version of the process.
 
\end_layout

\begin_layout Standard
For two processes, 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

, denote by 
\begin_inset Formula $N_{t}=\{X(t)\neq Y(t)\}$
\end_inset

, 
\begin_inset Formula $0\leq t\leq T$
\end_inset

.
 In the above example, 
\begin_inset Formula $\mathbb{P}(N_{t})=\mathbb{P}(\tau=t)=0$
\end_inset

 for any 
\begin_inset Formula $t$
\end_inset

, 
\begin_inset Formula $0\leq t\leq1$
\end_inset

.
 However, 
\begin_inset Formula $\mathbb{P}(\bigcup_{0\leq t\leq1}N_{t})=\mathbb{P}(\tau=t\:\text{for some }t\:\text{in }[0,1])=1$
\end_inset

.
 Although, each of 
\begin_inset Formula $N_{t}$
\end_inset

 is a 
\begin_inset Formula $\mathbb{P}$
\end_inset

-null set, the union 
\begin_inset Formula $N=\bigcup_{0\leq t\leq1}N_{t}$
\end_inset

 contains uncountably many null sets, and in this particular case it is
 a set of of probability one.
\end_layout

\begin_layout Standard
If it happens that 
\begin_inset Formula $\mathbb{P}(N)=0$
\end_inset

, then 
\begin_inset Formula $N$
\end_inset

 is called an 
\emph on
evanescent set
\emph default
, and the processes 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are called 
\emph on
indistinguishable
\emph default
.
 Note that in this case, 
\begin_inset Formula $\mathbb{P}(\{\omega:\exists t:X(t)\neq Y(t)\})=\mathbb{P}(\bigcup_{0\leq t\leq1}\{X(t)\neq Y(t))=0$
\end_inset

 and 
\begin_inset Formula $\mathbb{P}(\bigcap_{0\leq t\leq1}\{X(t)=Y(t)\})=1$
\end_inset

.
 It is clear, that if the time is discrete, then any two versions of the
 process are indistinguishable.
 It is also not hard to see, that if 
\begin_inset Formula $X(t)$
\end_inset

 and 
\begin_inset Formula $Y(t)$
\end_inset

 are versions of one another and they are both right-continuous, they are
 indistinguishable.
\end_layout

\begin_layout Theorem
(Paul Levy's construction of Brownian Motion).
 Standard Brownian motion exists.
\end_layout

\begin_layout Proof
I reproduce the standard proof as present in 
\emph on
Brownian Motion
\emph default
 by Morters and Peres.
 I added some remarks for greater clarity.
\end_layout

\begin_layout Proof
Let 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathcal{D}_{n} & =\left\{ \frac{k}{2^{n}}:k=0,1,2,\ldots,2^{n}\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
be a finite set of dyadic points.
 
\end_layout

\begin_layout Proof
Let 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathcal{D} & =\bigcup_{n=0}^{\infty}\mathcal{D}_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $\{Z_{t}:t\in\mathcal{D}\}$
\end_inset

 be a collection of independent, standard normally distributed random variables.
 This is a countable set of random variables.
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $B(0):=0$
\end_inset

 and 
\begin_inset Formula $B(1):=Z_{1}$
\end_inset

.
\end_layout

\begin_layout Proof
For each 
\begin_inset Formula $n\in\mathbf{N}$
\end_inset

, we define the random variables 
\begin_inset Formula $B(d)$
\end_inset

, 
\begin_inset Formula $d\in\mathcal{D}_{n}$
\end_inset

 such that, the following invariant holds:
\end_layout

\begin_layout Proof
(1) for all 
\begin_inset Formula $r<s<t$
\end_inset

 in 
\begin_inset Formula $\mathcal{D}_{n}$
\end_inset

 the random variable 
\begin_inset Formula $B(t)-B(s)$
\end_inset

 is normally distributed with mean zero and variance 
\begin_inset Formula $t-s$
\end_inset

 and is independent of 
\begin_inset Formula $B(s)-B(r)$
\end_inset

.
\end_layout

\begin_layout Proof
(2) the vectors 
\begin_inset Formula $(B(d):d\in\mathcal{D}_{n})$
\end_inset

 and 
\begin_inset Formula $(Z_{t}:t\in\mathcal{D}\setminus\mathcal{D}_{n})$
\end_inset

 are independent.
 
\end_layout

\begin_layout Proof
Note that we have already done this for 
\begin_inset Formula $\mathcal{D}_{0}=\{0,1\}$
\end_inset

.
 Proceeding inductively, let's assume that the above holds for some 
\begin_inset Formula $n-1$
\end_inset

.
 We are interested to prove that the invariant also holds for 
\begin_inset Formula $n$
\end_inset

.
\end_layout

\begin_layout Proof
We define 
\begin_inset Formula $B(d)$
\end_inset

 for 
\begin_inset Formula $d\in\mathcal{D}_{n}\backslash\mathcal{D}_{n-1}$
\end_inset

 by:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
B(d) & =\frac{B(d-2^{-n})+B(d+2^{-n})}{2}+\frac{Z_{d}}{2^{(n+1)/2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Note that, the points 
\begin_inset Formula $0,\frac{1}{2^{n-1}},\ldots,\frac{k}{2^{n-1}},\frac{k+1}{2^{n-1}},\ldots,1$
\end_inset

 belong to 
\begin_inset Formula $\mathcal{D}_{n-1}$
\end_inset

.
 The first summand is the linear interpolation of the values of 
\begin_inset Formula $B$
\end_inset

 at the neighbouring points of 
\begin_inset Formula $d$
\end_inset

 in 
\begin_inset Formula $\mathcal{D}_{n-1}$
\end_inset

.
 That is,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
B\left(\frac{2k+1}{2^{n}}\right) & =\frac{B\left(\frac{k}{2^{n-1}}\right)+B\left(\frac{k+1}{2^{n-1}}\right)}{2}+\frac{Z_{d}}{2^{(n+1)/2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $P(n-1)$
\end_inset

 holds, 
\begin_inset Formula $B(d-2^{-n})$
\end_inset

 and 
\begin_inset Formula $B(d+2^{-n})$
\end_inset

 are have no dependence on 
\begin_inset Formula $(Z_{t}:t\in\mathcal{D}\setminus\mathcal{D}_{n-1})$
\end_inset

.
 Consequently, 
\begin_inset Formula $B(d)$
\end_inset

 has no dependence on 
\begin_inset Formula $(Z_{t}:t\in\mathcal{D}\setminus\mathcal{D}_{n})$
\end_inset

 and the second property is fulfilled.
\end_layout

\begin_layout Proof
Moreover, as 
\begin_inset Formula $\frac{1}{2}[B(d+2^{-n})-B(d-2^{-n})]$
\end_inset

 depends only on 
\begin_inset Formula $(Z_{t}:t\in\mathcal{D}_{n-1})$
\end_inset

, it is independent of 
\begin_inset Formula $\frac{Z_{d}}{2^{(n+1)/2}}$
\end_inset

.
 By our induction assumptions, they are both nromally distributed with mean
 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $\frac{1}{2^{(n+1)}}$
\end_inset

.
\end_layout

\begin_layout Proof
So, their sum and difference random variables
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
B(d)-B(d-2^{-n}) & =\frac{B(d+2^{-n})-B(d-2^{-n})}{2}+\frac{Z_{d}}{2^{(n+1)/2}}\\
B(d+2^{-n})-B(d) & =\frac{B(d+2^{-n})-B(d-2^{-n})}{2}-\frac{Z_{d}}{2^{(n+1)/2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
are also independent, with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $\frac{1}{2^{n}}$
\end_inset

 (the variance of independent random variables is the sum of the variances).
 
\end_layout

\begin_layout Proof
Indeed all increments 
\begin_inset Formula $B(d)-B(d-2^{-n})$
\end_inset

 for 
\begin_inset Formula $d\in\mathcal{D}_{n}\setminus\{0\}$
\end_inset

 are independent.
 To see this, it suffices to show that they are pairwise independent.
 We have seen in the previous paragraph that the pairs 
\begin_inset Formula $B(d)-B(d-2^{-n})$
\end_inset

 and 
\begin_inset Formula $B(d+2^{-n})-B(d)$
\end_inset

 with 
\begin_inset Formula $d\in\mathcal{D}_{n}\setminus\mathcal{D}_{n-1}$
\end_inset

 are independent.
 The other possibility is that the increments are over the intervals separated
 by some 
\begin_inset Formula $d\in\mathcal{D}_{n-1}$
\end_inset

.
 For concreteness, if 
\begin_inset Formula $n$
\end_inset

 were 
\begin_inset Formula $3$
\end_inset

, then the increments, 
\begin_inset Formula $B_{7/8}-B_{6/8}$
\end_inset

 and 
\begin_inset Formula $B_{5/8}-B_{4/8}$
\end_inset

 are seperated by 
\begin_inset Formula $d=\frac{3}{4}\in\mathcal{D}_{2}$
\end_inset

.
 Choose 
\begin_inset Formula $d\in\mathcal{D}_{j}$
\end_inset

 with this property and minimal 
\begin_inset Formula $j$
\end_inset

, so, the two intervals are contained in 
\begin_inset Formula $[d-2^{-j},d]$
\end_inset

 and 
\begin_inset Formula $[d,d+2^{-j}]$
\end_inset

 respectively.
 By induction, the increments over these two intervals of length 
\begin_inset Formula $2^{-j}$
\end_inset

 are independent and the increments over the intervals of length 
\begin_inset Formula $2^{-n}$
\end_inset

 are constructed from the independent increments 
\begin_inset Formula $B(d)-B(d-2^{-j})$
\end_inset

 and 
\begin_inset Formula $B(d+2^{-j})-B(d)$
\end_inset

 using a disjoint set of variables 
\begin_inset Formula $(Z_{t}:t\in\mathcal{D}_{n})$
\end_inset

.
 Hence, they are independent and this implies pairwise independence.
 This implies the first property.
 Consequently, the vector of increments 
\begin_inset Formula $(B(d)-B(d-2^{-n})$
\end_inset

 for all 
\begin_inset Formula $d\in\mathcal{D}_{n}$
\end_inset

 is Gaussian.
 
\end_layout

\begin_layout Proof
Having thus chosen the value of the process on all the dyadic points, we
 interpolate between them.
 Formally, we define:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
F_{0}(t) & =\begin{cases}
Z_{1} & \text{for }t=1\\
0 & \text{for }t=0\\
\text{\text{linear in between}}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
and for each 
\begin_inset Formula $n\geq1$
\end_inset

, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
F_{n}(t) & =\begin{cases}
\frac{Z_{t}}{2^{(n+1)/2}} & \text{for }t\in\mathcal{D}\setminus\mathcal{D}_{n-1}\\
0 & \text{for }t\in\mathcal{D}_{n-1}\\
\text{\text{linear between consecutive points in }\ensuremath{\mathcal{D}_{n}}}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
These functions are continuous on 
\begin_inset Formula $[0,1]$
\end_inset

 and for all 
\begin_inset Formula $n$
\end_inset

 and 
\begin_inset Formula $d\in\mathcal{D}_{n}$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
B(d) & =\sum_{i=0}^{n}F_{i}(d)=\sum_{i=0}^{\infty}F_{i}(d)\label{eq:claim-of-induction-for-bd}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
To see this, assume that above equation holds for all 
\begin_inset Formula $d\in\mathcal{D}_{n-1}$
\end_inset

.
 
\end_layout

\begin_layout Proof
Let's consider the point 
\begin_inset Formula $d\in\mathcal{D}_{n}\setminus\mathcal{D}_{n-1}$
\end_inset

.
 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
B(d) & =\frac{B(d-2^{-n})+B(d+2^{-n})}{2}+\frac{Z_{d}}{2^{(n+1)/2}}\nonumber \\
 & =\sum_{i=0}^{n-1}\frac{F_{i}(d-2^{-n})+F_{i}(d+2^{-n})}{2}+\frac{Z_{d}}{2^{(n+1)/2}}\label{eq:expression-for-bd}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
Now, 
\begin_inset Formula $d-2^{-n}$
\end_inset

 and 
\begin_inset Formula $d+2^{-n}$
\end_inset

 belong to 
\begin_inset Formula $\mathcal{D}_{n-1}$
\end_inset

 and are not in 
\begin_inset Formula $\bigcup_{i<n-1}\mathcal{D}_{i}$
\end_inset

.
 Therefore, for 
\begin_inset Formula $i=0,1,\ldots,n-2$
\end_inset

, the points 
\begin_inset Formula $(d-2^{-n},F_{i}(d-2^{-n}))$
\end_inset

 and 
\begin_inset Formula $(d+2^{-n},F_{i}(d+2^{-n})$
\end_inset

 lie on some straight line and have 
\begin_inset Formula $(d,F_{i}(d))$
\end_inset

 as their midpoint.
 Moreover, 
\begin_inset Formula $d-2^{-n}$
\end_inset

 and 
\begin_inset Formula $d+2^{-n}$
\end_inset

 are vertices in 
\begin_inset Formula $\mathcal{D}_{n-1}$
\end_inset

.
 So, by definition of 
\begin_inset Formula $F_{n-1}(d)$
\end_inset

, we have 
\begin_inset Formula $F_{n-1}(d)=[F_{n-1}(d-2^{-n})+F_{n-1}(d+2^{-n})]/2$
\end_inset

.
 
\end_layout

\begin_layout Proof
To summarize, the first term on the right hand side of expression 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:expression-for-bd"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is equal to 
\begin_inset Formula $\sum_{i=0}^{n-1}F_{i}(d)$
\end_inset

.
 By mathematical induction, it follows that the claim 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:claim-of-induction-for-bd"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is true for all 
\begin_inset Formula $n\in\mathbf{N}$
\end_inset

.
\end_layout

\begin_layout Proof
It's extremely easy to find an upper bound on the probability contained
 in the Gaussian tails.
 Suppose 
\begin_inset Formula $X\sim N(0,1)$
\end_inset

 and let 
\begin_inset Formula $x>0$
\end_inset

.
 We are interested in the tail probability 
\begin_inset Formula $\mathbb{P}(X>x)$
\end_inset

.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}(X>x) & =\int_{x}^{\infty}e^{-x^{2}/2}dx=\int_{x}^{\infty}\frac{xe^{-x^{2}/2}dx}{x}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $u=\frac{1}{x}$
\end_inset

 and 
\begin_inset Formula $dv=xe^{-x^{2}/2}dx$
\end_inset

.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" bottomline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $u=\frac{1}{x}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dv=xe^{-x^{2}/2}dx$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $du=-\frac{1}{x^{2}}dx$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $v=-e^{-x^{2}/2}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Proof
Thus, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}(X>x) & =-\left.\frac{1}{x}e^{-x^{2}/2}\right|_{x}^{\infty}-\int_{x}^{\infty}\frac{e^{-x^{2}/2}}{x^{2}}dx\\
 & =\frac{e^{-x^{2}/2}}{x}-\int_{x}^{\infty}\frac{e^{-x^{2}/2}}{x^{2}}dx\\
 & \quad\left\{ I(x)=\int_{x}^{\infty}\frac{e^{-x^{2}/2}}{x^{2}}\geq0\right\} \\
 & \leq\frac{e^{-x^{2}/2}}{x}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Thus, for 
\begin_inset Formula $c>1$
\end_inset

 and large 
\begin_inset Formula $n$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}(|Z_{d}|\geq c\sqrt{n}) & \leq\frac{1}{c\sqrt{n}}e^{-c^{2}n/2}\leq\exp\left(-\frac{c^{2}n}{2}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
So, the series:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sum_{n=0}^{\infty}\mathbb{P}\left\{ \text{There exists atleast one }d\in\mathcal{D}_{n}\text{ with }|Z_{d}|\geq c\sqrt{n}\right\}  & \leq\sum_{n=0}^{\infty}\sum_{d\in\mathcal{D}_{n}}\mathbb{P}\left\{ |Z_{d}|\geq c\sqrt{n}\right\} \\
 & \leq\sum_{n=0}^{\infty}(2^{n}+1)\exp\left(-\frac{c^{2}n}{2}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, the series 
\begin_inset Formula $(a_{n})$
\end_inset

 given by, 
\begin_inset Formula $a_{n}:=(2^{n}+1)e^{-c^{2}n/2}$
\end_inset

 has the ratio between successive terms:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim\left|\frac{a_{n+1}}{a_{n}}\right| & =\lim_{n\to\infty}\frac{2^{n+1}+1}{2^{n}+1}\cdot\frac{e^{(c^{2}n)/2}}{e^{c^{2}(n+1)/2}}\\
 & =\lim_{n\to\infty}\frac{\frac{1}{2}+\frac{1}{2^{n}}}{1+\frac{1}{2^{n}}}\cdot\frac{1}{e^{c^{2}/2}}\\
 & =\frac{1}{2e^{c^{2}/2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
If this ratio is less than unity, that is 
\begin_inset Formula $c>\sqrt{2\log2}$
\end_inset

, than by the ratio test, 
\begin_inset Formula $\sum(2^{n}+1)e^{-c^{2}n/2}$
\end_inset

 converges to a finite value.
 Fix such a 
\begin_inset Formula $c$
\end_inset

.
\end_layout

\begin_layout Proof
By BCL1(Borel-Cantelli Lemma), if 
\begin_inset Formula $A_{n}:=\left\{ \text{There exists atleast one }d\in\mathcal{D}_{n}\text{ with }|Z_{d}|\geq c\sqrt{n}\right\} $
\end_inset

 and 
\begin_inset Formula $\sum_{n=0}^{\infty}\mathbb{P}(A_{n})$
\end_inset

 converges to a finite value, then the event 
\begin_inset Formula $A_{n}$
\end_inset

 occurs finitely many times with probability 
\begin_inset Formula $1$
\end_inset

.
 There exists 
\begin_inset Formula $N\in\mathbf{N}$
\end_inset

, such that for all 
\begin_inset Formula $n\geq N$
\end_inset

, 
\begin_inset Formula $A_{n}$
\end_inset

 fails to occur with probability 
\begin_inset Formula $1$
\end_inset

.
 Thus, for all 
\begin_inset Formula $n\geq N$
\end_inset

, 
\begin_inset Formula $\{Z_{d}\leq c\sqrt{n}\}$
\end_inset

 occurs with probability 
\begin_inset Formula $1$
\end_inset

.
 It follows that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sup_{t\in[0,1]}F_{n}(t) & \leq\frac{c\sqrt{n}}{2^{(n+1)/2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Define 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
M_{n} & =\frac{c\sqrt{n}}{2^{(n+1)/2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $\sum M_{n}$
\end_inset

 converges, by the Weierstrass 
\begin_inset Formula $M$
\end_inset

-test, the infinite series of functions 
\begin_inset Formula $\sum_{n=0}^{\infty}F_{n}(t)$
\end_inset

 converges uniformly on 
\begin_inset Formula $[0,1].$
\end_inset

 Since, each 
\begin_inset Formula $F_{n}(t)$
\end_inset

 is piecewise linear and continuous, by the Term-by-Term continuity theorem,
 
\begin_inset Formula $\sum_{n=0}^{\infty}F_{n}(t)$
\end_inset

 is continuous on 
\begin_inset Formula $[0,1]$
\end_inset

.
 
\end_layout

\begin_layout Subsection
A point of comparison: The Poisson Process.
\end_layout

\begin_layout Standard
Like the Brownian motion, the Poisson process is defined as a process with
 stationary and independent increments.
 
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:poisson-process"

\end_inset

 A process 
\begin_inset Formula $(N_{t},t\geq0)$
\end_inset

 defined on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 has the distribution of the Poisson process with rate 
\begin_inset Formula $\lambda>0$
\end_inset

, if and only if the following hold:
\end_layout

\begin_layout Definition
(1) 
\begin_inset Formula $N_{0}=0$
\end_inset

.
\end_layout

\begin_layout Definition
(2) For any 
\begin_inset Formula $s<t$
\end_inset

, the increment 
\begin_inset Formula $N_{t}-N_{s}$
\end_inset

 is a Poisson random variable with parameter 
\begin_inset Formula $\lambda(t-s).$
\end_inset


\end_layout

\begin_layout Definition
(3) For any 
\begin_inset Formula $n\in\mathbf{N}$
\end_inset

 and any choice 
\begin_inset Formula $0<t_{1}<t_{2}<\ldots<t_{n}<\infty$
\end_inset

, the increments 
\begin_inset Formula $N_{t_{2}}-N_{t_{1}},N_{t_{3}}-N_{t_{2}},\ldots,N_{t_{n}}-N_{t_{n-1}}$
\end_inset

 are independent.
 
\end_layout

\begin_layout Standard
Poisson paths can be sampled using this definition.
 By construction, it is not hard to see that the paths of Poisson processes
 are piecewise, constant, integer-valued and non-decreasing.
 In particular, the paths of Poisson processes have finite variation.
 Poisson paths are much simpler than the ones of Brownian motion in many
 ways!
\end_layout

\begin_layout Example
(Simulating the Poisson Process.) Use the definition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "def:poisson-process"
plural "false"
caps "false"
noprefix "false"

\end_inset

 to generate 
\begin_inset Formula $10$
\end_inset

 paths of the Poisson process with rate 
\begin_inset Formula $1$
\end_inset

 on the interval 
\begin_inset Formula $[0,10]$
\end_inset

 with step-size 
\begin_inset Formula $0.01$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{language=Python,backgroundcolor=
\backslash
color{backcolour},breaklines=true,commentstyle=
\backslash
color{codegreen},stringstyle=
\backslash
color{magenta},keywordstyle=
\backslash
bfseries
\backslash
color{blue!40!black},basicstyle=
\backslash
footnotesize
\backslash
ttfamily,frame=single}
\end_layout

\begin_layout Plain Layout


\backslash
begin{lstlisting}[caption=Generating 10 paths of a Poisson process]
\end_layout

\begin_layout Plain Layout

def generatePoissonProcess(lam,T,stepSize):
\end_layout

\begin_layout Plain Layout

    N = int(T/stepSize)
\end_layout

\begin_layout Plain Layout

    x = np.random.poisson(lam=lam,size=N)
\end_layout

\begin_layout Plain Layout

    y = np.cumsum(x)
\end_layout

\begin_layout Plain Layout

    y = np.concatenate([[0.0],y])
\end_layout

\begin_layout Plain Layout

    return y
\end_layout

\begin_layout Plain Layout


\backslash
end{lstlisting}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/poisson_process.tex"

\end_inset


\end_layout

\begin_layout Standard
We can construct a Poisson process as follows.
 Consider 
\begin_inset Formula $(\tau_{j},j\in\mathbf{N})$
\end_inset

 IID exponential random variables with parameter 
\begin_inset Formula $1/\lambda$
\end_inset

.
 One should think of 
\begin_inset Formula $\tau_{j}$
\end_inset

 as the waiting time from the 
\begin_inset Formula $(j-1)$
\end_inset

st to the 
\begin_inset Formula $j$
\end_inset

th jump.
 Then, one defines :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
N_{t} & =\#\{k:\tau_{1}+\tau_{2}+\ldots+\tau_{k}\leq t\}\\
 & =\text{Number of jumps upto and including time }t
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Now, here is an idea! What about defining a new process with stationary
 and independent increments using a given distribution other than Poisson
 and Gaussian? Is this even possible? The answer is yes, but only if the
 distribution satisfies the property of being 
\emph on
infinitely divisible
\emph default
.
 To see this, consider the value of the process at time 
\begin_inset Formula $1$
\end_inset

, 
\begin_inset Formula $N_{1}$
\end_inset

.
 Then, no matter how many subintervals we chop the interval 
\begin_inset Formula $[0,1]$
\end_inset

 into, we must have the increments add up to 
\begin_inset Formula $N_{1}$
\end_inset

.
 In other words, we must be able to write 
\begin_inset Formula $N_{1}$
\end_inset

 as a sum of 
\begin_inset Formula $n$
\end_inset

 IID random variables for every possible 
\begin_inset Formula $n$
\end_inset

.
 This is certainly true for Poisson random variables and Gaussian random
 variables.
 Another example is the Cauchy distribution.
 In general, processes that can be constructed using independent, stationary
 increments are called Levy processes.
\end_layout

\begin_layout Example

\series bold
Time Inversion.
 
\series default
Let 
\begin_inset Formula $(B_{t},t\geq0)$
\end_inset

 be a standard brownian motion.
 We consider the process:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
X_{t} & =tB_{1/t}\quad\text{for }t>0
\end{align*}

\end_inset


\end_layout

\begin_layout Example

\emph on
This property relates the behavior of 
\begin_inset Formula $t$
\end_inset

 large to the behavior of 
\begin_inset Formula $t$
\end_inset

 small.
\end_layout

\begin_layout Standard
(a) Show that 
\begin_inset Formula $(X_{t},t>0)$
\end_inset

 has the distribution of Brownian motion on 
\begin_inset Formula $t>0$
\end_inset

.
\end_layout

\begin_layout Standard

\emph on
Proof.
\end_layout

\begin_layout Standard
Like 
\begin_inset Formula $B(t)$
\end_inset

, it is an easy exercise to prove that 
\begin_inset Formula $X(t)$
\end_inset

 is also a Gaussian process.
\end_layout

\begin_layout Standard
We have, 
\begin_inset Formula $\mathbb{E}[X_{s}]=0$
\end_inset

.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $s<t$
\end_inset

.
 We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Cov(X_{s},X_{t}) & =\mathbb{E}[sB(1/s)\cdot tB(1/t)]\\
 & =st\mathbb{E}[B(1/s)\cdot B(1/t)]\\
 & =st\cdot\frac{1}{t}\\
 & \quad\left\{ \because\frac{1}{t}<\frac{1}{s}\right\} \\
 & =s
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Consequently, 
\begin_inset Formula $X(t)$
\end_inset

 has the distribution of a Brownian motion.
\end_layout

\begin_layout Standard
(b) Argue that 
\begin_inset Formula $X(t)$
\end_inset

 converges to 
\begin_inset Formula $0$
\end_inset

 as 
\begin_inset Formula $t\to0$
\end_inset

 in the sense of 
\begin_inset Formula $L^{2}$
\end_inset

-convergence.
 It is possible to show convergence almost surely so that 
\begin_inset Formula $(X_{t},t\geq0)$
\end_inset

 is really a Brownian motion for 
\begin_inset Formula $t\geq0$
\end_inset

.
 
\end_layout

\begin_layout Standard

\emph on
Solution
\emph default
.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $(t_{n})$
\end_inset

 be any arbitrary sequence of positive real numbers approaching 
\begin_inset Formula $0$
\end_inset

 and consider the sequence of random variables 
\begin_inset Formula $(X(t_{n}))_{n=1}^{\infty}$
\end_inset

.
 We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[X(t_{n})^{2}\right] & =\mathbb{E}\left[t_{n}^{2}B(1/t_{n})^{2}\right]\\
 & =t_{n}^{2}\mathbb{E}\left[B(1/t_{n})^{2}\right]\\
 & =t_{n}^{2}\cdot\frac{1}{t_{n}}\\
 & =t_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Hence, 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\lim\mathbb{E}\left[X(t_{n})^{2}\right] & =\lim t_{n}=0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $(t_{n})$
\end_inset

 was an arbitrary sequence, it follows that 
\begin_inset Formula $\lim_{t\to0}\mathbb{E}[(X(t))^{2}]=0$
\end_inset

.
 
\end_layout

\begin_layout Standard
(c) Use this property of Brownian motion to show the law of large numbers
 for Brownian motion:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\lim_{t\to\infty}\frac{X(t)}{t} & =0\quad\text{almost surely}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
What we need to do is to show that 
\begin_inset Formula $X(t)\to0$
\end_inset

 as 
\begin_inset Formula $t\to0$
\end_inset

 almost surely.
 That would show that 
\begin_inset Formula $\frac{B(1/t)}{1/t}\to0$
\end_inset

 as 
\begin_inset Formula $t\to0$
\end_inset

 almost surely, which is the same as showing 
\begin_inset Formula $\frac{B(t)}{t}\to0$
\end_inset

 as 
\begin_inset Formula $t\to\infty$
\end_inset

, which is the law of large numbers for Brownian motion.
\end_layout

\begin_layout Standard
What we have done in part (b), is to prove the claim that 
\begin_inset Formula $\mathbb{E}[X(t)^{2}]\to0$
\end_inset

 as 
\begin_inset Formula $t\to0$
\end_inset

, which shows convergence in the 
\begin_inset Formula $L^{2}$
\end_inset

 sense and hence convergence in probability.
 This is infact the weak law of large numbers.
 
\begin_inset Formula $\frac{B(t)}{t}\stackrel{\mathbb{\mathbf{P}}}{\to}0$
\end_inset

 as 
\begin_inset Formula $t\to\infty$
\end_inset

.
\end_layout

\begin_layout Standard
For 
\begin_inset Formula $t>0$
\end_inset

, continuity is clear.
 However, it is the proof that as 
\begin_inset Formula $t\to0$
\end_inset

, 
\begin_inset Formula $X(t)\to0$
\end_inset

 almost surely which we have not done.
\end_layout

\begin_layout Standard
Note that, the limit 
\begin_inset Formula $X(t)\to0$
\end_inset

 as 
\begin_inset Formula $t\to0$
\end_inset

 if and only if 
\begin_inset Formula $(\forall n\geq1)$
\end_inset

, 
\begin_inset Formula $(\exists m\geq1)$
\end_inset

, such that 
\begin_inset Formula $\forall r\in\mathbb{Q}\cap(0,\frac{1}{m}]$
\end_inset

, we have 
\begin_inset Formula $|X(r)|=\left|rB\left(\frac{1}{r}\right)\right|\leq\frac{1}{n}$
\end_inset

.
\end_layout

\begin_layout Standard
To understand the above, we just recall the 
\begin_inset Formula $\epsilon-\delta$
\end_inset

 definition of continuity.
 Note that 
\begin_inset Formula $\frac{1}{n}$
\end_inset

 plays the role of 
\begin_inset Formula $\epsilon$
\end_inset

 and 
\begin_inset Formula $\frac{1}{m}$
\end_inset

 works as 
\begin_inset Formula $\delta$
\end_inset

.
\end_layout

\begin_layout Standard
That is,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\Omega^{X}:=\left\{ \lim_{t\to0}X(t)=0\right\}  & =\bigcap_{n\geq1}\bigcup_{m\geq1}\bigcap_{r\in\mathbb{Q}\cap(0,\frac{1}{m}]}\left\{ \left|X(r)\right|\leq\frac{1}{n}\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Also, note that 
\begin_inset Formula $X(t)$
\end_inset

 is continuous on all 
\begin_inset Formula $[a,1]$
\end_inset

 for all 
\begin_inset Formula $a>0$
\end_inset

, thus, uniformly continuous on 
\begin_inset Formula $[a,1]$
\end_inset

, and hence uniformly continuous on 
\begin_inset Formula $\mathbb{Q}\cap(0,1]$
\end_inset

.
 So, there exists a continuous extension of 
\begin_inset Formula $X(t)$
\end_inset

 on 
\begin_inset Formula $[0,1]$
\end_inset

.
 We already know from part (a), that 
\begin_inset Formula $(X(t))_{t>0}$
\end_inset

 and 
\begin_inset Formula $(B(t))_{t>0}$
\end_inset

 have the same finite dimensional distributions.
 Therefore, the RHS event has the same probability as 
\begin_inset Formula $\Omega^{B}:=\bigcap_{n\geq1}\bigcup_{m\geq1}\bigcap_{r\in\mathbb{Q}\cap(0,\frac{1}{m}]}\left\{ \left|B(r)\right|\leq\frac{1}{n}\right\} $
\end_inset

.
 Since 
\begin_inset Formula $B(t)\to0$
\end_inset

 as 
\begin_inset Formula $t\to0$
\end_inset

 almost surely, the event 
\begin_inset Formula $\Omega^{B}$
\end_inset

 has probability 
\begin_inset Formula $1$
\end_inset

.
 Thus, 
\begin_inset Formula $\mathbb{P}\left\{ \lim_{t\to0}X(t)=0\right\} =1$
\end_inset

.
 
\end_layout

\begin_layout Standard
This actually shows that 
\begin_inset Formula $X(t)$
\end_inset

 is a bonafide standard brownian motion, as we have established continuity
 as well.
\end_layout

\begin_layout Section
Martingales.
\end_layout

\begin_layout Subsection
Elementary conditional expectation.
\end_layout

\begin_layout Standard
In elementary probability, the conditional expectation of a variable 
\begin_inset Formula $Y$
\end_inset

 given another random variable 
\begin_inset Formula $X$
\end_inset

 refers to the expectation of 
\begin_inset Formula $Y$
\end_inset

 given the conditional distribution 
\begin_inset Formula $f_{Y|X}(y|x)$
\end_inset

 of 
\begin_inset Formula $Y$
\end_inset

 given 
\begin_inset Formula $X$
\end_inset

.
 To illustrate this, let's go through a simple example.
 Consider 
\begin_inset Formula $\mathcal{B}_{1}$
\end_inset

, 
\begin_inset Formula $\mathcal{B}_{2}$
\end_inset

 to be two independent Bernoulli-distributed random variables with 
\begin_inset Formula $p=1/2$
\end_inset

.
 Then, construct:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
X=\mathcal{B}_{1}, & \quad Y=\mathcal{B}_{1}+\mathcal{B}_{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
It is easy to compute 
\begin_inset Formula $\mathbb{E}[Y|X=0]$
\end_inset

 and 
\begin_inset Formula $\mathbb{E}[Y|X=1]$
\end_inset

.
 By definition, it is given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}[Y|X=0] & =\sum_{j=0}^{2}j\mathbb{P}(Y=j|X=0)\\
 & =\sum_{j=0}^{2}j\cdot\frac{\mathbb{P}(Y=j,X=0)}{P(X=0)}\\
 & =0+1\cdot\frac{(1/4)}{(1/2)}+2\cdot\frac{0}{(1/2)}\\
 & =\frac{1}{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
and 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}[Y|X=1] & =\sum_{j=0}^{2}j\mathbb{P}(Y=j|X=1)\\
 & =\sum_{j=0}^{2}j\cdot\frac{\mathbb{P}(Y=j,X=1)}{P(X=1)}\\
 & =0+1\cdot\frac{(1/4)}{(1/2)}+2\cdot\frac{(1/4)}{(1/2)}\\
 & =\frac{3}{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
With this point of view, the conditional expectation is computed given the
 information that the event 
\begin_inset Formula $\{X=0\}$
\end_inset

 occurred or the event 
\begin_inset Formula $\{X=1\}$
\end_inset

 occurred.
 It is possible to regroup both conditional expectations in a single object,
 if we think of the conditional expectation as a random variable and denote
 it by 
\begin_inset Formula $\mathbb{E}[Y|X]$
\end_inset

.
 Namely, we take:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\mathbb{E}[Y|X](\omega) & =\begin{cases}
\frac{1}{2} & \text{if }X(\omega)=0\\
\frac{3}{2} & \text{if }X(\omega)=1
\end{cases}\label{eq:elementary-conditional-expectation-example}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
This random variable is called the 
\emph on
conditional expectation 
\emph default
of 
\begin_inset Formula $Y$
\end_inset

 given 
\begin_inset Formula $X$
\end_inset

.
 We make two important observations:
\end_layout

\begin_layout Standard
(i) If the value of 
\begin_inset Formula $X$
\end_inset

 is known, then the value of 
\begin_inset Formula $\mathbb{E}[Y|X]$
\end_inset

 is determined.
\end_layout

\begin_layout Standard
(ii) If we have another random variable 
\begin_inset Formula $g(X)$
\end_inset

 constructed from 
\begin_inset Formula $X$
\end_inset

, then we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}[g(X)Y] & =\mathbb{E}[g(X)\mathbb{E}[Y|X]]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In other words, as far as 
\begin_inset Formula $X$
\end_inset

 is concerned, the conditional expectation 
\begin_inset Formula $\mathbb{E}[Y|X]$
\end_inset

 is a proxy for 
\begin_inset Formula $Y$
\end_inset

 in the expectation.
 We sometimes say that 
\begin_inset Formula $\mathbb{E}[Y|X]$
\end_inset

 is the best estimate of 
\begin_inset Formula $Y$
\end_inset

 given the information of 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_layout Standard
The last observation is easy to verify since:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}[g(X)Y] & =\sum_{i=0}^{1}\sum_{j=0}^{2}g(i)\cdot j\cdot\mathbb{P}(X=i,Y=j)\\
 & =\sum_{i=0}^{1}\mathbb{P}(X=i)g(i)\left\{ \sum_{j=0}^{2}j\cdot\frac{\mathbb{P}(X=i,Y=j)}{\mathbb{P}(X=i)}\right\} \\
 & =\mathbb{E}[g(X)\mathbb{E}[Y|X]]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "ex:elementary-definitions-of-conditional-expectation"

\end_inset

(Elementary Definitions of Conditional Expectation).
\end_layout

\begin_layout Example
(1) 
\begin_inset Formula $(X,Y)$
\end_inset

 discrete.
 The treatment is similar to the above.
 If a random variable 
\begin_inset Formula $X$
\end_inset

 takes values 
\begin_inset Formula $(x_{i},i\geq1)$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 takes values 
\begin_inset Formula $(y_{j},j\geq1)$
\end_inset

, we have by definition that the conditional expectation as a random variable
 is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}[Y|X](\omega) & =\sum_{j\geq1}y_{j}\mathbb{P}(Y=y_{j}|X=x_{i})\quad\text{for }\omega\text{ such that }X(\omega)=x_{i}
\end{align*}

\end_inset

(2) 
\begin_inset Formula $(X,Y)$
\end_inset

 continuous with joint PDF 
\begin_inset Formula $f_{X,Y}(x,y)$
\end_inset

: In this case, the conditional expectation is the random variable given
 by 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}[Y|X] & =h(X)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
where 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
h(x) & =\int_{\mathbf{R}}yf_{Y|X}(y|x)dy=\int_{\mathbf{R}}y\frac{f_{X,Y}(x,y)}{f_{X}(x)}dy=\frac{\int_{\mathbf{R}}yf_{X,Y}(x,y)dy}{\int_{\mathbf{R}}f_{X,Y}(x,y)dy}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In the two examples above, the expectation of the random variable 
\begin_inset Formula $\mathbb{E}[Y|X]$
\end_inset

 is equal to 
\begin_inset Formula $\mathbb{E}[Y]$
\end_inset

.
 Indeed in the discrete case, we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}[\mathbb{E}[Y|X]] & =\sum_{i=0}^{1}P(X=x_{i})\cdot\sum_{j=0}^{2}y_{j}\mathbb{P}(Y=y_{j}|X=x_{i})\\
 & =\sum_{i=0}^{1}\sum_{j=0}^{2}y_{j}\mathbb{P}(Y=y_{j},X=x_{i})\\
 & =\sum_{j=0}^{2}y_{j}\mathbb{P}(Y=y_{j})\\
 & =\mathbb{E}[Y]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
(Conditional Probability vs Conditional expectation).
 The conditional probability of the event 
\begin_inset Formula $A$
\end_inset

 given 
\begin_inset Formula $B$
\end_inset

 can be recast in terms of conditional expectation using indicator functions.
 If 
\begin_inset Formula $0<\mathbb{P}(B)<1$
\end_inset

, it is not hard to check that: 
\begin_inset Formula $\mathbb{P}(A|B)=\mathbb{E}[\mathbf{1}_{A}|\mathbf{1}_{B}=1]$
\end_inset

 and 
\begin_inset Formula $\mathbb{P}(A|B^{C})=\mathbb{E}[\mathbf{1}_{A}|1_{B}=0]$
\end_inset

.
 Indeed the random variables 
\begin_inset Formula $\mathbf{1}_{A}$
\end_inset

 and 
\begin_inset Formula $\mathbf{1}_{B}$
\end_inset

 are discrete.
 If we proceed as in the discrete case above, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}[\mathbf{1}_{A}|\mathbf{1}_{B}=1] & =1\cdot\mathbb{P}(\mathbf{1}_{A}=1|\mathbf{1}_{B}=1)\\
 & =\frac{\mathbb{P}(\mathbf{1}_{A}=1,\mathbf{1}_{B}=1)}{\mathbb{P}(\mathbf{1}_{B}=1)}\\
 & =\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}\\
 & =\mathbb{P}(A|B)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
A similar calculation gives 
\begin_inset Formula $\mathbb{P}(A|B^{C})$
\end_inset

.
 In particular, the formula for total probability for 
\begin_inset Formula $A$
\end_inset

 is a rewriting of the expectation of the random variable 
\begin_inset Formula $\mathbb{E}[\mathbf{1}_{A}|\mathbf{1}_{B}]$
\end_inset

:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}[\mathbb{E}[\mathbf{1}_{A}|\mathbf{1}_{B}]] & =\mathbb{E}[\mathbf{1}_{A}|\mathbf{1}_{B}=1]\mathbb{P}(\mathbf{1}_{B}=1)+\mathbb{E}[\mathbf{1}_{A}|\mathbf{1}_{B}=0]\mathbb{P}(\mathbf{1}_{B}=0)\\
 & =\mathbb{P}(A|B)\cdot\mathbb{P}(B)+\mathbb{P}(A|B^{C})\cdot\mathbb{P}(B^{C})\\
 & =\mathbb{P}(A)
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Conditional Expectation as a projection.
\end_layout

\begin_layout Paragraph
Conditioning on one variable.
 
\end_layout

\begin_layout Standard
We start by giving the definition of conditional expectation given a single
 variable.
 This relates to the two observations (A) and (B) made previously.
 We assume that the random variable is integrable for the expectations to
 be well-defined.
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:conditional-expectation"

\end_inset

Let 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 be integrable random variables on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 The conditional expectation of 
\begin_inset Formula $Y$
\end_inset

 given 
\begin_inset Formula $X$
\end_inset

 is the random variable denoted by 
\begin_inset Formula $\mathbb{E}[Y|X]$
\end_inset

 with the following two properties:
\end_layout

\begin_layout Definition
(A) There exists a function 
\begin_inset Formula $h:\mathbf{R}\to\mathbf{R}$
\end_inset

 such that 
\begin_inset Formula $\mathbb{E}[Y|X]=h(X)$
\end_inset

.
\end_layout

\begin_layout Definition
(B) For any bounded random variable of the form 
\begin_inset Formula $g(X)$
\end_inset

 for some function 
\begin_inset Formula $g$
\end_inset

,
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{equation}
\mathbb{E}[g(X)Y]=\mathbb{E}[g(X)\mathbb{E}[Y|X]]\label{eq:definition-conditional-expectation}
\end{equation}

\end_inset


\end_layout

\begin_layout Definition
We can intepret the second property as follows.
 The conditional expectation 
\begin_inset Formula $\mathbb{E}[Y|X]$
\end_inset

 serves as a proxy for 
\begin_inset Formula $Y$
\end_inset

 as far as 
\begin_inset Formula $X$
\end_inset

 is concerned.
 Note that in equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:definition-conditional-expectation"
plural "false"
caps "false"
noprefix "false"

\end_inset

, the expectation on the left can be seen as an average over the joint values
 of 
\begin_inset Formula $(X,Y)$
\end_inset

, whereas the one on the right is an average over the values of 
\begin_inset Formula $X$
\end_inset

 only! Another way to see this property is to write is as:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{equation}
\mathbb{E}[g(X)(Y-\mathbb{E}[Y|X])]=0
\end{equation}

\end_inset


\end_layout

\begin_layout Definition
In other words, the 
\emph on
random variable 
\begin_inset Formula $Y-\mathbb{E}[Y|X]$
\end_inset

 is orthogonal to any random variable constructed from 
\begin_inset Formula $X$
\end_inset

.
 
\end_layout

\begin_layout Definition
Finally, it is important to notice that if we take 
\begin_inset Formula $g(X)=1$
\end_inset

, then the second property implies :
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
\mathbb{E}[Y] & =\mathbb{E}[\mathbb{E}[Y|X]]
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
In other words, the expectation of the conditional expectation of 
\begin_inset Formula $Y$
\end_inset

 is simply the expectation of 
\begin_inset Formula $Y$
\end_inset

.
\end_layout

\begin_layout Definition
The existence of the conditional expectation 
\begin_inset Formula $\mathbb{E}[Y|X]$
\end_inset

 is not obvious.
 We know, it exists in particular cases given in example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:elementary-definitions-of-conditional-expectation"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 We will show more generally, that it exists, it is unique whenever 
\begin_inset Formula $Y$
\end_inset

 is in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 (In fact, it can be shown to exist whenever 
\begin_inset Formula $Y$
\end_inset

 is integrable).
 Before doing so, let's warm up by looking at the case of Gaussian vectors.
 
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "ex:conditional-expectation-of-gaussian-vectors"

\end_inset

(Conditional expectation of Gaussian vectors - I).
 Let 
\begin_inset Formula $(X,Y)$
\end_inset

 be a Gaussian vector of mean 
\begin_inset Formula $0$
\end_inset

.
 Then:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{equation}
\mathbb{E}[Y|X]=\frac{\mathbb{E}[XY]}{\mathbb{E}[X^{2}]}X\label{eq:conditional-expectation-of-gaussian-vector}
\end{equation}

\end_inset


\end_layout

\begin_layout Example
This candidate satisfies the two defining properties of conditional expectation
 : (A) It is clearly a function of 
\begin_inset Formula $X$
\end_inset

; in fact it is a simple multiple of 
\begin_inset Formula $X$
\end_inset

.
 (B) We have that the random variable 
\begin_inset Formula $\left(Y-\frac{\mathbb{E}[XY]}{\mathbb{E}[X^{2}]}X\right)$
\end_inset

 is orthogonal and thus independent to 
\begin_inset Formula $X$
\end_inset

.
 This is a consequence of the proposition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:diagonal-cov-matrix-implies-independence-of-gaussians"
plural "false"
caps "false"
noprefix "false"

\end_inset

, since:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[X\left(Y-\frac{\mathbb{E}[XY]}{\mathbb{E}[X^{2}]}X\right)\right] & =\mathbb{E}XY-\frac{\mathbb{E}[XY]}{\mathbb{E}[X^{2}]}\mathbb{E}X^{2}\\
 & =\mathbb{E}XY-\frac{\mathbb{E}[XY]}{\cancel{\mathbb{E}[X^{2}]}}\cancel{\mathbb{E}X^{2}}\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Therefore, we have for any bounded function 
\begin_inset Formula $g(X)$
\end_inset

 of 
\begin_inset Formula $X$
\end_inset

:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}[g(X)(Y-\mathbb{E}(Y|X))] & =\mathbb{E}[g(X)]\mathbb{E}[Y-\mathbb{E}[Y|X]]=0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "ex:brownian-conditioning-I"

\end_inset

(Brownian conditioning-I) Let 
\begin_inset Formula $(B_{t},t\geq0)$
\end_inset

 be a standard Brownian motion.
 Consider the Gaussian vector 
\begin_inset Formula $(B_{1/2},B_{1})$
\end_inset

.
 Its covariance matrix is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
C & =\left[\begin{array}{cc}
1/2 & 1/2\\
1/2 & 1
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Let's compute 
\begin_inset Formula $\mathbb{E}[B_{1}|B_{1/2}]$
\end_inset

 and 
\begin_inset Formula $\mathbb{E}[B_{1/2}|B_{1}]$
\end_inset

.
 This is easy using the equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:conditional-expectation-of-gaussian-vector"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 We have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}[B_{1}|B_{1/2}] & =\frac{\mathbb{E}[B_{1}B_{1/2}]}{\mathbb{E}[B_{1/2}^{2}]}B_{1/2}\\
 & =\frac{(1/2)}{(1/2)}B_{1/2}\\
 & =B_{1/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In other words, the best approximation of 
\begin_inset Formula $B_{1}$
\end_inset

 given the information of 
\begin_inset Formula $B_{1/2}$
\end_inset

 is 
\begin_inset Formula $B_{1/2}$
\end_inset

.
 There is no problem in computing 
\begin_inset Formula $\mathbb{E}[B_{1/2}|B_{1}]$
\end_inset

, even though we are conditioning on a future position.
 Indeed the same formula gives 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}[B_{1/2}|B_{1}] & =\frac{\mathbb{E}[B_{1}B_{1/2}]}{\mathbb{E}[B_{1}^{2}]}B_{1}=\frac{1}{2}B_{1}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
This means that the best approximation of 
\begin_inset Formula $B_{1/2}$
\end_inset

 given the position at time 
\begin_inset Formula $1$
\end_inset

, is 
\begin_inset Formula $\frac{1}{2}B_{1}$
\end_inset

 which makes a whole lot of sense! 
\end_layout

\begin_layout Standard
In example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:conditional-expectation-of-gaussian-vector"
plural "false"
caps "false"
noprefix "false"

\end_inset

 for the Gaussian vector 
\begin_inset Formula $(X,Y)$
\end_inset

, the conditional expectation was equal to the 
\emph on
orthogonal projection 
\emph default
of 
\begin_inset Formula $Y$
\end_inset

 onto 
\begin_inset Formula $X$
\end_inset

 in 
\begin_inset Formula $L^{2}$
\end_inset

.
 In particular, the conditional expectation was a multiple of 
\begin_inset Formula $X$
\end_inset

.
 Is this always the case? Unfortunately, it is not.
 For example, in the equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:elementary-conditional-expectation-example"
plural "false"
caps "false"
noprefix "false"

\end_inset

, the conditional expectation is clearly not a multiple of the random variable
 
\begin_inset Formula $X$
\end_inset

.
 However, it is a function of 
\begin_inset Formula $X$
\end_inset

, as is always the case by definition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "def:conditional-expectation"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
The idea to construct the conditional expectation 
\begin_inset Formula $\mathbb{E}[Y|X]$
\end_inset

 in general is to 
\emph on
project 
\begin_inset Formula $Y$
\end_inset

 on the space of all random variables that can be constructed from 
\begin_inset Formula $X$
\end_inset

.
 To make this precise, consider the following subspace of 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 :
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 be a probability space and 
\begin_inset Formula $X$
\end_inset

 a random variable defined on it.
 The space 
\begin_inset Formula $L^{2}(\Omega,\sigma(X),\mathbb{P})$
\end_inset

 is the linear subspace of 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 consisting of the square-integrable random variables of the form 
\begin_inset Formula $g(X)$
\end_inset

 for some function 
\begin_inset Formula $g:\mathbf{R}\to\mathbf{R}$
\end_inset

.
\end_layout

\begin_layout Standard
This is a linear subspace of 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

: It contains the random variable 
\begin_inset Formula $0$
\end_inset

, and any linear combination of random variables of this kind is also a
 function of 
\begin_inset Formula $X$
\end_inset

 and must have a finite second moment.
 We note the following:
\end_layout

\begin_layout Remark*
\begin_inset Formula $L^{2}(\Omega,\sigma(X),\mathbb{P})$
\end_inset

 is a subspace of 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

, very much how a plane or line (going through the origin) is a subspace
 of 
\begin_inset Formula $\mathbf{R}^{3}$
\end_inset

.
\end_layout

\begin_layout Remark*
In particular, as in the case of a line or a plane, we can project an element
 of 
\begin_inset Formula $Y$
\end_inset

 of 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 onto 
\begin_inset Formula $L^{2}(\Omega,\sigma(X),\mathbb{P})$
\end_inset

.
 The resulting projection is an element of 
\begin_inset Formula $L^{2}(\Omega,\sigma(X),\mathbb{P})$
\end_inset

, a square-integrable random-variable that is a function of 
\begin_inset Formula $X$
\end_inset

.
 For a subspace 
\begin_inset Formula $\mathcal{S}$
\end_inset

 of 
\begin_inset Formula $\mathbf{R}^{3}$
\end_inset

 (e.g.
 a line or a plane), the projection of the vector 
\begin_inset Formula $\mathbf{v}\in\mathbf{R}^{3}$
\end_inset

 onto the subspace 
\begin_inset Formula $\mathcal{S}$
\end_inset

, denoted 
\begin_inset Formula $\text{Proj}_{\mathcal{S}}(\mathbf{v})$
\end_inset

 is the closest point to 
\begin_inset Formula $\mathbf{v}$
\end_inset

 lying in the subspace 
\begin_inset Formula $\mathcal{S}$
\end_inset

.
 Moreover, 
\begin_inset Formula $\mathbf{v}-\text{Proj}_{\mathcal{S}}(\mathbf{v})$
\end_inset

 is orthogonal to the subspace.
 This picture of orthogonal projection also holds in 
\begin_inset Formula $L^{2}$
\end_inset

.
 Let 
\begin_inset Formula $Y$
\end_inset

 be a random variable in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 and let 
\begin_inset Formula $L^{2}(\Omega,\sigma(X),\mathbb{P})$
\end_inset

 be the subspace of those random variables that are functions of 
\begin_inset Formula $X$
\end_inset

.
 We write 
\begin_inset Formula $Y^{\star}$
\end_inset

 for the random variable in 
\begin_inset Formula $L^{2}(\Omega,\sigma(X),\mathbb{P})$
\end_inset

 that is 
\emph on
closest 
\emph default
to 
\begin_inset Formula $Y$
\end_inset

.
 In other words, we have (using the definition of the 
\begin_inset Formula $L^{2}$
\end_inset

-distance square):
\end_layout

\begin_layout Remark*
\begin_inset Formula 
\begin{equation}
\inf_{Z\in L^{2}(\Omega,\sigma(X),\mathbb{P})}\mathbb{E}[(Y-Z)^{2}]=\mathbb{E}[(Y-Y^{\star})^{2}]\label{eq:Y-star-is-the-closest-to-Y-in-L2-sense}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
It turns out that 
\begin_inset Formula $Y^{\star}$
\end_inset

 is the right candidate for the conditional expectation.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
tikzset{axis/.style={thick,-latex}}
\end_layout

\begin_layout Plain Layout


\backslash
tikzset{vec/.style={thick,gray,-latex}}
\end_layout

\begin_layout Plain Layout


\backslash
tikzset{vect/.style={dashed,gray,}}
\end_layout

\begin_layout Plain Layout


\backslash
tikzset{base/.style={thin,blue}}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}
\end_layout

\begin_layout Plain Layout

		
\backslash
draw[axis] node [anchor=north] {$O$} (0,0,0) -- (8,0,0);
\end_layout

\begin_layout Plain Layout

		
\backslash
draw[axis] (0,0,0) -- (0,5,0);
\end_layout

\begin_layout Plain Layout

		
\backslash
draw[axis] (0,0,0) -- (0,0,8);
\end_layout

\begin_layout Plain Layout

 	   
\backslash
draw[vec] (0,0,0) -- (4,4,4) node [pos=1.1] {$Y$};
\end_layout

\begin_layout Plain Layout

		
\backslash
draw[vec] (0,0,0) -- (4,0,4) node [pos=1.1] {$Y^{
\backslash
star}=
\backslash
mathbf{E}[Y|X]$};
\end_layout

\begin_layout Plain Layout

		
\backslash
draw[vect] (4,4,4) -- (4,0,4);
\end_layout

\begin_layout Plain Layout

		
\backslash
draw[base] (0,0,0) -- (7,0,0) -- node [pos=1.1] {$L^2(
\backslash
Omega,
\backslash
sigma(X),
\backslash
mathbb{P})$} (7,0,7) -- (0,0,7) -- (0,0,0);
\end_layout

\begin_layout Plain Layout

		
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Figure.
 An illustration of the conditional expectation $
\backslash
mathbb{E}[Y|X]$ as an orthogonal projection of $Y$ onto the subspace $L^2(
\backslash
Omega,
\backslash
sigma(X),
\backslash
mathbb{P})$.
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "th:existence-and-uniqueness-of-the-conditional-expectation"

\end_inset

(Existence and uniqueness of the conditional expectation) Let 
\begin_inset Formula $X$
\end_inset

 be a random variable on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Let 
\begin_inset Formula $Y$
\end_inset

 be a random variable in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Then the conditional expectation 
\begin_inset Formula $\mathbb{E}[Y|X]$
\end_inset

 is the random variable 
\begin_inset Formula $Y^{\star}$
\end_inset

 given in the equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Y-star-is-the-closest-to-Y-in-L2-sense"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Namely, it is the random variable in 
\begin_inset Formula $L^{2}(\Omega,\sigma(X),\mathbb{P})$
\end_inset

 that is closest to 
\begin_inset Formula $Y$
\end_inset

 in the 
\begin_inset Formula $L^{2}$
\end_inset

-distance.
 
\end_layout

\begin_layout Theorem
In particular we have the following:
\end_layout

\begin_layout Theorem
1) It is the orthogonal projection of 
\begin_inset Formula $Y$
\end_inset

 onto 
\begin_inset Formula $L^{2}(\Omega,\sigma(X),\mathbb{P})$
\end_inset

, that is 
\begin_inset Formula $Y-Y^{\star}$
\end_inset

 is orthogonal to any random variables in the subspace 
\begin_inset Formula $L^{2}(\Omega,\sigma(X),\mathbb{P})$
\end_inset

.
\end_layout

\begin_layout Theorem
2) It is unique.
\end_layout

\begin_layout Remark*
This result reinforces the meaning of the conditional expectation 
\begin_inset Formula $\mathbb{E}[Y|X]$
\end_inset

 as the best estimation of 
\begin_inset Formula $Y$
\end_inset

 given the information of 
\begin_inset Formula $X$
\end_inset

: it is the closest random variable to 
\begin_inset Formula $Y$
\end_inset

 among all the functions of 
\begin_inset Formula $X$
\end_inset

 in the sense of 
\begin_inset Formula $L^{2}$
\end_inset

.
\end_layout

\begin_layout Proof
We write for short 
\begin_inset Formula $L^{2}(X)$
\end_inset

 for the subspace 
\begin_inset Formula $L^{2}(\Omega,\sigma(X),\mathbb{P})$
\end_inset

.
 Let 
\begin_inset Formula $Y^{\star}$
\end_inset

 be as in equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Y-star-is-the-closest-to-Y-in-L2-sense"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 We show successively that (1) 
\begin_inset Formula $Y-Y^{\star}$
\end_inset

 is orthogonal to any element of 
\begin_inset Formula $L^{2}(X)$
\end_inset

, so it is the orthogonal projection (2) 
\begin_inset Formula $Y^{\star}$
\end_inset

 has the properties of conditional expectation in definition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:definition-conditional-expectation"
plural "false"
caps "false"
noprefix "false"

\end_inset

 (3) 
\begin_inset Formula $Y^{\star}$
\end_inset

 is unique.
 
\end_layout

\begin_layout Proof
(1) Let 
\begin_inset Formula $W=g(X)$
\end_inset

 be a random variable in 
\begin_inset Formula $L^{2}(X)$
\end_inset

.
 We show that 
\begin_inset Formula $W$
\end_inset

 is orthogonal to 
\begin_inset Formula $Y-Y^{\star}$
\end_inset

; that is 
\begin_inset Formula $\mathbb{E}[(Y-Y^{\star})W]=0$
\end_inset

.
 This should be intuitively clear from figure above.
 On the one hand, we have by developing the square:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
\mathbb{E}[(W-(Y-Y^{\star}))^{2}] & =\mathbb{E}[W^{2}-2W(Y-Y^{\star})+(Y-Y^{\star})^{2}]\nonumber \\
 & =\mathbb{E}[W^{2}]-2\mathbb{E}[W(Y-Y^{\star})]+\mathbb{E}(Y-Y^{\star})^{2}]\label{eq:developing-the-square}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
On the other hand, 
\begin_inset Formula $Y^{\star}+W$
\end_inset

 is an arbitrary vector in 
\begin_inset Formula $L^{2}(X)$
\end_inset

(it is a linear combination of the elements in 
\begin_inset Formula $L^{2}(X)$
\end_inset

), we must have from equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Y-star-is-the-closest-to-Y-in-L2-sense"
plural "false"
caps "false"
noprefix "false"

\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
\mathbb{E}[(W-(Y-Y^{\star}))^{2}] & =\mathbb{E}[(Y-(Y^{\star}+W))^{2}]\nonumber \\
 & \geq\inf_{Z\in L^{2}(X)}\mathbb{E}[(Y-Z)^{2}]\nonumber \\
 & =\mathbb{E}[(Y-Y^{\star})^{2}]\label{eq:lower-bound}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
Putting the last two equations 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:developing-the-square"
plural "false"
caps "false"
noprefix "false"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:lower-bound"
plural "false"
caps "false"
noprefix "false"

\end_inset

 together, we get that for any 
\begin_inset Formula $W\in L^{2}(X)$
\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}[W^{2}]-2\mathbb{E}[W(Y-Y^{\star})] & \geq0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
In particular, this also holds for 
\begin_inset Formula $aW$
\end_inset

, in which case we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
a^{2}\mathbb{E}[W^{2}]-2a\mathbb{E}[W(Y-Y^{\star})] & \geq0\\
\implies a\left\{ a\mathbb{E}[W^{2}]-2\mathbb{E}[W(Y-Y^{\star})]\right\}  & \geq0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
If 
\begin_inset Formula $a>0$
\end_inset

, then:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
a\mathbb{E}[W^{2}]-2\mathbb{E}[W(Y-Y^{\star})]\geq0\label{eq:case-when-a-gt-zero}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
whereas if 
\begin_inset Formula $a<0$
\end_inset

, then the sign changes upon dividing throughout by 
\begin_inset Formula $a$
\end_inset

, and we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
a\mathbb{E}[W^{2}]-2\mathbb{E}[W(Y-Y^{\star})]\leq0\label{eq:case-when-a-lt-zero}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Rearranging 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:case-when-a-gt-zero"
plural "false"
caps "false"
noprefix "false"

\end_inset

 yields:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\mathbb{E}[W(Y-Y^{\star})]\leq a\mathbb{E}[W^{2}]/2\label{eq:case-when-a-gt-zero-rearranged}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Rearranging 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:case-when-a-lt-zero"
plural "false"
caps "false"
noprefix "false"

\end_inset

 yields:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\mathbb{E}[W(Y-Y^{\star})]\geq a\mathbb{E}[W^{2}]/2\label{eq:case-when-a-lt-zero-rearranged}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:case-when-a-gt-zero-rearranged"
plural "false"
caps "false"
noprefix "false"

\end_inset

 holds for all 
\begin_inset Formula $a>0$
\end_inset

, the stronger inequality, 
\begin_inset Formula $\mathbb{E}[W(Y-Y^{\star})]\leq0$
\end_inset

 must hold.
 Since, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:case-when-a-lt-zero-rearranged"
plural "false"
caps "false"
noprefix "false"

\end_inset

 holds for all 
\begin_inset Formula $a<0$
\end_inset

, the stronger inequality 
\begin_inset Formula $\mathbb{E}[W(Y-Y^{\star})]\geq0$
\end_inset

 must hold.
 Consequently,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\mathbb{E}[W(Y-Y^{\star})]=0
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
(2) It is clear that 
\begin_inset Formula $Y^{\star}$
\end_inset

 is a function of 
\begin_inset Formula $X$
\end_inset

 by construction, since it is in 
\begin_inset Formula $L^{2}(X)$
\end_inset

.
 Moreover, for any 
\begin_inset Formula $W\in L^{2}(X)$
\end_inset

, we have from (1) that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}[W(Y-Y^{\star})] & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
which is the second defining property of conditional expectations.
 
\end_layout

\begin_layout Proof
(3) Lastly, suppose there is another element 
\begin_inset Formula $Y'$
\end_inset

 that is in 
\begin_inset Formula $L^{2}(X)$
\end_inset

 that minimizes the distance to 
\begin_inset Formula $Y$
\end_inset

.
 Then we would get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}[(Y-Y')^{2}] & =\mathbb{E}[(Y-Y^{\star}+Y^{\star}-Y')^{2}]\\
 & =\mathbb{E}[(Y-Y^{\star})^{2}]+2\mathbb{E}[(Y-Y^{\star})(Y^{\star}-Y')]+\mathbb{E}[(Y^{\star}-Y')^{2}]\\
 & =\mathbb{E}[(Y-Y^{\star})^{2}]+0+\mathbb{E}[(Y^{\star}-Y')^{2}]\\
 & \quad\left\{ (Y^{\star}-Y')\in L^{2}(X)\perp(Y-Y^{\star})\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
where we used the fact, that 
\begin_inset Formula $Y^{\star}-Y'$
\end_inset

 is a vector in 
\begin_inset Formula $L^{2}(X)$
\end_inset

 and the orthogonality of 
\begin_inset Formula $Y-Y^{\star}$
\end_inset

 with 
\begin_inset Formula $L^{2}(X)$
\end_inset

 as in (1).
 But, this implies that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\cancel{\mathbb{E}[(Y-Y')^{2}]} & =\cancel{\mathbb{E}[(Y-Y^{\star})^{2}]}+\mathbb{E}[(Y^{\star}-Y')^{2}]\\
\mathbb{E}[(Y^{\star}-Y')^{2}] & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
So, 
\begin_inset Formula $Y^{\star}=Y'$
\end_inset

 almost surely.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "ex:[Arguin-4.1]-Conditional-Expectation-of-continuous-random-variables"

\end_inset

[Arguin-4.1] 
\series bold
Conditional Expectation of continuous random variables.
 
\series default
Let 
\begin_inset Formula $(X,Y)$
\end_inset

 be two random variables with joint density 
\begin_inset Formula $f_{X,Y}(x,y)$
\end_inset

 on 
\begin_inset Formula $\mathbf{R}^{2}$
\end_inset

.
 Suppose for simplicity, that 
\begin_inset Formula $\int_{\mathbf{R}}f(x,y)dx>0$
\end_inset

 for every 
\begin_inset Formula $y$
\end_inset

 belonging to 
\begin_inset Formula $\mathbf{R}$
\end_inset

.
 Show that the conditional expectation 
\begin_inset Formula $\mathbf{E}[Y|X]$
\end_inset

 equals 
\begin_inset Formula $h(X)$
\end_inset

 where 
\begin_inset Formula $h$
\end_inset

 is the function:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align}
h(x) & =\frac{\int_{\mathbf{R}}yf_{X,Y}(x,y)dy}{\int_{\mathbf{R}}f_{X,Y}(x,y)dy}\label{eq:conditional-expectation-of-continuous-random-variables}
\end{align}

\end_inset


\end_layout

\begin_layout Example
In particular, verify that 
\begin_inset Formula $\mathbf{E}[\mathbf{E}[Y|X]]=\mathbf{E}[Y]$
\end_inset

.
\end_layout

\begin_layout Example

\emph on
Hint
\emph default
: To prove this, verify that the above formula satisfies both the properties
 of conditional expectations; then invoke uniqueness to finish it off.
 
\end_layout

\begin_layout Solution*
(i) The density function 
\begin_inset Formula $f_{X,Y}(x,y)$
\end_inset

 is a map 
\begin_inset Formula $f:\mathbf{R}^{2}\to\mathbf{R}$
\end_inset

.
 The integral 
\begin_inset Formula $\int_{y=-\infty}^{y=+\infty}yf_{X,Y}(x_{0},y)dy$
\end_inset

 is the area under the curve 
\begin_inset Formula $yf(x,y)$
\end_inset

 at the point 
\begin_inset Formula $x=x_{0}$
\end_inset

.
 Let's call it 
\begin_inset Formula $A(x_{0})$
\end_inset

.
 If instead, we have an arbitrary 
\begin_inset Formula $x$
\end_inset

, 
\begin_inset Formula $\int_{y=-\infty}^{y=+\infty}yf_{X,Y}(x,y)dy$
\end_inset

 represents the area 
\begin_inset Formula $A(x)$
\end_inset

 of an arbitrary slice of the surface 
\begin_inset Formula $yf_{X,Y}$
\end_inset

 at the point 
\begin_inset Formula $x$
\end_inset

.
 Hence, it is a function of 
\begin_inset Formula $x$
\end_inset

.
 The denominator 
\begin_inset Formula $\int_{\mathbf{R}}f_{X,Y}(x,y)dy=f_{X}(x)$
\end_inset

, the density of 
\begin_inset Formula $X$
\end_inset

, which is a function of 
\begin_inset Formula $x$
\end_inset

.
 Hence, the ratio is a function of 
\begin_inset Formula $x$
\end_inset

.
 
\end_layout

\begin_layout Solution*
(ii) Let 
\begin_inset Formula $g(X)$
\end_inset

 is a bounded random variable.
 We have:
\end_layout

\begin_layout Solution*
\begin_inset Formula 
\begin{align*}
\mathbf{E}[g(X)(Y-h(X))] & =\mathbf{E}[Yg(X)]-\mathbf{E}[g(X)h(X)]\\
 & =\int\int_{\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx-\int_{\mathbf{R}}g(x)h(x)f(x)dx\\
 & =\int\int_{\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx\\
 & -\int_{\mathbf{R}}\begin{array}{c}
g(x)\cdot\frac{\int_{\mathbf{R}}yf_{X,Y}(x,y)dy}{\int_{\mathbf{R}}f_{X,Y}(x,y)dy}\end{array}\cdot\int_{\mathbf{R}}f_{X,Y}(x,y)dy\ dx\\
 & =\int\int_{\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx\\
 & -\int_{\mathbf{R}}\begin{array}{c}
g(x)\cdot\frac{\int_{\mathbf{R}}yf_{X,Y}(x,y)dy}{\cancel{\int_{\mathbf{R}}f_{X,Y}(x,y)dy}}\end{array}\cdot\cancel{\int_{\mathbf{R}}f_{X,Y}(x,y)dy}\ dx\\
 & =\int\int_{\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)dydx-\int_{\mathbf{R}^{2}}yg(x)f_{X,Y}(x,y)\cdot dx\cdot dy\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Thus, 
\begin_inset Formula $h(X)$
\end_inset

 is a valid candidate for the conditional expectation 
\begin_inset Formula $\mathbf{E}[Y|X]$
\end_inset

.
 Moreover, by the existence and uniqueness theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:existence-and-uniqueness-of-the-conditional-expectation"
plural "false"
caps "false"
noprefix "false"

\end_inset

, 
\begin_inset Formula $\mathbf{E}[Y|X]$
\end_inset

 is unique and equals 
\begin_inset Formula $h(X)$
\end_inset

.
\end_layout

\begin_layout Paragraph*
Conditioning on several random variables.
\end_layout

\begin_layout Standard
We would like to generalize the conditional expectation to the case when
 we condition on the information of more than one random variable.
 Taking the 
\begin_inset Formula $L^{2}$
\end_inset

 point of view, we should expect that the conditional expectation is the
 orthogonal projection of the given random variable on the subspace generated
 by square integrable functions of all the variables on which we condition.
 
\end_layout

\begin_layout Standard
It is now useful to study sigma-fields, an object that was defined in chapter
 1.
 
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:sigma-field"

\end_inset

(Sigma-Field) A sigma-field or sigma-algebra 
\begin_inset Formula $\mathcal{F}$
\end_inset

 of a sample space 
\begin_inset Formula $\Omega$
\end_inset

 is a collection of all measurable events with the following properties:
\end_layout

\begin_layout Definition
(1) 
\begin_inset Formula $\Omega$
\end_inset

 is in 
\begin_inset Formula $\mathcal{F}$
\end_inset

.
\end_layout

\begin_layout Definition
(2) Closure under complement.
 If 
\begin_inset Formula $A\in\mathcal{F}$
\end_inset

, then 
\begin_inset Formula $A^{C}\in\mathcal{F}$
\end_inset

.
\end_layout

\begin_layout Definition
(3) Closure under countable unions.
 If 
\begin_inset Formula $A_{1},A_{2},\ldots,\in\mathcal{F}$
\end_inset

, then 
\begin_inset Formula $\bigcup_{n=1}^{\infty}A_{n}\in\mathcal{F}$
\end_inset

.
\end_layout

\begin_layout Standard
Such objects play a fundamental role in the rigorous study of probability
 and real analysis in general.
 We will focus on the intuition behind them.
 First let's mention some examples of sigma-fields of a given sample space
 
\begin_inset Formula $\Omega$
\end_inset

 to get acquainted with the concept.
\end_layout

\begin_layout Example
(Examples of sigma-fields).
\end_layout

\begin_layout Example
(1) 
\emph on
The trivial sigma-field
\emph default
.
 Note that the collection of events 
\begin_inset Formula $\{\emptyset,\Omega\}$
\end_inset

 is a sigma-field of 
\begin_inset Formula $\Omega$
\end_inset

.
 We generally denote it by 
\begin_inset Formula $\mathcal{F}_{0}$
\end_inset

.
\end_layout

\begin_layout Example
(2) 
\emph on
The 
\begin_inset Formula $\sigma$
\end_inset

-field generated by an event 
\begin_inset Formula $A$
\end_inset

.
 
\emph default
Let 
\begin_inset Formula $A$
\end_inset

 be an event that is not 
\begin_inset Formula $\emptyset$
\end_inset

 and not the entire 
\begin_inset Formula $\Omega$
\end_inset

.
 Then the smallest sigma-field containing 
\begin_inset Formula $A$
\end_inset

 ought to be:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathcal{F}_{1} & =\{\emptyset,A,A^{C},\Omega\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
This sigma-field is denoted by 
\begin_inset Formula $\sigma(A)$
\end_inset

.
\end_layout

\begin_layout Example
(3) The 
\emph on
sigma-field generated by a random variable 
\begin_inset Formula $X$
\end_inset

.
 
\end_layout

\begin_layout Example
We now define the 
\begin_inset Formula $\mathcal{F}_{X}$
\end_inset

 as follows:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathcal{F}_{X} & =X^{-1}(\mathcal{B}):=\{\omega:X(\omega)\in B\},\forall B\in\mathcal{B}(\mathbf{R})
\end{align*}

\end_inset


\end_layout

\begin_layout Example
where 
\begin_inset Formula $\mathcal{B}$
\end_inset

 is the Borel 
\begin_inset Formula $\sigma$
\end_inset

-algebra on 
\begin_inset Formula $\mathbf{R}$
\end_inset

.
 
\begin_inset Formula $\mathcal{F}_{X}$
\end_inset

 is sometimes denoted as 
\begin_inset Formula $\sigma(X)$
\end_inset

.
 
\begin_inset Formula $\mathcal{F}_{X}$
\end_inset

is the set of all events pertaining to 
\begin_inset Formula $X$
\end_inset

.
 It is a sigma-algebra because:
\end_layout

\begin_layout Example
(i) 
\begin_inset Formula $\Omega\in\sigma(X)$
\end_inset

 because 
\begin_inset Formula $\Omega=\{\omega:X(\omega)\in\mathbf{R}\}$
\end_inset

 and 
\begin_inset Formula $\mathbf{R}\in\mathcal{B}(\mathbf{R})$
\end_inset

.
\end_layout

\begin_layout Example
(ii) Let any event 
\begin_inset Formula $C\in\sigma(X)$
\end_inset

.
 We need to show that 
\begin_inset Formula $\Omega\setminus C\in\sigma(X)$
\end_inset

.
\end_layout

\begin_layout Example
Since 
\begin_inset Formula $C\in\sigma(X)$
\end_inset

, there exists 
\begin_inset Formula $A\in\mathcal{B}(\mathbf{R})$
\end_inset

, such that:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
C & =\{\omega\in\Omega:X(\omega)\in A\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Now, we calculate:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\Omega\setminus C & =\{\omega\in\Omega:X(\omega)\in\mathbf{R}\setminus A\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Since 
\begin_inset Formula $\mathcal{B}(\mathbf{R})$
\end_inset

 is a sigma-algebra, it is closed under complementation.
 Hence, if 
\begin_inset Formula $A\in\mathcal{B}(\mathbf{R})$
\end_inset

, it implies that 
\begin_inset Formula $\mathbf{R}\setminus A\in\mathcal{B}(\mathbf{R})$
\end_inset

.
 So, 
\begin_inset Formula $\Omega\setminus C\in\sigma(X)$
\end_inset

.
\end_layout

\begin_layout Example
(iii) Consider a sequence of events 
\begin_inset Formula $C_{1},C_{2},\ldots,C_{n},\ldots\in\sigma(X)$
\end_inset

.
 We need to prove that 
\begin_inset Formula $\bigcup_{n=1}^{\infty}C_{n}\in\sigma(X)$
\end_inset

.
\end_layout

\begin_layout Example
Since 
\begin_inset Formula $C_{n}\in\sigma(X)$
\end_inset

, there exists 
\begin_inset Formula $A_{n}\in\mathcal{B}(\mathbf{R})$
\end_inset

 such that:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
C_{n} & =\{\omega\in\Omega:X(\omega)\in A_{n}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Now, we calculuate:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\bigcup_{n=1}C_{n} & =\{\omega\in\Omega:X(\omega)\in\bigcup_{n=1}^{\infty}A_{n}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
But, 
\begin_inset Formula $\bigcup_{n=1}^{\infty}A_{n}\in\mathcal{B}(\mathbf{R})$
\end_inset

.
 So, 
\begin_inset Formula $\bigcup_{n=1}^{\infty}C_{n}\in\sigma(X)$
\end_inset

.
\end_layout

\begin_layout Example
Consequently, 
\begin_inset Formula $\sigma(X)$
\end_inset

 is indeed a 
\begin_inset Formula $\sigma$
\end_inset

-algebra.
\end_layout

\begin_layout Example
Intuitively, we think of 
\begin_inset Formula $\sigma(X)$
\end_inset

 as containing all information about 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_layout Example
(4) 
\emph on
The sigma-field generated by a stochastic process 
\begin_inset Formula $(X_{s},s\leq t)$
\end_inset

.
 
\emph default
Let 
\begin_inset Formula $(X_{s},s\geq0)$
\end_inset

 be a stochastic process.
 Consider the process restricted to 
\begin_inset Formula $[0,t]$
\end_inset

, 
\begin_inset Formula $(X_{s},s\leq t)$
\end_inset

.
 We consider the smallest sigma-field containing all events pertaining to
 the random variables 
\begin_inset Formula $X_{s},s\leq t$
\end_inset

.
 We denote it by 
\begin_inset Formula $\sigma(X_{s},s\leq t)$
\end_inset

 or 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

.
\end_layout

\begin_layout Standard
The sigma-fields on 
\begin_inset Formula $\Omega$
\end_inset

 have a natural (partial) ordering: two sigma-fields 
\begin_inset Formula $\mathcal{G}$
\end_inset

 and 
\begin_inset Formula $\mathcal{F}$
\end_inset

 of 
\begin_inset Formula $\Omega$
\end_inset

 are such that 
\begin_inset Formula $\mathcal{G}\subseteq\mathcal{F}$
\end_inset

 if all the events in 
\begin_inset Formula $\mathcal{G}$
\end_inset

 are in 
\begin_inset Formula $\mathcal{F}$
\end_inset

.
 For example, the trivial 
\begin_inset Formula $\sigma$
\end_inset

-field 
\begin_inset Formula $\mathcal{F}_{0}=\{\emptyset,\Omega\}$
\end_inset

 is contained in all the 
\begin_inset Formula $\sigma$
\end_inset

-fields of 
\begin_inset Formula $\Omega$
\end_inset

.
 Clearly, the 
\begin_inset Formula $\sigma$
\end_inset

-field 
\begin_inset Formula $\mathcal{F}_{t}=\sigma(X_{s},s\leq t)$
\end_inset

 is contained in 
\begin_inset Formula $\mathcal{F}_{t'}$
\end_inset

 if 
\begin_inset Formula $t\leq t'$
\end_inset

.
\end_layout

\begin_layout Standard
If all the events pertaining to a random variable 
\begin_inset Formula $X$
\end_inset

 are in the 
\begin_inset Formula $\sigma$
\end_inset

-field 
\begin_inset Formula $\mathcal{G}$
\end_inset

 (and thus we can compute 
\begin_inset Formula $\mu(X^{-1}((a,b]))$
\end_inset

), we will say that 
\begin_inset Formula $X$
\end_inset

 is 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable.
 This means that all information about 
\begin_inset Formula $X$
\end_inset

 is contained in 
\begin_inset Formula $\mathcal{G}$
\end_inset

.
 
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $X$
\end_inset

 be a random variable defined on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Consider another 
\begin_inset Formula $\mathcal{G}\subseteq\mathcal{F}$
\end_inset

.
 Then 
\begin_inset Formula $X$
\end_inset

 is said to be 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable, if and only if:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
\{\omega:X(\omega)\in(a,b]\} & \in\mathcal{G}\text{ for all intervals }(a,b]\in\mathbf{R}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
(
\begin_inset Formula $\mathcal{F}_{0}$
\end_inset

-measurable random variables).
 Consider the trivial sigma-field 
\begin_inset Formula $\mathcal{F}_{0}=\{\emptyset,\Omega\}$
\end_inset

.
 A random variable that is 
\begin_inset Formula $\mathcal{F}_{0}$
\end_inset

-measurable must be a constant.
 Indeed, we have that for any interval 
\begin_inset Formula $(a,b]$
\end_inset

, 
\begin_inset Formula $\{\omega:X(\omega)\in(a,b]\}=\emptyset$
\end_inset

 or 
\begin_inset Formula $\{\omega:X(\omega)\in(a,b]\}=\Omega$
\end_inset

.
 This can only hold if 
\begin_inset Formula $X$
\end_inset

 takes a single value.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "ex:sigma(X)-measurable-random-variables-example"

\end_inset

(
\begin_inset Formula $\sigma(X)$
\end_inset

-measurable random variables).
 Let 
\begin_inset Formula $X$
\end_inset

 be a given random variable on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Roughly speaking, a 
\begin_inset Formula $\sigma(X)$
\end_inset

-measurable random variable is determined by the information of 
\begin_inset Formula $X$
\end_inset

 only.
 Here is the simplest example of a 
\begin_inset Formula $\sigma(X)$
\end_inset

-measurable random variable.
 Take the indicator function 
\begin_inset Formula $Y=\mathbf{1}_{\{X\in B\}}$
\end_inset

 for some event 
\begin_inset Formula $\{X\in B\}$
\end_inset

 pertaining to 
\begin_inset Formula $X$
\end_inset

.
 Then the pre-images 
\begin_inset Formula $\{\omega:Y(\omega)\in(a,b]\}$
\end_inset

 are either 
\begin_inset Formula $\emptyset$
\end_inset

, 
\begin_inset Formula $\{X\in B\}$
\end_inset

, 
\begin_inset Formula $\{X\in B^{C}\}$
\end_inset

 or 
\begin_inset Formula $\Omega$
\end_inset

 depending on whether 
\begin_inset Formula $0,1$
\end_inset

 are in 
\begin_inset Formula $(a,b]$
\end_inset

 or not.
 All of these events are in 
\begin_inset Formula $\sigma(X)$
\end_inset

.
 More generally, one can construct a 
\begin_inset Formula $\sigma(X)$
\end_inset

-measurable random variable by taking linear combinations of indicator functions
 of events of the form 
\begin_inset Formula $\{X\in B\}$
\end_inset

.
 
\end_layout

\begin_layout Example
It turns out that any (Borel measurable) function of 
\begin_inset Formula $X$
\end_inset

 can be approximated by taking limits of such simple functions.
 
\end_layout

\begin_layout Example
Concretely, this translates to the following statement:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{equation}
\text{If }Y\text{ is \ensuremath{\sigma}(X)-measurable, then Y=g(X) for some function g}
\end{equation}

\end_inset


\end_layout

\begin_layout Example
In the same way, if 
\begin_inset Formula $Z$
\end_inset

 is 
\begin_inset Formula $\sigma(X,Y)$
\end_inset

-measurable, then 
\begin_inset Formula $Z=h(X,Y)$
\end_inset

 for some 
\begin_inset Formula $h$
\end_inset

.
 These facts can be proved rigorously using measure theory.
 
\end_layout

\begin_layout Standard
We are ready to give the general definition of conditional expectation.
 
\end_layout

\begin_layout Example
(Coin-Tossing Space).
 Suppose a coin is tossed infinitely many times.
 Let 
\begin_inset Formula $\Omega$
\end_inset

 be the set of all infinite sequences of 
\begin_inset Formula $H$
\end_inset

s and 
\begin_inset Formula $T$
\end_inset

s.
 A generic element of 
\begin_inset Formula $\Omega$
\end_inset

 is denoted by 
\begin_inset Formula $\omega_{1}\omega_{2}\ldots$
\end_inset

, where 
\begin_inset Formula $\omega_{n}$
\end_inset

 indicates the result of the 
\begin_inset Formula $n$
\end_inset

th coin toss.
 
\begin_inset Formula $\Omega$
\end_inset

 is an uncountable sample space.
 The trivial sigma-field 
\begin_inset Formula $\mathcal{F}_{0}=\{\emptyset,\Omega\}$
\end_inset

.
 Assume that we don't know anything about the outcome of the experiement.
 Even without any information, we know that the true 
\begin_inset Formula $\omega$
\end_inset

 belongs to 
\begin_inset Formula $\Omega$
\end_inset

 and does not belong to 
\begin_inset Formula $\emptyset$
\end_inset

.
 It is the information learned at time 
\begin_inset Formula $0$
\end_inset

.
\end_layout

\begin_layout Example
Next, assume that we know the outcome of the first coin toss.
 Define 
\begin_inset Formula $A_{H}=\{\omega:\omega_{1}=H\}$
\end_inset

=set of all sequences beginning with 
\begin_inset Formula $H$
\end_inset

 and 
\begin_inset Formula $A_{T}=\{\omega:\omega_{1}=T\}$
\end_inset

=set of all sequences beginning with 
\begin_inset Formula $T$
\end_inset

.
 The four sets resolved by the first coin-toss form the the 
\begin_inset Formula $\sigma$
\end_inset

-field 
\begin_inset Formula $\mathcal{F}_{1}=\{\emptyset,A_{H},A_{T},\Omega\}$
\end_inset

.
 We shall think of this 
\begin_inset Formula $\sigma$
\end_inset

-field as containing the information learned by knowing the outcome of the
 first coin toss.
 More precisely, if instead of being told about the first coin toss, we
 are told for each set in 
\begin_inset Formula $\mathcal{F}_{1}$
\end_inset

, whether or not the true 
\begin_inset Formula $\omega$
\end_inset

 belongs to that set, then we know the outcome of the first coin toss and
 nothing more.
 
\end_layout

\begin_layout Example
If we are told the first two coin tosses, we obtain a finer resolution.
 In particular, the four sets:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
A_{HH} & =\{\omega:\omega_{1}=H,\omega_{2}=H\}\\
A_{HT} & =\{\omega:\omega_{1}=H,\omega_{2}=T\}\\
A_{TH} & =\{\omega:\omega_{1}=T,\omega_{2}=H\}\\
A_{TT} & =\{\omega:\omega_{1}=T,\omega_{2}=T\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
are resolved.
 Of course, the sets in 
\begin_inset Formula $\mathcal{F}_{1}$
\end_inset

 are resolved.
 Whenever a set is resolved, so is its complement, which means that 
\begin_inset Formula $A_{HH}^{C}$
\end_inset

, 
\begin_inset Formula $A_{HT}^{C}$
\end_inset

, 
\begin_inset Formula $A_{TH}^{C}$
\end_inset

 and 
\begin_inset Formula $A_{TT}^{C}$
\end_inset

 are resolved, so is their union which means that 
\begin_inset Formula $A_{HH}\cup A_{TH}$
\end_inset

, 
\begin_inset Formula $A_{HH}\cup A_{TT}$
\end_inset

, 
\begin_inset Formula $A_{HT}\cup A_{TH}$
\end_inset

 and 
\begin_inset Formula $A_{HT}\cup A_{TT}$
\end_inset

 are resolved.
 The other two pair-wise unions 
\begin_inset Formula $A_{HH}\cup A_{HT}=A_{H}$
\end_inset

 and 
\begin_inset Formula $A_{TH}\cup A_{TT}=A_{T}$
\end_inset

 are already resolved.
 Finally, the triple unions are also resolved, because 
\begin_inset Formula $A_{HH}\cup A_{HT}\cup A_{TH}=A_{TT}^{C}$
\end_inset

 and so forth.
 Hence, the information pertaining to the second coin-toss is contained
 in:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathcal{F}_{2} & =\{\emptyset,\Omega,\\
 & A_{H},A_{T},\\
 & A_{HH},A_{HT},A_{TH},A_{TT},\\
 & A_{HH}^{C},A_{HT}^{C},A_{TH}^{C},A_{TT}^{C},\\
 & A_{HH}\cup A_{TH},A_{HH}\cup A_{TT},A_{HT}\cup A_{TH},A_{HT}\cup A_{TT}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Hence, if the outcome of the first two coin tosses is known, all of the
 events in 
\begin_inset Formula $\mathcal{F}_{2}$
\end_inset

 are resolved - we exactly know, if each event has ocurred or not.
 
\begin_inset Formula $\mathcal{F}_{2}$
\end_inset

 is the information learned by observing the first two coin tosses.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Exercise
[Arguin-4.2] (
\series bold
Exercises on sigma-fields
\series default
).
 
\end_layout

\begin_layout Exercise
(a) Let 
\begin_inset Formula $A$
\end_inset

, 
\begin_inset Formula $B$
\end_inset

 be two proper subsets of 
\begin_inset Formula $\Omega$
\end_inset

 such that 
\begin_inset Formula $A\cap B\neq\emptyset$
\end_inset

 and 
\begin_inset Formula $A\cup B\neq\Omega$
\end_inset

.
 Write down 
\begin_inset Formula $\sigma(\{A,B\})$
\end_inset

, the smallest sigma-field containing 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 explicitly.
 What if 
\begin_inset Formula $A\cap B=\emptyset$
\end_inset

?
\end_layout

\begin_layout Exercise
(b) The Borel sigma-field is the smallest sigma-field containing intervals
 of the form 
\begin_inset Formula $(a,b]$
\end_inset

 in 
\begin_inset Formula $\mathbf{R}$
\end_inset

.
 Show that all singletons 
\begin_inset Formula $\{b\}$
\end_inset

 are in 
\begin_inset Formula $\mathcal{B}(\mathbf{R})$
\end_inset

 by writing 
\begin_inset Formula $\{b\}$
\end_inset

 as a countable intersection of intervals 
\begin_inset Formula $(a,b]$
\end_inset

.
 Conclude that all open intervals 
\begin_inset Formula $(a,b)$
\end_inset

 and all closed intervals 
\begin_inset Formula $[a,b]$
\end_inset

 are in 
\begin_inset Formula $\mathcal{B}(\mathbf{R})$
\end_inset

.
 Is the subset 
\begin_inset Formula $\mathbf{Q}$
\end_inset

 of rational numbers a Borel set?
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
(a) The sigma-field generated by the two events 
\begin_inset Formula $A$
\end_inset

, 
\begin_inset Formula $B$
\end_inset

 is given by:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sigma(\{A,B\}) & =\{\emptyset,\Omega,\\
 & A,B,A^{C},B^{C},\\
 & A\cup B,A\cap B,\\
 & A\cup B^{C},A^{C}\cup B,A^{C}\cup B^{C},\\
 & A\cap B^{C},A^{C}\cap B,A^{C}\cap B^{C},\\
 & (A\cup B)\cap(A\cap B)^{C},\\
 & (A\cup B)^{C}\cup(A\cap B)\}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(b) Firstly, recall that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathcal{B}(\mathbf{R}) & =\bigcap_{\alpha\in\Lambda}\mathcal{F}_{\alpha}=\bigcap\sigma(\{I:I\text{ is an interval }(a,b]\subseteq\mathbf{R}\})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We can write:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\{b\} & =\bigcap_{n=1}^{\infty}\left(b-\frac{1}{n},b\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
As 
\begin_inset Formula $\mathcal{B}(\mathbf{R})$
\end_inset

 is a sigma-field, it is closed under countable intersections.
 Hence, the singleton set 
\begin_inset Formula $\{b\}$
\end_inset

is a Borel set.
 
\end_layout

\begin_layout Proof
Similarly, we can write, any open interval as the countable union:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
(a,b) & =\bigcup_{n=1}^{\infty}\left(a,b-\frac{1}{n}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We can convince ourselves, that equality indeed holds.
 Let 
\begin_inset Formula $x\in(a,b)$
\end_inset

 and choose 
\begin_inset Formula $N$
\end_inset

, such that 
\begin_inset Formula $\frac{1}{N}<|b-x|$
\end_inset

.
 Then, for all 
\begin_inset Formula $n\geq N$
\end_inset

, 
\begin_inset Formula $x\in(a,b-1/n]$
\end_inset

.
 Thus, it belongs to the RHS.
 In the reverse direction, let 
\begin_inset Formula $x$
\end_inset

 belong to 
\begin_inset Formula $\bigcup_{n=1}^{\infty}\left(a,b-\frac{1}{n}\right]$
\end_inset

.
 So, 
\begin_inset Formula $x$
\end_inset

 belongs to atleast one of these sets.
 Therefore, 
\begin_inset Formula $x\in(a,b)$
\end_inset

 is trivially true.
 So, the two sets are equal.
 
\end_layout

\begin_layout Proof
Hence, open intervals are Borel sets.
\end_layout

\begin_layout Proof
Similarly, we may write:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
[a,b] & =\bigcap_{n=1}^{\infty}\left(a-\frac{1}{n},b+\frac{1}{n}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Consequently, closed intervals are Borel sets.
 Since 
\begin_inset Formula $\mathbf{Q}$
\end_inset

 is countable, it is a Borel set.
 Moreover, the empty set 
\begin_inset Formula $\emptyset$
\end_inset

 and 
\begin_inset Formula $\mathbf{R}$
\end_inset

 are Borel sets.
 So, 
\begin_inset Formula $\mathbf{R}\backslash\mathbf{Q}$
\end_inset

 is also a Borel set.
\end_layout

\begin_layout Exercise
[Arguin-4.4] Let 
\begin_inset Formula $(X,Y)$
\end_inset

 be a Gaussian vector with mean 
\begin_inset Formula $0$
\end_inset

 and covariance matrix 
\end_layout

\begin_layout Exercise
\begin_inset Formula 
\begin{align*}
C & =\left[\begin{array}{cc}
1 & \rho\\
\rho & 1
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
for 
\begin_inset Formula $\rho\in(-1,1)$
\end_inset

.
 We verify that the example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:conditional-expectation-of-gaussian-vectors"
plural "false"
caps "false"
noprefix "false"

\end_inset

 and exercise 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:[Arguin-4.1]-Conditional-Expectation-of-continuous-random-variables"
plural "false"
caps "false"
noprefix "false"

\end_inset

 yield the same conditional expectation.
 
\end_layout

\begin_layout Exercise
(a) Use equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:conditional-expectation-of-gaussian-vector"
plural "false"
caps "false"
noprefix "false"

\end_inset

 to show that 
\begin_inset Formula $\mathbf{E}[Y|X]=\rho X$
\end_inset

.
\end_layout

\begin_layout Exercise
(b) Write down the joint PDF 
\begin_inset Formula $f(x,y)$
\end_inset

 of 
\begin_inset Formula $(X,Y)$
\end_inset

.
\end_layout

\begin_layout Exercise
(c) Show that 
\begin_inset Formula $\int_{\mathbf{R}}yf(x,y)dy=\rho x$
\end_inset

 and that 
\begin_inset Formula $\int_{\mathbf{R}}f(x,y)dy=1$
\end_inset

.
\end_layout

\begin_layout Exercise
(d) Deduce that 
\begin_inset Formula $\mathbf{E}[Y|X]=\rho X$
\end_inset

 using the equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:conditional-expectation-of-continuous-random-variables"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
(a) Since 
\begin_inset Formula $(X,Y)$
\end_inset

 have mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $1$
\end_inset

, it follows that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[(X-EX)(Y-EY)] & =\mathbf{E}(XY)\\
\sqrt{(\mathbf{E}[X^{2}]-(\mathbf{E}X)^{2})}\cdot\sqrt{(\mathbf{E}[Y^{2}]-(\mathbf{E}Y)^{2})} & =\sqrt{(1-0)(1-0)}\\
 & =1
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
and therefore,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\rho & =\frac{\mathbf{E}(XY)}{1}=\frac{\mathbf{E}[XY]}{\mathbf{E}[X^{2}]}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $(X,Y)$
\end_inset

 is a Gaussian vector, using 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:conditional-expectation-of-gaussian-vector"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Y|X] & =\frac{\mathbf{E}[XY]}{\mathbf{E}[X^{2}]}X=\rho X
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(b) Consider the augmented matrix 
\begin_inset Formula $[C|I]$
\end_inset

.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
[C|I] & =\left[\left.\begin{array}{cc}
1 & \rho\\
\rho & 1
\end{array}\right|\begin{array}{cc}
1 & 0\\
0 & 1
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Performing 
\begin_inset Formula $R_{2}=R_{2}-\rho R_{1}$
\end_inset

, the above system is row-equivalent to:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\left[\left.\begin{array}{cc}
1 & \rho\\
0 & 1-\rho^{2}
\end{array}\right|\begin{array}{cc}
1 & 0\\
-\rho & 1
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Proof
Performing 
\begin_inset Formula $R_{2}=\frac{1}{1-\rho^{2}}R_{2}$
\end_inset

, the above system is row-equivalent to:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\left[\begin{array}{cc}
1 & \rho\\
0 & 1
\end{array}\left|\begin{array}{cc}
1 & 0\\
\frac{-\rho}{1-\rho^{2}} & \frac{1}{1-\rho^{2}}
\end{array}\right.\right]
\]

\end_inset


\end_layout

\begin_layout Proof
Performing 
\begin_inset Formula $R_{1}=R_{1}-\rho R_{2}$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\left[\begin{array}{cc}
1 & 0\\
0 & 1
\end{array}\left|\begin{array}{cc}
\frac{1}{1-\rho^{2}} & -\frac{\rho}{1-\rho^{2}}\\
\frac{-\rho}{1-\rho^{2}} & \frac{1}{1-\rho^{2}}
\end{array}\right.\right]
\]

\end_inset


\end_layout

\begin_layout Proof
Thus, 
\begin_inset Formula 
\begin{align*}
C^{-1} & =\frac{1}{1-\rho^{2}}\left[\begin{array}{cc}
1 & -\rho\\
-\rho & 1
\end{array}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Moreover, 
\begin_inset Formula $\det C=1-\rho^{2}.$
\end_inset


\end_layout

\begin_layout Proof
Therefore, the joint density of 
\begin_inset Formula $(X,Y)$
\end_inset

 is given by:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
f(x,y) & =\frac{1}{2\pi\sqrt{1-\rho^{2}}}\exp\left[-\frac{1}{2(1-\rho^{2})}\left[\begin{array}{cc}
x & y\end{array}\right]\left[\begin{array}{cc}
1 & -\rho\\
-\rho & 1
\end{array}\right]\left[\begin{array}{c}
x\\
y
\end{array}\right]\right]\\
 & =\frac{1}{2\pi\sqrt{1-\rho^{2}}}\exp\left[-\frac{1}{2(1-\rho^{2})}\left[\begin{array}{cc}
x-\rho y & -\rho x+y\end{array}\right]\left[\begin{array}{c}
x\\
y
\end{array}\right]\right]\\
 & \frac{1}{2\pi\sqrt{1-\rho^{2}}}\exp\left[-\frac{1}{2(1-\rho^{2})}(x^{2}-2\rho xy+y^{2})\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(c) Claim I.
 
\begin_inset Formula $\int_{\mathbf{R}}yf(x,y)dy=\rho x$
\end_inset

.
\end_layout

\begin_layout Proof
Completing the square, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
(x^{2}-2\rho xy+y^{2}) & =(y-\rho x)^{2}+x^{2}(1-\rho^{2})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Thus, we can write:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\int_{\mathbf{R}}yf(x,y)dy & =\frac{1}{2\pi\sqrt{1-\rho^{2}}}e^{-\frac{1}{2}x^{2}}\int_{\mathbf{R}}ye^{-\frac{1}{2}\frac{(y-\rho x)^{2}}{(1-\rho^{2})}}dy
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Let's substitute
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
z & =\frac{(y-\rho x)}{\sqrt{1-\rho^{2}}}\\
dz & =\frac{dy}{\sqrt{1-\rho^{2}}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Therefore,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\int_{\mathbf{R}}ye^{-\frac{1}{2}\frac{(y-\rho x)^{2}}{(1-\rho^{2})}}dy & =\sqrt{1-\rho^{2}}\int_{\mathbf{R}}(\rho x+\sqrt{1-\rho^{2}}z)e^{-\frac{z^{2}}{2}}dz\\
 & =\rho x\cdot\sqrt{1-\rho^{2}}\int_{\mathbf{R}}e^{-\frac{z^{2}}{2}}dz+(1-\rho^{2})\int_{\mathbf{R}}ze^{-\frac{z^{2}}{2}}dz\\
 & =\rho x\cdot\sqrt{1-\rho^{2}}\cdot\sqrt{2\pi}+(1-\rho^{2})\cdot0\\
 & =\rho x\cdot\sqrt{1-\rho^{2}}\cdot\sqrt{2\pi}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Consequently, 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\int_{\mathbf{R}}yf(x,y)dy & =\frac{1}{2\pi\cancel{\sqrt{1-\rho^{2}}}}e^{-\frac{1}{2}x^{2}}\rho x\cdot\cancel{\sqrt{1-\rho^{2}}}\cdot\sqrt{2\pi}\\
 & =\rho x\cdot\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}x^{2}}\\
 & =\rho x\cdot f_{X}(x)\\
\frac{\int_{\mathbf{R}}yf(x,y)dy}{f_{X}(x)} & =\frac{\int_{\mathbf{R}}yf(x,y)dy}{\int_{\mathbf{R}}f(x,y)}=\rho x
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(d) For a Gaussian vector 
\begin_inset Formula $(X,Y),$
\end_inset

 the conditional expectation 
\begin_inset Formula $\mathbf{E}[Y|X]=h(X)$
\end_inset

.
 Hence, 
\begin_inset Formula $\mathbf{E}[Y|X]=\rho X$
\end_inset

.
\end_layout

\begin_layout Definition
(Conditional Expectation) Let 
\begin_inset Formula $Y$
\end_inset

 be an integrable random variable on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 and let 
\begin_inset Formula $\mathcal{G}\subseteq\mathcal{F}$
\end_inset

 be a sigma-field of 
\begin_inset Formula $\Omega$
\end_inset

.
 The conditional expectation of 
\begin_inset Formula $Y$
\end_inset

 given 
\begin_inset Formula $\mathcal{G}$
\end_inset

 is the random variable denoted by 
\begin_inset Formula $\mathbb{E}[Y|\mathcal{G}]$
\end_inset

 such that the following hold:
\end_layout

\begin_layout Definition
(a) 
\begin_inset Formula $\mathbb{E}[Y|\mathcal{G}]$
\end_inset

 is 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable.
\end_layout

\begin_layout Definition
In other words, all events pertaining to the random variable 
\begin_inset Formula $\mathbb{E}[Y|\mathcal{G}]$
\end_inset

 are in 
\begin_inset Formula $\mathcal{G}$
\end_inset

.
\end_layout

\begin_layout Definition
(b) For any (bounded) random variable 
\begin_inset Formula $W$
\end_inset

, that is 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable,
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
\mathbb{E}[WY] & =\mathbb{E}[W\mathbb{E}[Y|\mathcal{G}]]
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
In other words, 
\begin_inset Formula $\mathbf{E}[Y|\mathcal{G}]$
\end_inset

 is a proxy for 
\begin_inset Formula $Y$
\end_inset

 as far as the events in 
\begin_inset Formula $\mathcal{G}$
\end_inset

 are concerned.
 
\end_layout

\begin_layout Definition
Note that, by taking 
\begin_inset Formula $W=1$
\end_inset

 in the property (B), we recover:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
\mathbf{E}[\mathbf{E}[Y|\mathcal{G}]] & =\mathbf{E}[Y]
\end{align*}

\end_inset


\end_layout

\begin_layout Remark*
Beware of the notation! If 
\begin_inset Formula $\mathcal{G}=\sigma(X)$
\end_inset

, then the conditional expectation 
\begin_inset Formula $\mathbf{E}[Y|\sigma(X)]$
\end_inset

 is usually denoted by 
\begin_inset Formula $\mathbf{E}[Y|X]$
\end_inset

 for short.
 However, one should always keep in mind that conditioning on 
\begin_inset Formula $X$
\end_inset

 is in fact projecting on the linear subspace 
\emph on
generated by all variables constructed from 
\begin_inset Formula $X$
\end_inset


\emph default
 and not on the linear space generated by generated by 
\begin_inset Formula $X$
\end_inset

 alone.
 In the same way, the conditional expectation 
\begin_inset Formula $\mathbf{E}[Z|\sigma(X,Y)]$
\end_inset

 is often written 
\begin_inset Formula $\mathbf{E}[Z|X,Y]$
\end_inset

 for short.
 
\end_layout

\begin_layout Remark*
As expected, if 
\begin_inset Formula $Y$
\end_inset

 is in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

, then 
\begin_inset Formula $\mathbf{E}[Y|\mathcal{G}]$
\end_inset

 is given by the orthogonal projection of 
\begin_inset Formula $Y$
\end_inset

 onto the subspace 
\begin_inset Formula $L^{2}(\Omega,\mathcal{G},\mathbb{P})$
\end_inset

, the subspace of square integrable random variables that are 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable.
 We write 
\begin_inset Formula $Y^{\star}$
\end_inset

 for the random variable in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{G},\mathbb{P})$
\end_inset

 that is closest to 
\begin_inset Formula $Y$
\end_inset

 that is:
\end_layout

\begin_layout Remark*
\begin_inset Formula 
\begin{align}
\min_{Z\in L^{2}(\Omega,\mathcal{G},\mathbb{P})}\mathbf{E}[(Y-Z)^{2}] & =\mathbf{E}[(Y-Y^{\star})^{2}]\label{eq:conditional-expectation}
\end{align}

\end_inset


\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "th:existence-and-uniqueness-of-conditional-expectations-II"

\end_inset

(Existence and Uniqueness of Conditional Expectations) Let 
\begin_inset Formula $\mathcal{G}\subset\mathcal{F}$
\end_inset

 be a sigma-field of 
\begin_inset Formula $\Omega$
\end_inset

.
 Let 
\begin_inset Formula $Y$
\end_inset

 be a random variable in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Then, the conditional expectation 
\begin_inset Formula $\mathbf{E}[Y|\mathcal{G}]$
\end_inset

 is the random variable 
\begin_inset Formula $Y^{\star}$
\end_inset

 given in the equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:conditional-expectation"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Namely, it is the random variable in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{G},\mathbb{P})$
\end_inset

 that is closest to 
\begin_inset Formula $Y$
\end_inset

 in the 
\begin_inset Formula $L^{2}$
\end_inset

-distance.
 In particular we have the following:
\end_layout

\begin_layout Itemize
It is the orthogonal projection of 
\begin_inset Formula $Y$
\end_inset

 onto 
\begin_inset Formula $L^{2}(\Omega,\mathcal{G},\mathbb{P})$
\end_inset

, that is, 
\begin_inset Formula $Y-Y^{\star}$
\end_inset

 is orthogonal to the random variables in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{G},\mathbb{P})$
\end_inset

.
\end_layout

\begin_layout Itemize
It is unique.
\end_layout

\begin_layout Standard
Again, the result should be interpreted as follows: The conditional expectation
 
\begin_inset Formula $\mathbf{E}[Y|\mathcal{G}]$
\end_inset

 is the best approximation of 
\begin_inset Formula $Y$
\end_inset

 given the information included in 
\begin_inset Formula $\mathcal{G}$
\end_inset

.
 
\end_layout

\begin_layout Remark*
The conditional expectation in fact exists and is unique for any integrable
 random variable 
\begin_inset Formula $Y$
\end_inset

(i.e.
 
\begin_inset Formula $Y\in L^{1}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 as the definition suggests.
 However, there is no orthogonal projection in 
\begin_inset Formula $L^{1}$
\end_inset

, so the intuitive geometric picture is lost.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
tikzset{axis/.style={thick,-latex}}
\end_layout

\begin_layout Plain Layout


\backslash
tikzset{vec/.style={thick,gray,-latex}}
\end_layout

\begin_layout Plain Layout


\backslash
tikzset{vect/.style={dashed,gray,-latex}}
\end_layout

\begin_layout Plain Layout


\backslash
tikzset{base/.style={thin,blue}}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}
\end_layout

\begin_layout Plain Layout

		
\backslash
draw[axis] node [anchor=north] {$O$} (0,0,0) -- (8,0,0);
\end_layout

\begin_layout Plain Layout

		
\backslash
draw[axis] (0,0,0) -- (0,5,0);
\end_layout

\begin_layout Plain Layout

		
\backslash
draw[axis] (0,0,0) -- (0,0,8);
\end_layout

\begin_layout Plain Layout

 	   
\backslash
draw[vec] (0,0,0) -- (4,4,4) node [pos=1.1] {$Y$};
\end_layout

\begin_layout Plain Layout

		
\backslash
draw[vec] (0,0,0) -- (4,0,4) node [pos=1.1] {$Y^{
\backslash
star}=
\backslash
mathbf{E}[Y|
\backslash
mathcal{G}]$};
\end_layout

\begin_layout Plain Layout

		
\backslash
draw[vect] (4,4,4) -- (4,0,4);
\end_layout

\begin_layout Plain Layout

		
\backslash
node (X) at (5.2,2,4) {$Y-
\backslash
mathbf{E}[Y|
\backslash
mathcal{G}]$};
\end_layout

\begin_layout Plain Layout

		
\backslash
draw[base] (0,0,0) -- (7,0,0) -- node [pos=1.1] {$L^2(
\backslash
Omega,
\backslash
mathcal{G},
\backslash
mathbb{P})$} (7,0,7) -- (0,0,7) -- (0,0,0);
\end_layout

\begin_layout Plain Layout

		
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Figure.
 An illustration of the conditional expectation $
\backslash
mathbb{E}[Y|
\backslash
mathcal{G}]$ as an orthogonal projection of $Y$ onto the subspace $L^2(
\backslash
Omega,
\backslash
mathcal{G},
\backslash
mathbb{P})$.
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\end_inset


\end_layout

\begin_layout Example
(Conditional Expectation for Gaussian Vectors.
 II.) Consider the Gaussian vector 
\begin_inset Formula $(X_{1},\ldots,X_{n})$
\end_inset

.
 Without loss of generality, suppose it has mean 
\begin_inset Formula $0$
\end_inset

 and is non-degenerate.
 What is the best approximation of 
\begin_inset Formula $X_{n}$
\end_inset

 given the information 
\begin_inset Formula $X_{1},\ldots,X_{n-1}$
\end_inset

? In other words, what is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\mathbf{E}[X_{n}|\sigma(X_{1},\ldots,X_{n-1})
\]

\end_inset


\end_layout

\begin_layout Example
With example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:sigma(X)-measurable-random-variables-example"
plural "false"
caps "false"
noprefix "false"

\end_inset

 in mind, let's write 
\begin_inset Formula $\mathbf{E}[X_{n}|X_{1}\ldots X_{n-1}]$
\end_inset

 for short.
 From example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:[Arguin-4.1]-Conditional-Expectation-of-continuous-random-variables"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we know that if 
\begin_inset Formula $(X,Y)$
\end_inset

 is a Gaussian vector with mean 
\begin_inset Formula $0$
\end_inset

, then 
\begin_inset Formula $\mathbf{E}[Y|X]$
\end_inset

 is a multiple of 
\begin_inset Formula $X$
\end_inset

.
 Thus, we expect, that 
\begin_inset Formula $\mathbf{E}[X_{n}|X_{1}X_{2}\ldots X_{n-1}]$
\end_inset

 is a linear combination of 
\begin_inset Formula $X_{1},X_{2},\ldots,X_{n-1}$
\end_inset

.
 That is, there exists 
\begin_inset Formula $a_{1},\ldots,a_{n-1}$
\end_inset

 such that:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[X_{n}|X_{1}X_{2}\ldots X_{n-1}] & =a_{1}X_{1}+a_{2}X_{2}+\ldots+a_{n-1}X_{n-1}
\end{align*}

\end_inset

 In particular, since the conditional expectation is a linear combination
 of the 
\begin_inset Formula $X$
\end_inset

's, it is itself a Gaussian random variable.
 The best way to find the coefficient 
\begin_inset Formula $a$
\end_inset

's is to go back to IID decomposition of Gaussian vectors.
 
\end_layout

\begin_layout Example
Let 
\begin_inset Formula $(Z_{1},Z_{2},\ldots,Z_{n-1})$
\end_inset

 be IID standard Gaussians constructed from the linear combination of 
\begin_inset Formula $(X_{1},X_{2},\ldots,X_{n-1})$
\end_inset

.
 Then, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[X_{n}|X_{1}X_{2}\ldots X_{n-1}] & =b_{1}Z_{1}+\ldots+b_{n-1}Z_{n-1}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Now, recall, that we construct the random variables 
\begin_inset Formula $Z_{1}$
\end_inset

, 
\begin_inset Formula $Z_{2}$
\end_inset

, 
\begin_inset Formula $\ldots$
\end_inset

, 
\begin_inset Formula $Z_{n}$
\end_inset

 using Gram-Schmidt orthogonalization:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\tilde{Z_{1}} & =X_{1}, & Z_{1} & =\frac{\tilde{Z_{1}}}{\mathbf{E}(\tilde{Z}_{1}^{2})}\\
\tilde{Z_{2}} & =X_{2}-\mathbf{E}(X_{2}Z_{1})Z_{1} & Z_{2} & =\frac{\tilde{Z}_{2}}{\mathbf{E}(\tilde{Z}_{2}^{2})}\\
\tilde{Z_{3}} & =X_{3}-\sum_{i=1}^{2}\mathbf{E}(X_{3}Z_{i})Z_{i} & Z_{3} & =\frac{\tilde{Z}_{3}}{\mathbf{E}(\tilde{Z}_{3}^{2})}\\
 & \vdots
\end{align*}

\end_inset


\end_layout

\begin_layout Standard

\series bold
The simple case for 
\begin_inset Formula $n=2$
\end_inset

 random variables.
 
\end_layout

\begin_layout Standard
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Standard
We have already seen before:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{E}[X_{1}(X_{2}-\mathbf{E}(X_{2}Z_{1})Z_{1})] & =\mathbf{E}[\tilde{Z}_{1}(X_{2}-\mathbf{E}(X_{2}Z_{1})Z_{1})]\\
 & =\frac{\mathbf{E}[\tilde{Z}_{1}^{2}]}{\mathbf{E}[\tilde{Z}_{1}^{2}]}\times\mathbf{E}\left[\tilde{Z}_{1}(X_{2}-\mathbf{E}(X_{2}Z_{1})Z_{1})\right]\\
 & =\mathbf{E}[\tilde{Z}_{1}^{2}]\times\mathbf{E}\left[\frac{\tilde{Z}_{1}}{\mathbf{E}[\tilde{Z}_{1}^{2}]}(X_{2}-\mathbf{E}(X_{2}Z_{1})Z_{1})\right]\\
 & =\mathbf{E}[\tilde{Z}_{1}^{2}]\times\mathbf{E}[Z_{1}(X_{2}-\mathbf{E}(X_{2}Z_{1})Z_{1})]\\
 & =\mathbf{E}[\tilde{Z}_{1}^{2}]\times\left(\mathbf{E}[Z_{1}X_{2}]-\mathbf{E}(X_{2}Z_{1})\mathbf{E}[Z_{1}^{2}]\right)\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
So,
\begin_inset Formula $X_{2}-\mathbf{E}(X_{2}Z_{1})Z_{1}$
\end_inset

 is orthogonal to 
\begin_inset Formula $X_{1}$
\end_inset

.
\end_layout

\begin_layout Standard
Moreover, 
\begin_inset Formula $\mathbf{E}(X_{2}Z_{1})Z_{1}$
\end_inset

 is a function of 
\begin_inset Formula $X_{1}$
\end_inset

.
 Thus, both the properties of conditional expectation are satisfied.
 Since conditional expectations are unique, we must have, 
\begin_inset Formula $\mathbf{E}[X_{2}|X_{1}]=\mathbf{E}(X_{2}Z_{1})Z_{1}$
\end_inset

.
 
\end_layout

\begin_layout Standard

\series bold
The case for 
\begin_inset Formula $n=3$
\end_inset

 random variables.
\end_layout

\begin_layout Standard
\begin_inset VSpace bigskip
\end_inset

We have seen that:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{E}[X_{1}(X_{3}-\mathbf{E}(X_{3}Z_{1})Z_{1}-\mathbf{E}(X_{3}Z_{2})Z_{2})] & =\frac{\mathbf{E}[\tilde{Z}_{1}^{2}]}{\mathbf{E}[\tilde{Z}_{1}^{2}]}\times\mathbf{E}[\tilde{Z}_{1}(X_{3}-\mathbf{E}(X_{3}Z_{1})Z_{1}-\mathbf{E}(X_{3}Z_{2})Z_{2})]\\
 & =\mathbf{E}[\tilde{Z}_{1}^{2}]\times\mathbf{E}\left\{ \frac{\tilde{Z}_{1}}{\mathbf{E}[\tilde{Z}_{1}^{2}]}(X_{3}-\mathbf{E}(X_{3}Z_{1})Z_{1}-\mathbf{E}(X_{3}Z_{2})Z_{2})\right\} \\
 & =\mathbf{E}[\tilde{Z}_{1}^{2}]\times\mathbf{E}\left\{ Z_{1}(X_{3}-\mathbf{E}(X_{3}Z_{1})Z_{1}-\mathbf{E}(X_{3}Z_{2})Z_{2})\right\} \\
 & =\mathbf{E}[\tilde{Z}_{1}^{2}]\times\mathbf{E}[X_{3}Z_{1}]-\mathbf{E}[X_{3}Z_{1}]\mathbf{E}[Z_{1}^{2}]-\mathbf{E}[X_{3}Z_{2}]\mathbf{E}[Z_{1}Z_{2}]\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
It is an easy exercise to show that it is orthogonal to 
\begin_inset Formula $X_{2}$
\end_inset

.
\end_layout

\begin_layout Standard
Hence, 
\begin_inset Formula $X_{3}-\mathbf{E}(X_{3}Z_{1})Z_{1}-\mathbf{E}(X_{3}Z_{2})Z_{2}$
\end_inset

 is orthogonal to 
\begin_inset Formula $X_{1}$
\end_inset

 and 
\begin_inset Formula $X_{2}$
\end_inset

.
 Moreover, 
\begin_inset Formula $\mathbf{E}(X_{3}Z_{1})Z_{1}+\mathbf{E}(X_{3}Z_{2})Z_{2}$
\end_inset

 is a function of 
\begin_inset Formula $X_{1}$
\end_inset

, 
\begin_inset Formula $X_{2}$
\end_inset

.
 Thus, we must have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{E}[X_{3}|X_{1}X_{2}] & =\mathbf{E}(X_{3}Z_{1})Z_{1}+\mathbf{E}(X_{3}Z_{2})Z_{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In general, 
\begin_inset Formula $X_{n}-\sum_{i=1}^{n-1}\mathbf{E}(X_{n}Z_{i})Z_{i}$
\end_inset

 is orthogonal to 
\begin_inset Formula $X_{1}$
\end_inset

, 
\begin_inset Formula $X_{2}$
\end_inset

, 
\begin_inset Formula $\ldots$
\end_inset

, 
\begin_inset Formula $X_{n-1}$
\end_inset

.
 Hence,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{E}[X_{n}|X_{1}X_{2}\ldots X_{n-1}] & =\sum_{i=1}^{n-1}\mathbf{E}(X_{n}Z_{i})Z_{i}
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection
Properties of Conditional Expectation.
\end_layout

\begin_layout Standard
We now list the properties of conditional expectation that follow from the
 two defining properties (A), (B) in the definition.
 They are extremely useful, when doing explicit computations on martingales.
 A good way to remember them is to understand how they relate to the interpretat
ion of conditional expectation as an orthogonal projection onto a subspace
 or, equivalently, as the best approximation of the variable given the informati
on available.
 
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:properties-of-conditional-expectation"

\end_inset

Let 
\begin_inset Formula $Y$
\end_inset

 be an integrable random variable on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Let 
\begin_inset Formula $\mathcal{G}\subseteq\mathcal{F}$
\end_inset

 be another sigma-field of 
\begin_inset Formula $\Omega$
\end_inset

.
 Then, the conditional expectation 
\begin_inset Formula $\mathbf{E}[Y|\mathcal{G}]$
\end_inset

 has the following properties:
\end_layout

\begin_layout Proposition
(1) If 
\begin_inset Formula $Y$
\end_inset

 is 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable, then :
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Y|\mathcal{G}] & =Y
\end{align*}

\end_inset


\end_layout

\begin_layout Proposition
(2) Taking out what is known.
 More generally, if 
\begin_inset Formula $Y$
\end_inset

 is 
\begin_inset Formula $\mathcal{G-}$
\end_inset

measurable and 
\begin_inset Formula $X$
\end_inset

 is another integrable random variable (with 
\begin_inset Formula $XY$
\end_inset

 also integrable), then :
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
\mathbf{E}[XY|\mathcal{G}] & =Y\mathbf{E}[X|\mathcal{G}]
\end{align*}

\end_inset


\end_layout

\begin_layout Proposition
This makes sense, since 
\begin_inset Formula $Y$
\end_inset

 is determined by 
\begin_inset Formula $\mathcal{G}$
\end_inset

, so we can take out what is known; it can be treated as a constant for
 the conditional expectation.
 
\end_layout

\begin_layout Proposition
(3) Independence.
 If 
\begin_inset Formula $Y$
\end_inset

 is independent of 
\begin_inset Formula $\mathcal{G}$
\end_inset

, that is, for any events 
\begin_inset Formula $\{Y\in(a,b]\}$
\end_inset

 and 
\begin_inset Formula $A\in\mathcal{G}$
\end_inset

:
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
\mathbb{P}(\{Y\in I\}\cap A) & =\mathbb{P}(\{Y\in I\})\cdot\mathbb{P}(A)
\end{align*}

\end_inset


\end_layout

\begin_layout Proposition
then
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Y|\mathcal{G}] & =\mathbf{E}[Y]
\end{align*}

\end_inset


\end_layout

\begin_layout Proposition
In other words, if you have no information on 
\begin_inset Formula $Y$
\end_inset

, your best guess for its value is simply plain expectation.
 
\end_layout

\begin_layout Proposition
(4) Linearity of conditional expectations.
 Let 
\begin_inset Formula $X$
\end_inset

 be another integrable random variable on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Then,
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
\mathbf{E}[aX+bY|\mathcal{G}] & =a\mathbf{E}[X|\mathcal{G}]+b\mathbf{E}[Y|\mathcal{G}],\quad\text{for any }a,b\in\mathbf{R}
\end{align*}

\end_inset


\end_layout

\begin_layout Proposition
The linearity justifies the cumbersom choice of notation 
\begin_inset Formula $\mathbf{E}[Y|\mathcal{G}]$
\end_inset

 for the random variable.
\end_layout

\begin_layout Proposition
(5) Tower Property : If 
\begin_inset Formula $\mathcal{H}\subseteq\mathcal{G}$
\end_inset

 is another sigma-field of 
\begin_inset Formula $\Omega$
\end_inset

, then:
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Y|\mathcal{H}] & =\mathbf{E}[\mathbf{E}[Y|\mathcal{G}]|\mathcal{H}]
\end{align*}

\end_inset


\end_layout

\begin_layout Proposition
Think in terms of two successive projections: first on a plane, then on
 a line in the plane.
 
\end_layout

\begin_layout Proposition
(6) Pythagoras Theorem.
 We have:
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Y^{2}] & =\mathbf{E}\left[\left(\mathbf{E}[Y|\mathcal{G}]\right)^{2}\right]+\mathbf{E}\left[\left(Y-\mathbf{E}[Y|\mathcal{G}]\right)^{2}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proposition
In particular:
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\left(\mathbf{E}\left[Y|\mathcal{G}\right]\right)^{2}\right] & \leq\mathbf{E}[Y^{2}]
\end{align*}

\end_inset


\end_layout

\begin_layout Proposition
In words, the 
\begin_inset Formula $L^{2}$
\end_inset

 norm of 
\begin_inset Formula $\mathbf{E}[X|\mathcal{G}]$
\end_inset

 is smaller than the one of 
\begin_inset Formula $X$
\end_inset

, which is clear if you think in terms of orthogonal projection.
 
\end_layout

\begin_layout Proposition
(7) Expectation of the conditional expectation.
 
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\mathbf{E}[Y|\mathcal{G}]\right] & =\mathbf{E}[Y]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard

\emph on
Proof.
 
\end_layout

\begin_layout Standard
The uniqueness property of conditional expectations in theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:existence-and-uniqueness-of-conditional-expectations-II"
plural "false"
caps "false"
noprefix "false"

\end_inset

 might appear to be an academic curiosity.
 On the contrary, it is very practical, since it ensures, that if we find
 a candidate for the conditional expectation that has the two properties
 in Definition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "def:conditional-expectation"
plural "false"
caps "false"
noprefix "false"

\end_inset

, then it must be 
\emph on
the
\emph default
 conditional expectation.
 To see this, let's prove property (1).
\end_layout

\begin_layout Claim
If 
\begin_inset Formula $Y$
\end_inset

 is 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable, then 
\begin_inset Formula $\mathbf{E}[Y|\mathcal{G}]=Y$
\end_inset

.
\end_layout

\begin_layout Claim
It suffices to show that 
\begin_inset Formula $Y$
\end_inset

 has the two defining properties of conditional expectation.
 
\end_layout

\begin_layout Claim
(1) We are given that, 
\begin_inset Formula $Y$
\end_inset

 is 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable.
 So, property (A) is satisfied.
\end_layout

\begin_layout Claim
(2) For any bounded random variable 
\begin_inset Formula $W$
\end_inset

 that is 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable, we have:
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{E}[W(Y-Y)] & =\mathbf{E}[0]=0
\end{align*}

\end_inset


\end_layout

\begin_layout Claim
So, property (B) is also a triviality.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Claim
(Taking out what is known.) If 
\begin_inset Formula $Y$
\end_inset

 is 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable and 
\begin_inset Formula $X$
\end_inset

 is another integrable random variable, then:
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{E}[XY|\mathcal{G}] & =Y\mathbf{E}[X|\mathcal{G}]
\end{align*}

\end_inset


\end_layout

\begin_layout Claim
In a similar vein, it suffices to show that, 
\begin_inset Formula $Y\mathbf{E}[X|\mathcal{G}]$
\end_inset

 has the two defining properties of conditional expectation.
\end_layout

\begin_layout Claim
(1) We are given that 
\begin_inset Formula $Y$
\end_inset

 is 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable; from property (1), 
\begin_inset Formula $\mathbf{E}[X|\mathcal{G}]$
\end_inset

 is 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable.
 It follows that, 
\begin_inset Formula $Y\mathbf{E}[X|\mathcal{G}]$
\end_inset

 is 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable.
\end_layout

\begin_layout Claim
(2) From theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:existence-and-uniqueness-of-conditional-expectations-II"
plural "false"
caps "false"
noprefix "false"

\end_inset

, 
\begin_inset Formula $X-\mathbf{E}[X|\mathcal{G}]$
\end_inset

 is orthogonal to the random variables 
\begin_inset Formula $L^{2}(\Omega,\mathcal{G},\mathbb{P})$
\end_inset

.
 So, if 
\begin_inset Formula $W$
\end_inset

 is any bounded 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable random variable, it follows that:
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{E}[WY(X-\mathbf{E}[X|\mathcal{G}])] & =0\\
\implies\mathbf{E}[W\cdot XY] & =\mathbf{E}[WY\mathbf{E}[X|\mathcal{G}]]
\end{align*}

\end_inset


\end_layout

\begin_layout Claim
This closes the proof.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Claim
(Independence.) If 
\begin_inset Formula $Y$
\end_inset

 is independent of 
\begin_inset Formula $\mathcal{G}$
\end_inset

, that is, for all events 
\begin_inset Formula $\{Y\in(a,b]\}$
\end_inset

 and 
\begin_inset Formula $A\in\mathcal{G}$
\end_inset

, 
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{\mathbb{P}}\{Y\in(a,b]\cap A\} & =\mathbb{P}\{Y\in(a,b]\}\cdot\mathbb{P}(A)
\end{align*}

\end_inset


\end_layout

\begin_layout Claim
then
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Y|\mathcal{G}] & =\mathbf{E}[Y]
\end{align*}

\end_inset


\end_layout

\begin_layout Claim
Let us show that 
\begin_inset Formula $\mathbf{E}[Y]$
\end_inset

 has the two defining properties of conditional expectations.
\end_layout

\begin_layout Claim
(1) 
\begin_inset Formula $\mathbf{E}[Y]$
\end_inset

 is a constant and so it is 
\begin_inset Formula $\mathcal{F}_{0}$
\end_inset

 measurable.
 Hence, it is 
\begin_inset Formula $\mathcal{G}$
\end_inset

 measurable.
\end_layout

\begin_layout Claim
(2) If 
\begin_inset Formula $W$
\end_inset

 is another 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable random variable,
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{E}[WY] & =\mathbf{E}[W]\cdot\mathbf{E}[Y]
\end{align*}

\end_inset


\end_layout

\begin_layout Claim
since 
\begin_inset Formula $Y$
\end_inset

 is independent of 
\begin_inset Formula $\mathcal{G}$
\end_inset

 and therefore it is independent of 
\begin_inset Formula $Y$
\end_inset

.
 Hence,
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{E}[W(Y-\mathbf{E}[Y])] & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Claim
Consequently, 
\begin_inset Formula $\mathbf{E}[Y|\mathcal{G}]=\mathbf{E}[Y]$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Claim
(Linearity of conditional expectations) Let 
\begin_inset Formula $X$
\end_inset

 be another integrable random variable on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Then,
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{E}[aX+bY|\mathcal{G}] & =a\mathbf{E}[X|\mathcal{G}]+b\mathbf{E}[Y|\mathcal{G}],\quad\text{for any }a,b\in\mathbf{R}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $\mathbf{E}[X|\mathcal{G}]$
\end_inset

 and 
\begin_inset Formula $\mathbf{E}[Y|\mathcal{G}]$
\end_inset

 are 
\begin_inset Formula $\mathcal{G}-$
\end_inset

measurable, any linear combination of these two random variables is also
 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable.
\end_layout

\begin_layout Standard
Also, if 
\begin_inset Formula $W$
\end_inset

 is any bounded 
\begin_inset Formula $\mathcal{G}-$
\end_inset

measurable random variable, we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{E}[W(aX+bY-(a\mathbf{E}[X|\mathcal{G}]+b\mathbf{E}[Y|\mathcal{G}]))] & =a\mathbf{E}[W(X-\mathbf{E}[X|\mathcal{G}])]\\
 & +b\mathbf{E}[W(Y-\mathbf{E}[Y|\mathcal{G}])]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
By definition, 
\begin_inset Formula $X-\mathbf{E}(X|\mathcal{G})$
\end_inset

 is orthogonal t o the subspace 
\begin_inset Formula $L^{2}(\Omega,\mathcal{G},\mathbb{P})$
\end_inset

 and hence to all 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable random-variables.
 Hence, the two expectations on the right hand side of the above expression
 are 
\begin_inset Formula $0$
\end_inset

.
 Since, conditional expectations are unique, we have the desired result.
\end_layout

\begin_layout Claim
If 
\begin_inset Formula $\mathcal{H}\subseteq\mathcal{G}$
\end_inset

 is another sigma-field of 
\begin_inset Formula $\Omega$
\end_inset

, then 
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Y|\mathcal{H}] & =\mathbf{E}[\mathbf{E}[Y|\mathcal{G}]|\mathcal{H}]
\end{align*}

\end_inset


\end_layout

\begin_layout Claim
Define 
\begin_inset Formula $U:=\mathbf{E}[Y|\mathcal{G}]$
\end_inset

.
 By definition, 
\begin_inset Formula $\mathbf{E}[U|\mathcal{H}]$
\end_inset

 is 
\begin_inset Formula $\mathcal{H}$
\end_inset

-measurable.
\end_layout

\begin_layout Claim
Let 
\begin_inset Formula $W$
\end_inset

 be any bounded 
\begin_inset Formula $\mathcal{H}$
\end_inset

-measurable random variable.
 We have:
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{E}[W\{\mathbf{E}(Y|\mathcal{G})-\mathbf{E}(\mathbf{E}(Y|\mathcal{G})|\mathcal{H})\}] & =\mathbf{E}[W(U-\mathbf{E}(U|\mathcal{H})]
\end{align*}

\end_inset


\end_layout

\begin_layout Claim
But, by definition 
\begin_inset Formula $U-\mathbf{E}(U|\mathcal{H})$
\end_inset

 is always orthogonal to the subspace 
\begin_inset Formula $L^{2}(\Omega,\mathcal{H},\mathbb{P})$
\end_inset

 and hence, 
\begin_inset Formula $\mathbf{E}[W(U-\mathbf{\mathbf{E}}(U|\mathcal{H})]=0$
\end_inset

.
 Since, conditional expectations are unique, we have the desired result.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Claim

\series bold
Pythagoras's theorem
\series default
.
 We have:
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Y^{2}] & =\mathbf{E}[(\mathbf{E}[Y|\mathcal{G}])^{2}]+\mathbf{E}[(Y-\mathbf{E}(Y|\mathcal{G}))^{2}]
\end{align*}

\end_inset


\end_layout

\begin_layout Claim
In particular, 
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{E}[(\mathbf{E}[Y|\mathcal{G}])^{2}] & \leq\mathbf{E}[Y^{2}]
\end{align*}

\end_inset


\end_layout

\begin_layout Claim
Consider the orthogonal decomposition:
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
Y & =\mathbf{E}[Y|\mathcal{G}]+(Y-\mathbf{E}[Y|\mathcal{G}])
\end{align*}

\end_inset


\end_layout

\begin_layout Claim
Squaring on both sides and taking expectations, we have:
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Y^{2}] & =\mathbf{E}[(\mathbf{E}(Y|\mathcal{G}))^{2}]+\mathbf{E}[(Y-\mathbf{E}[Y|\mathcal{G}])^{2}]+2\mathbf{E}\left[\mathbf{E}[Y|\mathcal{G}](Y-\mathbf{E}[Y|\mathcal{G}])\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Claim
By definition of conditional expectation, 
\begin_inset Formula $(Y-\mathbf{E}[Y|\mathcal{G}])$
\end_inset

 is orthogonal to the subspace 
\begin_inset Formula $L^{2}(\Omega,\mathcal{G},\mathbb{P})$
\end_inset

.
 By the properties of conditional expectation, 
\begin_inset Formula $\mathbf{E}[Y|\mathcal{G}]$
\end_inset

 is 
\begin_inset Formula $\mathcal{G}-$
\end_inset

measurable, so it belongs to 
\begin_inset Formula $L^{2}(\Omega,\mathcal{G},\mathbb{P})$
\end_inset

.
 Hence, the dot-product on the right-hand side is 
\begin_inset Formula $0$
\end_inset

.
 Consequently, we have the desired result.
\end_layout

\begin_layout Claim
Moreover, since 
\begin_inset Formula $(Y-\mathbf{E}[Y|\mathcal{G}])^{2}$
\end_inset

 is a non-negative random variable, 
\begin_inset Formula $\mathbf{E}[(Y-\mathbf{E}[Y|\mathcal{G}])^{2}]\geq0$
\end_inset

.
 It follows that: 
\begin_inset Formula $\mathbf{E}[Y^{2}]\geq\mathbf{E}[(\mathbf{E}(Y|\mathcal{G}))^{2}]$
\end_inset

.
\end_layout

\begin_layout Claim
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Claim
Our claim is:
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\mathbf{E}[Y|\mathcal{G}]\right] & =\mathbf{E}[Y]
\end{align*}

\end_inset


\end_layout

\begin_layout Claim
We know that, if 
\begin_inset Formula $W$
\end_inset

 is any bounded 
\begin_inset Formula $\mathcal{G}$
\end_inset

-measurable random variable:
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[WY\right] & =\mathbf{E}[W\mathbf{E}[Y|\mathcal{G}]]
\end{align*}

\end_inset


\end_layout

\begin_layout Claim
Taking 
\begin_inset Formula $W=1$
\end_inset

, we have:
\end_layout

\begin_layout Claim
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[Y\right] & =\mathbf{E}[\mathbf{E}[Y|\mathcal{G}]]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
(Brownian Conditioning II).
 We continue the example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:brownian-conditioning-I"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Let's now compute the conditional expectations 
\begin_inset Formula $\mathbf{E}[e^{aB_{1}}|B_{1/2}]$
\end_inset

 and 
\begin_inset Formula $\mathbf{E}[e^{aB_{1/2}}|B_{1}]$
\end_inset

 for some parameter 
\begin_inset Formula $a$
\end_inset

.
 We shall need the properties of conditional expectation in proposition
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:properties-of-conditional-expectation"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 For the first one we use the fact that 
\begin_inset Formula $B_{1/2}$
\end_inset

 is independent of 
\series bold

\begin_inset Formula $B_{1}-B_{1/2}$
\end_inset


\series default
 to get:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[e^{aB_{1}}|B_{1/2}] & =\mathbf{E}[e^{a((B_{1}-B_{1/2})+B_{1/2})}|B_{1/2}]\\
 & =\mathbf{E}[e^{a(B_{1}-B_{2})}\cdot e^{aB_{1/2}}|B_{1/2}]\\
 & \quad\left\{ \text{Taking out what is known}\right\} \\
 & =e^{aB_{1/2}}\mathbf{E}[e^{a(B_{1}-B_{1/2})}|B_{1/2}]\\
 & =e^{aB_{1/2}}\cdot\mathbf{E}[e^{a(B_{1}-B_{1/2})}]\\
 & \quad\{\text{Independence}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We know that, 
\begin_inset Formula $a(B_{1}-B_{1/2})$
\end_inset

 is a gaussian random variable with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $a^{2}/2$
\end_inset

.
 We also know that, 
\begin_inset Formula $\mathbf{E}[e^{tZ}]=e^{t^{2}/2}$
\end_inset

.
 So, 
\begin_inset Formula $\mathbf{E}[e^{a(B_{1}-B_{1/2})}]=e^{a^{2}/4}$
\end_inset

.
 Consequently, 
\begin_inset Formula $\mathbf{E}[e^{aB_{1}}|B_{1/2}]=e^{aB_{1/2}+a^{2}/4}$
\end_inset

.
\end_layout

\begin_layout Example
The result itself has the form of the MGF of a Gaussian with mean 
\begin_inset Formula $B_{1/2}$
\end_inset

 and variance 
\begin_inset Formula $1/2$
\end_inset

.
 (The MGF of 
\begin_inset Formula $X=\mu+\sigma Z$
\end_inset

, 
\begin_inset Formula $Z=N(0,1)$
\end_inset

 is 
\begin_inset Formula $M_{X}(a)=\exp\left[\mu+\frac{1}{2}\sigma^{2}a^{2}\right]$
\end_inset

.) In fact, this shows that the conditional distribution of 
\begin_inset Formula $B_{1}$
\end_inset

 given 
\begin_inset Formula $B_{1/2}$
\end_inset

 is Gaussian of mean 
\begin_inset Formula $B_{1/2}$
\end_inset

 and variance 
\begin_inset Formula $1/2$
\end_inset

.
 
\end_layout

\begin_layout Example
For the other expectation, note that 
\begin_inset Formula $B_{1/2}-\frac{1}{2}B_{1}$
\end_inset

 is independent of 
\begin_inset Formula $B_{1}$
\end_inset

.
 We have: 
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\left(B_{1/2}-\frac{1}{2}B_{1}\right)B_{1}\right] & =\mathbf{E}(B_{1/2}B_{1})-\frac{1}{2}\mathbf{E}[B_{1}^{2}]\\
 & =\frac{1}{2}-\frac{1}{2}\cdot1\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Therefore, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[e^{aB_{1/2}}|B_{1}] & =\mathbf{E}[e^{a(B_{1/2}-\frac{1}{2}B_{1})+\frac{a}{2}B_{1}}|B_{1}]\\
 & =\mathbf{E}[e^{a(B_{1/2}-\frac{1}{2}B_{1})}\cdot e^{\frac{a}{2}B_{1}}|B_{1}]\\
 & =e^{\frac{a}{2}B_{1}}\mathbf{E}[e^{a(B_{1/2}-\frac{1}{2}B_{1})}|B_{1}]\\
 & \quad\{\text{Taking out what is known }\}\\
 & =e^{\frac{a}{2}B_{1}}\mathbf{E}[e^{a(B_{1/2}-\frac{1}{2}B_{1})}]\\
 & \quad\{\text{Independence}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Now, 
\begin_inset Formula $a(B_{1/2}-\frac{1}{2}B_{1})$
\end_inset

 is a random variable with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $a^{2}(\frac{1}{2}-\frac{1}{4})=\frac{a^{2}}{4}$
\end_inset

.
 Consequently, 
\begin_inset Formula $\mathbf{E}[e^{(a/2)Z}]=e^{\frac{a^{2}}{8}}$
\end_inset

.
 Thus, 
\begin_inset Formula $\mathbf{E}[e^{aB_{1/2}}|B_{1}]=e^{\frac{a}{2}B_{1}+\frac{a^{2}}{8}}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(Brownian bridge is conditioned Brownian motion).
 We know that the Brownian bridge 
\begin_inset Formula $M_{t}=B_{t}-tB_{1}$
\end_inset

, 
\begin_inset Formula $t\in[0,1]$
\end_inset

 is independent of 
\begin_inset Formula $B_{1}$
\end_inset

.
 We use this to show that the conditional distribution of the Brownian motion
 given the value at the end-point 
\begin_inset Formula $B_{1}$
\end_inset

 is the one of a Brownian bridge shifted by the straight line going from
 
\begin_inset Formula $0$
\end_inset

 to 
\begin_inset Formula $B_{1}$
\end_inset

.
 To see this, we compute the conditional MGF of 
\begin_inset Formula $(B_{t_{1}},B_{t_{2}},\ldots,B_{t_{n}})$
\end_inset

 given 
\begin_inset Formula $B_{1}$
\end_inset

 for some arbitrary choices of 
\begin_inset Formula $t_{1},t_{2},\ldots,t_{n}$
\end_inset

 in 
\begin_inset Formula $[0,1]$
\end_inset

.
 We get the following by adding and subtracting 
\begin_inset Formula $t_{j}B_{1}$
\end_inset

:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[e^{a_{1}B_{t_{1}}+\ldots+a_{n}B_{t_{n}}}|B_{1}] & =\mathbf{E}[e^{a_{1}(B_{t_{1}}-t_{1}B_{1})+\ldots+a_{n}(B_{t_{n}}-t_{n}B_{1})}\cdot e^{(a_{1}t_{1}B_{1}+\ldots+a_{n}t_{n}B_{1})}|B_{1}]\\
 & =e^{(a_{1}t_{1}B_{1}+\ldots+a_{n}t_{n}B_{1})}\mathbf{E}[e^{a_{1}M_{t_{1}}+\ldots+a_{n}M_{t_{n}}}|B_{1}]\\
 & \quad\{\text{Taking out what is known}\}\\
 & =e^{(a_{1}t_{1}B_{1}+\ldots+a_{n}t_{n}B_{1})}\mathbf{E}[e^{a_{1}M_{t_{1}}+\ldots+a_{n}M_{t_{n}}}]\\
 & \quad\{\text{Independence}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The right side is exactly the MGF of the process 
\begin_inset Formula $M_{t}+tB_{1},t\in[0,1]$
\end_inset

 (for a fixed value 
\begin_inset Formula $B_{1})$
\end_inset

, where 
\begin_inset Formula $(M_{t},t\in[0,1])$
\end_inset

 is a Brownian bridge.
 This proves the claim.
\end_layout

\begin_layout Lemma
(Conditional Jensen's Inequality) If 
\begin_inset Formula $c$
\end_inset

 is a convex function on 
\begin_inset Formula $\mathbf{R}$
\end_inset

 and 
\begin_inset Formula $X$
\end_inset

 is a random variable on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

, then:
\end_layout

\begin_layout Lemma
\begin_inset Formula 
\begin{align*}
\mathbf{E}[c(X)] & \geq c(\mathbf{E}[X])
\end{align*}

\end_inset


\end_layout

\begin_layout Lemma
More generally, if 
\begin_inset Formula $\mathcal{G}\subseteq\mathcal{F}$
\end_inset

 is a sigma-field, then:
\end_layout

\begin_layout Lemma
\begin_inset Formula 
\begin{equation}
\mathbf{E}[c(X)|\mathcal{G}]\geq c(\mathbf{E}[X|\mathcal{G}])
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
We know that, if 
\begin_inset Formula $c(x)$
\end_inset

 is a convex function, the tangent to the curve 
\begin_inset Formula $c$
\end_inset

 at any point lies below the curve.
 The tangent to the cuve at this point, is a straight-line of the form:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
c(t)=y & =mt+c
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
where 
\begin_inset Formula $m(t)=c'(t)$
\end_inset

.
 This holds for all 
\begin_inset Formula $t\in\mathbf{R}$
\end_inset

.
 At an arbitrary point 
\begin_inset Formula $x$
\end_inset

 we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
c(x)\geq & y=mx+c
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Therefore, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
c(x)-c(t) & \geq m(t)(x-t)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
for any 
\begin_inset Formula $x$
\end_inset

 and any point of tangency 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
c(X)-c(Y) & \geq m(Y)(X-Y)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Substituting 
\begin_inset Formula $Y=\mathbf{E}[X|\mathcal{G}]$
\end_inset

, we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
c(X)-c(\mathbf{E}[X|\mathcal{G}]) & \geq m(\mathbf{E}[X|\mathcal{G}])(X-\mathbf{E}[X|\mathcal{G}])
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Taking expectations on both sides, we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[(c(X)-c(\mathbf{E}[X|\mathcal{G}]))|\mathcal{G}] & \geq\mathbf{E}[m(\mathbf{E}[X|\mathcal{G}])(X-\mathbf{E}[X|\mathcal{G}])|\mathcal{G}]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The left-hand side simplifies as:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[(c(X)-c(\mathbf{E}[X|\mathcal{G}]))|\mathcal{G}] & =\mathbf{E}[c(X)|\mathcal{G}]-\mathbf{E}[c(\mathbf{E}[X|\mathcal{G}]))|\mathcal{G}]\\
 & \quad\{\text{Linearity}\}\\
 & =\mathbf{E}[c(X)|\mathcal{G}]-c(\mathbf{E}[X|\mathcal{G}])\\
 & \quad\{\text{c(\mathbf{E}[X|\mathcal{G}])) is \ensuremath{\mathcal{G}}-measurable}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
On the right hand side, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[m(\mathbf{E}[X|\mathcal{G}])(X-\mathbf{E}[X|\mathcal{G}])|\mathcal{G}] & =\mathbf{E}[m(\mathbf{E}[X|\mathcal{G}])\cdot X|\mathcal{G}]-\mathbf{E}[m(\mathbf{E}[X|\mathcal{G}])\cdot\mathbf{E}[X|\mathcal{G}]|\mathcal{G}]\\
 & =\mathbf{E}[X|\mathcal{G}]m(\mathbf{E}[X|\mathcal{G}])-m(\mathbf{E}[X|\mathcal{G}])\cdot\mathbf{E}[X|\mathcal{G}]\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Consequently, it follows that 
\begin_inset Formula $\mathbf{E}[c(X)|\mathcal{G}]\geq c(\mathbf{E}[X|\mathcal{G}])$
\end_inset

.
\end_layout

\begin_layout Example
(Embeddings of 
\begin_inset Formula $L^{p}$
\end_inset

 spaces) Square-integrable random variables are in fact integrable.
 In other words, there is always the inclusion 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})\subseteq L^{1}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 In particular, square integrable random variables always have a well-defined
 variance.
 This embedding is a simple consequence of Jensen's inequality since:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
|\mathbf{E}[X]|^{2} & \leq\mathbf{E}[|X|^{2}]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
as 
\begin_inset Formula $f(x)=|x|^{2}$
\end_inset

 is convex.
 By taking the square root on both sides, we get:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\left\Vert X\right\Vert _{1} & \leq\left\Vert X\right\Vert _{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
More generally, for any 
\begin_inset Formula $1<p<\infty$
\end_inset

, we can define 
\begin_inset Formula $L^{p}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 to be the linear space of random variables such that 
\begin_inset Formula $\mathbf{E}[|X|^{p}]<\infty$
\end_inset

.
 Then for 
\begin_inset Formula $p<q$
\end_inset

, since 
\begin_inset Formula $x^{q/p}$
\end_inset

 is convex, we get by Jensen's inequality :
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[|X|^{q}] & =\mathbf{E}[(|X|^{p})^{\frac{q}{p}}]\geq\left(\mathbf{E}[|X|^{p}]\right)^{\frac{q}{p}}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Taking the 
\begin_inset Formula $q$
\end_inset

-th root on both sides:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[|X|^{p}]^{1/p} & \leq\mathbf{E}[|X|^{q}]^{1/q}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
So, if 
\begin_inset Formula $X\in L^{q}$
\end_inset

, then it must also be in 
\begin_inset Formula $L^{p}$
\end_inset

.
 Concretely, this means that any random variable with a finite 
\begin_inset Formula $q$
\end_inset

-moment will also have a finite 
\begin_inset Formula $p$
\end_inset

-moment, for 
\begin_inset Formula $q>p$
\end_inset

.
\end_layout

\begin_layout Subsection
Martingales.
\end_layout

\begin_layout Standard
We now have all the tools to define martingales.
 
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:Filtration"

\end_inset

(Filtration).
 A 
\emph on
filtration
\emph default
 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

 of 
\begin_inset Formula $\Omega$
\end_inset

 is an increasing sequence of 
\begin_inset Formula $\sigma$
\end_inset

-fields of 
\begin_inset Formula $\Omega$
\end_inset

.
 That is,
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
\mathcal{F}_{s} & \subseteq\mathcal{F}_{t},\quad\forall s\leq t
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
We will usually take 
\begin_inset Formula $\mathcal{F}_{0}=\{\emptyset,\Omega\}$
\end_inset

.
 The canonical example of a filtration is the natural filtration of a given
 process 
\begin_inset Formula $(M_{s}:s\geq0)$
\end_inset

.
 This is the filtration given by 
\begin_inset Formula $\mathcal{F}_{t}=\sigma(M_{s},s\leq t)$
\end_inset

.
 The inclusions of the 
\begin_inset Formula $\sigma$
\end_inset

-fields are then clear.
 For a given Brownian motion 
\begin_inset Formula $(B_{t},t\geq0)$
\end_inset

, the filtration 
\begin_inset Formula $\mathcal{F}_{t}=\sigma(B_{s},s\leq t)$
\end_inset

 is sometimes called the 
\emph on
Brownian filtration
\emph default
.
 We think of the filtration as the 
\emph on
flow of information of the process
\emph default
.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:Adapted-process"

\end_inset

A stochastic process 
\begin_inset Formula $(X_{t}:t\geq0)$
\end_inset

 is said to be adapted to 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

, if for each 
\begin_inset Formula $t$
\end_inset

, the random variable 
\begin_inset Formula $X_{t}$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{t}-$
\end_inset

measurable.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Definition
(Martingale).
 A process 
\begin_inset Formula $(M_{t}:t\geq0)$
\end_inset

 is a martingale for the filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

 if the following hold:
\end_layout

\begin_layout Definition
(1) The process is 
\emph on
adapted
\emph default
, that is 
\begin_inset Formula $M_{t}$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{t}-$
\end_inset

measurable for all 
\begin_inset Formula $t\geq0$
\end_inset

.
\end_layout

\begin_layout Definition
(2) 
\begin_inset Formula $\mathbf{E}[|M_{t}|]<\infty$
\end_inset

 for all 
\begin_inset Formula $t\geq0$
\end_inset

.
 (This ensures that the conditional expectation is well defined.)
\end_layout

\begin_layout Definition
(3) 
\emph on
Martingale property:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
\mathbf{E}[M_{t}|\mathcal{F}_{s}] & =M_{s}\quad\forall s\leq t
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
Roughly, speaking this means that the best approximation of a process at
 a future time 
\begin_inset Formula $t$
\end_inset

 is its value at the present.
 
\end_layout

\begin_layout Standard
In particular, the martingale property implies that:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\mathbf{E}[M_{t}|\mathcal{F}_{0}] & =M_{0}\nonumber \\
\mathbf{E}[\mathbf{E}[M_{t}|\mathcal{F}_{0}]] & =\mathbf{E}[M_{0}]\nonumber \\
\mathbf{E}[M_{t}] & =\mathbf{E}[M_{0}]\label{eq:expected-value-of-martingale-at-any-time-is-constant}\\
 & \quad\{\text{Tower Property}\}\nonumber 
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Usually, we take 
\begin_inset Formula $\mathcal{F}_{0}$
\end_inset

 to be the trivial sigma-field 
\begin_inset Formula $\{\emptyset,\Omega\}$
\end_inset

.
 A random variable that is 
\begin_inset Formula $\mathcal{F}_{0}$
\end_inset

-measurable must be a constant, so 
\begin_inset Formula $M_{0}$
\end_inset

 is a constant.
 In this case, 
\begin_inset Formula $\mathbf{E}[M_{t}]=M_{0}$
\end_inset

 for all 
\begin_inset Formula $t$
\end_inset

.
 If properties (1) and (2) are satisfied, but the best approximation is
 larger, 
\begin_inset Formula $\mathbf{E}[M_{t}|\mathcal{F}_{s}]\geq M_{s}$
\end_inset

, the process is called a 
\emph on
submartingale
\emph default
.
 If it is smaller on average, 
\begin_inset Formula $\mathbf{E}[M_{t}|\mathcal{F}_{s}]\leq\mathbf{E}[M_{s}]$
\end_inset

, we say it is a supermartingale.
\end_layout

\begin_layout Standard
We will be mostly interested in martingales that are continuous and square-integ
rable.
 Continuous martingales are martingales whose paths 
\begin_inset Formula $t\mapsto M_{t}(\omega)$
\end_inset

 are continuous almost surely.
 Square-integrable martingales are such that 
\begin_inset Formula $\mathbf{E}[|M_{t}|^{2}]<\infty$
\end_inset

 for all 
\begin_inset Formula $t$
\end_inset

's.
 This condition is stronger than 
\begin_inset Formula $\mathbf{E}[|M_{t}|]<\infty$
\end_inset

 due to Jensen's inequality.
\end_layout

\begin_layout Remark*
(Martingales in Discrete-time).
 Martingales can be defined the same way if the index set of the process
 is discrete.
 For example, the filtration 
\begin_inset Formula $(\mathcal{F}_{n}:n\in\mathbf{N})$
\end_inset

 is a countable set and the martingale property is then replaced by 
\begin_inset Formula $\mathbf{E}[M_{n+1}|\mathcal{F}_{n}]=M_{n}$
\end_inset

 as expected.
 The tower-property then yields the martingale property 
\begin_inset Formula $\mathbf{E}[M_{n+k}|\mathcal{F}_{n}]=M_{n}$
\end_inset

 for 
\begin_inset Formula $k\geq1$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Remark*
(Continuous Filtrations).
 Filtrations with continuous time can be tricky to handle rigorously.
 For example, one has to make sense of what it means for 
\begin_inset Formula $\mathcal{F}_{s}$
\end_inset

 as 
\begin_inset Formula $s$
\end_inset

 approaches 
\begin_inset Formula $t$
\end_inset

 from the left.
 Is it equal to 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

? Or is there actually less information in 
\begin_inset Formula $\lim_{s\to t^{-}}\mathcal{F}_{s}$
\end_inset

 than in 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

? This is a bit of headache when dealing with processes with jumps, like
 the Poisson process.
 However, if the paths are continuous, the technical problems are not as
 heavy.
 
\end_layout

\begin_layout Remark*
Let's look at some of the important examples of martingales constructed
 from Brownian Motion.
\end_layout

\begin_layout Example
(Examples of Brownian Martingales)
\end_layout

\begin_layout Example
(i) 
\emph on
Standard Brownian Motion.

\emph default
 Let 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

 be a standard Brownian motion and let 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

 be a 
\emph on
Brownian filtration
\emph default
.
 Then 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

 is a square integrable martingale for the filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

.
 Property (1) is obvious, because all the sets in 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

 are resolved, upon observing the outcome of 
\begin_inset Formula $B_{t}$
\end_inset

.
 Similarly, 
\begin_inset Formula $\mathbf{E}[|B_{t}|]=0$
\end_inset

.
 As for the martingale property, note that, by the properties of conditional
 expectation in proposition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:properties-of-conditional-expectation"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we have: 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[B_{t}|\mathcal{F}_{s}] & =\mathbf{E}[B_{t}|B_{s}]\\
 & =\mathbf{E}[B_{t}-B_{s}+B_{s}|B_{s}]\\
 & =\mathbf{E}[B_{t}-B_{s}|B_{s}]+\mathbf{E}[B_{s}|B_{s}]\\
 & \quad\{\text{Linearity}\}\\
 & =\mathbf{E}[B_{t}-B_{s}]+B_{s}\\
 & \quad\{\text{Independence}\}\\
 & =B_{s}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
(ii) 
\emph on
Geometric Brownian Motion.

\emph default
 Let 
\begin_inset Formula $(B_{t},t\ge0)$
\end_inset

 be a standard brownian motion, and 
\begin_inset Formula $\mathcal{F}_{t}=\sigma(B_{s},s\leq t)$
\end_inset

.
 A 
\emph on
geometric brownian motion 
\emph default
is a process 
\begin_inset Formula $(S_{t},t\geq0)$
\end_inset

 defined by:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
S_{t} & =S_{0}\exp\left(\sigma B_{t}+\mu t\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
for some parameter 
\begin_inset Formula $\sigma>0$
\end_inset

 and 
\begin_inset Formula $\mu\in\mathbf{R}$
\end_inset

.
 This is simply the exponential of the Brownian motion with drift.
 This is not a martingale for most choices of 
\begin_inset Formula $\mu$
\end_inset

! In fact, one must take 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mu & =-\frac{1}{2}\sigma^{2}
\end{align*}

\end_inset

 for the process to be a martingale for the Brownian filtration.
 Let's verify this.
 Property (1) is obvious since 
\begin_inset Formula $S_{t}$
\end_inset

 is a function of 
\begin_inset Formula $B_{t}$
\end_inset

 for each 
\begin_inset Formula $t$
\end_inset

.
 So, it is 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

 measurable.
 Moreover, property (2) is clear: 
\begin_inset Formula $\mathbf{E}[\exp(\sigma B_{t}+\mu t)]=\mathbf{E}[\exp(\sigma\sqrt{t}Z+\mu t)]=\exp(\mu t+\frac{1}{2}\sigma^{2}t)$
\end_inset

.
 So, its a finite quantity.
 As for the martingale property, note that by the properties of conditional
 expectation, and the MGF of Gaussians, we have for 
\begin_inset Formula $s\leq t$
\end_inset

:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[S_{t}|\mathcal{F}_{s}] & =\mathbf{E}\left[S_{0}\exp\left(\sigma B_{t}-\frac{1}{2}\sigma^{2}t\right)|\mathcal{F}_{s}\right]\\
 & =S_{0}\exp(-\frac{1}{2}\sigma^{2}t)\mathbf{E}[\exp(\sigma(B_{t}-B_{s}+B_{s}))|\mathcal{F}_{s}]\\
 & =S_{0}\exp(-\frac{1}{2}\sigma^{2}t)\exp(\sigma B_{s})\mathbf{E}[\exp(\sigma(B_{t}-B_{s}))|\mathcal{F}_{s}]\\
 & \quad\{\text{Taking out what is known}\}\\
 & =S_{0}\exp\left(\sigma B_{s}-\frac{1}{2}\sigma^{2}t\right)\mathbf{E}\left[\exp\left(\sigma(B_{t}-B_{s})\right)\right]\\
 & \quad\{\text{Independence}\}\\
 & =S_{0}\exp\left(\sigma B_{s}-\frac{1}{2}\sigma^{2}t+\frac{1}{2}\sigma^{2}(t-s)\right)\\
 & =S_{0}\exp(\sigma B_{s}-\frac{1}{2}\sigma^{2}s)\\
 & =S_{s}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We will sometimes abuse terminology and refer to the martingale case of
 geometric brownian motion simply as geometric Brownian Motion when the
 context is clear.
\end_layout

\begin_layout Example
(iii) 
\emph on
The square of the Brownian motion, compensated
\emph default
.
 It is easy to check 
\begin_inset Formula $(B_{t}^{2},t\geq0)$
\end_inset

 is a submartingale by direct computation using increments or by Jensen's
 inequality: 
\begin_inset Formula $\mathbf{E}[B_{t}^{2}|\mathcal{F}_{s}]>(\mathbf{E}[B_{t}|\mathcal{F}_{s}])^{2}=B_{s}^{2}$
\end_inset

, 
\begin_inset Formula $s<t$
\end_inset

.
 It is nevertheless possible to compensate to get a martingale:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
M_{t} & =B_{t}^{2}-t
\end{align*}

\end_inset


\end_layout

\begin_layout Example
It is an easy exercise to verify that 
\begin_inset Formula $(M_{t}:t\geq0)$
\end_inset

 is a martingale for the Brownian filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

.
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[M_{t}|\mathcal{F}_{s}] & =\mathbf{E}[B_{t}^{2}-t|\mathcal{F}_{s}]\\
 & =\mathbf{E}[B_{t}^{2}|\mathcal{F}_{s}]-t\\
 & =\mathbf{E}[(B_{t}-B_{s}+B_{s})^{2}|\mathcal{F}_{s}]-t\\
 & =\mathbf{E}[(B_{t}-B_{s})^{2}|\mathcal{F}_{s}]+2\mathbf{E}[(B_{t}-B_{s})B_{s}|\mathcal{F}_{s}]+\mathbf{E}[B_{s}^{2}|\mathcal{F}_{s}]-t\\
 & =\mathbf{E}[(B_{t}-B_{s})^{2}]+2B_{s}\mathbf{E}[(B_{t}-B_{s})|\mathcal{F}_{s}]+B_{s}^{2}-t\\
 & =\mathbf{E}[(B_{t}-B_{s})^{2}]+2B_{s}\mathbf{E}[(B_{t}-B_{s})]+B_{s}^{2}-t\\
 & \left\{ \begin{array}{c}
\text{\ensuremath{(B_{t}-B_{s})} is independent of \ensuremath{\mathcal{F}_{s}}}\\
\text{Also, \ensuremath{B_{s}} is known at time \ensuremath{s}}
\end{array}\right\} \\
 & =(t-s)+2B_{s}\cdot0+B_{s}^{2}-t\\
 & =B_{s}^{2}-s\\
 & =M_{s}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(Other important martingales).
\end_layout

\begin_layout Example
(1) 
\emph on
Symmetric random walks.
 
\emph default
This is an example of a martingale in discrete time.
 Take 
\begin_inset Formula $(X_{i}:i\in\mathbf{N})$
\end_inset

 to be IID random variables with 
\begin_inset Formula $\mathbf{E}[X_{i}]=0$
\end_inset

 and 
\begin_inset Formula $\mathbf{E}[|X_{i}|]<\infty$
\end_inset

.
 Take 
\begin_inset Formula $\mathcal{F}_{n}=\sigma(X_{i},i\leq n)$
\end_inset

 and 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
S_{n} & =X_{1}+X_{2}+\ldots+X_{n},\quad S_{0}=0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Firstly, the information learned by observing the outcomes of 
\begin_inset Formula $X_{1}$
\end_inset

,
\begin_inset Formula $\ldots$
\end_inset

,
\begin_inset Formula $X_{n}$
\end_inset

 is enough to completely determine 
\begin_inset Formula $S_{n}$
\end_inset

.
 Hence, 
\begin_inset Formula $S_{n}$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{n}-$
\end_inset

measurable.
\end_layout

\begin_layout Example
Next, 
\begin_inset Formula 
\begin{align*}
|S_{n}| & =\left|\sum_{i=1}^{n}X_{i}\right|\\
 & \leq\sum_{i=1}^{n}|X_{i}|
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Consequently, by the montonocity of expectations, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[|S_{n}|] & \leq\sum_{i=1}^{n}\mathbf{E}[|X_{i}|]<\infty
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The martingale property is also satisfied.
 We have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[S_{n+1}|\mathcal{F}_{n}] & =\mathbf{E}[S_{n}+X_{n+1}|\mathcal{F}_{n}]\\
 & =\mathbf{E}[S_{n}|\mathcal{F}_{n}]+\mathbf{E}[X_{n+1}|\mathcal{F}_{n}]\\
 & =S_{n}+\mathbf{E}[X_{n+1}]\\
 & \left\{ \begin{array}{c}
\text{\ensuremath{S_{n}} is \ensuremath{\mathcal{F}_{n}}-measurable}\\
\text{\ensuremath{X_{n+1}} is independent of \ensuremath{\mathcal{F}_{n}}}
\end{array}\right\} \\
 & =S_{n}+0\\
 & =S_{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
(2) 
\emph on
Compensated Poisson process
\emph default
.
 Let 
\begin_inset Formula $(N_{t}:t\geq0)$
\end_inset

 be a Poisson process with rate 
\begin_inset Formula $\lambda$
\end_inset

 and 
\begin_inset Formula $\mathcal{F}_{t}=\sigma(N_{s},s\leq t)$
\end_inset

.
 Then, 
\begin_inset Formula $N_{t}$
\end_inset

 is a submartingale for its natural filtration.
 Again, properties (1) and (2) are easily checked.
 
\begin_inset Formula $N_{t}$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

 measurable.
 Moreover, 
\begin_inset Formula $\mathbf{E}[|N_{t}|]=\mathbf{E}[N_{t}]=\frac{1}{\lambda t}<\infty$
\end_inset

.
 The submartingale property follows by the independence of increments :
 for 
\begin_inset Formula $s\leq t$
\end_inset

,
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[N_{t}|\mathcal{F}_{s}] & =\mathbf{E}[N_{t}-N_{s}+N_{s}|\mathcal{F}_{s}]\\
 & =\mathbf{E}[N_{t}-N_{s}|\mathcal{F}_{s}]+\mathbf{E}[N_{s}|\mathcal{F}_{s}]\\
 & =\mathbf{E}[N_{t}-N_{s}]+N_{s}\\
 & =\lambda(t-s)+N_{s}\\
 & \left\{ \because\mathbf{E}[N_{t}]=\lambda t\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Example
More importantly, we get a martingale by slightly modifying the process.
 Indeed, if we subtract 
\begin_inset Formula $\lambda t$
\end_inset

, we have that the process :
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
M_{t} & =N_{t}-\lambda t
\end{align*}

\end_inset


\end_layout

\begin_layout Example
is a martingale.
 We have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[M_{t}|\mathcal{F}_{s}] & =\mathbf{E}[N_{t}-\lambda t|\mathcal{F}_{s}]\\
 & =\lambda t-\lambda s+N_{s}-\lambda t\\
 & =N_{s}-\lambda s\\
 & =M_{s}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
This is called the 
\emph on
compensated Poisson process
\emph default
.
 Let us simulate 
\begin_inset Formula $10$
\end_inset

 paths of the compensated poisson process on 
\begin_inset Formula $[0,10]$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{language=Python,backgroundcolor=
\backslash
color{backcolour},breaklines=true,commentstyle=
\backslash
color{codegreen},stringstyle=
\backslash
color{magenta},keywordstyle=
\backslash
bfseries
\backslash
color{blue!40!black},basicstyle=
\backslash
footnotesize
\backslash
ttfamily,frame=single}
\end_layout

\begin_layout Plain Layout


\backslash
begin{lstlisting}[caption=Generating 10 paths of a compensated Poisson process]
\end_layout

\begin_layout Plain Layout

import numpy as np
\end_layout

\begin_layout Plain Layout

import matplotlib.pyplot as plt
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# Generates a sample path of a compensated poisson process 
\end_layout

\begin_layout Plain Layout

# with rate : `lambda_` per unit time
\end_layout

\begin_layout Plain Layout

# on the interval [0,T], and subintervals of size `stepSize`.
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

def generateCompensatedPoissonPath(lambda_,T,stepSize):
\end_layout

\begin_layout Plain Layout

    N = int(T/stepSize)   
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    poissonParam = lambda_ * stepSize   	 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    x = np.random.poisson(lam=poissonParam,size=N)  
\end_layout

\begin_layout Plain Layout

    x = np.concatenate([[0.0], x])
\end_layout

\begin_layout Plain Layout

    N_t = np.cumsum(x)  
\end_layout

\begin_layout Plain Layout

    t = np.linspace(start=0.0,stop=10.0,num=1001)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    M_t = np.subtract(N_t,lambda_ * t)  
\end_layout

\begin_layout Plain Layout

    return M_t
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

t = np.linspace(0,10,1001)
\end_layout

\begin_layout Plain Layout

plt.grid(True)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

plt.xlabel(r'Time $t$')
\end_layout

\begin_layout Plain Layout

plt.ylabel(r'Compensated poisson process $M(t)$')
\end_layout

\begin_layout Plain Layout

plt.grid(True)
\end_layout

\begin_layout Plain Layout

plt.title(r'$10$ paths of the compensated Poisson process on $[0,10]$')
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

for i in range(10):
\end_layout

\begin_layout Plain Layout

    # Generate a poisson path with rate 1 /sec = 0.01 /millisec
\end_layout

\begin_layout Plain Layout

    n_t = generateCompensatedPoissonPath(lambda_=1.0, T=10, stepSize=0.01)
\end_layout

\begin_layout Plain Layout

    plt.plot(t, n_t)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

plt.show()
\end_layout

\begin_layout Plain Layout

plt.close()
\end_layout

\begin_layout Plain Layout


\backslash
end{lstlisting}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/compensated_poisson_process.tex"

\end_inset


\end_layout

\begin_layout Standard
We saw in the two examples, that, even though a process is not itself a
 martingale, we can sometimes 
\emph on
compensate
\emph default
 to obtain a martingale! Ito Calculus will greatly extend this perspective.
 We will have systematic rules that show when a function of Brownian motion
 is a martingale and if not, how to modify it to get one.
 
\end_layout

\begin_layout Standard
For now, we observe that a convex function of a martingale is always a submartin
gale by Jensen's inequality.
 
\end_layout

\begin_layout Corollary
\begin_inset CommandInset label
LatexCommand label
name "corollary:the-convex-function-of-martingale-is-a-submartingale"

\end_inset

If 
\begin_inset Formula $c$
\end_inset

 is a convex function on 
\begin_inset Formula $\mathbf{R}$
\end_inset

 and 
\begin_inset Formula $(M_{t}:t\geq0)$
\end_inset

 is a martingale for 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

, then the process 
\begin_inset Formula $(c(M_{t}):t\geq0)$
\end_inset

 is a submartingale for the same filtration, granted that 
\begin_inset Formula $\mathbf{E}[|c(M_{t})|]<\infty$
\end_inset

.
\end_layout

\begin_layout Proof
The fact that 
\begin_inset Formula $c(M_{t})$
\end_inset

 is adapted to the filtration is clear since it is an explicit function
 of 
\begin_inset Formula $M_{t}$
\end_inset

.
 The integrability is by assumption.
 The submartingale property is checked as follows:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[c(M_{t})|\mathcal{F}_{s}] & \geq c(\mathbf{E}[M_{t}|\mathcal{F}_{s}])=c(M_{s})
\end{align*}

\end_inset


\end_layout

\begin_layout Remark*
(The Doob-Meyer Decomposition Theorem).
 Let 
\begin_inset Formula $(X_{n}:n\in\mathbf{N})$
\end_inset

 be a submartingale with respect to a filtration 
\begin_inset Formula $(\mathcal{F}_{n}:n\in\mathbf{N})$
\end_inset

.
 Define a sequence of random variables 
\begin_inset Formula $(A_{n}:n\in\mathbf{N})$
\end_inset

 by 
\begin_inset Formula $A_{0}=0$
\end_inset

 and 
\end_layout

\begin_layout Remark*
\begin_inset Formula 
\begin{align*}
A_{n} & =\sum_{i=1}^{n}(\mathbf{E}[X_{i}|\mathcal{F}_{i-1}]-X_{i-1}),\quad n\geq1
\end{align*}

\end_inset


\end_layout

\begin_layout Remark*
Note that 
\begin_inset Formula $A_{n}$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{n-1}$
\end_inset

-measurable.
 Moreover, since 
\begin_inset Formula $(X_{n}:n\in\mathbf{N})$
\end_inset

 is a submartingale, we have 
\begin_inset Formula $\mathbf{E}[X_{i}|\mathcal{F}_{i-1}]-X_{i-1}\geq0$
\end_inset

 almost surely.
 Hence, 
\begin_inset Formula $(A_{n}:n\in\mathbf{N})$
\end_inset

 is an increasing sequence almost surely.
 Let 
\begin_inset Formula $M_{n}=X_{n}-A_{n}$
\end_inset

.
 
\end_layout

\begin_layout Remark*
We have:
\end_layout

\begin_layout Remark*
\begin_inset Formula 
\begin{align*}
\mathbf{E}[M_{n}|\mathcal{F}_{n-1}] & =\mathbf{E}[X_{n}-A_{n}|\mathcal{F}_{n-1}]\\
 & =\mathbf{E}[X_{n}|\mathcal{F}_{n-1}]-\mathbf{E}[A_{n}|\mathcal{F}_{n-1}]\\
 & =\mathbf{E}[X_{n}|\mathcal{F}_{n-1}]-\mathbf{E}\left[\left.\mathbf{E}[X_{n}|\mathcal{F}_{n-1}]-X_{n-1}+A_{n-1}\right|\mathcal{F}_{n-1}\right]\\
 & =\mathbf{E}[X_{n}|\mathcal{F}_{n-1}]-\mathbf{E}[X_{n}|\mathcal{F}_{n-1}]+\mathbf{E}[X_{n-1}|\mathcal{F}_{n-1}]-\mathbf{E}[A_{n-1}|\mathcal{F}_{n-1}]\\
 & =\cancel{\mathbf{E}[X_{n}|\mathcal{F}_{n-1}]}-\cancel{\mathbf{E}[X_{n}|\mathcal{F}_{n-1}]}+X_{n-1}-A_{n-1}\\
 & =M_{n-1}
\end{align*}

\end_inset


\end_layout

\begin_layout Remark*
Thus, 
\begin_inset Formula $(M_{n}:n\in\mathbf{N})$
\end_inset

 is a martingale.
 Thus, we have obtained the Doob decomposition:
\end_layout

\begin_layout Remark*
\begin_inset Formula 
\begin{align}
X_{n} & =M_{n}+A_{n}\label{eq:doob-decomposition}
\end{align}

\end_inset


\end_layout

\begin_layout Remark*
This decomposition of a submartingale as a sum of a martingale and an adapted
 increasing sequence is unique, if we require that 
\begin_inset Formula $A_{0}=0$
\end_inset

 and that 
\begin_inset Formula $A_{n}$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{n-1}$
\end_inset

-measurable.
\end_layout

\begin_layout Remark*
For the continuous-time case, the situation is much more complicated.
 The analogue of equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:doob-decomposition"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is called the 
\emph on
Doob-Meyer decomposition
\emph default
.
 We briefly describe this decomposition and avoid the technical details.
 All stochastic processes 
\begin_inset Formula $X(t)$
\end_inset

 are assumed to be right-continuous with left-hand limits 
\begin_inset Formula $X(t-)$
\end_inset

.
\end_layout

\begin_layout Remark*
Let 
\begin_inset Formula $X(t)$
\end_inset

, 
\begin_inset Formula $a\leq t\leq b$
\end_inset

 be a submartingale with respect to a right-continuous filtration 
\begin_inset Formula $(\mathcal{F}_{t}:a\leq t\leq b)$
\end_inset

.
 If 
\begin_inset Formula $X(t)$
\end_inset

 satisfies certain conditions, then it can be uniquely decomposed as:
\end_layout

\begin_layout Remark*
\begin_inset Formula 
\begin{align*}
X(t) & =M(t)+C(t),\quad a\leq t\leq b
\end{align*}

\end_inset


\end_layout

\begin_layout Remark*
where 
\begin_inset Formula $M(t)$
\end_inset

, 
\begin_inset Formula $a\leq t\leq b$
\end_inset

 is a martingale with respect to 
\begin_inset Formula $(\mathcal{F}_{t};a\leq t\leq b)$
\end_inset

, 
\begin_inset Formula $C(t)$
\end_inset

 is right-continuous and increasing almost surely with 
\begin_inset Formula $\mathbf{E}[C(t)]<\infty$
\end_inset

.
\end_layout

\begin_layout Example
(Square of a Poisson Process).
 Let 
\begin_inset Formula $(N_{t}:t\geq0)$
\end_inset

 be a Poisson process with rate 
\begin_inset Formula $\lambda$
\end_inset

.
 We consider the compensated process 
\begin_inset Formula $M_{t}=N_{t}-\lambda t$
\end_inset

.
 By 
\begin_inset CommandInset ref
LatexCommand eqref
reference "corollary:the-convex-function-of-martingale-is-a-submartingale"
plural "false"
caps "false"
noprefix "false"

\end_inset

, the process 
\begin_inset Formula $(M_{t}^{2}:t\geq0)$
\end_inset

 is a submartingale for the filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

 of the Poisson process.
 How should we compensated 
\begin_inset Formula $M_{t}^{2}$
\end_inset

 to get a martingale? A direct computation using the properties of conditional
 expectation yields:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[M_{t}^{2}|\mathcal{F}_{s}] & =\mathbf{E}[(M_{t}-M_{s}+M_{s})^{2}|\mathcal{F}_{s}]\\
 & =\mathbf{E}[(M_{t}-M_{s})^{2}+2(M_{t}-M_{s})M_{s}+M_{s}^{2}|\mathcal{F}_{s}]\\
 & =\mathbf{E}[(M_{t}-M_{s})^{2}|\mathcal{F}_{s}]+2\mathbf{E}[(M_{t}-M_{s})M_{s}|\mathcal{F}_{s}]+\mathbf{E}[M_{s}^{2}|\mathcal{F}_{s}]\\
 & =\mathbf{E}[(M_{t}-M_{s})^{2}]+2M_{s}\underbrace{\mathbf{E}[M_{t}-M_{s}]}_{\text{equals \ensuremath{0}}}+M_{s}^{2}\\
 & =\mathbf{E}[(M_{t}-M_{s})^{2}]+M_{s}^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Now, if 
\begin_inset Formula $X\sim\text{Poisson\ensuremath{(\lambda t)}}$
\end_inset

, then 
\begin_inset Formula $\mathbf{E}[X]=\lambda t$
\end_inset

 and 
\begin_inset Formula $\mathbf{E}\ensuremath{[X^{2}]}=\lambda t(\lambda t+1)$
\end_inset

.
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[(M_{t}-M_{s})^{2}] & =\mathbf{E}\left[\left\{ (N_{t}-N_{s})-\lambda(t-s)\right\} ^{2}\right]\\
 & =\mathbf{E}\left[(N_{t}-N_{s})^{2}\right]-2\lambda(t-s)\mathbf{E}\left[(N_{t}-N_{s})\right]+\lambda^{2}(t-s)^{2}\\
 & =\lambda^{2}(t-s)^{2}+\lambda(t-s)-2\lambda(t-s)\cdot\lambda(t-s)+\lambda^{2}(t-s)^{2}\\
 & =\lambda(t-s)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Thus,
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[M_{t}^{2}-\lambda t|\mathcal{F}_{s}] & =M_{s}^{2}-\lambda s
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We conclude that the process 
\begin_inset Formula $(M_{t}^{2}-\lambda t:t\geq0)$
\end_inset

 is a martingale.
 The Doob-Meyer decomposition of the submartingale 
\begin_inset Formula $M_{t}^{2}$
\end_inset

 is then:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
M_{t}^{2} & =(M_{t}^{2}-\lambda t)+\lambda t
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
Consider a Brownian motion 
\begin_inset Formula $B(t)$
\end_inset

.
 The quadratic variation of the process 
\begin_inset Formula $(B(t):t\geq0)$
\end_inset

 over the interval 
\begin_inset Formula $[0,t]$
\end_inset

 is given by 
\begin_inset Formula $[B]_{t}=t$
\end_inset

.
 On the other hand, we saw, that the square of Brownian motion compensated,
 
\begin_inset Formula $(B_{t}^{2}-t:t\geq0)$
\end_inset

 is a martingale.
 Hence, the Doob-Meyer decomposition of 
\begin_inset Formula $B(t)^{2}$
\end_inset

 is given by:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
B(t)^{2} & =(B(t)^{2}-t)+t
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Computations with Martingales.
\end_layout

\begin_layout Standard
Martingales are not only conceptually interesting, they are also formidable
 tools to compute probabilities and expectations of processes.
 For example, in this section, we will solve the 
\emph on
gambler's ruin
\emph default
 problem for Brownian motion.
 For convenience, we introduce the notion of 
\emph on
stopping time 
\emph default
before doing so.
\end_layout

\begin_layout Definition
A random variable 
\begin_inset Formula $\tau:\Omega\to\mathbf{N}\cup\{+\infty\}$
\end_inset

 is said to be a 
\emph on
stopping time 
\emph default
for the filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

 if and only if:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
\{\omega:\tau(\omega)\leq t\} & \in\mathcal{F}_{t},\quad\forall t\geq0
\end{align*}

\end_inset

Note that since 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

 is a sigma-field, if 
\begin_inset Formula $\tau$
\end_inset

 is a stopping time, then we must also have that 
\begin_inset Formula $\{\omega:\tau(\omega)>t\}\in\mathcal{F}_{t}$
\end_inset

.
\end_layout

\begin_layout Definition
In other words, 
\begin_inset Formula $\tau$
\end_inset

 is a stopping time, if we can decide if the events 
\begin_inset Formula $\{\tau\leq t\}$
\end_inset

 occurred or not based on the information available at time 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Definition
The term 
\emph on
stopping time
\emph default
 comes from gambling: a gambler can decide to stop playing at a random time
 (depending for example on previous gains or losses), but when he or she
 decides to stop, his/her decision is based solely upon the knowledge of
 what happened before, and does not depend on future outcomes.
 In other words, the stopping policy/strategy can only depend on past outcomes.
 Otherwise, it would mean that he/she has a crystall ball.
 
\end_layout

\begin_layout Example
(Examples of stopping times).
 
\end_layout

\begin_layout Example
(i) 
\emph on
First passage time
\emph default
.
 This is the first time when a process reaches a certain value.
 To be precise, let 
\begin_inset Formula $X=(X_{t}:t\geq0)$
\end_inset

 be a process and 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

 be its natural filtration.
 For 
\begin_inset Formula $a>0$
\end_inset

, we define the first passage time at 
\begin_inset Formula $a$
\end_inset

 to be:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\tau(\omega) & =\inf\{s\geq0:X_{s}(\omega)\geq a\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
If the path 
\begin_inset Formula $\omega$
\end_inset

 never reaches 
\begin_inset Formula $a$
\end_inset

, we set 
\begin_inset Formula $\tau(\omega)=\infty$
\end_inset

.
 Now, for 
\begin_inset Formula $t$
\end_inset

 fixed and for a given path 
\begin_inset Formula $X(\omega)$
\end_inset

, it is possible to know if 
\begin_inset Formula $\{\tau(\omega)\leq t\}$
\end_inset

 (the path has reached 
\begin_inset Formula $a$
\end_inset

 before time 
\begin_inset Formula $t$
\end_inset

) or 
\begin_inset Formula $\{\tau(\omega)>t\}$
\end_inset

 (the path has not reached 
\begin_inset Formula $a$
\end_inset

 before time 
\begin_inset Formula $t$
\end_inset

) with the information available at time 
\begin_inset Formula $t$
\end_inset

, since we are looking at the first time the process reaches 
\begin_inset Formula $a$
\end_inset

.
 Hence, we conclude that 
\begin_inset Formula $\tau$
\end_inset

 is a stopping time.
\end_layout

\begin_layout Example
(ii) 
\emph on
Hitting time
\emph default
.
 More generally, we can consider the first time (if ever) that the path
 of a process 
\begin_inset Formula $(X_{t}:t\geq0)$
\end_inset

 enters or hits a subset 
\begin_inset Formula $B$
\end_inset

 of 
\begin_inset Formula $\mathbf{R}$
\end_inset

:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\tau(\omega) & =\min\{s\geq0:X_{s}(\omega)\in B\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The first passage time is the particular case in which 
\begin_inset Formula $B=[a,\infty)$
\end_inset

.
\end_layout

\begin_layout Example
(iii) 
\emph on
Minimum of two stopping times.
 
\emph default
If 
\begin_inset Formula $\tau$
\end_inset

 and 
\begin_inset Formula $\tau'$
\end_inset

 are two stopping times for the same filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

, then so is the minimum 
\begin_inset Formula $\tau\land\tau'$
\end_inset

 between the two, where 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
(\tau\land\tau')(\omega) & =\min\{\tau(\omega),\tau'(\omega)\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
This is because for any 
\begin_inset Formula $t\geq0$
\end_inset

:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\{\omega: & (\tau\land\tau')(\omega)\leq t\}=\{\omega:\tau(\omega)\leq t\}\cup\{\omega:\tau'(\omega)\leq t\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Since the right hand side is the union of two events in 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

, it must also be in 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

 by the properties of a sigma-field.
 We conclude that 
\begin_inset Formula $\tau\land\tau'$
\end_inset

 is a stopping time.
 Is it also the case that the maximum 
\begin_inset Formula $\tau\lor\tau'$
\end_inset

 is a stopping time?
\end_layout

\begin_layout Example
For any fixed 
\begin_inset Formula $t\geq0$
\end_inset

, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\{\omega:(\tau\lor\tau')(\omega)\leq t\} & =\{\omega:\tau(\omega)\leq t\}\cap\{\omega:\tau'(\omega)\leq t\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Since the right hand side is the intersection of two events in 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

, it must also be in 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

 by the properties of a sigma-field.
 We conclude that 
\begin_inset Formula $\tau\lor\tau'$
\end_inset

 is a stopping time.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(Last passage time is not a stopping time).
 What if we look at the last time the process reaches 
\begin_inset Formula $a$
\end_inset

, that is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\rho(\omega) & =\sup\{t\geq0:X_{t}(\omega)\geq a\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
This is a well-defined random variable, but it is not a stopping time.
 Based on the information available at time 
\begin_inset Formula $t$
\end_inset

, we are not able to decide whether or not 
\begin_inset Formula $\{\rho(\omega)\leq t\}$
\end_inset

 occurred or not, as the path can always reach 
\begin_inset Formula $a$
\end_inset

 one more time after 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Standard
It turns out that a martingale that is stopped when the stopping time is
 attained remains a martingale.
\end_layout

\begin_layout Proposition
(Stopped Martingale).
 If 
\begin_inset Formula $(M_{t}:t\geq0)$
\end_inset

 is a continuous martingale for the filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

 and 
\begin_inset Formula $\tau$
\end_inset

 is a stopping time for the same filtration, then the stopped process defined
 by 
\begin_inset Formula 
\begin{align*}
M_{t\land\tau} & =\begin{cases}
M_{t} & t\leq\tau\\
M_{\tau} & t>\tau
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Proposition
is also a continuous martingale for the same filtration.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "th:doob's-optional-sampling-theorem"

\end_inset

(Doob's Optional sampling theorem).
 If 
\begin_inset Formula $(M_{t}:t\geq0)$
\end_inset

 is a continuous martingale for the filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

 and 
\begin_inset Formula $\tau$
\end_inset

 is a stopping time such that 
\begin_inset Formula $\tau<\infty$
\end_inset

 and the stopped process 
\begin_inset Formula $(M_{t\land\tau}:t\geq0)$
\end_inset

 is bounded, then:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
\mathbf{E}[M_{\tau}] & =M_{0}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $(M_{\tau\land t}:t\geq0)$
\end_inset

 is a martingale, we always have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[M_{\tau\land t}] & =M_{0}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, since 
\begin_inset Formula $\tau(\omega)<\infty$
\end_inset

, we must 
\end_layout

\begin_layout Proof
have that 
\begin_inset Formula $\lim_{t\to\infty}M_{\tau\land t}=M_{\tau}$
\end_inset

 almost surely.
 In particular, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[M_{\tau}] & =\mathbf{E}\left[\lim_{t\to\infty}M_{\tau\land t}\right]=\lim_{t\to\infty}\mathbf{E}[M_{\tau\land t}]=\lim_{t\to\infty}M_{0}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
where we passed to the limit, using the dominated convergence theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:dominated-convergence-theorem"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "example:probability-of-hitting-times"

\end_inset

(Gambler's ruin with Brownian motion).
 The 
\emph on
gambler's ruin problem
\emph default
 is known in different forms.
 Roughly speaking, it refers to the problem of computing the probability
 of a gambler making a series of bets reaching a certain amount before going
 broke.
 In terms of Brownian motion (and stochastic processes in general), it translate
s to the following questions: Let 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

 be a standard brownian motion starting at 
\begin_inset Formula $B_{0}=0$
\end_inset

 and 
\begin_inset Formula $a,b>0$
\end_inset

.
\end_layout

\begin_layout Example
(1) What is the probability that a Brownian path reaches 
\begin_inset Formula $a$
\end_inset

 before 
\begin_inset Formula $-b$
\end_inset

?
\end_layout

\begin_layout Example
(2) What is the expected waiting time for the path to reach 
\begin_inset Formula $a$
\end_inset

 or 
\begin_inset Formula $-b$
\end_inset

?
\end_layout

\begin_layout Example
For the first question, it is a simple computation using stopping time and
 martingale properties.
 Define the hitting time:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\tau(\omega) & =\inf\{t\geq0:B_{t}(\omega)\geq a\text{ or }B_{t}(\omega)\leq-b\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Note that 
\begin_inset Formula $\tau$
\end_inset

 is the minimum between the first passage time at 
\begin_inset Formula $a$
\end_inset

 and the one at 
\begin_inset Formula $-b$
\end_inset

.
\end_layout

\begin_layout Example
We first show that 
\begin_inset Formula $\tau<\infty$
\end_inset

 almost surely.
 In other words, all Brownian paths reach 
\begin_inset Formula $a$
\end_inset

 or 
\begin_inset Formula $-b$
\end_inset

 eventually.
 To see this, consider the event 
\begin_inset Formula $E_{n}$
\end_inset

 that the 
\begin_inset Formula $n$
\end_inset

-th increment exceeds 
\begin_inset Formula $a+b$
\end_inset


\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
E_{n} & :=\left\{ |B_{n}-B_{n-1}|>a+b\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Note that, if 
\begin_inset Formula $E_{n}$
\end_inset

 occurs, then we must have that the Brownian motion path exits the interval
 
\begin_inset Formula $[-b,a].$
\end_inset

 Moreover, we have 
\begin_inset Formula $\mathbb{P}(E_{n})=\mathbb{P}(E_{1})$
\end_inset

 for all 
\begin_inset Formula $n$
\end_inset

.
 Call this probability 
\begin_inset Formula $p$
\end_inset

.
 
\end_layout

\begin_layout Example
Since the events 
\begin_inset Formula $E_{n}$
\end_inset

 are independent, we have: 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{P}(E_{1}^{C}\cap E_{2}^{C}\cap\ldots\cap E_{n}^{C}) & =(1-p)^{n}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
As 
\begin_inset Formula $n\to\infty$
\end_inset

 we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}\mathbb{P}(E_{1}^{C}\cap E_{2}^{C}\cap\ldots\cap E_{n}^{C}) & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The sequence of events 
\begin_inset Formula $(F_{n})$
\end_inset

 where 
\begin_inset Formula $F_{n}=E_{1}^{C}\cap E_{2}^{C}\cap\ldots\cap E_{n}^{C}$
\end_inset

 is a decreasing sequence of events.
 By the continuity of probability measure lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:continuity-property-of-lebesgue-measure"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we conclude that:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}\mathbb{P}\left(F_{n}\right) & =\mathbb{P}\left(\bigcap_{n=1}^{\infty}F_{n}\right)=0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Therefore, it must be the case 
\begin_inset Formula $\mathbb{P}(\cup_{n=1}^{\infty}E_{n})=1$
\end_inset

.
 So, 
\begin_inset Formula $E_{n}$
\end_inset

 must occur for some 
\begin_inset Formula $n$
\end_inset

, so all brownian motion paths reach 
\begin_inset Formula $a$
\end_inset

 or 
\begin_inset Formula $-b$
\end_inset

 almost surely.
\end_layout

\begin_layout Example
Since 
\begin_inset Formula $\tau<\infty$
\end_inset

 with probability one, the random variable 
\begin_inset Formula $B_{\tau}$
\end_inset

 is well-defined : 
\begin_inset Formula $B_{\tau}(\omega)=B_{t}(\omega)$
\end_inset

 if 
\begin_inset Formula $\tau(\omega)=t$
\end_inset

.
 It can only take two values: 
\begin_inset Formula $a$
\end_inset

 or 
\begin_inset Formula $-b$
\end_inset

.
 Question (1) above translates into computing 
\begin_inset Formula $\mathbb{P}(B_{\tau}=a)$
\end_inset

.
 On one hand, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[B_{\tau}] & =a\mathbb{P}(B_{\tau}=a)+(-b)(1-\mathbb{P}(B_{\tau}=a))
\end{align*}

\end_inset


\end_layout

\begin_layout Example
On the other hand, by corollary 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:doob's-optional-sampling-theorem"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we have 
\begin_inset Formula $\mathbf{E}[B_{\tau}]=\mathbf{E}[B_{0}]=0$
\end_inset

.
 (Note that the stopped process 
\begin_inset Formula $(B_{t\land\tau}:t\geq0)$
\end_inset

 is bounded above by 
\begin_inset Formula $a$
\end_inset

 and by 
\begin_inset Formula $-b$
\end_inset

 below).
 Putting these two observations together, we get:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{P}(B_{\tau}=a) & =\frac{b}{a+b}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
A very simple and elegant answer! 
\end_layout

\begin_layout Example
We will revisit this problem again and again.
 In particular, we will answer the question above for Brownian motion with
 a drift at length further ahead.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "ex:expected-waiting-times"

\end_inset

(Expected Waiting Time).
 Let 
\begin_inset Formula $\tau$
\end_inset

 be as in the last example.
 We now answer question (2) of the gambler's ruin problem:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[\tau] & =ab
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Note that the expected waiting time is consistent with the rough heuristic
 that Brownian motion travels a distance 
\begin_inset Formula $\sqrt{t}$
\end_inset

 by time 
\begin_inset Formula $t$
\end_inset

.
 We now use the martingale 
\begin_inset Formula $M_{t}=B_{t}^{2}-t$
\end_inset

.
 On the one hand, if we apply optional stopping in corollary 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:doob's-optional-sampling-theorem"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we get:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[M_{\tau}] & =M_{0}=0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Moreover, we know the distribution of 
\begin_inset Formula $B_{\tau}$
\end_inset

, thanks to the probability calculated in the last example.
 We can therefore compute 
\begin_inset Formula $\mathbf{E}[M_{\tau}]$
\end_inset

 directly:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
0 & =\mathbf{E}[M_{\tau}]\\
 & =\mathbf{E}[B_{\tau}^{2}-\tau]\\
 & =\mathbf{E}[B_{\tau}^{2}]-\mathbf{E}[\tau]\\
 & =a^{2}\cdot\frac{b}{a+b}+b^{2}\cdot\frac{a}{a+b}-\mathbf{E}[\tau]\\
\mathbf{E}[\tau] & =\frac{a^{2}b+b^{2}a}{a+b}\\
 & =\frac{ab\cancel{(a+b)}}{\cancel{(a+b)}}=ab
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Why can we apply optional stopping here? The random variable 
\begin_inset Formula $\tau$
\end_inset

 is finite with probability 
\begin_inset Formula $1$
\end_inset

 as before.
 However, the stopped martingale is not necessarily bounded as before: 
\begin_inset Formula $B_{\tau\land t}$
\end_inset

 is bounded but 
\begin_inset Formula $\tau$
\end_inset

 is not.
 However, the conclusion of optional stopping still holds.
 Indeed, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[M_{t\land\tau}] & =\mathbf{E}[B_{t\land\tau}^{2}]-\mathbf{E}[t\land\tau]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
By the bounded convergence theorem, we get 
\begin_inset Formula $\lim_{t\to\infty}\mathbf{E}[B_{t\land\tau}^{2}]=\mathbf{E}[\lim_{t\to\infty}B_{t\land\tau}^{2}]=\mathbf{E}[B_{\tau}^{2}]$
\end_inset

.
 Since 
\begin_inset Formula $\tau\land t$
\end_inset

 is a non-decreasing sequence and as 
\begin_inset Formula $t\to\infty$
\end_inset

, 
\begin_inset Formula $t\land\tau\to\tau$
\end_inset

 almost surely, as 
\begin_inset Formula $\tau<\infty$
\end_inset

, by the monotone convergence theorem, 
\begin_inset Formula $\lim_{t\to\infty}\mathbf{E}[t\land\tau]=\mathbf{E}[\tau]$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(First passage time of Brownian Motion.) We can use the previous two examples
 to get some very interesting information on the first passage time:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\tau_{a} & =\inf\{t\geq0:B_{t}\geq a\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $\tau=\tau_{a}\land\tau_{-b}$
\end_inset

 be as in the previous examples with 
\begin_inset Formula $\tau_{-b}=\inf\{t\geq0:B_{t}\leq-b\}$
\end_inset

.
 Note that 
\begin_inset Formula $(\tau_{-b},b\in\mathbf{R}_{+})$
\end_inset

 is a sequence of random variables that is increasing in 
\begin_inset Formula $b$
\end_inset

.
 A brownian motion path must cross through 
\begin_inset Formula $-1$
\end_inset

 before it hits 
\begin_inset Formula $-2$
\end_inset

 for the first time and in general 
\begin_inset Formula $\tau_{-n}(\omega)\leq\tau_{-(n+1)}(\omega)$
\end_inset

.
 Moreover, we have 
\begin_inset Formula $\tau_{-b}\to\infty$
\end_inset

 almost surely as 
\begin_inset Formula $b\to\infty$
\end_inset

.
 That's because, 
\begin_inset Formula $\mathbb{P}\{\tau<\infty\}=1$
\end_inset

.
 Moreover, the event 
\begin_inset Formula $\{B_{\tau}=a\}$
\end_inset

 is the same as 
\begin_inset Formula $\{\tau_{a}<\tau_{-b}\}$
\end_inset

.
 Now, the events 
\begin_inset Formula $\{\tau_{a}<\tau_{-b}\}$
\end_inset

 are increasing in 
\begin_inset Formula $b$
\end_inset

, since if a path reaches 
\begin_inset Formula $a$
\end_inset

 before 
\begin_inset Formula $-b$
\end_inset

, it will do so as well for a more negative value of 
\begin_inset Formula $-b$
\end_inset

.
 On one hand, this means by the continuity of probability measure lemma
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:continuity-property-of-lebesgue-measure"
plural "false"
caps "false"
noprefix "false"

\end_inset

 that:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\lim_{b\to\infty}\mathbb{P}\left\{ \tau_{a}<\tau_{-b}\right\}  & =\mathbb{P}\{\lim_{b\to\infty}\tau_{a}<\tau_{-b}\}\\
 & =\mathbb{P}\{\tau_{a}<\infty\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
On the other hand, we have by example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "example:probability-of-hitting-times"
plural "false"
caps "false"
noprefix "false"

\end_inset


\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\lim_{b\to\infty}\mathbb{P}\left\{ \tau_{a}<\tau_{-b}\right\}  & =\lim_{b\to\infty}\mathbb{P}\{B_{\tau}=a\}\\
 & =\lim_{b\to\infty}\frac{b}{b+a}\\
 & =1
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We just showed that:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align}
\mathbb{P}\left\{ \tau_{a}<\infty\right\}  & =1\label{eq:first-passage-time-to-a-is-finite-almost-surely}
\end{align}

\end_inset


\end_layout

\begin_layout Example
In other words, every Brownian path will reach 
\begin_inset Formula $a$
\end_inset

, no matter how large 
\begin_inset Formula $a$
\end_inset

 is!
\end_layout

\begin_layout Example
How long will it take to reach 
\begin_inset Formula $a$
\end_inset

 on average? Well, we know from example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:expected-waiting-times"
plural "false"
caps "false"
noprefix "false"

\end_inset

 that 
\begin_inset Formula $\mathbf{E}[\tau_{a}\land\tau_{-b}]=ab$
\end_inset

.
 On one hand this means,
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\lim_{b\to\infty}\mathbf{E}[\tau_{a}\land\tau_{-b}] & =\lim_{b\to\infty}ab=\infty
\end{align*}

\end_inset


\end_layout

\begin_layout Example
On the other hand, since the random variables 
\begin_inset Formula $\tau_{-b}$
\end_inset

 are increasing,
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\lim_{b\to\infty}\mathbf{E}[\tau_{a}\land\tau_{-b}] & =\mathbf{E}\left[\lim_{b\to\infty}\tau_{a}\land\tau_{-b}\right]=\mathbf{E}[\tau_{a}]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
by the monotone convergence theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:monotone-convergence-theorem"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 We just proved that:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[\tau_{a}] & =\infty
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In other words, any Brownian motion path will reach 
\begin_inset Formula $a$
\end_inset

, but the expected waiting time for this to occur is infinite, no matter,
 how small 
\begin_inset Formula $a$
\end_inset

 is! What is happening here? No matter, how small 
\begin_inset Formula $a$
\end_inset

 is, there is always paths that reach very large negative values before
 hitting 
\begin_inset Formula $a$
\end_inset

.
 These paths might be unlikely.
 However, the first passage time for these paths is so large that they affect
 the value of the expectation substantially.
 In other words, 
\begin_inset Formula $\tau_{a}$
\end_inset

 is a 
\emph on
heavy-tailed random variable
\emph default
.
 We look at the distribution of 
\begin_inset Formula $\tau_{a}$
\end_inset

 in more detail in the next section.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(When option stopping fails).
 Consider 
\begin_inset Formula $\tau_{a}$
\end_inset

, the first passage time at 
\begin_inset Formula $a>0$
\end_inset

.
 The random variable 
\begin_inset Formula $B_{\tau_{a}}$
\end_inset

 is well-defined since 
\begin_inset Formula $\tau_{a}<\infty$
\end_inset

.
 In fact, we have 
\begin_inset Formula $B_{\tau_{a}}=a$
\end_inset

 with probability one.
 Therefore, the following must hold:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[B_{\tau_{a}}] & =a\neq B_{0}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Optional stopping theorem corollary 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:doob's-optional-sampling-theorem"
plural "false"
caps "false"
noprefix "false"

\end_inset

 does not apply here, since the stopped process 
\begin_inset Formula $(B_{t\land\tau_{a}}:t\geq0)$
\end_inset

 is not bounded.
 
\begin_inset Formula $B_{t\land\tau_{a}}$
\end_inset

 can become infinitely negative before hitting 
\begin_inset Formula $a$
\end_inset

.
 
\end_layout

\begin_layout Subsection
Reflection principle for Brownian motion.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:bacheliers-formula"

\end_inset

(Bachelier's formula).
 Let 
\begin_inset Formula $(B_{t}:t\leq T)$
\end_inset

 be a standard brownian motion on 
\begin_inset Formula $[0,T].$
\end_inset

 Then, the CDF of the random variable 
\begin_inset Formula $\sup_{0\leq t\leq T}B_{t}$
\end_inset

 is:
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\sup_{0\leq t\leq T}B_{t}\leq a\right) & =\mathbb{P}\left(|B_{T}|\leq a\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proposition
In particular, its PDF is:
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
f_{\max}(a) & =\frac{2}{\sqrt{2\pi T}}e^{-\frac{a^{2}}{2T}}
\end{align*}

\end_inset


\end_layout

\begin_layout Remark*
We can verify these results empirically.
 Note that the paths of the random variables 
\begin_inset Formula $\max_{0\leq s\leq t}B_{s}$
\end_inset

 and 
\begin_inset Formula $|B_{t}|$
\end_inset

 are very different as 
\begin_inset Formula $t$
\end_inset

 varies for a given 
\begin_inset Formula $\omega$
\end_inset

.
 One is increasing and the other is not.
 The equality holds in distribution for a fixed 
\begin_inset Formula $t$
\end_inset

.
 As a bonus corollary, we get the distribution of the first passage time
 at 
\begin_inset Formula $a$
\end_inset

.
\end_layout

\begin_layout Corollary
Let 
\begin_inset Formula $a\geq0$
\end_inset

 and 
\begin_inset Formula $\tau_{a}=\inf\{t\geq0:B_{t}\geq a\}$
\end_inset

.
 Then:
\end_layout

\begin_layout Corollary
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\tau_{a}\leq T\right) & =\mathbb{P}\left(\max_{0\leq t\leq T}B_{t}\geq a\right)=\int_{a}^{\infty}\frac{2}{\sqrt{2\pi T}}e^{-\frac{x^{2}}{2T}}dx
\end{align*}

\end_inset


\end_layout

\begin_layout Corollary
In particular, the random variable 
\begin_inset Formula $\tau_{a}$
\end_inset

 has the PDF:
\end_layout

\begin_layout Corollary
\begin_inset Formula 
\begin{align*}
f_{\tau_{a}}(t) & =\frac{a}{\sqrt{2\pi}}\frac{e^{-\frac{a^{2}}{2t}}}{t^{3/2}},\quad t>0
\end{align*}

\end_inset

 
\end_layout

\begin_layout Corollary
This implies that it is heavy-tailed with 
\begin_inset Formula $\mathbf{E}[\tau_{a}]=\infty$
\end_inset

.
\end_layout

\begin_layout Proof
The maximum on 
\begin_inset Formula $[0,T]$
\end_inset

 is larger than or equal to 
\begin_inset Formula $a$
\end_inset

 if and only if 
\begin_inset Formula $\tau_{a}\leq T$
\end_inset

.
 Therefore, the events 
\begin_inset Formula $\{\max_{0\leq t\leq T}B_{t}\geq a\}$
\end_inset

 and 
\begin_inset Formula $\{\tau_{a}\leq T\}$
\end_inset

 are the same.
 So, the CDF 
\begin_inset Formula $\mathbb{P}(\tau_{a}\leq t)$
\end_inset

 of 
\begin_inset Formula $\tau_{a}$
\end_inset

, by proposition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:bacheliers-formula"
plural "false"
caps "false"
noprefix "false"

\end_inset

 
\begin_inset Formula $\int_{a}^{\infty}f_{\max}(x)dx=\int_{a}^{\infty}\frac{2}{\sqrt{2\pi T}}e^{-\frac{x^{2}}{2T}}dx$
\end_inset

.
 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
f_{\tau_{a}}(t) & =-2\phi(a/\sqrt{t})\cdot a\cdot\left(-\frac{1}{2t^{3/2}}\right)\\
 & =\frac{a}{t^{3/2}}\phi\left(\frac{a}{\sqrt{t}}\right)\\
 & =\frac{a}{t^{3/2}}\cdot\frac{1}{\sqrt{2\pi}}e^{-\frac{a^{2}}{2t}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
To estimate the expectation, it suffices to realize that for 
\begin_inset Formula $t\geq1$
\end_inset

, 
\begin_inset Formula $e^{-\frac{a^{2}}{2t}}$
\end_inset

 is larger than 
\begin_inset Formula $e^{-\frac{a^{2}}{2}}$
\end_inset

.
 Therefore, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[\tau_{a}] & =\int_{0}^{\infty}t\frac{a}{\sqrt{2\pi}}\frac{e^{-a^{2}/2t}}{t^{3/2}}dt\geq\frac{ae^{-a^{2}/2}}{\sqrt{2\pi}}\int_{1}^{\infty}t^{-1/2}dt
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
This is an improper integral and it diverges like 
\begin_inset Formula $\sqrt{t}$
\end_inset

 and is infinite as claimed.
\end_layout

\begin_layout Standard
To prove proposition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:bacheliers-formula"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we will need an important property of Brownian motion called the 
\emph on
reflection principle
\emph default
.
 To motivate it, recall the reflection symmetry of Brownian motion at time
 
\begin_inset Formula $s$
\end_inset

 in proposition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:brownian-motion-symmetry-of-reflection-at-time-s"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 It turns out that this reflection property also holds if 
\begin_inset Formula $s$
\end_inset

 is replaced by a stopping time.
 
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lemma:BM-reflection-principle"

\end_inset

(Reflection principle).
 Let 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

 be a standard Brownian motion and let 
\begin_inset Formula $\tau$
\end_inset

 be a stopping time for its filtration.
 Then, the process 
\begin_inset Formula $(\tilde{B}_{t}:t\geq0)$
\end_inset

 defined by the reflection at time 
\begin_inset Formula $\tau$
\end_inset

:
\end_layout

\begin_layout Lemma
\begin_inset Formula 
\begin{align*}
\tilde{B}_{t} & =\begin{cases}
B_{t} & \text{if \ensuremath{t\leq\tau}}\\
B_{\tau}-(B_{t}-B_{\tau}) & \text{if \ensuremath{t>\tau}}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Lemma
is also a standard brownian motion.
 
\end_layout

\begin_layout Remark*
We defer the proof of the reflection property of Brownian motion to a further
 section.
 It is intuitive and instructive to quickly picture this in the discrete-time
 setting.
 I adopt the approach as in Shreve-I.
 
\end_layout

\begin_layout Remark*
We repeatedly toss a fair coin (
\begin_inset Formula $p$
\end_inset

, the probability of 
\begin_inset Formula $H$
\end_inset

 on each toss, and 
\begin_inset Formula $q=1-p$
\end_inset

, the probability of 
\begin_inset Formula $T$
\end_inset

 on each toss, are both equal to 
\begin_inset Formula $\frac{1}{2}$
\end_inset

).
 We denote the successive outcomes of the tosses by 
\begin_inset Formula $\omega_{1}\omega_{2}\omega_{3}\ldots$
\end_inset

.
 Let
\end_layout

\begin_layout Remark*
\begin_inset Formula 
\begin{align*}
X_{j} & =\begin{cases}
-1 & \text{if \ensuremath{\omega_{j}=H}}\\
+1 & \text{if \ensuremath{\omega_{j}=T}}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Remark*
and define 
\begin_inset Formula $M_{0}=0$
\end_inset

, 
\begin_inset Formula $M_{n}=\sum_{j=1}^{n}X_{n}$
\end_inset

.
 The process 
\begin_inset Formula $(M_{n}:n\in\mathbf{N})$
\end_inset

 is a symmetric random walk.
\end_layout

\begin_layout Remark*
Suppose we toss a coin an odd number 
\begin_inset Formula $(2j-1)$
\end_inset

 of times.
 Some of the paths will reach level 
\begin_inset Formula $1$
\end_inset

 in the first 
\begin_inset Formula $2j-1$
\end_inset

 steps and other will not reach.
 In the case of 
\begin_inset Formula $3$
\end_inset

 tosses, there are 
\begin_inset Formula $2^{3}=8$
\end_inset

 possible paths and 
\begin_inset Formula $5$
\end_inset

 of these reach level 
\begin_inset Formula $1$
\end_inset

 at some time 
\begin_inset Formula $\tau_{1}\leq2j-1$
\end_inset

.
 From that moment on, we can create a reflected path, which steps up each
 time the original path steps down and steps down each time the original
 path steps up.
 If the original path ends above 
\begin_inset Formula $1$
\end_inset

 at the final time 
\begin_inset Formula $2j-1$
\end_inset

, the reflected path ends below 
\begin_inset Formula $1$
\end_inset

 and vice versa.
 If the original path ends at 
\begin_inset Formula $1$
\end_inset

, the reflected path does also.
 In fact, the reflection at the first hitting time has the same distribution
 as the original random walk.
 
\end_layout

\begin_layout Remark*
The key here is, out of the 
\begin_inset Formula $5$
\end_inset

 paths that reach level 
\begin_inset Formula $1$
\end_inset

 at some time, there are as many reflected paths that exceed 
\begin_inset Formula $1$
\end_inset

 at time 
\begin_inset Formula $(2j-1)$
\end_inset

 as there are original paths that exceed 
\begin_inset Formula $1$
\end_inset

 at time 
\begin_inset Formula $(2j-1)$
\end_inset

.
 So, to count the total number of paths that reach level 
\begin_inset Formula $1$
\end_inset

 by time 
\begin_inset Formula $(2j-1)$
\end_inset

, we can count the paths that are at 
\begin_inset Formula $1$
\end_inset

 at time 
\begin_inset Formula $(2j-1)$
\end_inset

 and then add on 
\emph on
twice 
\emph default
the number of paths that exceed 
\begin_inset Formula $1$
\end_inset

 at time 
\begin_inset Formula $(2j-1)$
\end_inset

.
 
\end_layout

\begin_layout Standard
With this new tool, we can now prove proposition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:bacheliers-formula"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 
\end_layout

\begin_layout Proof
Consider 
\begin_inset Formula $\mathbb{P}(\max_{t\leq T}B_{t}\geq a)$
\end_inset

.
 By splitting this probability over the event of the endpoint, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\max_{t\leq T}B_{t}\geq a\right) & =\mathbb{P}\left(\max_{t\leq T}B_{t}\geq a,B_{T}>a\right)+\mathbb{P}\left(\max_{t\leq T}B_{t}\geq a,B_{T}\leq a\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Note also, that 
\begin_inset Formula $\mathbb{P}(B_{T}=a)=0$
\end_inset

.
 Hence, the first probability equals 
\begin_inset Formula $\mathbb{P}(B_{T}\geq a)$
\end_inset

.
 As for the second, consider the time 
\begin_inset Formula $\tau_{a}$
\end_inset

.
 On the event considered, we have 
\begin_inset Formula $\tau_{a}\leq T$
\end_inset

 and using lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lemma:BM-reflection-principle"
plural "false"
caps "false"
noprefix "false"

\end_inset

 at that time, we get 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\max_{t\leq T}B_{t}\geq a,B_{T}\leq a\right) & =\mathbb{P}\left(\max_{t\leq T}B_{t}\geq a,\tilde{B}_{T}\geq a\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Observe that the event 
\begin_inset Formula $\{\max_{t\leq T}B_{t}\geq a\}$
\end_inset

 is the same as 
\begin_inset Formula $\{\max_{t\leq T}\tilde{B}_{T}\geq a\}$
\end_inset

.
 (A rough picture might help here.) Thereforem the above probability is
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\max_{t\leq T}B_{t}\geq a,B_{T}\leq a\right) & =\mathbb{P}\left(\max_{t\leq T}\tilde{B}_{t}\geq a,\tilde{B}_{T}\geq a\right)=\mathbb{P}\left(\max_{t\leq T}B_{t}\geq a,B_{T}\geq a\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
where the last equality follows from the reflection principle (
\begin_inset Formula $\tilde{B}_{t}$
\end_inset

 is also a standard brownian motion, and 
\begin_inset Formula $B_{T}$
\end_inset

 and 
\begin_inset Formula $\tilde{B}_{T}$
\end_inset

 have the same distribution.) But, as above, the last probability is equal
 to 
\begin_inset Formula $\mathbb{P}(B_{T}\geq a)$
\end_inset

.
 We conclude that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\max_{t\leq T}B_{t}\geq a\right) & =2\mathbb{P}(B_{T}\geq a)=\frac{2}{\sqrt{2\pi T}}\int_{a}^{\infty}e^{-\frac{x^{2}}{2T}}dx=\mathbb{P}(|B_{T}|\geq a)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
This implies in particular that 
\begin_inset Formula $\mathbb{P}\left(\max_{t\leq T}B_{t}=a\right)=0$
\end_inset

.
 Thus, we also have 
\begin_inset Formula $\mathbb{P}(\max_{t\leq T}B_{t}\leq a)=\mathbb{P}(|B_{T}|\leq a)$
\end_inset

 as claimed.
 
\end_layout

\begin_layout Example
(Simulating Martingales) Sample 
\begin_inset Formula $10$
\end_inset

 paths of the following process with a step-size of 
\begin_inset Formula $0.01$
\end_inset

:
\end_layout

\begin_layout Example
(a) 
\begin_inset Formula $B_{t}^{2}-t$
\end_inset

, 
\begin_inset Formula $t\in[0,1]$
\end_inset


\end_layout

\begin_layout Example
(b) Geometric Brownian motion : 
\begin_inset Formula $S_{t}=\exp(B_{t}-t/2)$
\end_inset

, 
\begin_inset Formula $t\in[0,1]$
\end_inset

.
\end_layout

\begin_layout Example
Let's write a simple 
\begin_inset Formula $\texttt{BrownianMotion}$
\end_inset

 class, that we shall use to generate sample paths.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{language=Python,backgroundcolor=
\backslash
color{backcolour},breaklines=true,commentstyle=
\backslash
color{codegreen},stringstyle=
\backslash
color{magenta},keywordstyle=
\backslash
bfseries
\backslash
color{blue!40!black},basicstyle=
\backslash
footnotesize
\backslash
ttfamily,frame=single}
\end_layout

\begin_layout Plain Layout


\backslash
begin{lstlisting}[caption=10 paths of $B_t^2 - t$]
\end_layout

\begin_layout Plain Layout

import numpy as np
\end_layout

\begin_layout Plain Layout

import matplotlib.pyplot as plt
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

import attrs
\end_layout

\begin_layout Plain Layout

from attrs import define, field
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

@define
\end_layout

\begin_layout Plain Layout

class BrownianMotion:
\end_layout

\begin_layout Plain Layout

    _step_size = field(validator=attrs.validators.and_(attrs.validators.instance_of(
float),
\end_layout

\begin_layout Plain Layout

                                                       attrs.validators.ge(0.0)))
\end_layout

\begin_layout Plain Layout

    # Time T
\end_layout

\begin_layout Plain Layout

    _T = field(validator=attrs.validators.and_(attrs.validators.instance_of(float),
\end_layout

\begin_layout Plain Layout

                                               attrs.validators.ge(0.0)))
\end_layout

\begin_layout Plain Layout

    # number of paths
\end_layout

\begin_layout Plain Layout

    _N = field(validator=attrs.validators.and_(attrs.validators.instance_of(int),
\end_layout

\begin_layout Plain Layout

                                               attrs.validators.gt(0)))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    _num_steps = field(init=False)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def __attrs_post_init__(self):
\end_layout

\begin_layout Plain Layout

        self._num_steps = int(self._T/self._step_size)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    def covariance_matrix(self):
\end_layout

\begin_layout Plain Layout

        C = np.zeros((self._num_steps,self._num_steps))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        for i in range(self._num_steps):
\end_layout

\begin_layout Plain Layout

            for j in range(self._num_steps):
\end_layout

\begin_layout Plain Layout

                s = (i+1) * self._step_size
\end_layout

\begin_layout Plain Layout

                t = (j+1) * self._step_size
\end_layout

\begin_layout Plain Layout

                C[i,j] = min(s,t)
\end_layout

\begin_layout Plain Layout

        return C
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    # Each column vector represents a sample path
\end_layout

\begin_layout Plain Layout

    def generate_paths(self):
\end_layout

\begin_layout Plain Layout

        C = self.covariance_matrix()
\end_layout

\begin_layout Plain Layout

        A = np.linalg.cholesky(C)
\end_layout

\begin_layout Plain Layout

        Z = np.random.standard_normal((self._num_steps, self._N))
\end_layout

\begin_layout Plain Layout

        X = np.matmul(A,Z)
\end_layout

\begin_layout Plain Layout

        X = np.concatenate((np.zeros((1,self._N)),X),axis=0)
\end_layout

\begin_layout Plain Layout

        return X.transpose()
\end_layout

\begin_layout Plain Layout


\backslash
end{lstlisting}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Now, the process 
\begin_inset Formula $B_{t}^{2}-t$
\end_inset

 can be sampled as follows:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{language=Python,backgroundcolor=
\backslash
color{backcolour},breaklines=true,commentstyle=
\backslash
color{codegreen},stringstyle=
\backslash
color{magenta},keywordstyle=
\backslash
bfseries
\backslash
color{blue!40!black},basicstyle=
\backslash
footnotesize
\backslash
ttfamily,frame=single}
\end_layout

\begin_layout Plain Layout


\backslash
begin{lstlisting}[caption=10 paths of $B_t^2 - t$]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

def generateSquareOfBMCompensated(numOfPaths,stepSize,T):
\end_layout

\begin_layout Plain Layout

    N = int(T/stepSize)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    X = []
\end_layout

\begin_layout Plain Layout

    brownianMotion = BrownianMotion(stepSize,T)
\end_layout

\begin_layout Plain Layout

    for n in range(numOfPaths):
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        B_t = brownianMotion.samplePath()
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        B_t_sq = np.square(B_t)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

        t = np.linspace(start=0.0,stop=1.0,num=N+1)
\end_layout

\begin_layout Plain Layout

        M_t = np.subtract(B_t_sq,t)
\end_layout

\begin_layout Plain Layout

        X.append(M_t)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    return X
\end_layout

\begin_layout Plain Layout


\backslash
end{lstlisting}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/compensated_squared_bm.tex"

\end_inset


\end_layout

\begin_layout Standard
The gBM process can be sampled similarly, with 
\begin_inset Formula $\texttt{M_{t} = np.exp(np.subtract(B_{t},t/2))}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/gBM.tex"

\end_inset


\end_layout

\begin_layout Example

\series bold
(Maximum of Brownian Motion.) 
\series default
Consider the maximum of Brownian motion on 
\begin_inset Formula $[0,1]$
\end_inset

: 
\begin_inset Formula $\max_{s\leq1}B_{s}$
\end_inset

.
\end_layout

\begin_layout Example
(a) Draw the histogram of the random variable 
\begin_inset Formula $\max_{s\leq1}B_{s}$
\end_inset

using 
\begin_inset Formula $10,0000$
\end_inset

 sampled Brownian paths with a step size of 
\begin_inset Formula $0.01$
\end_inset

.
\end_layout

\begin_layout Example
(b) Compare this to the PDF of the random variable 
\begin_inset Formula $|B_{1}|$
\end_inset

.
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
I use the 
\begin_inset Formula $\texttt{itertools}$
\end_inset

 python library to compute the running maximum of a brownian motion path.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstset{language=Python,backgroundcolor=
\backslash
color{backcolour},breaklines=true,commentstyle=
\backslash
color{codegreen},stringstyle=
\backslash
color{magenta},keywordstyle=
\backslash
bfseries
\backslash
color{blue!40!black},basicstyle=
\backslash
footnotesize
\backslash
ttfamily,frame=single}
\end_layout

\begin_layout Plain Layout


\backslash
begin{lstlisting}[caption=The process $
\backslash
sup_{s
\backslash
leq 1}B_s$]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

brownianMotion = BrownianMotion(stepSize=0.01,T=1)
\end_layout

\begin_layout Plain Layout

data = []
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

for i in range(10000):
\end_layout

\begin_layout Plain Layout

    B_t = brownianMotion.samplePath()
\end_layout

\begin_layout Plain Layout

    max_B_t = list(itertools.accumulate(B_t,max))
\end_layout

\begin_layout Plain Layout

    data.append(max_B_t[100])
\end_layout

\begin_layout Plain Layout


\backslash
end{lstlisting}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/runningMax.tex"

\end_inset


\end_layout

\begin_layout Standard
Analytically, we know that 
\begin_inset Formula $B_{1}$
\end_inset

 is a gaussian random variable with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $1$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{P}(|B_{1}|\leq z) & =\mathbb{P}(|Z|\leq z)\\
 & =\mathbb{P}(-z\leq Z\leq z)\\
 & =\mathbb{P}(Z\leq z)-\mathbb{P}(Z\leq-z)\\
 & =\mathbb{P}(Z\leq z)-(1-\mathbb{P}(Z\leq z))\\
F_{|B_{1}|}(z) & =2\Phi(z)-1
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Differentiating on both sides, we get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
f_{|B_{1}|}(z) & =2\phi(z)=\frac{2}{\sqrt{2\pi}}e^{-\frac{z^{2}}{2}},\quad z\in[0,\infty)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/PDF_abs_B_T.tex"

\end_inset


\end_layout

\begin_layout Example
(First passage time.) Let 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

 be a standard brownian motion.
 Consider the random variable:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\tau & =\min\{t\geq0:B_{t}\geq1\}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
This is the first time that 
\begin_inset Formula $B_{t}$
\end_inset

 reaches 
\begin_inset Formula $1$
\end_inset

.
\end_layout

\begin_layout Example
(a) Draw a histogram for the distribution of 
\begin_inset Formula $\tau\land10$
\end_inset

 on the time-interval 
\begin_inset Formula $[0,10]$
\end_inset

 using 
\begin_inset Formula $10,000$
\end_inset

 brownian motion paths on 
\begin_inset Formula $[0,10]$
\end_inset

 with discretization 
\begin_inset Formula $0.01$
\end_inset

.
\end_layout

\begin_layout Example

\emph on
The notation 
\begin_inset Formula $\tau\land10$
\end_inset

 means that if the path does not reach 
\begin_inset Formula $1$
\end_inset

 on 
\begin_inset Formula $[0,10]$
\end_inset

, then give the value 
\begin_inset Formula $10$
\end_inset

 to the stopping time.
 
\end_layout

\begin_layout Example
(b) Estimate 
\begin_inset Formula $\mathbf{E}[\tau\land10]$
\end_inset

.
\end_layout

\begin_layout Example
(c) What proportion of paths never reach 
\begin_inset Formula $1$
\end_inset

 in the time interval 
\begin_inset Formula $[0,10]$
\end_inset

?
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/hitting_times.tex"

\end_inset


\end_layout

\begin_layout Standard
To compute the expectation, we classify the hitting times of all paths into
 
\begin_inset Formula $50$
\end_inset

 bins.
 I simply did 
\end_layout

\begin_layout Standard
\begin_inset Formula $\texttt{frequency, bins = np.histogram(firstPassageTimes,bins=50,range=(0,10))}$
\end_inset

 
\end_layout

\begin_layout Standard
and then computed 
\end_layout

\begin_layout Standard
\begin_inset Formula $\texttt{expectation=np.dot(frequency,bins[1:])/10000}$
\end_inset

.
 
\end_layout

\begin_layout Standard
This expectation estimate on my machine is 
\begin_inset Formula $\mathbf{E}[\tau\land10]=4.34$
\end_inset

 secs.
 There were approximately 
\begin_inset Formula $2600$
\end_inset

 paths out of 
\begin_inset Formula $10,000$
\end_inset

 that did not reach 
\begin_inset Formula $1$
\end_inset

.
\end_layout

\begin_layout Example

\series bold
Gambler's ruin at the French Roulette.
 
\series default
Consider the scenario in which you are gambling 
\begin_inset Formula $\$1$
\end_inset

 at the French roulette on the reds: You gain 
\begin_inset Formula $\$1$
\end_inset

 with probability 
\begin_inset Formula $18/38$
\end_inset

 and you lose a dollar with probability 
\begin_inset Formula $20/38$
\end_inset

.
 We estimate the probability of your fortune reaching 
\begin_inset Formula $\$200$
\end_inset

 before it reaches 
\begin_inset Formula $0$
\end_inset

.
 
\end_layout

\begin_layout Example
(a) Write a function that samples the simple random walk path from time
 
\begin_inset Formula $0$
\end_inset

 to time 
\begin_inset Formula $5,000$
\end_inset

 with a given starting point.
 
\end_layout

\begin_layout Example
(b) Use the above to estimate the probability of reaching 
\begin_inset Formula $\$200$
\end_inset

 before 
\begin_inset Formula $\$0$
\end_inset

 on a sample of 
\begin_inset Formula $100$
\end_inset

 paths if you start with 
\begin_inset Formula $\$100$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example

\series bold
\begin_inset CommandInset label
LatexCommand label
name "ex:doob's-maximal-inequality"

\end_inset

Doob's maximal inequalities
\series default
.
 We prove the following: Let 
\begin_inset Formula $(M_{k}:k\geq1)$
\end_inset

 be positive submartingale for the filtration 
\begin_inset Formula $(\mathcal{F}_{k}:k\in\mathbf{N})$
\end_inset

.
 Then, for any 
\begin_inset Formula $1\leq p<\infty$
\end_inset

 and 
\begin_inset Formula $a>0$
\end_inset


\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\max_{k\leq n}M_{k}>a\right) & \leq\frac{1}{a^{p}}\mathbf{E}[M_{n}^{p}]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
(a) Use Jensen's inequality to show that if 
\begin_inset Formula $(M_{k}:k\geq1)$
\end_inset

 is a positive submartingale, then so is 
\begin_inset Formula $(M_{k}^{p}:k\geq1)$
\end_inset

 for 
\begin_inset Formula $1\leq p<\infty$
\end_inset

.
 Conclude that it suffices to prove the statement for 
\begin_inset Formula $p=1$
\end_inset

.
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
The function 
\begin_inset Formula $f(x)=x^{p}$
\end_inset

 is convex.
 By conditional Jensen's inequality,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left(\mathbf{E}[M_{k+1}|\mathcal{F}_{k}]\right)^{p} & \leq\mathbf{E}[M_{k}^{p}|\mathcal{F}_{k}]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Thus,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{E}[M_{k+1}^{p}|\mathcal{F}_{k}] & \geq\left(\mathbf{E}[M_{k+1}|\mathcal{F}_{k}]\right)^{p}\geq M_{k}^{p}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where the last inequality follows from the fact that 
\begin_inset Formula $(M_{k}:k\geq1)$
\end_inset

 is a positive submartingale, so 
\begin_inset Formula $\mathbf{E}[M_{k+1}|\mathcal{F}_{k}]\geq M_{k}$
\end_inset

.
 Consequently, 
\begin_inset Formula $(M_{k}^{p}:k\geq1)$
\end_inset

 is also a positive submartingale.
\end_layout

\begin_layout Standard
(b) Consider the events 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
B_{k} & =\bigcap_{j<k}\{\omega:M_{j}(\omega)\leq a\}\cap\{\omega:M_{k}(\omega)>a\}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Argue that the 
\begin_inset Formula $B_{k}$
\end_inset

's are disjoint and that 
\begin_inset Formula $\bigcup_{k\leq n}B_{k}=\{\max_{k\leq n}M_{k}>a\}=B$
\end_inset

.
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
Clearly, 
\begin_inset Formula $B_{k}$
\end_inset

 is the event that the first time to cross 
\begin_inset Formula $a$
\end_inset

 is 
\begin_inset Formula $k$
\end_inset

.
 If 
\begin_inset Formula $B_{k}$
\end_inset

 occurs, 
\begin_inset Formula $B_{k+1},B_{k+2},\ldots$
\end_inset

 fail to occur.
 Hence, all 
\begin_inset Formula $B_{k}'s$
\end_inset

 are pairwise disjoint.
 The event 
\begin_inset Formula $\bigcup_{k\leq n}B_{k}$
\end_inset

 is the event that the random walk crosses 
\begin_inset Formula $a$
\end_inset

 at any time 
\begin_inset Formula $k\leq n$
\end_inset

.
 Thus, the running maximum of the Brownian motion at time 
\begin_inset Formula $n$
\end_inset

 exceeds 
\begin_inset Formula $a$
\end_inset

.
 
\end_layout

\begin_layout Standard
(c) Show that 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{E}[M_{n}]\geq\mathbf{E}[M_{n}\mathbf{1}_{B}] & \geq a\sum_{k\leq n}\mathbb{P}(B_{k})=a\mathbb{P}(B)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
by decomposing 
\begin_inset Formula $B$
\end_inset

 in 
\begin_inset Formula $B_{k}$
\end_inset

's and by using the properties of expectations, as well as the submartingale
 property.
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
Clearly, 
\begin_inset Formula $M_{n}\geq M_{n}\mathbf{1}_{B}\geq a\mathbf{1}_{B}$
\end_inset

.
 And 
\begin_inset Formula $M_{n}$
\end_inset

 is a positive random variable.
 By monotonicity of expectations, 
\begin_inset Formula $\mathbf{E}[M_{n}]\geq\mathbf{E}[M_{n}\mathbf{1}_{B}]\geq a\mathbf{E}[\mathbf{1}_{B}]=a\mathbb{P}(B)=a\sum_{k\leq n}\mathbb{P}(B_{k})$
\end_inset

, where the last equality holds because the 
\begin_inset Formula $B_{k}$
\end_inset

's are disjoint.
 
\end_layout

\begin_layout Standard
(d) Argue that the inequality holds for continuous paths by discretizing
 time and using convergence theorems : If 
\begin_inset Formula $(M_{t}:t\geq0)$
\end_inset

 is a positive submartingale with continuous paths for the filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

, then for any 
\begin_inset Formula $1\leq p<\infty$
\end_inset

 and 
\begin_inset Formula $a>0$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\max_{s\leq t}M_{s}>a\right) & \leq\frac{1}{a^{p}}\mathbf{E}[M_{t}^{p}]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $(M_{t}:t\geq0)$
\end_inset

 be a positive submartingale with continuous paths for the filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

.
 Consider a sequence of partitions of the interval 
\begin_inset Formula $[0,t]$
\end_inset

 into 
\begin_inset Formula $2^{r}$
\end_inset

 subintervals : 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
D_{r} & =\left\{ \frac{kt}{2^{r}}:k=0,1,2,\ldots,2^{n}\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
And consider a sequence of discrete positive sub-martingales:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
M_{kt/2^{r}}^{(r)} & =M_{kt/2^{r}},\quad k\in\mathbf{N},0\leq k\leq2^{r}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Next, we define for 
\begin_inset Formula $r=1,2,3,\ldots$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
A_{r} & =\left\{ \sup_{s\in D_{r}}|M_{s}^{(r)}|>a\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
By using the maximal inequality in discrete time, gives us:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{P}(A_{r})=\mathbb{P}\left\{ \sup_{s\in D_{r}}|M_{s}^{(r)}|>a\right\}  & \leq\frac{1}{a^{p}}\mathbf{E}\left[\left(M_{s}^{(r)}\right)^{p}\right]=\frac{1}{a^{p}}\mathbf{E}\left[M_{t}^{p}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\max_{s\leq t}M_{s}>a\right) & =\mathbb{P}\left(\bigcup_{r=1}^{\infty}A_{r}\right)\\
 & =\lim_{r\to\infty}\mathbb{P}\left(A_{r}\right)\\
 & \left\{ \text{Continuity of probability measure}\right\} \\
 & \leq\lim_{r\to\infty}\frac{1}{a^{p}}\mathbf{E}\left[M_{t}^{p}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Section
Ito Calculus.
\end_layout

\begin_layout Standard
The Riemann-Stieltjes integral of 
\begin_inset Formula $g$
\end_inset

 with respect to 
\begin_inset Formula $f$
\end_inset

 is understood to be limit of the sums:
\begin_inset Formula 
\begin{align*}
\int_{0}^{t}g(s)\cdot df(s) & =\lim_{n\to\infty}\sum_{j=0}^{n-1}g(t_{j})(f(t_{j+1})-f(t_{j}))
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The goal is to make sense of the above, when 
\begin_inset Formula $f$
\end_inset

 is replaced by a Brownian motion 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\int_{0}^{t}g(s)\cdot dB_{s} & =\lim_{n\to\infty}\sum_{j=0}^{n-1}g(t_{j})(B_{t_{j+1}}-B_{t_{j}})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The major hurdle here is not the fact that the Brownian motion paths are
 random, but instead that these paths have 
\emph on
unbounded variation.
 
\emph default
This means that the classical construction does not apply for a given path.
 
\end_layout

\begin_layout Standard
Note that the sum 
\begin_inset Formula $\sum_{j=0}^{n-1}g(t_{j})(B_{t_{j+1}}-B_{t_{j}})$
\end_inset

 is a random variable.
 If the end-point 
\begin_inset Formula $t_{n}=t$
\end_inset

 is varied, it can be seen as a stochastic process.
 Since Brownian motion paths are continuous, this new stochastic process
 also has continuous paths.
 As we shall see, this stochastic process is in fact a continuous martingale.
 It turns out that these properties remain in the limit as 
\begin_inset Formula $n\to\infty$
\end_inset

.
\end_layout

\begin_layout Standard
What is the intepretation of the stochastic integral? If we think of 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

 as modelling the price of a stock, then 
\begin_inset Formula $\sum_{j=0}^{n-1}g(t_{j})(B_{t_{j+1}}-B_{t_{j}})$
\end_inset

 gives the value of a portfolio at time 
\begin_inset Formula $t$
\end_inset

 that implements the following strategy: At 
\begin_inset Formula $t_{j}$
\end_inset

 we buy 
\begin_inset Formula $g(t_{j})$
\end_inset

 shares of the stock that we sell at time 
\begin_inset Formula $t_{j+1}$
\end_inset

.
 We do this for every 
\begin_inset Formula $j\leq n-1$
\end_inset

.
 The net gain or loss of this strategy is the sum over 
\begin_inset Formula $j$
\end_inset

 of 
\begin_inset Formula $g(t_{j})(B_{t_{j+1}}-B_{t_{j}})$
\end_inset

.
 Of course, in this implementation, the number of shares 
\begin_inset Formula $g(t_{j})$
\end_inset

 put in play could be random and depend on the past information of the path
 upto time 
\begin_inset Formula $t_{j}$
\end_inset

.
\end_layout

\begin_layout Subsection
Martingale Transform.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $(M_{t},t\leq T)$
\end_inset

 be a continuous square-integrable martingale on 
\begin_inset Formula $[0,T]$
\end_inset

 for the filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\leq T)$
\end_inset

 defined on some probability space 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 The idea of the martingale transform is to modify the amplitude of each
 increment in such a way as to produce a martingale when these new increments
 are summed up.
 The martingale transforms are to the Ito Integral, what Riemann sums are
 for the Riemann integral.
\end_layout

\begin_layout Standard
More precisely, let 
\begin_inset Formula $(t_{j},j\leq n)$
\end_inset

 be a sequence of partitions of 
\begin_inset Formula $[0,T]$
\end_inset

 with 
\begin_inset Formula $t_{0}=0$
\end_inset

 and 
\begin_inset Formula $t_{n}=T$
\end_inset

.
 For example, we can take 
\begin_inset Formula $t_{j}=\frac{jT}{n}$
\end_inset

.
 Consider 
\begin_inset Formula $n$
\end_inset

 fixed numbers 
\begin_inset Formula $(Y_{t_{0}},Y_{t_{1}},\ldots,Y_{t_{n-1}})$
\end_inset

.
 It is convenient to construct a function of time 
\begin_inset Formula $X_{t}$
\end_inset

 from these:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
X_{t} & =Y_{t_{j}}\quad\text{if \ensuremath{t\in(t_{j},t_{j+1}]}}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This can also be written as a sum of indicator functions:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
X_{t} & =\sum_{j=0}^{n-1}Y_{t_{j}}\mathbf{1}_{(t_{j},t_{j+1}]}(t),\quad t\leq T\label{eq:simple-process-1}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
The integral of 
\begin_inset Formula $(X_{t}:t\leq T)$
\end_inset

 with respect to the martingale 
\begin_inset Formula $M$
\end_inset

 on 
\begin_inset Formula $[0,T]$
\end_inset

 also called a 
\emph on
martingale transform, 
\emph default
is the sum of the increments of the martingale modulated by 
\begin_inset Formula $X$
\end_inset

; that is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
I_{T} & =Y_{0}(M_{1}-M_{0})+\ldots+Y_{n-1}(M_{T}-M_{t_{n-1}})=\sum_{j=0}^{n-1}Y_{j}(M_{t_{j+1}}-M_{t_{j}})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This is a random variable in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

, since it is a linear combination of random variables in 
\begin_inset Formula $L^{2}$
\end_inset

.
 Note that, we recover 
\begin_inset Formula $M_{T}$
\end_inset

 when 
\begin_inset Formula $X_{t_{j}}$
\end_inset

 is 
\begin_inset Formula $1$
\end_inset

 for all intervals.
 We may think of 
\begin_inset Formula $(M_{s}:s\leq T)$
\end_inset

 as the price of an asset, say a stock, on a time interval 
\begin_inset Formula $[0,T]$
\end_inset

.
 Then, the term:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Y_{t_{j}}(M_{t_{j+1}}-M_{t_{j}})
\]

\end_inset


\end_layout

\begin_layout Standard
can be seen as the gain/loss in the time interval 
\begin_inset Formula $(t_{j},t_{j+1}]$
\end_inset

 of buying 
\begin_inset Formula $Y_{t_{j}}$
\end_inset

 units of the asset at time 
\begin_inset Formula $t_{j}$
\end_inset

 at price 
\begin_inset Formula $M_{t_{j}}$
\end_inset

 and selling these at time 
\begin_inset Formula $t_{j+1}$
\end_inset

 at price 
\begin_inset Formula $M_{t_{j+1}}$
\end_inset

.
 Summing these terms over time gives the value of implementing the investment
 strategy 
\begin_inset Formula $X$
\end_inset

 on the interval 
\begin_inset Formula $[0,T]$
\end_inset

.
 It is not hard to modify the definition to obtain a stochastic process
 on the whole interval 
\begin_inset Formula $[0,T]$
\end_inset

.
 For 
\begin_inset Formula $t\leq T$
\end_inset

, we simply sum up the increments up to 
\begin_inset Formula $t$
\end_inset

.
 This can be written down as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
I_{t} & =Y_{t_{0}}(M_{t_{1}}-M_{t_{0}})+\ldots+Y_{t_{j}}(M_{t}-M_{t_{j}}),\quad\text{if \ensuremath{t\in(t_{j},t_{j+1}]}}\label{eq:integral-of-a-simple-process}
\end{align}

\end_inset


\end_layout

\begin_layout Example
(Integral of a simple process).
 Consider a standard Brownian motion 
\begin_inset Formula $(B_{t}:t\in[0,1])$
\end_inset

 on the time interval 
\begin_inset Formula $[0,1]$
\end_inset

.
 We know very well by now, that it is a martingale.
 We look at the simple integral constructed from it.
 We take the following integrand:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
X_{t} & =\begin{cases}
10 & \text{if \ensuremath{t\in(0,1/3]}}\\
5 & \text{if \ensuremath{t\in}}(1/3,2/3]\\
2 & \text{if \ensuremath{t\in(2/3,1]}}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Then the integrals 
\begin_inset Formula $I_{t}$
\end_inset

 as in equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:integral-of-a-simple-process"
plural "false"
caps "false"
noprefix "false"

\end_inset

 forms a process 
\begin_inset Formula $(I_{t}:t\in[0,1])$
\end_inset

 of the form:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
I_{t} & =\begin{cases}
10B_{t} & \text{if \ensuremath{t\in(0,1/3]}}\\
10B_{1/3}+5(B_{t}-B_{1/3}) & \text{if \ensuremath{t\in}}(1/3,2/3]\\
10B_{1/3}+5(B_{2/3}-B_{1/3})+2(B_{t}-B_{2/3}) & \text{if \ensuremath{t\in(2/3,1]}}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We make three important observations.
 First, the paths of the process 
\begin_inset Formula $(I_{t},t\in[0,1])$
\end_inset

 are continuous, because Brownian paths are.
 Second the process is a square-integrable martingale.
 It is easy to see that it is adapted and square-integrable, because 
\begin_inset Formula $I_{t}$
\end_inset

 is a sum of square-integrable random variables.
 The martingale property is also not hard to verify.
 For example, we have for 
\begin_inset Formula $t\in(2/3,1]$
\end_inset

:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[I_{t}|\mathcal{F}_{2/3}] & =10B_{1/3}+5(B_{2/3}-B_{1/3})+2\mathbf{E}[B_{t}-B_{2/3}|\mathcal{F}_{2/3}]=I_{2/3}.
\end{align*}

\end_inset


\end_layout

\begin_layout Example
since 
\begin_inset Formula $\mathbf{E}[B_{t}-B_{2/3}|\mathcal{F}_{2/3}]=0$
\end_inset

 by the martingale property of Brownian motion.
 
\end_layout

\begin_layout Example
We can generalize the integrand or the investing strategy 
\begin_inset Formula $X$
\end_inset

 by considering values 
\begin_inset Formula $X_{t_{j}}$
\end_inset

 that depend on the process, hence are random, but predictable in a way.
 Namely, we can take 
\begin_inset Formula $X$
\end_inset

 to be a random vector such that 
\begin_inset Formula $X_{t_{j}}$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{t_{j}}$
\end_inset

 measurable.
 In other words, 
\begin_inset Formula $X_{t_{j}}$
\end_inset

 may be random, but it must depend only on the information available up
 to time 
\begin_inset Formula $t_{j}$
\end_inset

.
 Common sense dictates that the number of shares you buy today should not
 depend on the information in the future.
 With this in mind, for a given filtration, we define the space of simple
 (that is, discrete) adapted processes on 
\begin_inset Formula $[0,T]$
\end_inset

 as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\mathcal{S}(T) & =\left\{ (X_{t}:t\leq T):X_{t}=\sum_{j=0}^{n-1}Y_{t_{j}}\mathbf{1}_{(t_{j},t_{j+1}]}(t),Y_{t_{j}}\text{ is \ensuremath{\mathcal{F}_{t_{j}}}measurable, \ensuremath{\mathbf{E}[Y_{t_{j}}^{2}]<\infty}}\right\} \label{eq:simple-process}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
In other words, the processes in 
\begin_inset Formula $\mathcal{S}(T)$
\end_inset

 have paths that are piecewise constant on a finite number of intervals
 of 
\begin_inset Formula $[0,T].$
\end_inset

 The values 
\begin_inset Formula $Y_{t_{j}}(\omega)$
\end_inset

 on each time interval might vary depending on the paths 
\begin_inset Formula $\omega$
\end_inset

.
 As random variables, the 
\begin_inset Formula $Y_{t_{j}}$
\end_inset

's depend only on the information available upto time 
\begin_inset Formula $t_{j}$
\end_inset

and have a finite second moment : 
\begin_inset Formula $\mathbf{E}[Y_{t_{j}}^{2}]<\infty$
\end_inset

.
 Note that, 
\begin_inset Formula $\mathcal{S}(T)$
\end_inset

 is a linear space.
 If 
\begin_inset Formula $X$
\end_inset

, 
\begin_inset Formula $X'$
\end_inset

 belong to 
\begin_inset Formula $\mathcal{S}(T)$
\end_inset

, then 
\begin_inset Formula $aX+bX'\in\mathcal{S}(T)$
\end_inset

 for all 
\begin_inset Formula $a,b\in\mathbf{R}$
\end_inset

.
 Indeed, if the paths of 
\begin_inset Formula $X,X'$
\end_inset

 take a finite number of values, then so are the ones of 
\begin_inset Formula $aX+bX'$
\end_inset

.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "ex:example-of-a-simple-adapted-process"

\end_inset

(An example of a simple adapted process).
 Let 
\begin_inset Formula $(B_{t}:t\leq1)$
\end_inset

 be a standard Brownian motion.
 For the interval 
\begin_inset Formula $[0,1]$
\end_inset

, consider the investing strategy 
\begin_inset Formula $X$
\end_inset

 in 
\begin_inset Formula $\mathcal{S}(1)$
\end_inset

 given by the position of the Brownian path at times 
\begin_inset Formula $0,1/3,2/3$
\end_inset

:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
X_{s} & =\begin{cases}
0 & \text{if \ensuremath{s\in[0,1/3]}}\\
B_{1/3} & \text{if \ensuremath{s\in(1/3,2/3]}}\\
B_{2/3} & \text{if \ensuremath{s\in(2/3,1]}}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Clearly, 
\begin_inset Formula $X$
\end_inset

 is simple and adapted to the Brownian filtration.
 For example, the value at 
\begin_inset Formula $s=3/4$
\end_inset

 is 
\begin_inset Formula $B_{2/3}$
\end_inset

.
 In particular, it depends only on the information prior to the time 
\begin_inset Formula $3/4$
\end_inset

.
 
\end_layout

\begin_layout Example
For a simple adapted process 
\begin_inset Formula $X$
\end_inset

, the integral 
\begin_inset Formula $I_{t}$
\end_inset

 of 
\begin_inset Formula $X$
\end_inset

 with respect to the martingale 
\begin_inset Formula $(M_{t}:t\leq T)$
\end_inset

 is the same as equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:integral-of-a-simple-process"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Example
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy//miscellaneous/simple_process.tex"

\end_inset


\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:martingale-transform"

\end_inset

Let 
\begin_inset Formula $(M_{t}:t\leq T)$
\end_inset

 be a continuous square-integrable martingale for the filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\leq T)$
\end_inset

.
 Let 
\begin_inset Formula $X\in\mathcal{S}(T)$
\end_inset

 be a simple, adapted process 
\begin_inset Formula $X=\sum_{j=0}^{n-1}Y_{t_{j}}\mathbf{1}_{(t_{j},t_{j+1}]}$
\end_inset

 on 
\begin_inset Formula $[0,T]$
\end_inset

.
 The martingale transform 
\begin_inset Formula $I_{t}(X)$
\end_inset

 is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
I_{t}(X)=\int_{0}^{t}X_{s}dM_{s} & =\sum_{j=0}^{n-1}Y_{t_{j}}(M_{t_{j+1}}-M_{t_{j}})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
It defines a process 
\begin_inset Formula $(I_{t}:t\leq T)$
\end_inset

.
\end_layout

\begin_layout Example
(Another integral of a simple process).
 Consider the simple process 
\begin_inset Formula $X$
\end_inset

 of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:example-of-a-simple-adapted-process"
plural "false"
caps "false"
noprefix "false"

\end_inset

 defined on a Brownian motion.
 The integral of 
\begin_inset Formula $X$
\end_inset

 as a process on 
\begin_inset Formula $[0,1]$
\end_inset

 is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
I_{s}(X) & =\begin{cases}
0 & \text{if \ensuremath{s\in[0,1/3]}}\\
B_{1/3}(B_{s}-B_{1/3}) & \text{if \ensuremath{s\in(1/3,2/3]}}\\
B_{1/3}(B_{2/3}-B_{1/3})+B_{2/3}(B_{s}-B_{2/3}) & \text{if \ensuremath{s\in(2/3,1]}}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
As in example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:example-of-a-simple-adapted-process"
plural "false"
caps "false"
noprefix "false"

\end_inset

, the paths of 
\begin_inset Formula $I_{s}(X)$
\end_inset

 are continuous for all 
\begin_inset Formula $s\in[0,1]$
\end_inset

, since the paths of 
\begin_inset Formula $B_{s}$
\end_inset

 are continuous! This is also true at the integer times 
\begin_inset Formula $s=1/3,2/3$
\end_inset

, if we approached from the left or right.
 The process 
\begin_inset Formula $(I_{s}:s\leq1)$
\end_inset

 is also a martingale for the Brownian filtration.
 The key here is that the value multiplying the increment on the interval
 
\begin_inset Formula $(t_{j},t_{j+1}]$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{t_{j}}-$
\end_inset

measurable.
 For example, take 
\begin_inset Formula $t>2/3$
\end_inset

 and 
\begin_inset Formula $1/3<s<2/3$
\end_inset

.
 The properties of conditional expectation in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:properties-of-conditional-expectation"
plural "false"
caps "false"
noprefix "false"

\end_inset

 and the fact that Brownian motion is a martingale give:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[I_{t}|\mathcal{F}_{s}] & =\mathbf{E}[B_{1/3}(B_{2/3}-B_{1/3})+B_{2/3}(B_{t}-B_{2/3})|\mathcal{F}_{s}]\\
 & =\mathbf{E}[B_{1/3}(B_{2/3}-B_{1/3})|\mathcal{F}_{s}]+\mathbf{E}[B_{2/3}(B_{t}-B_{2/3})|\mathcal{F}_{s}]\\
 & =B_{1/3}(B_{s}-B_{1/3})+\mathbf{E}[\mathbf{E}[B_{2/3}(B_{t}-B_{2/3})|\mathcal{F}_{2/3}]|\mathcal{F}_{s}]\\
 & =B_{1/3}(B_{s}-B_{1/3})+\mathbf{E}[B_{2/3}\mathbf{E}[B_{t}-B_{2/3}|\mathcal{F}_{2/3}]|\mathcal{F}_{s}]\\
 & =B_{1/3}(B_{s}-B_{1/3})+\mathbf{E}[B_{2/3}(B_{2/3}-B_{2/3})|\mathcal{F}_{s}]\\
 & =B_{1/3}(B_{s}-B_{1/3})\\
 & =I_{s}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Note that it was crucial to use the tower property in the third equality
 and that we took out what is known at 
\begin_inset Formula $t=2/3$
\end_inset

 in the fourth equality.
\end_layout

\begin_layout Example
Martingale transforms are always themselves martingales.
 In particular, it is not possible in this setup to design an investment
 strategy who value would be increasing on average.
 
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:continuity-and-martingale-property-of-martingale-transforms"

\end_inset

Martingale transforms are martingales.
 Let 
\begin_inset Formula $(M_{t}:t\leq T)$
\end_inset

 be a continuous square-integrable martingale for the filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\leq T)$
\end_inset

 and let 
\begin_inset Formula $X\in\mathcal{S}(T)$
\end_inset

 be a simple process as in equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:simple-process"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Then, the martingale transform 
\begin_inset Formula $(I_{t}:t\leq T)$
\end_inset

 is a continuous martingale on 
\begin_inset Formula $[0,T]$
\end_inset

 for the same filtration.
\end_layout

\begin_layout Proof
The fact that 
\begin_inset Formula $I_{t}(X)$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{t}-$
\end_inset

measurable for 
\begin_inset Formula $t\leq T$
\end_inset

 is clear from the construction in equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:integral-of-a-simple-process"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Indeed, the increments 
\begin_inset Formula $M_{t_{j+1}}-M_{t_{j}}$
\end_inset

 are 
\begin_inset Formula $\mathcal{F}_{t}-$
\end_inset

measurable for 
\begin_inset Formula $t_{j+1}\leq t$
\end_inset

 since the martingale is adapted.
 The integrand 
\begin_inset Formula $X$
\end_inset

 is also adapted.
 Moreover, 
\begin_inset Formula $I_{t}(X)$
\end_inset

 is integrable since:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[|I_{t}|] & \leq\mathbf{E}[|I_{T}|]=\mathbf{E}\left[\left|\sum_{j=0}^{n-1}Y_{t_{j}}(M_{t_{j+1}}-M_{t_{j}})\right|\right]\\
 & \leq\mathbf{E}\left[\sum_{j=0}^{n-1}\left|Y_{t_{j}}(M_{t_{j+1}}-M_{t_{j}})\right|\right]=\sum_{j=0}^{n-1}\mathbf{E}[|Y_{t_{j}}||(M_{t_{j+1}}-M_{t_{j}})|]\\
 & \leq\sum_{j=0}^{n-1}\left(\mathbf{E}[Y_{t_{j}}^{2}]\right)^{1/2}\left(\mathbf{E}[(M_{t_{j+1}}-M_{t_{j}})^{2}]\right)^{1/2}\\
 & \quad\left\{ \text{Cauchy-Schwarz}\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, since both 
\begin_inset Formula $M_{t_{j}}$
\end_inset

 and 
\begin_inset Formula $M_{t_{j+1}}$
\end_inset

 both belong to 
\begin_inset Formula $L^{2}$
\end_inset

, and 
\begin_inset Formula $L^{2}$
\end_inset

 is a linear space, their difference also belongs to 
\begin_inset Formula $L^{2}$
\end_inset

.
 Moreover, 
\begin_inset Formula $\mathbf{E}[Y_{t_{j}}^{2}]<\infty$
\end_inset

.
 Hence, the above sum is finite.
\end_layout

\begin_layout Proof
As for continuity, since 
\begin_inset Formula $(M_{t}:t\leq T)$
\end_inset

 is continuous, the only possible issue could be at the points 
\begin_inset Formula $t_{j}$
\end_inset

 for some 
\begin_inset Formula $j$
\end_inset

.
 But in that case, we have 
\begin_inset Formula $t>t_{j}$
\end_inset

 but close and any outcome 
\begin_inset Formula $\omega$
\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
I_{t}(\omega) & =\sum_{i=0}^{j-1}Y_{t_{i}}(M_{t_{i+1}}(\omega)-M_{t_{i}}(\omega))+Y_{j}(M_{t}(\omega)-M_{t_{j}}(\omega)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
as 
\begin_inset Formula $t\to t_{j}^{+}$
\end_inset

, 
\begin_inset Formula $I_{t}\to I_{t_{j}}$
\end_inset

 by continuity of 
\begin_inset Formula $M_{t}(\omega)$
\end_inset

.
 A similar argument holds for 
\begin_inset Formula $t\to t_{j}^{-}$
\end_inset

.
 If both the left- and right- limits exist and are equal to 
\begin_inset Formula $I_{t_{j}},$
\end_inset

 then 
\begin_inset Formula $I_{t}$
\end_inset

 is continuous at 
\begin_inset Formula $t_{j}$
\end_inset

.
\end_layout

\begin_layout Proof
To prove the martingale property, consider 
\begin_inset Formula $s<t$
\end_inset

.
 We want to show that 
\begin_inset Formula $\mathbf{E}[I_{t}|\mathcal{F}_{s}]=I_{s}$
\end_inset

.
 Suppose that 
\begin_inset Formula $t\in(t_{j},t_{j+1}]$
\end_inset

 for some 
\begin_inset Formula $t_{j}<T$
\end_inset

.
 By linearity of conditional expectations, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
\mathbf{E}[I_{t}|\mathcal{F}_{s}] & =\sum_{i=0}^{j}\mathbf{E}[Y_{t_{i}}(M_{t_{i+1}}-M_{t_{i}})|\mathcal{F}_{s}]\label{eq:verification-of-the-martingale-property}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
where it is understood that 
\begin_inset Formula $t=t_{j+1}$
\end_inset

 in the above to simplify notation.
 We can now handle each summand.
 There are three possibilities 
\begin_inset Formula $s\geq t_{i+1}$
\end_inset

, 
\begin_inset Formula $s\in(t_{i},t_{i+1})$
\end_inset

 and 
\begin_inset Formula $s<t_{i}$
\end_inset

.
 It all depends on proposition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:properties-of-conditional-expectation"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 In the case 
\begin_inset Formula $s\geq t_{i+1}$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Y_{t_{i}}(M_{t_{i+1}}-M_{t_{i}})|\mathcal{F}_{s}] & =Y_{t_{i}}(M_{t_{i+1}}-M_{t_{i}})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
since the whole summand is 
\begin_inset Formula $\mathcal{F}_{s}-$
\end_inset

measurable.
 In the case 
\begin_inset Formula $s\in(t_{i},t_{i+1})$
\end_inset

, we have that 
\begin_inset Formula $Y_{t_{i}}$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{s}-$
\end_inset

measurable; therefore:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Y_{t_{i}}(M_{t_{i+1}}-M_{t_{i}})|\mathcal{F}_{s}] & =Y_{t_{i}}\mathbf{E}[(M_{t_{i+1}}-M_{t_{i}})|\mathcal{F}_{s}]=Y_{t_{i}}(M_{s}-M_{t_{i}})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
by the martingale property.
 In the case, 
\begin_inset Formula $s<t_{i}$
\end_inset

, we use the tower property to get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Y_{t_{i}}(M_{t_{i+1}}-M_{t_{i}})|\mathcal{F}_{s}] & =\mathbf{E}[\mathbf{E}[Y_{t_{i}}(M_{t_{i+1}}-M_{t_{i}})|\mathcal{F}_{t_{i}}]|\mathcal{F}_{s}]\\
 & =\mathbf{E}[Y_{t_{i}}\mathbf{E}[(M_{t_{i+1}}-M_{t_{i}})|\mathcal{F}_{t_{i}}]|\mathcal{F}_{s}]\\
 & =\mathbf{E}[Y_{t_{i}}(M_{t_{i}}-M_{t_{i}})|\mathcal{F}_{t_{i}}]|\mathcal{F}_{s}]\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
since 
\begin_inset Formula $\mathbf{E}[(M_{t_{i+1}}-M_{t_{i}})|\mathcal{F}_{t_{i}}]=0$
\end_inset

 by the martingale property.
 Putting all the cases together, in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:verification-of-the-martingale-property"
plural "false"
caps "false"
noprefix "false"

\end_inset

 gives for 
\begin_inset Formula $s\in(t_{k},t_{k+1}]$
\end_inset

, say:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[I_{t}|\mathcal{F}_{s}] & =Y_{t_{0}}(M_{t_{1}}-M_{t_{0}})+\ldots+Y_{t_{k-1}}(M_{t_{k}}-M_{t_{k-1}})+Y_{t_{k}}(M_{s}-M_{t_{k}})=I_{s}
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
Let 
\begin_inset Formula $(M_{n}:n\in\mathbf{N})$
\end_inset

 be a martingale in discrete time for the filtration 
\begin_inset Formula $(\mathcal{F}_{n}:n\geq0)$
\end_inset

.
 Let 
\begin_inset Formula $\tau$
\end_inset

 be a stopping time for the same filtration.
 Use the Martingale transform with the process:
\end_layout

\begin_layout Exercise
\begin_inset Formula 
\begin{align*}
X_{n}(\omega) & =\begin{cases}
+1 & \text{if \ensuremath{n<\tau(\omega)}}\\
0 & \text{if \ensuremath{n\geq\tau(\omega)}}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
to show that the stopped martingale 
\begin_inset Formula $(M_{\tau\land n},n\in\mathbf{N})$
\end_inset

 is a martingale.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $n$
\end_inset

 be an arbitrary time.
 At any given time 
\begin_inset Formula $n$
\end_inset

, by definition of stopping times, we know if the event 
\begin_inset Formula $\{\tau(\omega)\leq n\}$
\end_inset

 has occurred.
 Thus, 
\begin_inset Formula $X_{n}=\mathbf{1}_{\{\tau(\omega)\leq n\}}$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{n}-$
\end_inset

measurable.
 Also, 
\begin_inset Formula $\mathbf{E}[X_{n}^{2}]\leq1$
\end_inset

.
 So, 
\begin_inset Formula $X_{n}$
\end_inset

 is a simple adapted process.
\end_layout

\begin_layout Proof
Consider the martingale transform of the process 
\begin_inset Formula $(X_{n}:n\in\mathbf{N})$
\end_inset

 defined above:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
I(n) & =\sum_{i=1}^{n-1}X_{i}(M_{i+1}-M_{i})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
I_{n} & =\begin{cases}
M_{n} & \text{if \ensuremath{n<\tau(\omega)}}\\
M_{\tau} & \text{if \ensuremath{n\geq\tau(\omega)}}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
That is, 
\begin_inset Formula $I_{n}=M_{n\land\tau}$
\end_inset

.
 By proposition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:continuity-and-martingale-property-of-martingale-transforms"
plural "false"
caps "false"
noprefix "false"

\end_inset

, martingale transforms are martingales.
 So, a stopped martingale is also a martingale.
\end_layout

\begin_layout Subsection
The Ito Integral.
\end_layout

\begin_layout Standard
We now turn to martingale transforms where the underlying martingale is
 a standard Brownian motion 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

.
 This gives our first definition of the Ito integral.
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:ito-integral-for-simple-adapted-process"

\end_inset

(Ito Integral on 
\begin_inset Formula $\mathcal{S}(T)).$
\end_inset

 Let 
\begin_inset Formula $(B_{t}:t\leq T)$
\end_inset

 be a standard brownian motion on 
\begin_inset Formula $[0,T]$
\end_inset

 and let 
\begin_inset Formula $X\in\mathcal{S}(T)$
\end_inset

 be a simple process 
\begin_inset Formula $X=\sum_{j=0}^{n-1}Y_{t_{j}}\mathbf{1}_{(t_{j},t_{j+1}]}$
\end_inset

 on 
\begin_inset Formula $[0,T]$
\end_inset

 adapted to the Brownian filtration.
 The Ito integral of 
\begin_inset Formula $X$
\end_inset

 with respect to the Brownian motion is defined as the martingale transform:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
\int_{0}^{T}X_{s}dB_{s} & =\sum_{j=0}^{n-1}Y_{t_{j}}(B_{t_{j+1}}-B_{t_{j}})
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
and similarly for any 
\begin_inset Formula $t\leq T$
\end_inset

,
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
\int_{0}^{t}X_{s}dB_{s} & =Y_{t_{0}}(B_{t_{1}}-B_{t_{0}})+\ldots+Y_{t_{j}}(B_{t}-B_{t_{j}})\quad\text{if \ensuremath{t\in(t_{j},t_{j+1}]}}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Note again the similarities with Riemann sums.
 The interpretation of the Ito integral is as follows:
\end_layout

\begin_layout Standard

\emph on
The value of implementing the strategy 
\begin_inset Formula $X$
\end_inset

 on the underlying asset with price given by the Brownian motion.
 
\end_layout

\begin_layout Standard
The martingale transform with Brownian motion has more properties than with
 a generic martingale as given in definition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "def:martingale-transform"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 This is because Brownian motion increments are independent.
 We gather the properties of the Ito integral for 
\begin_inset Formula $X\in\mathcal{S}(T)$
\end_inset

 in an important proposition.
 The same exact result will hold for continuous strategies.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:properties-of-ito-integral-discrete-case"

\end_inset

(Properties of the Ito Integral).
 Let 
\begin_inset Formula $(B_{t}:t\leq T)$
\end_inset

 be a standard Brownian motion on 
\begin_inset Formula $[0,T]$
\end_inset

 defined on a probability space 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 The Ito integral in the definition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "def:ito-integral-for-simple-adapted-process"
plural "false"
caps "false"
noprefix "false"

\end_inset

 has the following properties:
\end_layout

\begin_layout Itemize

\series bold
Linearity.
 
\series default
If 
\begin_inset Formula $X,X'\in\mathcal{S}(T)$
\end_inset

 and 
\begin_inset Formula $a,b\in\mathbf{R}$
\end_inset

, then for all 
\begin_inset Formula $t\leq T$
\end_inset

, 
\begin_inset Formula 
\begin{align*}
\int_{0}^{t}(aX_{s}+bX_{s}')dB_{s} & =a\int_{0}^{t}X_{s}dB_{s}+b\int_{0}^{t}X_{s}'dB_{s}
\end{align*}

\end_inset


\end_layout

\begin_layout Itemize

\series bold
Continuous martingale.

\series default
 The process 
\begin_inset Formula $(\int_{0}^{t}X_{s}dB_{s},t\leq T)$
\end_inset

 is a continuous martingale on 
\begin_inset Formula $[0,T]$
\end_inset

 for a Brownian filtration.
 
\end_layout

\begin_layout Itemize

\series bold
Ito Isometry.
 
\series default
The random variable 
\begin_inset Formula $\int_{0}^{t}X_{s}dB_{s}$
\end_inset

 is in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 with mean 
\begin_inset Formula $0$
\end_inset

 and variance:
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}\right)^{2}\right] & =\int_{0}^{t}\mathbf{E}[X_{s}^{2}]ds=\mathbf{E}\left[\int_{0}^{t}X_{s}^{2}ds\right],\quad t\leq T
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
It is very important for the understanding of the theory to keep in mind
 that 
\begin_inset Formula $\int_{0}^{t}X_{s}dB_{s}$
\end_inset

 is a random variable.
 We should walk away from the temptation to use the reflexes of classical
 calculus to manipulate it as if it were a Riemann Integral.
 The reason we use the integral sign to denote the random variable 
\begin_inset Formula $\int_{0}^{t}X_{s}dB_{s}$
\end_inset

 is because it shares the linearity property with the Riemann integral.
 
\end_layout

\begin_layout Standard
It turns out that Ito's isometry not only yields the mean and variance of
 the random variable 
\begin_inset Formula $\int_{0}^{t}X_{s}dB_{s}$
\end_inset

, but also the covariances of these random variables at different times,
 and the covariances for two integrals built with two different strategies
 on the same Brownian motion.
 What about the distribution of 
\begin_inset Formula $\int_{0}^{t}X_{s}dB_{s}$
\end_inset

? It turns out that the random variable 
\begin_inset Formula $\int_{0}^{t}X_{s}dB_{s}$
\end_inset

 is not Gaussian in general.
 However, if the process 
\begin_inset Formula $X$
\end_inset

 is not random, then it will be.
\end_layout

\begin_layout Proof
The linearity property is clear from the definition of the martingale transform.
 The continuity and the martingale property follow from proposition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:continuity-and-martingale-property-of-martingale-transforms"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Proof
We now prove Ito's isometry.
 We will use the properties of conditional expectation many times.
 To simplify notation, for fixed 
\begin_inset Formula $t\in[0,T]$
\end_inset

, we can suppose that the partition 
\begin_inset Formula $(t_{j},j\leq n)$
\end_inset

 is a partition of 
\begin_inset Formula $[0,t]$
\end_inset

 with 
\begin_inset Formula $t_{n}=t$
\end_inset

.
 Since 
\begin_inset Formula $Y_{t_{j}}$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{t_{j}}$
\end_inset

-measurable, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Y_{t_{j}}(B_{t_{j+1}}-B_{t_{j}})] & =\mathbf{E}[\mathbf{E}[Y_{t_{j}}(B_{t_{j+1}}-B_{t_{j}})|\mathcal{F}_{t_{j}}]]\\
 & =\mathbf{E}[Y_{t_{j}}\mathbf{E}[B_{t_{j+1}}-B_{t_{j}}|\mathcal{F}_{t_{j}}]]\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
since 
\begin_inset Formula $\mathbf{E}[Y_{t_{j}}(B_{t_{j+1}}-B_{t_{j}})]=0$
\end_inset

 as Brownian motion is a martingale.
 Therefore, it follows that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\int_{0}^{t}X_{s}dB_{s}\right] & =\sum_{j=0}^{n-1}\mathbf{E}[Y_{t_{j}}(B_{t_{j+1}}-B_{t_{j}})]=0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
As for the variance, we have by conditioning on 
\begin_inset Formula $\mathcal{F}_{t_{j}}$
\end_inset

, that for 
\begin_inset Formula $t_{i}<t_{j}$
\end_inset

:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Y_{t_{j}}Y_{t_{i}}(B_{t_{j+1}}-B_{t_{j}})(B_{t_{i+1}}-B_{t_{i}})] & =\mathbf{E}[Y_{t_{i}}Y_{t_{j}}(B_{t_{i+1}}-B_{t_{i}})\mathbf{E}[(B_{t_{j+1}}-B_{t_{j}})|\mathcal{F}_{t_{j}}]]\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
since 
\begin_inset Formula $\mathbf{E}[B_{t_{j+1}}-B_{t_{j}}|\mathcal{F}_{t_{j}}]=0$
\end_inset

 and since all factors but 
\begin_inset Formula $B_{t_{j+1}}-B_{t_{j}}$
\end_inset

 are 
\begin_inset Formula $\mathcal{F}_{t_{j}}$
\end_inset

-measurable.
 Thus, this yields:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}\right)^{2}\right] & =\sum_{i,j=0}^{n-1}\mathbf{E}[Y_{t_{j}}Y_{t_{i}}(B_{t_{j+1}}-B_{t_{j}})(B_{t_{i+1}}-B_{t_{i}})]\\
 & =\sum_{j=0}^{n-1}\mathbf{E}[Y_{t_{j}}^{2}\mathbf{E}[(B_{t_{j+1}}-B_{t_{j}})^{2}|\mathcal{F}_{t_{j}}]]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
by the previous equation and the fact that 
\begin_inset Formula $Y_{t_{j}}$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{t_{j}}$
\end_inset

-measurable.
 Since the increment 
\begin_inset Formula $B_{t_{j+1}}-B_{t_{j}}$
\end_inset

 is independent of 
\begin_inset Formula $\mathcal{F}_{t_{j}}$
\end_inset

, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[(B_{t_{j+1}}-B_{t_{j}})^{2}|\mathcal{F}_{t_{j}}] & =\mathbf{E}[(B_{t_{j+1}}-B_{t_{j}})^{2}]=t_{j+1}-t_{j}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Therefore, we conclude that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}\right)^{2}\right] & =\sum_{j=0}^{n-1}\mathbf{E}[Y_{t_{j}}^{2}](t_{j+1}-t_{j})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
From the definition of 
\begin_inset Formula $X$
\end_inset

 as a simple process in equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:simple-process-1"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we have 
\begin_inset Formula $\int_{0}^{t}\mathbf{E}[X_{s}^{2}]ds=\sum_{j=0}^{n-1}\mathbf{E}[Y_{t_{j}}^{2}](t_{j+1}-t_{j})$
\end_inset

 since 
\begin_inset Formula $X_{s}=Y_{t_{j}}$
\end_inset

 on the whole interval 
\begin_inset Formula $(t_{j},t_{j+1}]$
\end_inset

.
\end_layout

\begin_layout Example
We go back to the Ito integral in example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:example-of-a-simple-adapted-process"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The mean of 
\begin_inset Formula $I_{t}(X)$
\end_inset

 is 
\begin_inset Formula $0$
\end_inset

 by proposition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:properties-of-ito-integral-discrete-case"
plural "false"
caps "false"
noprefix "false"

\end_inset

 or by direct computation.
 It is not hard to compute the variance.
 For example at 
\begin_inset Formula $t=1$
\end_inset

, it is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[I_{1}^{2}(X)] & =\int_{0}^{1}\mathbf{E}[X_{u}^{2}]du\\
 & =\mathbf{E}[B_{0}^{2}]\cdot\frac{1}{3}+\mathbf{E}[B_{1/3}^{2}]\cdot\frac{1}{3}+\mathbf{E}[B_{2/3}^{2}]\frac{1}{3}=\frac{1}{9}+\frac{2}{9}=\frac{1}{3}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Consider now another process 
\begin_inset Formula $Y$
\end_inset

 on 
\begin_inset Formula $[0,1]$
\end_inset

 defined on the same Brownian motion:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Y_{t} & =B_{0}^{2}\mathbf{1}_{[0,1/3]}(t)+B_{1/3}^{2}\mathbf{1}_{(1/3,2/3]}(t)+B_{2/3}^{2}\mathbf{1}_{(2/3,1]}(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Again the Ito integral 
\begin_inset Formula $J_{t}=\int_{0}^{t}Y_{s}dB_{s}$
\end_inset

 is well-defined as a process on 
\begin_inset Formula $[0,1]$
\end_inset

:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
J_{t} & =\begin{cases}
0 & \text{if \ensuremath{t\in[0,1/3]}}\\
B_{1/3}^{2}(B_{t}-B_{1/3}) & \text{if \ensuremath{t\in(1/3,2/3]}}\\
B_{1/3}^{2}(B_{2/3}-B_{1/3})+B_{2/3}^{2}(B_{t}-B_{2/3}) & \text{if \ensuremath{t\in(2/3,1]}}
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The covariance between the random variables 
\begin_inset Formula $I_{1}$
\end_inset

 and 
\begin_inset Formula $J_{1}$
\end_inset

 can be computed easily by using the independence of the increments and
 suitable conditioning.
 Indeed, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[I_{1}(X)J_{1}(Y)] & =\sum_{i,j=0}^{3}\mathbf{E}[B_{i/3}B_{j/3}^{2}(B_{(i+1)/3}-B_{i/3})(B_{(j+1)/3}-B_{j/3})]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
If 
\begin_inset Formula $j>i$
\end_inset

, we can condition on 
\begin_inset Formula $\mathcal{F}_{j/3}$
\end_inset

 in the above summand to get:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
 & \mathbf{E}[B_{i/3}B_{j/3}^{2}(B_{(i+1)/3}-B_{i/3})(B_{(j+1)/3}-B_{j/3})|\mathcal{F}_{j/3}]\\
= & B_{i/3}B_{j/3}^{2}(B_{(i+1)/3}-B_{(j+1)/3})\mathbf{E}[(B_{(j+1)/3}-B_{j/3})|\mathcal{F}_{j/3}]=0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The same holds for 
\begin_inset Formula $i>j$
\end_inset

 by conditioning on 
\begin_inset Formula $\mathcal{F}_{i/3}$
\end_inset

.
 The only remaining terms are 
\begin_inset Formula $i=j$
\end_inset

:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[I_{1}J_{1}] & =\sum_{i=0}^{3}\mathbf{E}[B_{i/3}^{3}(B_{(i+1)/3}-B_{i/3})^{2}]\\
 & =\sum_{i=0}^{3}\mathbf{E}[B_{i/3}^{3}]\cdot\mathbf{E}[(B_{(i+1)/3}-B_{i/2})^{2}]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
by independence of increments.
 The first factor of each term is zero (due to the nature of odd moments
 of a Gaussian centered at 
\begin_inset Formula $0$
\end_inset

).
 Therefore, the variables 
\begin_inset Formula $I_{1}$
\end_inset

 and 
\begin_inset Formula $J_{1}$
\end_inset

 are uncorrelated.
 
\end_layout

\begin_layout Remark*
An 
\emph on
isometry 
\emph default
is a mapping between metric spaces(that is, with a distance) that actually
 preserves the distance between two points.
 (It literally means the 
\emph on
same measure
\emph default
 in Greek.) In case of Ito's isometry, the mapping is the one that sends
 the integrand 
\begin_inset Formula $X$
\end_inset

 to the square-integrable random variable given by the integral:
\end_layout

\begin_layout Remark*
\begin_inset Formula 
\begin{align*}
I:\mathcal{S}(T) & \to L^{2}(\Omega,\mathcal{F},\mathbb{P})\\
X & \mapsto\int_{0}^{T}X_{s}dB_{s}
\end{align*}

\end_inset


\end_layout

\begin_layout Remark*
The 
\begin_inset Formula $L^{2}-$
\end_inset

norm of 
\begin_inset Formula $\int_{0}^{T}X_{s}dB_{s}$
\end_inset

 is 
\begin_inset Formula $\left\{ \mathbf{E}\left[\left(\int_{0}^{T}X_{s}dB_{s}\right){}^{2}\right]\right\} {}^{1/2}$
\end_inset

 .
 It turns out that the space 
\begin_inset Formula $\mathcal{S}(T)$
\end_inset

 is also a linear space with the norm 
\begin_inset Formula $\left\Vert X\right\Vert _{\mathcal{S}}=\left(\int_{0}^{T}\mathbf{E}[X_{s}]^{2}ds\right)^{1/2}$
\end_inset

.
 Ito's isometry says that these two norms (and hence the lengths) are equal.
 In fact, this isometry extends in part to the 
\begin_inset Formula $L^{2}-$
\end_inset

space of functions on 
\begin_inset Formula $\Omega\times[0,T]$
\end_inset

, for which 
\begin_inset Formula $\mathcal{S}(T)$
\end_inset

 is a subspace.
 We will see that this isometry is central to the extension of the Ito integral
 in the limit as 
\begin_inset Formula $n\to\infty.$
\end_inset


\end_layout

\begin_layout Remark*
The next goal is to extend the Ito integral to processes 
\begin_inset Formula $X$
\end_inset

 other than simple processes.
 The integral will be defined as a limit of the integrals of simple processes,
 much like the Riemann integral is a limit of the Riemann sums.
 But first, we need a good class of integrands.
 
\end_layout

\begin_layout Definition
For a given Brownian filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\leq T)$
\end_inset

, we consider the class of processes 
\begin_inset Formula $\mathcal{L}_{c}^{2}(T)$
\end_inset

 of processes 
\begin_inset Formula $(X_{t}:t\leq T)$
\end_inset

 such that the following hold:
\end_layout

\begin_layout Standard
(1) 
\begin_inset Formula $X_{t}$
\end_inset

 is adapted.
 That is, 
\begin_inset Formula $X_{t}$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

-measurable.
\end_layout

\begin_layout Standard
(2) The norm of 
\begin_inset Formula $X_{t}$
\end_inset

: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left\Vert X\right\Vert _{\mathcal{L}_{c}^{2}}^{2} & =\int_{0}^{T}\mathbf{E}[X_{t}^{2}]dt=\mathbf{E}\left[\int_{0}^{T}X_{t}^{2}dt\right]<\infty
\end{align*}

\end_inset

 (3) 
\begin_inset Formula $(X_{t})$
\end_inset

 is almost surely continuous.
\end_layout

\begin_layout Standard
It is not hard to check that the processes 
\begin_inset Formula $(B_{t}:t\leq T)$
\end_inset

 and 
\begin_inset Formula $(B_{t}^{2}:t\leq T)$
\end_inset

 are in
\begin_inset Formula $\mathcal{L}_{c}^{2}(T)$
\end_inset

.
 In fact, if 
\begin_inset Formula $f$
\end_inset

 is a continuous function and 
\begin_inset Formula $\int_{0}^{T}\mathbf{E}[f(B_{t})^{2}]dt<\infty$
\end_inset

, then the process 
\begin_inset Formula $(f(B_{t}):t\leq T)$
\end_inset

 is in 
\begin_inset Formula $\mathcal{L}_{c}^{2}(T)$
\end_inset

.
 Indeed, 
\begin_inset Formula $f(B_{t})$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

-measurable, since it is an explicit function of 
\begin_inset Formula $B_{t}$
\end_inset

.
 Moreover, the second condition is by assumption.
 The third simply holds because the composition of continuous functions
 is continuous.
 The main advantage of processes in 
\begin_inset Formula $\mathcal{L}_{c}^{2}(T)$
\end_inset

 is that they are easily approximated by simple adapted processes.
 
\end_layout

\begin_layout Lemma

\series bold
\begin_inset CommandInset label
LatexCommand label
name "lemma:approximation-lemma"

\end_inset

(Approximation Lemma
\series default
).
 Let 
\begin_inset Formula $X\in\mathcal{L}_{c}^{2}(T)$
\end_inset

.
 Then, there exists a sequence 
\begin_inset Formula $(X^{(n)})$
\end_inset

 of simple step adapted processes in 
\begin_inset Formula $\mathcal{S}(T)$
\end_inset

, such that:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\lim_{n\to\infty}\int_{0}^{T}\mathbf{E}[(X_{t}^{(n)}-X_{t})^{2}]dt=0
\]

\end_inset


\end_layout

\begin_layout Proof
(1) For a given 
\begin_inset Formula $n$
\end_inset

, consider the partition 
\begin_inset Formula $\{\frac{jT}{2^{n}},\frac{(j+1)T}{2^{n}}\}$
\end_inset

 and the simple step adapted process given by :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
X_{t}^{(n)}=\sum_{j=0}^{n}X_{t_{j}}\mathbf{1}_{(t_{j},t_{j+1}]}(t)
\]

\end_inset


\end_layout

\begin_layout Proof
In other words, we give the constant value 
\begin_inset Formula $X_{t_{j}}$
\end_inset

 on the whole interval 
\begin_inset Formula $(t_{j},t_{j+1}]$
\end_inset

.
 By continuity of paths of 
\begin_inset Formula $X$
\end_inset

, it is clear that 
\begin_inset Formula $X_{t}^{(n)}(\omega)\to X_{t}(\omega)$
\end_inset

 at any 
\begin_inset Formula $t\leq T$
\end_inset

 and for any 
\begin_inset Formula $\omega$
\end_inset

.
\end_layout

\begin_layout Proof
\begin_inset Formula $(\star)$
\end_inset

 
\series bold
Justification
\series default
.
 
\end_layout

\begin_layout Proof
For any 
\begin_inset Formula $s\in[0,T]$
\end_inset

, let 
\begin_inset Formula $A_{s}$
\end_inset

 be the set of all paths 
\begin_inset Formula $\omega$
\end_inset

, such that 
\begin_inset Formula $\lim_{t\to s}X(t,\omega)=X(s,\omega)$
\end_inset

.
 Then, 
\begin_inset Formula $\mathbb{P}(A_{s})=1$
\end_inset

.
\end_layout

\begin_layout Proof
Pick an arbitrary 
\begin_inset Formula $\epsilon>0$
\end_inset

 and fix a point 
\begin_inset Formula $c\in[0,T]$
\end_inset

.
 By definition of continuity, 
\begin_inset Formula $(\exists\delta>0)$
\end_inset

 such that for all 
\begin_inset Formula $|t-c|<\delta$
\end_inset

 implies 
\begin_inset Formula $|X_{t}-X_{c}|<\epsilon$
\end_inset

.
 By the Archimedean property, there exists 
\begin_inset Formula $N\in\mathbf{N}$
\end_inset

, such that 
\begin_inset Formula $\frac{1}{2^{N}}<\delta$
\end_inset

.
 
\end_layout

\begin_layout Proof
We divide the interval 
\begin_inset Formula $[0,T]$
\end_inset

 into 
\begin_inset Formula $2^{n}$
\end_inset

 subintervals of size 
\begin_inset Formula $\frac{T}{2^{n}}.$
\end_inset


\end_layout

\begin_layout Proof
We construct the simple process 
\begin_inset Formula $X^{(n)}$
\end_inset

, such that it takes the (random) but constant value 
\begin_inset Formula $X_{t_{j}}^{(n)}=X_{\frac{jT}{2^{n}}}$
\end_inset

 on the interval 
\begin_inset Formula $\frac{jT}{2^{n}}<t\leq\frac{(j+1)T}{2^{n}}$
\end_inset

.
 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
X_{t}^{(n)} & =\sum_{j=0}^{n-1}X_{\frac{jT}{2^{n}}}\cdot1_{t\in\left[\frac{jT}{2^{n}},\frac{(j+1)T}{2^{n}}\right)}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, there exists a sequence of dyadic intervals 
\begin_inset Formula $I_{N}\subseteq I_{N+1}\subseteq\ldots$
\end_inset

 always containing the point 
\begin_inset Formula $c$
\end_inset

.
 
\end_layout

\begin_layout Proof
From the almost sure continuity of 
\begin_inset Formula $(X_{t},t\leq T)$
\end_inset

, it follows that, for all 
\begin_inset Formula $n\geq N$
\end_inset

, since 
\begin_inset Formula $l(I_{n})<\delta$
\end_inset

, it follows that 
\begin_inset Formula $|X_{\frac{jT}{2^{n}}}-X_{c}|<\epsilon$
\end_inset

 with probability 
\begin_inset Formula $1$
\end_inset

.
 Now, for all 
\begin_inset Formula $n\geq N$
\end_inset

, 
\begin_inset Formula $X_{c}^{(n)}=X_{\frac{jT}{2^{n}}}$
\end_inset

.
 Consequently, for all 
\begin_inset Formula $n\geq N$
\end_inset

, 
\begin_inset Formula $\left|X_{c}^{(n)}-X_{c}\right|<\epsilon$
\end_inset

 with probability 
\begin_inset Formula $1$
\end_inset

.
 
\end_layout

\begin_layout Proof
Thus, 
\begin_inset Formula $X_{t}^{(n)}\xrightarrow{a.s.}X_{t}$
\end_inset

.
\end_layout

\begin_layout Proof
(2) Assume that 
\begin_inset Formula $(X_{t}^{(n)}-X_{t})$
\end_inset

 is uniformly bounded.
 
\begin_inset Formula $(\exists M)$
\end_inset

 
\begin_inset Formula $(\forall\omega)$
\end_inset

 s.t.
 
\begin_inset Formula $|X_{t}^{(n)}(\omega)-X_{t}(\omega)|\leq M$
\end_inset

.
 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\left\Vert X_{t}^{(n)}-X_{t}\right\Vert _{\mathcal{L}_{c}^{2}}^{2} & =\int_{0}^{T}\mathbf{E}[(X_{t}^{(n)}-X_{t})^{2}]dt
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Passing to the limit on both sides, by the dominated convergence theorem:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim\left\Vert X_{t}^{(n)}-X_{t}\right\Vert _{\mathcal{L}_{c}^{2}} & =\lim_{n\to\infty}\int_{0}^{T}\mathbf{E}[(X_{t}^{(n)}-X_{t})^{2}]dt=0
\end{align*}

\end_inset


\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lemma:convergence-in-l2-implies-convergence-of-first-and-second-moments"

\end_inset

(Convergence in 
\begin_inset Formula $L^{2}$
\end_inset

 implies convergence of the first and second moments).
 Let 
\begin_inset Formula $(X_{n}:n\geq0)$
\end_inset

 be a sequence of random variables that converge to 
\begin_inset Formula $X$
\end_inset

 in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
\end_layout

\begin_layout Lemma
(a) Show that 
\begin_inset Formula $\mathbf{E}[X_{n}^{2}]$
\end_inset

 converges to 
\begin_inset Formula $\mathbf{E}[X^{2}]$
\end_inset

.
\end_layout

\begin_layout Lemma
Hint: Write 
\begin_inset Formula $X=(X-X_{n})+X_{n}$
\end_inset

.
 The Cauchy Schwarz inequality might be useful.
 
\end_layout

\begin_layout Lemma
(b) Show that 
\begin_inset Formula $\mathbf{E}[X_{n}]$
\end_inset

 converges to 
\begin_inset Formula $\mathbf{E}[X]$
\end_inset

.
\end_layout

\begin_layout Lemma
Hint: Write 
\begin_inset Formula $|\mathbf{E}[X_{n}]-\mathbf{E}[X]|$
\end_inset

 and use Jensen's inequality twice.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
(a) We are given that 
\begin_inset Formula $\lim_{n\to\infty}\mathbf{E}[|X_{n}-X|^{2}]\to0$
\end_inset

.
 Firstly, let 
\begin_inset Formula $c(x)=|x|$
\end_inset

.
 Let 
\begin_inset Formula $p\in(0,1)$
\end_inset

.
 We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
c(pa+(1-p)b) & =|pa+(1-p)b|\\
 & \leq p|a|+(1-p)|b|\\
 & =pc(a)+(1-p)c(b)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Hence, 
\begin_inset Formula $|x|$
\end_inset

 is a convex function.
 Consequently, 
\begin_inset Formula $0\leq|\mathbf{E}[X^{2}-X_{n}^{2}]|\leq\mathbf{E}[|X^{2}-X_{n}^{2}]$
\end_inset

.
 Therefore, we can write:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{alignat*}{1}
0\leq|\mathbf{E}[X^{2}-X_{n}^{2}]| & \leq\mathbf{E}[|X^{2}-X_{n}^{2}|]\\
 & =\mathbf{E}[|((X-X_{n})+X_{n})^{2}-X_{n}^{2}|]\\
 & =\mathbf{E}[|(X-X_{n})^{2}+2(X-X_{n})X_{n}+X_{n}^{2}-X_{n}^{2}|]\\
 & \leq\mathbf{E}[|X-X_{n}|^{2}]+2\mathbf{E}[|(X-X_{n})(X_{n})|]\\
 & \leq\mathbf{E}[|X-X_{n}|^{2}]+2\left(\mathbf{E}[|(X-X_{n})|^{2}]\right)^{1/2}\left(\mathbf{E}[|X_{n}|^{2}]\right)^{1/2}\\
 & \{\text{Cauchy-Schwarz}\}
\end{alignat*}

\end_inset


\end_layout

\begin_layout Standard
Passing to the limit on both sides as 
\begin_inset Formula $n\to\infty$
\end_inset

, it follows that 
\begin_inset Formula $\lim|\mathbf{E}[X_{n}^{2}]-\mathbf{E}[X^{2}]|\to0$
\end_inset

.
 Consequently, 
\begin_inset Formula $\mathbf{E}[X_{n}^{2}]\to\mathbf{E}[X^{2}]$
\end_inset

.
 
\end_layout

\begin_layout Standard
(b) We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
0\leq|\mathbf{E}[X_{n}]-\mathbf{E}[X]| & =|\mathbf{E}[X_{n}-X]|\\
 & \leq\mathbf{E}[|X_{n}-X|]\\
 & \{\text{since \ensuremath{|x|} is a convex function}\}\\
 & \leq\left(\mathbf{E}[|X_{n}-X|^{2}]\right)^{1/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Passing to the limit on both sides, as 
\begin_inset Formula $n\to\infty$
\end_inset

, 
\begin_inset Formula $\mathbf{E}[X_{n}]\to\mathbf{E}[X]$
\end_inset

.
\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lemma:l2-spaces-are-complete"

\end_inset

We prove that the space 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 is complete; that is, if 
\begin_inset Formula $(X_{n}:n\geq1)$
\end_inset

 is a Cauchy sequence in 
\begin_inset Formula $L^{2}$
\end_inset

, then there exists 
\begin_inset Formula $X\in L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 such that 
\begin_inset Formula $X_{n}\to X$
\end_inset

 in 
\begin_inset Formula $L^{2}$
\end_inset

.
\end_layout

\begin_layout Lemma
(a) Argue from the definition of Cauchy sequence that we can find a subsequence
 
\begin_inset Formula $(X_{n_{k}}:k\geq0)$
\end_inset

 such that 
\begin_inset Formula $\left\Vert X_{m}-X_{n_{k}}\right\Vert \leq2^{-k}$
\end_inset

 for all 
\begin_inset Formula $m>n_{k}$
\end_inset

 where 
\begin_inset Formula $\left\Vert \cdot\right\Vert $
\end_inset

 is the 
\begin_inset Formula $L^{2}$
\end_inset

 norm.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
We are given that 
\begin_inset Formula $(X_{n}:n\in\mathbf{N})$
\end_inset

 is a Cauchy sequence.
 For a Cauchy sequence, given any 
\begin_inset Formula $\epsilon>0$
\end_inset

, we can find 
\begin_inset Formula $N(\epsilon)$
\end_inset

, such that for all 
\begin_inset Formula $m>n\geq N(\epsilon)$
\end_inset

, 
\begin_inset Formula $||X_{n}-X_{m}||<\epsilon$
\end_inset

.
 Let 
\begin_inset Formula $\epsilon_{k}=\frac{1}{2^{k}}$
\end_inset

.
 There exists 
\begin_inset Formula $n_{1}$
\end_inset

 such that for all 
\begin_inset Formula $m\geq n_{1}$
\end_inset

, 
\begin_inset Formula $||X_{n_{1}}-X_{m}||<\epsilon$
\end_inset

.
 There exists 
\begin_inset Formula $n_{2}$
\end_inset

 such that for all 
\begin_inset Formula $m\geq n_{2}$
\end_inset

, 
\begin_inset Formula $||X_{n_{2}}-X_{m}||<\frac{\epsilon}{2}$
\end_inset

.
 In general, there exists 
\begin_inset Formula $n_{k}$
\end_inset

, such that for all 
\begin_inset Formula $m\geq n_{k}$
\end_inset

,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\left\Vert X_{n_{k}}-X_{m}\right\Vert _{L^{2}} & <\epsilon_{k}=\frac{1}{2^{k}}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
(b) Consider the candidate limit 
\begin_inset Formula $\sum_{j=0}^{\infty}(X_{n_{j+1}}-X_{n_{j}})$
\end_inset

 with 
\begin_inset Formula $X_{n_{0}}=0$
\end_inset

.
 Show that this sum converges almost surely (so 
\begin_inset Formula $X$
\end_inset

 is well-defined) by considering
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sum_{j=0}^{k}\mathbf{E}\left[\left|X_{n_{j+1}}-X_{n_{j}}\right|\right]
\]

\end_inset


\end_layout

\begin_layout Proof
Firstly, by Jensen's inequality, we have 
\begin_inset Formula $(\mathbf{E}[|X|])^{2}\leq\mathbf{E}[|X|^{2}]$
\end_inset

.
 So, 
\begin_inset Formula $\mathbf{E}[|X|]\leq\mathbf{E}[|X|^{2}]^{\frac{1}{2}}$
\end_inset

 or 
\begin_inset Formula $\left\Vert X\right\Vert _{L^{1}}\leq\left\Vert X\right\Vert _{L^{2}}$
\end_inset

.
 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $A_{k}(\epsilon)$
\end_inset

 be the event that there is an excursion at 
\begin_inset Formula $n_{k}$
\end_inset

, 
\begin_inset Formula $\left\{ \left|X_{n_{k+1}}-X_{n_{k}}\right|>\epsilon\right\} $
\end_inset

.
 And let 
\series bold

\begin_inset Formula $B_{k}(\epsilon)$
\end_inset

 
\series default
be the event that atleast one of 
\begin_inset Formula $A_{k},A_{k+1},\ldots$
\end_inset

 occurs, 
\begin_inset Formula $\bigcup_{m\geq k}A_{m}(\epsilon)$
\end_inset

.
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{P}(B_{k}) & =\mathbb{P}(\cup_{m\geq k}A_{m})\\
 & \leq\sum_{m\geq k}\mathbb{P}(A_{m})\\
 & \left\{ \text{Union bound}\right\} \\
 & \leq\frac{1}{\epsilon}\sum_{m\geq k}\mathbb{E}[|X_{n_{m+1}}-X_{n_{m}}|]\\
 & \left\{ \text{Chebyshev Inequality}\right\} \\
 & \leq\frac{1}{\epsilon}\sum_{m\geq k}\left\Vert X_{n_{m+1}}-X_{n_{m}}\right\Vert _{L^{2}}\\
 & \leq\frac{1}{\epsilon}\sum_{m\geq k}\frac{1}{2^{m}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The series on the right is convergent.
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\lim_{k\to\infty}\mathbb{P}(B_{k}) & \leq\frac{1}{\epsilon}\lim_{k\to\infty}\sum_{m\geq k}\frac{1}{2^{m}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The tail sum of a convergent series approaches zero.
 So, 
\begin_inset Formula $\lim_{k\to\infty}\mathbb{P}(B_{k})=0$
\end_inset

.
\end_layout

\begin_layout Proof
By the necessary and sufficient condition for almost sure convergence, the
 series 
\begin_inset Formula $\sum\left(X_{n_{k+1}}-X_{n_{k}}\right)$
\end_inset

 converges almost surely.
\end_layout

\begin_layout Standard
(c) Show that 
\begin_inset Formula $\left\Vert X-X_{n_{k}}\right\Vert _{L_{2}}\to0$
\end_inset

 as 
\begin_inset Formula $k\to\infty$
\end_inset

.
 Conclude that 
\begin_inset Formula $\left\Vert X\right\Vert <\infty$
\end_inset

.
 (This shows the convergence in 
\begin_inset Formula $L^{2}$
\end_inset

 along the subsequence!)
\end_layout

\begin_layout Proof
We have shown that the sum 
\begin_inset Formula $\sum_{k=0}^{\infty}(X_{n_{k+1}}-X_{n_{k}})$
\end_inset

 converges and let the candidate limit be 
\begin_inset Formula $X$
\end_inset

.
 Therefore, 
\begin_inset Formula $\lim_{N\to\infty}\sum_{j=0}^{N}(X_{n_{j+1}}-X_{n_{j}})=X$
\end_inset

 almost surely.
 Therefore:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
X-X_{n_{k}} & =\lim_{N\to\infty}\sum_{j=k}^{N}(X_{n_{j+1}}-X_{n_{j}})=\liminf_{N\to\infty}\sum_{j=k}^{N}(X_{n_{j+1}}-X_{n_{j}})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
since 
\begin_inset Formula $X_{n_{k}}=\sum_{j=0}^{k-1}(X_{n_{j+1}}-X_{n_{j}})$
\end_inset

 and 
\begin_inset Formula $\liminf a_{n}=\lim a_{n}=\limsup a_{n}$
\end_inset

 for a convergent sequence 
\begin_inset Formula $(a_{n})$
\end_inset

.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\left\Vert X-X_{n_{k}}\right\Vert _{2} & =\left\Vert \liminf_{N\to\infty}\sum_{j=k}^{N}(X_{n_{j+1}}-X_{n_{j}})\right\Vert _{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By Fatou's lemma,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\left\Vert \liminf_{N\to\infty}\sum_{j=k}^{N}(X_{n_{j+1}}-X_{n_{j}})\right\Vert _{2} & \leq\liminf_{N\to\infty}\left\Vert \sum_{j=k}^{N}(X_{n_{j+1}}-X_{n_{j}})\right\Vert _{2}\\
 & \leq\liminf_{N\to\infty}\sum_{j=k}^{N}\left\Vert (X_{n_{j+1}}-X_{n_{j}})\right\Vert _{2}\\
 & \left\{ \text{Triangle Inequality}\right\} \\
 & =\frac{1}{2^{k}}\left(1+\frac{1}{2}+\frac{1}{2^{2}}+\ldots\right)\\
 & =\frac{1}{2^{k-1}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Thus, as 
\begin_inset Formula $k\to\infty$
\end_inset

, 
\begin_inset Formula $\left\Vert X-X_{n_{k}}\right\Vert _{2}\to0$
\end_inset

.
\end_layout

\begin_layout Proof
Similarly,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
X & =\lim_{N\to\infty}\sum_{j=0}^{N}(X_{n_{j+1}}-X_{n_{j}})=\liminf_{N\to\infty}\sum_{j=0}^{N}(X_{n_{j+1}}-X_{n_{j}})
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
So,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\left\Vert X\right\Vert _{2} & =\left\Vert \liminf_{N\to\infty}\sum_{j=0}^{N}(X_{n_{j+1}}-X_{n_{j}})\right\Vert _{2}\\
 & \leq\liminf_{N\to\infty}\left\Vert \sum_{j=0}^{N}(X_{n_{j+1}}-X_{n_{j}})\right\Vert _{2}\\
 & \{\text{Fatou's Lemma}\}\\
 & \leq\liminf_{N\to\infty}\sum_{j=0}^{N}\left\Vert (X_{n_{j+1}}-X_{n_{j}})\right\Vert _{2}\\
 & \{\text{Triangle Inequality}\}\\
 & =1+\frac{1}{2}+\frac{1}{2^{2}}+\ldots\\
 & <\infty
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(d) Use again the Cauchy definition and the subsequence to show convergence
 of the whole sequence that is, 
\begin_inset Formula $\left\Vert X-X_{n}\right\Vert \to0$
\end_inset

.
\end_layout

\begin_layout Proof
We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\left\Vert X-X_{n}\right\Vert  & =\left\Vert X-X_{n_{k}}+X_{n_{k}}-X_{n}\right\Vert \\
 & \leq\left\Vert X-X_{n_{k}}\right\Vert +\left\Vert X_{n_{k}}-X_{n}\right\Vert \\
 & \quad\{\text{Triangle inequality}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Pick an arbitrary 
\begin_inset Formula $\epsilon>0$
\end_inset

.
 There exists 
\begin_inset Formula $K_{1}(\epsilon)$
\end_inset

 such that, 
\begin_inset Formula $\left\Vert X-X_{n_{K_{1}}}\right\Vert <\epsilon/2$
\end_inset

.
 There exists 
\begin_inset Formula $K_{2}(\epsilon)$
\end_inset

 such that for all 
\begin_inset Formula $n>n_{K_{2}}$
\end_inset

, 
\begin_inset Formula $\left\Vert X_{n_{K_{2}}}-X_{n}\right\Vert <\epsilon/2$
\end_inset

.
 Pick 
\begin_inset Formula $n_{K}=\max\{n_{K_{1}},n_{K_{2}}\}$
\end_inset

.
 Then, for all 
\begin_inset Formula $n>n_{K}$
\end_inset

, 
\begin_inset Formula $\left\Vert X-X_{n}\right\Vert <\epsilon$
\end_inset

.
 Consequently, 
\begin_inset Formula $\left\Vert X-X_{n}\right\Vert \to0$
\end_inset

.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "th:properties-of-ito-integral"

\end_inset

Let 
\begin_inset Formula $(B_{t}:t\leq T)$
\end_inset

 be a standard Brownian motion on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Let 
\begin_inset Formula $(X_{t}:t\leq T)$
\end_inset

 be a process in 
\begin_inset Formula $\mathcal{L}_{c}^{2}(T)$
\end_inset

.
 There exist random variables 
\begin_inset Formula $\int_{0}^{t}X_{s}dB_{s}$
\end_inset

, 
\begin_inset Formula $t\leq T$
\end_inset

 with the following properties:
\end_layout

\begin_layout Theorem
(1) Linearity: If 
\begin_inset Formula $X,Y\in\mathcal{L}_{c}^{2}(T)$
\end_inset

 and 
\begin_inset Formula $a,b\in\mathbf{R}$
\end_inset

, then
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
\int_{0}^{t}(aX_{s}+bY_{s})dB_{s} & =a\int_{0}^{t}X_{s}dB_{s}+b\int_{0}^{t}Y_{s}dB_{s},\quad t\leq T
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
(2) Continuous Martingale: The process 
\begin_inset Formula $(\int_{0}^{t}X_{s}dB_{s},t\leq T)$
\end_inset

 is a continuous martingale for the Brownian filtration.
\end_layout

\begin_layout Theorem
(3) Ito's Isometry: The random variable 
\begin_inset Formula $\int_{0}^{t}X_{s}dB_{s}$
\end_inset

 is in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}\right)^{2}\right] & =\int_{0}^{t}\mathbf{E}[X_{s}^{2}]ds=\mathbf{E}\left[\int_{0}^{t}X_{s}^{2}ds\right],\quad t\leq T
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
In other words,
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
\left\Vert I^{X}(t)\right\Vert _{L^{2}} & =\left\Vert X\right\Vert _{\mathcal{L}_{c}^{2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Consider the process 
\begin_inset Formula $X=(X_{t}:t\leq T)$
\end_inset

 in 
\begin_inset Formula $\mathcal{L}_{c}^{2}(T)$
\end_inset

.
 By the approximation lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lemma:approximation-lemma"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we can approximate 
\begin_inset Formula $X$
\end_inset

 by a sequence of simple adapted processes 
\begin_inset Formula $(X_{t}^{(n)}:t\leq T)$
\end_inset

.
 In particular, that the sequence is Cauchy for the metric 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
\left\Vert X^{(n)}-X^{(m)}\right\Vert _{\mathcal{L}_{c}^{2}} & =\left(\int_{0}^{t}\mathbf{E}[(X_{s}^{(n)}-X_{s}^{(m)})^{2}]dt\right)^{1/2}\label{eq:distance-between-the-approximating-processes-in-L_c^2}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
The key step is the following.
 We know that the integral 
\begin_inset Formula $I^{X^{(n)}}(t)=\int_{0}^{t}X_{s}^{(n)}dB_{s}$
\end_inset

 is well defined as a random variable in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Moreover, we know from Ito Isometry, that the 
\begin_inset Formula $L^{2}-$
\end_inset

distance of the processes in equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:distance-between-the-approximating-processes-in-L_c^2"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is the same as the 
\begin_inset Formula $L^{2}$
\end_inset

 distance of the 
\begin_inset Formula $I^{X^{(n)}}$
\end_inset

's.
 Since 
\begin_inset Formula $(X^{(n)})$
\end_inset

 is Cauchy in 
\begin_inset Formula $\mathcal{L}_{c}^{2}$
\end_inset

, it means that the sequence 
\begin_inset Formula $(I^{X^{(n)}},n\in\mathbf{N})$
\end_inset

 is Cauchy in 
\begin_inset Formula $L^{2}$
\end_inset

.
 By Cauchy completeness property, 
\begin_inset Formula $I^{X^{(n)}}$
\end_inset

 converges in 
\begin_inset Formula $L^{2}$
\end_inset

 to a random variable that we denote by 
\begin_inset Formula $I^{X}(t)$
\end_inset

 or 
\begin_inset Formula $\int_{0}^{t}X_{s}dB_{s}$
\end_inset

.
 Furthermore, the limit 
\begin_inset Formula $I^{X}(t)$
\end_inset

 does not depend on the approximating sequence 
\begin_inset Formula $(X^{(n)})$
\end_inset

.
 We could have taken any other sequence to approximate 
\begin_inset Formula $X$
\end_inset

 and Ito isometry guarantees, that the corresponding integrals will converge
 to the same random variable.
 
\end_layout

\begin_layout Proof
We now prove the properties.
\end_layout

\begin_layout Proof
(1) Linearity.
 It follows by using linearity property in proposition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:properties-of-ito-integral-discrete-case"
plural "false"
caps "false"
noprefix "false"

\end_inset

 for 
\begin_inset Formula $X^{(n)}$
\end_inset

 and 
\begin_inset Formula $Y^{(n)}$
\end_inset

, the two sequences of approximating processes of 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
I(aX^{(n)}+bY^{(n)}) & =aI(X^{(n)})+bI(Y^{(n)})\\
\lim_{n\to\infty}I(aX^{(n)}+bY^{(n)}) & =a\lim_{n\to\infty}I(X^{(n)})+b\lim_{n\to\infty}I(Y^{(n)})\\
I(aX+bY) & =aI(X)+bI(Y)
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(2) Isometry.
 We refer lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lemma:convergence-in-l2-implies-convergence-of-first-and-second-moments"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The variance property now follows from the following facts:
\end_layout

\begin_layout Proof
The convergence of a sequence 
\begin_inset Formula $(X_{n})$
\end_inset

 to 
\begin_inset Formula $X$
\end_inset

 in 
\begin_inset Formula $L^{2}$
\end_inset

, implies the convergence of the first and second moments.
\end_layout

\begin_layout Proof
\begin_inset Formula $\mathcal{L}_{c}^{2}$
\end_inset

 is a subspace of 
\begin_inset Formula $L^{2}$
\end_inset

.
 Since, 
\begin_inset Formula $X^{(n)}\to X$
\end_inset

 in 
\begin_inset Formula $\mathcal{L}_{c}^{2}$
\end_inset

, it follows that 
\begin_inset Formula $||X^{(n)}-X||\to0$
\end_inset

.
 Thus,
\begin_inset Formula $\int_{0}^{t}\mathbf{E}\left[\left(X_{s}^{(n)}\right)^{2}\right]ds$
\end_inset

 converges to 
\begin_inset Formula $\int_{0}^{t}\mathbf{E}[X_{s}^{2}]ds$
\end_inset

.
 
\end_layout

\begin_layout Proof
Now, 
\begin_inset Formula $I_{t}^{X^{(n)}}\to I_{t}$
\end_inset

 in 
\begin_inset Formula $L^{2}$
\end_inset

.
 So, 
\begin_inset Formula $\mathbf{E}[I_{t}^{X^{(n)}}]\to\mathbf{E}[I_{t}^{X}]$
\end_inset

 and 
\begin_inset Formula $\mathbf{E}[\left(I_{t}^{X^{(n)}}\right)^{2}]\to\mathbf{E}[\left(I_{t}^{X}\right)^{2}]$
\end_inset

.
 That is, 
\begin_inset Formula $\mathbf{E}\left[\left(\int_{0}^{t}X_{s}^{(n)}dB_{s}\right)^{2}\right]$
\end_inset

 converges to 
\begin_inset Formula $\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}\right)^{2}\right]$
\end_inset

.
 
\end_layout

\begin_layout Proof
Since, Ito isometry for simple adapted processes implies 
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\int_{0}^{t}\mathbf{E}\left[\left(X_{s}^{(n)}\right)^{2}\right]ds & =\mathbf{E}[\left(I_{t}^{X^{(n)}}\right)^{2}]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
these sequences are equal and have the same limits.
 Consequently,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\int_{0}^{t}\mathbf{E}[X_{s}^{2}]ds & =\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}\right)^{2}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
(3) Continuous Martingale.
 Write 
\begin_inset Formula $I_{t}=\int_{0}^{t}X_{s}dB_{s}$
\end_inset

.
 We must show that 
\begin_inset Formula $\mathbf{E}[I_{t}|\mathcal{F}_{s}]=I_{s}$
\end_inset

 for any 
\begin_inset Formula $t>s$
\end_inset

.
 To see this, we go back to the definition of conditional expectations.
 The random variable 
\begin_inset Formula $I_{t}$
\end_inset

 must be 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

 measurable by construction.
 Now, for a bounded random variable 
\begin_inset Formula $W$
\end_inset

 that is 
\begin_inset Formula $\mathcal{F}_{s}$
\end_inset

-measurable, we need to show that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}[WI_{t}] & =\mathbf{E}[W\mathbf{E}[I_{t}|\mathcal{F}_{s}]]=\mathbf{E}[WI_{s}]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
This is clear for 
\begin_inset Formula $I_{t}^{(n)}$
\end_inset

, the approximating integrals, because 
\begin_inset Formula $(I_{t}^{(n)},t\leq T)$
\end_inset

 is a martingale.
 The above then follows from the fact that 
\begin_inset Formula $WI_{s}^{(n)}$
\end_inset

 converges to 
\begin_inset Formula $WI_{s}$
\end_inset

 in 
\begin_inset Formula $L^{2}$
\end_inset

 (and thus the expectation converges) and the same way for 
\begin_inset Formula $t$
\end_inset

.
 The fact that the path 
\begin_inset Formula $t\to I_{t}(\omega)$
\end_inset

 is continuous with probability one is a bit more involved.
 It uses Doob's maximal inequality.
\end_layout

\begin_layout Example
(Sampling Ito Integrals) How can we sample paths of processes given by Ito
 integrals? A very simple method is to go back to the integral on simple
 processes.
 Consider the process 
\begin_inset Formula $I_{t}=\int_{0}^{t}X_{s}dB_{s}$
\end_inset

, 
\begin_inset Formula $t\leq T$
\end_inset

 constructed from 
\begin_inset Formula $X\in\mathcal{L}_{c}^{2}(T)$
\end_inset

 and from a standard brownian motion 
\begin_inset Formula $(B_{t},t\geq0)$
\end_inset

.
 To simulate paths, we fix the endpoint, say 
\begin_inset Formula $T$
\end_inset

 and a step-size 
\begin_inset Formula $1/n$
\end_inset

.
 Then, we can generate the process at every 
\begin_inset Formula $t_{j}=\frac{jT}{n}$
\end_inset

 by taking 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
I_{t_{j}} & =\sum_{i=0}^{j-1}X_{t_{i}}(B_{t_{i+1}}-B_{t_{i}}),\quad j\leq n
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Here are two observations that makes this expression more palatable.
 First note that the increment 
\begin_inset Formula $B_{t_{i+1}}-B_{t_{i}}$
\end_inset

 is a Gaussian random variable of mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $\frac{T}{n}$
\end_inset

 for every 
\begin_inset Formula $i.$
\end_inset

 Second, we have 
\begin_inset Formula $I_{t_{j}}-I_{t_{j-1}}=X_{t_{j-1}}(B_{t_{j}}-B_{t_{j-1}})$
\end_inset

, so the values 
\begin_inset Formula $I_{t_{j}}$
\end_inset

 can be computed recursively.
 
\end_layout

\begin_layout Standard
Once the conclusions of theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:properties-of-ito-integral"
plural "false"
caps "false"
noprefix "false"

\end_inset

 are accepted, we are free to explore the beauty and the power of Ito Calculus.
 As a first step, we observe that with Ito's isometry, we can compute not
 only variances, but also covariances between integrals.
 This is because an isometry also preserves the inner product in 
\begin_inset Formula $L^{2}$
\end_inset

 spaces.
 
\end_layout

\begin_layout Example

\series bold
\begin_inset CommandInset label
LatexCommand label
name "ex:increments-of-martingales-are-uncorrelated"

\end_inset

Increments of martingales are uncorrelated.
\end_layout

\begin_layout Example
(a) Let 
\begin_inset Formula $(M_{t}:t\geq0)$
\end_inset

 be a square integrable martingale for the filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

.
 Use the properties of conditional expectation to show that for 
\begin_inset Formula $t_{1}\leq t_{2}\leq t_{3}\leq t_{4}$
\end_inset

, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[(M_{t_{2}}-M_{t_{1}})(M_{t_{4}}-M_{t_{3}})] & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
(b) Let 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

 be a standard brownian motion, and let 
\begin_inset Formula $(X_{t}:t\leq T)$
\end_inset

 be a process in 
\begin_inset Formula $\mathcal{L}_{c}^{2}(T)$
\end_inset

.
 Use part(a) to show that the covariance between integrals at different
 times 
\begin_inset Formula $t<t'$
\end_inset

 is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}\right)\left(\int_{0}^{t'}X_{s}dB_{s}\right)\right] & =\int_{0}^{t\land t'}\mathbf{E}[X_{s}^{2}]ds,\quad t,t\leq T
\end{align*}

\end_inset


\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
(a) We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[(M_{t_{2}}-M_{t_{1}})(M_{t_{4}}-M_{t_{3}})\right] & =\mathbf{E}\left[(M_{t_{2}}-M_{t_{1}})\mathbf{E}[(M_{t_{4}}-M_{t_{3}})|\mathcal{F}_{t_{3}}]\right]\\
 & =\mathbf{E}\left[(M_{t_{2}}-M_{t_{1}})(M_{t_{3}}-M_{t_{3}})|\mathcal{F}_{t_{3}}]\right]\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
(b) Let 
\begin_inset Formula $(X_{t}:t\leq T)$
\end_inset

 be a process in 
\begin_inset Formula $\mathcal{L}_{c}^{2}(T)$
\end_inset

.
 We know that the Ito integral 
\begin_inset Formula $I^{X}(t)=\int_{0}^{t}X_{s}dB_{s}$
\end_inset

 is a continuous martingale.
 With 
\begin_inset Formula $0\leq t\leq t'$
\end_inset

, consider the increments: 
\begin_inset Formula $(I^{X}(t)-0)$
\end_inset

, 
\begin_inset Formula $(I^{X}(t')-I^{X}(t))$
\end_inset

.
 These increments are uncorrelated.
 Hence, 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[I^{X}(t)(I^{X}(t')-I^{X}(t))\right] & =0\\
\mathbf{E}[I^{X}(t)I^{X}(t')] & =\mathbf{E}[(I^{X}(t))^{2}]\\
\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}\right)\left(\int_{0}^{t'}X_{s}dB_{s}\right)\right] & =\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}\right)^{2}\right]\\
 & =\int_{0}^{t\lor t'}\mathbf{E}[X_{s}]^{2}ds
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This closes the proof.
\end_layout

\begin_layout Corollary
\begin_inset CommandInset label
LatexCommand label
name "corollary:covariance-of-ito-integrals"

\end_inset

Let 
\begin_inset Formula $(B_{t}:t\leq T)$
\end_inset

 be a standard brownian motion, and let 
\begin_inset Formula $X\in\mathcal{L}_{c}^{2}(T)$
\end_inset

.
 We have:
\end_layout

\begin_layout Corollary
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[I_{t}I_{t'}\right] & =\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}\right)\left(\int_{0}^{t'}X_{s}dB_{s}\right)\right]=\int_{0}^{t\land t'}\mathbf{E}[X_{s}^{2}]ds,\quad t,t\leq T
\end{align*}

\end_inset

for any 
\begin_inset Formula $Y\in\mathcal{L}_{c}^{2}(T)$
\end_inset

, and 
\end_layout

\begin_layout Corollary
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}\right)\left(\int_{0}^{t}Y_{s}dB_{s}\right)\right] & =\int_{0}^{t}\mathbf{E}[X_{s}Y_{s}]ds,\quad t\leq T
\end{align*}

\end_inset


\end_layout

\begin_layout Corollary
Note that, when 
\begin_inset Formula $X$
\end_inset

 is just a constant 
\begin_inset Formula $1$
\end_inset

, we recover from the first equation the covariance of the Brownian motion.
 
\end_layout

\begin_layout Proof
We just proved assertion (1) in the example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:increments-of-martingales-are-uncorrelated"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 As for the second, we have on one hand by Ito's isometry:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\left(\int_{0}^{t}\{X_{s}+Y_{s}\}dB_{s}\right)^{2}\right] & =\int_{0}^{t}\mathbf{E}[(X_{s}+Y_{s})^{2}]ds\\
 & =\int_{0}^{t}\mathbf{E}[X_{s}^{2}]ds+\int_{0}^{t}\mathbf{E}[Y_{s}^{2}]ds+2\int_{0}^{t}\mathbf{E}[X_{s}Y_{s}]ds
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
On the other hand, by linearity of Ito integral and of the expectation,
 we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\left(\int_{0}^{t}\{X_{s}+Y_{s}\}dB_{s}\right)^{2}\right] & =\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}+\int Y_{s}dB_{s}\right)^{2}\right]\\
 & =\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}\right)^{2}\right]+\mathbf{E}\left[\left(\int_{0}^{t}Y_{s}dB_{s}\right)^{2}\right]\\
 & +2\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}\right)\left(\int_{0}^{t}Y_{s}dB_{s}\right)\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By Ito's Isometry, 
\begin_inset Formula $\left\Vert I_{s}(X)\right\Vert _{L^{2}}=\left\Vert X\right\Vert _{\mathcal{L}_{c}^{2}}$
\end_inset

 and 
\begin_inset Formula $\left\Vert I_{s}(Y)\right\Vert _{L^{2}}=\left\Vert Y\right\Vert _{\mathcal{L}_{c}^{2}}$
\end_inset

.
 Hence, by equating the above two expressions, we conclude that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}\right)\left(\int_{0}^{t}Y_{s}dB_{s}\right)\right] & =\int_{0}^{t}\mathbf{E}[X_{s}Y_{s}]ds
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Thus, Ito isometry also preserves inner products.
 
\begin_inset Formula $\left\langle I_{t}(X),I_{t}(Y)\right\rangle _{L^{2}}=\left\langle X_{t},Y_{t}\right\rangle _{\mathcal{L}_{c}^{2}}$
\end_inset

.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "ex:example-of-covariance-of-ito-integrals"

\end_inset

Consider the processes 
\begin_inset Formula $(B_{t}:t\leq T)$
\end_inset

 and 
\begin_inset Formula $(B_{t}^{2}:t\leq T)$
\end_inset

 for a given standard Brownian motion.
 Note that these two processes are in 
\begin_inset Formula $\mathcal{L}_{c}^{2}(T)$
\end_inset

 for any 
\begin_inset Formula $T>0$
\end_inset

.
 By the existence theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:properties-of-ito-integral"
plural "false"
caps "false"
noprefix "false"

\end_inset

, the random variables 
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
I_{t}=\int_{0}^{t}B_{s}dB_{s},\quad J_{t}=\int_{0}^{t}B_{s}^{2}dB_{s}
\]

\end_inset


\end_layout

\begin_layout Example
exist and are in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Their mean is 
\begin_inset Formula $0$
\end_inset

 and they have variances 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[I_{t}^{2}] & =\int_{0}^{t}\mathbf{E}[B_{s}^{2}]ds=\int_{0}^{t}sds=\frac{t^{2}}{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
and 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[J_{t}^{2}] & =\int_{0}^{t}\mathbf{E}[B_{s}^{4}]ds=\int_{0}^{t}3s^{2}ds=t^{3}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The covariance by corollary 
\begin_inset CommandInset ref
LatexCommand eqref
reference "corollary:covariance-of-ito-integrals"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is :
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[I_{t}J_{t}] & =\int_{0}^{t}\mathbf{E}[B_{s}^{3}]ds=0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The variables are uncorrelated.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(A path-dependent integral) Consider the process 
\begin_inset Formula $X_{t}=\int_{0}^{t}B_{s}dB_{s}$
\end_inset

 on 
\begin_inset Formula $[0,T]$
\end_inset

 as in example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:example-of-covariance-of-ito-integrals"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Note that the process 
\begin_inset Formula $(X_{t}:t\leq T)$
\end_inset

 is itself in 
\begin_inset Formula $\mathcal{L}_{c}^{2}(T)$
\end_inset

.
 In particular, the integral 
\begin_inset Formula $\int_{0}^{t}X_{s}dB_{s}$
\end_inset

 is well-defined! (Note that the integrand 
\begin_inset Formula $X_{t}$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{t}-$
\end_inset

measurable but its value depends on the whole Brownian motion upto time
 
\begin_inset Formula $t$
\end_inset

).
 The mean of the integral is 
\begin_inset Formula $0$
\end_inset

 and its variance is obtained by applying Ito's isometry twice:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\left(\int_{0}^{t}X_{s}dB_{s}\right)^{2}\right] & =\int_{0}^{t}\mathbf{E}[X_{s}^{2}]ds\\
 & =\int_{0}^{t}\left(\int_{0}^{s}\mathbf{E}[B_{s}^{2}]ds\right)ds\\
 & =\int_{0}^{t}\left(\int_{0}^{s}sds\right)ds\\
 & =\int_{0}^{t}(s^{2}/2)ds\\
 & =\frac{t^{3}}{6}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
In general, the Ito integral is not Gaussian.
 However, if the integrand 
\begin_inset Formula $X$
\end_inset

 is not random, the process is actually Gaussian.
 In this particular case, the integral is sometimes called the 
\emph on
Wiener Integral
\emph default
.
\end_layout

\begin_layout Corollary
\begin_inset CommandInset label
LatexCommand label
name "cor:wiener-integral"

\end_inset

(Wiener Integral.) Let 
\begin_inset Formula $(B_{t}:t\leq T)$
\end_inset

 be a standard Brownian motion and let 
\begin_inset Formula $f:[0,T]\to\mathbf{R}$
\end_inset

 be a function such that 
\begin_inset Formula $\int_{0}^{T}f^{2}(s)ds<\infty$
\end_inset

.
 Then, the process 
\begin_inset Formula $(I_{t}(f):t\leq T)=(\int_{0}^{t}f(s)dB_{s}:t\leq T)$
\end_inset

 is Gaussian with mean 
\begin_inset Formula $0$
\end_inset

 and covariance:
\end_layout

\begin_layout Corollary
\begin_inset Formula 
\begin{align*}
Cov\left(\int_{0}^{t}f(s)dB_{s},\int_{0}^{t'}f(s)dB_{s}\right) & =\int_{0}^{t\land t'}f(s)^{2}ds
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We prove the case when 
\begin_inset Formula $f$
\end_inset

 is continuous.
 In this case, we can use the proof of the approximation Lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lemma:approximation-lemma"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Let 
\begin_inset Formula $(t_{j}:j\leq2^{n})$
\end_inset

 be a partition of 
\begin_inset Formula $2^{n}$
\end_inset

 intervals.
 The lemma shows that the sequence of functions:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
f^{(n)}(t) & =\sum_{j=0}^{2^{n}-1}f(t_{j})\mathbf{1}_{(t_{j},t_{j+1}]}(t),\quad t\leq T
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
approximates 
\begin_inset Formula $f$
\end_inset

.
 The Ito integral of 
\begin_inset Formula $f^{(n)}$
\end_inset

 is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
I_{t}^{(n)} & =\sum_{i=0}^{2^{n}-1}f(t_{j})(B_{t_{j+1}}-B_{t_{j}}),\quad t\in(t_{j},t_{j+1}]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
This is a Gaussian process for any 
\begin_inset Formula $n$
\end_inset

.
 This is because for any choice of times 
\begin_inset Formula $s_{1},\ldots,s_{m}$
\end_inset

, the vector 
\begin_inset Formula $(I_{s_{1}}^{(n)},I_{s_{2}}^{(n)},\ldots,I_{s_{m}}^{(n)})$
\end_inset

 is Gaussian, since it reduces to linear combinations of Brownian motion
 increments at fixed times.
 Moreover, the random variable 
\begin_inset Formula $\int_{0}^{t}f(s)dB_{s}$
\end_inset

 is the 
\begin_inset Formula $L^{2}$
\end_inset

 limit of 
\begin_inset Formula $I_{t}^{(n)}$
\end_inset

 by existence theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:properties-of-ito-integral"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 It remains to show that an 
\begin_inset Formula $L^{2}-$
\end_inset

limit of a sequence of Gaussian vectors is Gaussian.
 This is sketched in the example below.
 The expression for covariances follows from the collary on covariance of
 Ito integrals 
\begin_inset CommandInset ref
LatexCommand eqref
reference "corollary:covariance-of-ito-integrals"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Exercise
\begin_inset Formula $L^{2}-$
\end_inset

limit of Gaussians is Gaussian.
 Let 
\begin_inset Formula $(X_{n}:n\geq0)$
\end_inset

 be a sequence of Gaussian random variables that converge to 
\begin_inset Formula $X$
\end_inset

 in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 
\end_layout

\begin_layout Exercise
(a)Show that 
\begin_inset Formula $X$
\end_inset

 is also Gaussian.
\end_layout

\begin_layout Exercise

\emph on
Hint: Use the characteristic function of a Gaussian random variable.
 Use also the fact that there is a subsequence that converges almost surely.
\end_layout

\begin_layout Exercise
(b) Find its mean and variance in terms of 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
(a)The sequence 
\begin_inset Formula $(X_{n})$
\end_inset

 converges to 
\begin_inset Formula $X$
\end_inset

 in 
\begin_inset Formula $L^{2}.$
\end_inset

 Thus, 
\begin_inset Formula $\mathbf{E}X_{n}\to\mathbf{E}X$
\end_inset

 and 
\begin_inset Formula $\mathbf{E}X_{n}^{2}\to\mathbf{E}X^{2}$
\end_inset

.
\end_layout

\begin_layout Standard
Also, mean square convergence implies convergence in probability, which
 in turn also implies that there exists a subsequence 
\begin_inset Formula $(X_{n_{k}})$
\end_inset

 that converges to 
\begin_inset Formula $X$
\end_inset

 almost surely.
 
\end_layout

\begin_layout Standard
The characteristic function of 
\begin_inset Formula $X_{n_{k}}$
\end_inset

 is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
M_{X_{n_{k}}}(s) & =\exp\left[\frac{1}{2}\mathbf{E}[(X_{n_{k}}-\mathbf{E}X_{n_{k}})^{2}]s^{2}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Moreover, as 
\begin_inset Formula $X_{n_{k}}\to X$
\end_inset

 in distribution, their characteristic functions converge.
 So,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
M_{X}(s) & =\exp\left[\frac{1}{2}\mathbf{E}[(X-\mathbf{E}X)^{2}]s^{2}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This shows that 
\begin_inset Formula $X$
\end_inset

 is a Gaussian random variable.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(Ornstein-Uhlenbeck process as an Ito Integral).
 Consider the function 
\begin_inset Formula $f(s)=e^{s}$
\end_inset

.
 The Ornstein-Uhlenbeck process starting at 
\begin_inset Formula $X_{0}$
\end_inset

 can also be written as:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Y_{t} & =e^{-t}\int_{0}^{t}e^{s}dB_{s},\quad t\geq0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
To see this mathematically, not that 
\begin_inset Formula $(Y_{t}:t\geq0)$
\end_inset

 is a Gaussian process by corollary 
\begin_inset CommandInset ref
LatexCommand eqref
reference "cor:wiener-integral"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The mean is 
\begin_inset Formula $0$
\end_inset

 and the covariance by corollary 
\begin_inset CommandInset ref
LatexCommand eqref
reference "corollary:covariance-of-ito-integrals"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Y_{t}Y_{s}] & =e^{-t}\cdot e^{-s}\int_{0}^{s}e^{2u}du=e^{-t-s}\cdot\left[\frac{e^{2u}}{2}\right]_{0}^{s}\\
 & =e^{-t-s}\cdot\left(\frac{e^{2s}}{2}-\frac{1}{2}\right)\\
 & =\frac{1}{2}(e^{-(t-s)}-e^{-(t+s)}),\quad s\leq t
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In this case, the process is stationary in the sense that 
\begin_inset Formula $(Y_{t}:t\geq0)$
\end_inset

 has the same distribution as 
\begin_inset Formula $(Y_{t+a}:t\geq0)$
\end_inset

 for any 
\begin_inset Formula $a\geq0$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Exercise

\series bold
Another application of Doob's maximal inequality.
 
\series default
Let 
\begin_inset Formula $(B_{t}:t\in[0,1])$
\end_inset

 be a Brownian motion defined on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 The Brownian bridge 
\begin_inset Formula $(Z_{t}:t\in[0,1])$
\end_inset

 is the stochastic process with the distribution defined in example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "example:brownian-bridge"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Another way to construct a Brownian bridge is as follows:
\end_layout

\begin_layout Exercise
\begin_inset Formula 
\begin{align*}
Z_{t} & =(1-t)\int_{0}^{t}\frac{1}{1-s}dB_{s},\quad t<1
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
In this exercise, we prove that 
\begin_inset Formula $\lim_{t\to1}Z_{t}=0$
\end_inset

 almost surely as expected.
 
\end_layout

\begin_layout Standard
(a) Show that 
\begin_inset Formula $\lim_{t\to1}Z_{t}=0$
\end_inset

 in 
\begin_inset Formula $L^{2}(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
By Ito Isometry, 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Z_{t}^{2}] & =(1-t)^{2}\int_{0}^{t}\frac{1}{(1-s)^{2}}ds\\
 & =(1-t)^{2}\left[\frac{1}{(1-s)}\right]_{0}^{t}\\
 & =(1-t)^{2}\left(\frac{1}{1-t}-1\right)\\
 & =(1-t)^{2}\left(\frac{t}{(1-t)}\right)\\
 & =t(1-t)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Thus, 
\begin_inset Formula $\lim_{t\to1}\mathbf{E}[Z_{t}^{2}]=0$
\end_inset

.
 Hence, 
\begin_inset Formula $\lim_{t\to1}Z_{t}\overset{L^{2}}{\to}0$
\end_inset

.
\end_layout

\begin_layout Standard
(b) Using the Doob's maximal inequality of example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:doob's-maximal-inequality"
plural "false"
caps "false"
noprefix "false"

\end_inset

 show that:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\max_{t\in\left[1-\frac{1}{2^{n}},1-\frac{1}{2^{n+1}}\right]}|Z_{t}|>\delta\right) & <\frac{1}{\delta^{2}}\frac{1}{2^{n-1}}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
Pick an arbitrary 
\begin_inset Formula $\delta>0$
\end_inset

.
 Let 
\begin_inset Formula $A_{n}(\delta)$
\end_inset

 be the event that 
\begin_inset Formula $Z_{t}$
\end_inset

 exceeds 
\begin_inset Formula $\delta$
\end_inset

 in the interval 
\begin_inset Formula $\left[1-\frac{1}{2^{n}},1-\frac{1}{2^{n+1}}\right]$
\end_inset

.
 By Doob's maximal inequality, the probability of this event is bounded
 by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(A_{n}(\delta)\right) & \leq\frac{1}{\delta^{2}}\mathbf{E}[Z_{1-\frac{1}{2^{n+1}}}^{2}]\\
 & =\frac{1}{\delta^{2}}\left(1-\frac{1}{2^{n+1}}\right)\frac{1}{2^{n+1}}\\
 & \leq\frac{1}{\delta^{2}}\cdot\frac{1}{2^{n+1}}\\
 & \leq\frac{1}{\delta^{2}}\cdot\frac{1}{2^{n-1}}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
(c) Deduce that 
\begin_inset Formula $\lim_{t\to1}Z_{t}=0$
\end_inset

 almost surely using Borel-Cantelli Lemma.
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
Consider the infinite series 
\begin_inset Formula $\sum_{n=1}^{\infty}\mathbb{P}(A_{n}(\delta))$
\end_inset

.
 We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\sum_{n=1}^{\infty}\mathbb{P}(A_{n}(\delta)) & \leq\frac{1}{\delta^{2}}\sum_{n=1}^{\infty}\frac{1}{2^{n-1}}\\
 & =\frac{2}{\delta^{2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $\sum_{n=1}^{\infty}\mathbb{P}(A_{n}(\delta))<\infty$
\end_inset

, by BCL1(Borel-Cantelli Lemma 1), the event 
\begin_inset Formula $A_{n}(\delta)$
\end_inset

 occurs finitely many times, almost surely.
 There exists 
\begin_inset Formula $n_{0}\in\mathbf{N}$
\end_inset

, such that for all 
\begin_inset Formula $n\geq n_{0}$
\end_inset

, 
\begin_inset Formula $\max_{t\in\left[1-\frac{1}{2^{n}},1-\frac{1}{2^{n+1}}\right]}|Z_{t}|\leq\delta$
\end_inset

 with probability 
\begin_inset Formula $1$
\end_inset

.
 But, 
\begin_inset Formula $\lim_{n\to\infty}\max_{t\in\left[1-\frac{1}{2^{n}},1-\frac{1}{2^{n+1}}\right]}|Z_{t}|=Z_{1}$
\end_inset

.
 Consequently, 
\begin_inset Formula $(\forall\delta>0)$
\end_inset

, 
\begin_inset Formula $\mathbb{P}(Z_{1}\leq\delta)=1$
\end_inset

.
 
\end_layout

\begin_layout Example
(Brownian bridge as an Ito Integral) We know that another way to construct
 a Brownian bridge process is as follows:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Z_{t} & =(1-t)\int_{0}^{t}\frac{1}{1-s}dB_{s}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We know that 
\begin_inset Formula $\lim_{t\to1}Z_{t}=0$
\end_inset

 almost surely.
 The process 
\begin_inset Formula $Z$
\end_inset

 is a Gaussian process by corollary 
\begin_inset CommandInset ref
LatexCommand eqref
reference "cor:wiener-integral"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The mean is zero and the covariance is, by corollary 
\begin_inset CommandInset ref
LatexCommand eqref
reference "corollary:covariance-of-ito-integrals"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is given by:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[Z_{t}Z_{s}] & =(1-s)(1-t)\int_{0}^{s}\frac{1}{(1-s)^{2}}dB_{s}\\
 & =(1-s)(1-t)\left[\frac{1}{(1-s)}\right]_{0}^{s}\\
 & =(1-s)(1-t)\left(\frac{1}{1-s}-1\right)\\
 & =(1-s)(1-t)\left(\frac{s}{1-s}\right)\\
 & =s(1-t)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The above representations of the Ornstein-Uhlenbeck process and the brownian
 bridge implies that they are not martingales.
\end_layout

\begin_layout Subsection
Ito's Formula.
\end_layout

\begin_layout Standard
The Ito integral was constructed in the last section in a rather abstract
 way.
 It is the limit of a sequence of random variables constructed from Brownian
 motion.
 It is good to remind ourselves that the classical Riemann integral is also
 very abstract! It is defined as the limit of the sequence of Riemann sums.
 It does not always have an explicit form.
 For example, the CDF of a Gaussian random variable 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\Phi(x) & =\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}e^{(-y^{2}/2)}dy
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
is a well-defined function of 
\begin_inset Formula $x$
\end_inset

, but the integral cannot be expressed in terms of the typical elementary
 functions of calculus.
 But, in some cases a Riemann integral can be written explicitly in terms
 of such functions.
 This is the content of the fundamental theorem of calculus.
 It is useful to recall the theorem, as Ito's formula is built upon it.
 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $f:[0,T]\to\mathbf{R}$
\end_inset

 be a function for which the derivative 
\begin_inset Formula $f'$
\end_inset

 exists and is a continuous function on 
\begin_inset Formula $[0,T]$
\end_inset

.
 We will say that such a function is in 
\begin_inset Formula $\mathcal{C}^{1}([0,T])$
\end_inset

.
 The fundamental theorem of calculus says that we can write:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
f(t)-f(0) & =\int_{0}^{t}f'(s)ds,\quad t\leq T\label{eq:FTC}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Note that, we often write this result in the differential form:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
df(t) & =f'(t)dt
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The differential form has no rigorous meaning in itself.
 It is simply a compact and convenient notation that encodes FTC 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:FTC"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
The stochastic equivalent of the fundamental theorem of calculus is the
 Ito's formula provided below.
 It related the Ito integral to an explicit function of Brownian motion.
 Note that the function 
\begin_inset Formula $f$
\end_inset

 must be in 
\begin_inset Formula $\mathcal{C}^{2}(\mathbf{R})$
\end_inset

, that is, 
\begin_inset Formula $f'$
\end_inset

 and 
\begin_inset Formula $f''$
\end_inset

 exist and are continuous on the whole space 
\begin_inset Formula $\mathbf{R}.$
\end_inset


\end_layout

\begin_layout Theorem
(Ito's Formula) Let 
\begin_inset Formula $(B_{t}:t\leq T)$
\end_inset

 be a standard Brownian motion.
 Consider 
\begin_inset Formula $f\in\mathcal{C}^{2}(\mathbf{R})$
\end_inset

.
 Then, with probability one, we have:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align}
f(B_{t})-f(B_{0}) & =\int_{0}^{t}f'(B_{s})dB_{s}+\frac{1}{2}\int_{0}^{t}f''(B_{s})ds,\quad t\leq T\label{eq:Ito's-formula-I}
\end{align}

\end_inset


\end_layout

\begin_layout Theorem
We will see other variations in proposition and later sections.
 Before giving an idea of the proof, we make some important observations:
\end_layout

\begin_layout Remark*
(1) Equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Ito's-formula-I"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is an equality of processes, which is much stronger than equality in distributi
on.
 In other words, if you take a path of the process on the left constructed
 on a given Brownian motion, then this path will be the same as the path
 of the on the right constructed on the same Brownian motion.
 This equality holds in the limit where the mesh of the partition of the
 interval 
\begin_inset Formula $[0,T]$
\end_inset

 goes to 
\begin_inset Formula $0$
\end_inset

.
\end_layout

\begin_layout Remark*
(2) Note the similarity with the classical formulation in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:FTC"
plural "false"
caps "false"
noprefix "false"

\end_inset

, if we replace the Riemann integral by Ito's integral.
 We do have the additional integral of 
\begin_inset Formula $f''(B_{s})$
\end_inset

.
 As we will see in the proof, this additional term comes from the quadratic
 term in the Taylor's approximation and from the quadratic variation of
 Brownian motion seen in theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:quadratic-variation-of-bm-approaches-t-in-mean-square"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 As in the classical case, it is very convenient to summarize the conclusion
 of Ito's formula in differential form:
\end_layout

\begin_layout Remark*
\begin_inset Formula 
\begin{align}
df(B_{t}) & =f'(B_{t})dB_{t}+\frac{1}{2}f''(B_{t})dt\label{eq:ito's-formula-in-differential-form}
\end{align}

\end_inset


\end_layout

\begin_layout Remark*
We stress that the differential form has no meaning by itself.
 It is a compact way to express the two integrals in Ito's formula and a
 powerful device for computations.
 
\end_layout

\begin_layout Remark*
(3) An important consequence of Ito's formula is that it provides a systematic
 way to construct martingales as explicit functions of Brownian motion.
 To make sure that, 
\begin_inset Formula $\int_{0}^{t}f'(B_{s})dB_{s},t\leq T$
\end_inset

 defines a continuous square integrable martingale on 
\begin_inset Formula $[0,T]$
\end_inset

, we might need to check that 
\begin_inset Formula $(f'(B_{t}),t\leq T)\in\mathcal{L}_{c}^{2}(T)$
\end_inset

.
 In general, the Ito integral makes sense as a local martingale.
\end_layout

\begin_layout Corollary
(Brownian Martingales).
 Let 
\begin_inset Formula $(B_{t}:t\leq T)$
\end_inset

 be a standard brownian motion.
 Consider 
\begin_inset Formula $f\in\mathcal{C}^{2}(\mathbf{R})$
\end_inset

 such that 
\begin_inset Formula $\int_{0}^{T}\mathbf{E}[f'(B_{s})^{2}]ds<\infty$
\end_inset

.
 Then the process:
\end_layout

\begin_layout Corollary
\begin_inset Formula 
\[
\left(f(B_{t})-\frac{1}{2}\int_{0}^{t}f''(B_{s})ds,\quad t\leq T\right)
\]

\end_inset


\end_layout

\begin_layout Corollary
is a martingale for the Brownian motion.
\end_layout

\begin_layout Proof
This is straightforward from the Ito's formula:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
f(B_{t})-\frac{1}{2}\int_{0}^{t}f''(B_{s})ds & =f(B_{0})+\int_{0}^{t}f'(B_{s})dB_{s}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The first term is a constant and the second term is a continuous martingale
 by proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "th:properties-of-ito-integral"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
The integral we subtracted from 
\begin_inset Formula $f(B_{t})$
\end_inset

 is called the 
\emph on
compensator
\emph default
.
 A simple case is given by the function 
\begin_inset Formula $f(x)=x^{2}$
\end_inset

.
 For this function the corollary gives that the process 
\begin_inset Formula $B_{t}^{2}-t,t\geq0$
\end_inset

 is a martingale, as we already observed.
 The compensator was then simply 
\begin_inset Formula $t$
\end_inset

.
 In general, a compensator might be random.
\end_layout

\begin_layout Standard
(4) The compensator is the Riemann integral 
\begin_inset Formula $\int_{0}^{t}f''(B_{s})ds$
\end_inset

.
 It might seem to be a strange object at first.
 The function 
\begin_inset Formula $f''(B_{s})$
\end_inset

 is random (it depends on 
\begin_inset Formula $\omega$
\end_inset

), so the integral is a random variable.
 There is no problem in integrating the random function 
\begin_inset Formula $f''(B_{s})$
\end_inset

 since by assumption it is a continuous function of 
\begin_inset Formula $s$
\end_inset

, since 
\begin_inset Formula $f''$
\end_inset

 and 
\begin_inset Formula $B_{s}(\omega)$
\end_inset

 are continuous.
 In fact, the paths of 
\begin_inset Formula $\int_{0}^{t}f''(B_{s})ds$
\end_inset

 are much smoother than the ones of Brownian motion in general: the paths
 are differentiable everywhere (the derivative is 
\begin_inset Formula $f''(B_{t}))$
\end_inset

 and in particular the paths have bounded variation.
\end_layout

\begin_layout Standard
To sum it up, Ito's formula says that 
\begin_inset Formula $f(B_{t})$
\end_inset

 can be expressed as a sum of two processes: one with bounded variation
 (the Riemann integral) and a (local) martingale with finite quadratic variation
 (the Ito integral).
 In the next section, we study Ito processes in more generality, which are
 processes that can be expressed as a sum of a Riemann integral and an Ito
 integral.
 
\end_layout

\begin_layout Example
Let 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
f(x) & =x^{3}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In this case, Ito's formula yields:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
B_{t}^{3} & =\int_{0}^{t}3B_{s}^{2}dB_{s}+\frac{1}{2}\int_{0}^{t}6B_{s}ds\\
 & =3\int_{0}^{t}B_{s}^{2}dB_{s}+3\int_{0}^{t}B_{s}ds
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We can look at a sample of a single path of each of these processes constructed
 from the same Brownian motion.
 Note that they are almost equal (the discrepancy is only due to discretization
 in the numerics)! From the above equation, we conclude that 
\begin_inset Formula $B_{t}^{3}-3\int_{0}^{t}B_{s}ds$
\end_inset

 is a martingale.
 See the figure below for a sample of its paths.
 The process 
\begin_inset Formula $(\int_{0}^{t}B_{s}ds,\quad t\geq0)$
\end_inset

 is not complicated.
 It is a Gaussian process since the integral is the limit (almost sure and
 
\begin_inset Formula $L^{2})$
\end_inset

 of the Riemann sums :
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\sum_{j=0}^{n-1}B_{t_{j}}(t_{j+1}-t_{j})
\]

\end_inset


\end_layout

\begin_layout Example
and each term of the sum is a Gaussian random variable.
 Clearly, the mean of 
\begin_inset Formula $\int_{0}^{t}B_{s}ds$
\end_inset

 is 
\begin_inset Formula $0$
\end_inset

.
 The covariance of the process can be calculated directly by interchanging
 the integrals and the expectation:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\left(\int_{0}^{t}B_{s}ds\right)\left(\int_{0}^{t'}B_{u}du\right)\right] & =\int_{0}^{t}\int_{0}^{t'}\mathbf{E}[B_{s}B_{u}]dsdu=\int_{0}^{t}\int_{0}^{t'}(s\land u)dsdu
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Here the domain of integration is 
\begin_inset Formula $D=[0,t]\times[0,t']$
\end_inset

.
 Assume that 
\begin_inset Formula $t<t'$
\end_inset

.
 We can divide the domain into two sub-domains 
\begin_inset Formula $D_{1}=\{(x,y):0\leq x\leq t,0\leq y\leq x\}$
\end_inset

 and 
\begin_inset Formula $D_{2}=\{(x,y):0\leq x\leq t,x\leq y\leq t'\}$
\end_inset

.
 Consequently, we can evaluate the above double integral as:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
I & =\int_{0}^{t}\int_{0}^{t'}\min(x,y)dxdy\\
 & =\int_{0}^{t}\int_{0}^{x}ydydx+\int_{0}^{t}\int_{x}^{t'}xdydx\\
 & =\int_{0}^{t}\left[\frac{y^{2}}{2}\right]_{0}^{x}dx+\int_{0}^{t}x\left[y\right]_{x}^{t'}dx\\
 & =\int_{0}^{t}\frac{x^{2}}{2}dx+\int_{0}^{t}x(t'-x)dx\\
 & =\left[\frac{x^{3}}{6}\right]_{0}^{t}+t'\left[\frac{x^{2}}{2}\right]_{0}^{t}-\left[\frac{x^{3}}{3}\right]_{0}^{t}\\
 & =\frac{t^{3}}{6}+\frac{t't^{2}}{2}-\frac{t^{3}}{3}\\
 & =-\frac{t^{3}}{6}+\frac{t't^{2}}{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In particular the variance at time 
\begin_inset Formula $t$
\end_inset

 is 
\begin_inset Formula $t^{3}/3$
\end_inset

.
 The paths of this process are very smooth, as can be observed in the figure
 below.
 In fact, the paths are differentiable and the derivative at time 
\begin_inset Formula $t$
\end_inset

 is 
\begin_inset Formula $B_{t}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
Let 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
f(x) & =\cos x
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In this case, the Ito's formula gives:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\cos B_{t}-\cos B_{0} & =\int_{0}^{t}-\sin(B_{s})dB_{s}+\frac{1}{2}\int_{0}^{t}(-\cos(B_{s})ds
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In particular, the process 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
M_{t} & =\cos B_{t}+\frac{1}{2}\int_{0}^{t}\cos B_{s}ds=1-\int_{0}^{t}\sin B_{s}dB_{s},\quad t\geq0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
is a continuous martingale starting at 
\begin_inset Formula $M_{0}=1$
\end_inset

.
 It is easy to check that the process 
\begin_inset Formula $(\sin B_{t},t\leq T)$
\end_inset

 is in 
\begin_inset Formula $\mathcal{L}_{c}^{2}(T)$
\end_inset

 for any 
\begin_inset Formula $T$
\end_inset

.
 
\begin_inset Formula $\sin B_{t}$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{t}-$
\end_inset

measurable since it is a function of 
\begin_inset Formula $B_{t}$
\end_inset

.
 Moreover, Also, 
\begin_inset Formula $\sin(x)$
\end_inset

 is continuous, and the composition of continuous functions is continuous.
 
\end_layout

\begin_layout Standard
Where does Ito's formula come from? It is the same idea as for the proof
 of the Fundamental Theorem of Calculus(FTC).
 Let's start with the latter.
 Suppose 
\begin_inset Formula $f\in\mathcal{C}^{1}(\mathbf{R})$
\end_inset

; that is: 
\begin_inset Formula $f$
\end_inset

 is differentiable with a continuous derivative.
 Then, 
\begin_inset Formula $f$
\end_inset

 admits a Taylor approximation around 
\begin_inset Formula $s$
\end_inset

 of the form:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
f(t)-f(s) & =f'(s)(t-s)+\mathcal{E}(s,t)\label{eq:linear-approximation}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
(This is in spirit of the mean value theorem) Here, 
\begin_inset Formula $\mathcal{E}(s,t)$
\end_inset

 is an error term that goes to 
\begin_inset Formula $0$
\end_inset

 faster than 
\begin_inset Formula $(t-s)$
\end_inset

 as 
\begin_inset Formula $s\to t$
\end_inset

 (for example 
\begin_inset Formula $(t-s)^{2})$
\end_inset

.
 Now, for a partition 
\begin_inset Formula $(t_{j},j\leq n)$
\end_inset

 of 
\begin_inset Formula $[0,t]$
\end_inset

, say 
\begin_inset Formula $t_{j}=\frac{jt}{n}$
\end_inset

, we can trivially write for any 
\begin_inset Formula $n$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
f(t)-f(0) & =\sum_{j=0}^{n}f(t_{j+1})-f(t_{j})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Now, we can use the equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:linear-approximation"
plural "false"
caps "false"
noprefix "false"

\end_inset

 at 
\begin_inset Formula $s=t_{j}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
f(t_{j+1})-f(t_{j}) & =f'(t_{j})(t_{j+1}-t_{j})+\mathcal{E}(t_{j},t_{j+1})
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Therefore, we have by taking the limit of large 
\begin_inset Formula $n$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
f(t)-f(0) & =\lim_{n\to\infty}\sum_{j=0}^{n}f'(t_{j})(t_{j+1}-t_{j})+\sum_{j=0}^{n}\mathcal{E}(t_{j},t_{j+1})=\int_{0}^{t}f'(s)ds+0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The idea for Ito's formula is similar to the above with two big differences
 : first we will consider a function of 
\emph on
space 
\emph default
and 
\emph on
time
\emph default
.
 Second, we shall need a Taylor approximation to the second order around
 a point 
\begin_inset Formula $x$
\end_inset

: if 
\begin_inset Formula $f\in\mathcal{C}^{2}(\mathbf{R})$
\end_inset

 we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
f(y)-f(x) & =(y-x)f'(x)+\frac{1}{2}(y-x)^{2}f''(x)+\mathcal{E}(x,y)\label{eq:second-order-taylors-series-expansion}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\mathcal{E}(x,y)$
\end_inset

 is the error term that converges to 
\begin_inset Formula $0$
\end_inset

 faster than 
\begin_inset Formula $(x-y)^{3}$
\end_inset

 as 
\begin_inset Formula $y\to x$
\end_inset

.
\end_layout

\begin_layout Proof
Recall that by assumption 
\begin_inset Formula $f\in\mathcal{C}^{2}(\mathbf{R})$
\end_inset

.
 We will prove the particular case, where 
\begin_inset Formula $f$
\end_inset

 is 
\begin_inset Formula $0$
\end_inset

 outside a bounded interval.
 This implies that both the derivatives are bounded, since by the preservation
 of the compact set theorem, continuous functions preserve compact sets.
 We first prove the formula for a fixed 
\begin_inset Formula $t$
\end_inset

.
 Then, we generalize to processes on 
\begin_inset Formula $[0,T].$
\end_inset

 Consider a partition 
\begin_inset Formula $(t_{j}:j\leq n)$
\end_inset

 of 
\begin_inset Formula $[0,t]$
\end_inset

.
 From the Taylor's series expansion above:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
f(B_{t})-f(B_{0}) & =\sum_{j=0}^{n-1}f'(B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})+\frac{1}{2}\sum_{j=0}^{n-1}f''(B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})^{2}+\sum_{j=0}^{n}\mathcal{E}(B_{t_{j}},B_{t_{j+1}})\label{eq:second-order-taylors-series-expansion-f(B_t)-f(B_0)}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
As 
\begin_inset Formula $n\to\infty$
\end_inset

, the first term converges (as a random variable in 
\begin_inset Formula $L^{2}$
\end_inset

) to the Ito integral.
 This is how we proved proposition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:properties-of-ito-integral"
plural "false"
caps "false"
noprefix "false"

\end_inset

 using simple processes.
 We claim that the second term converges to the Riemann integral.
 To see this, consider the corresponding Riemann sum :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\sum_{j=0}^{n-1}f''(B_{t_{j}})(t_{j+1}-t_{j})
\]

\end_inset


\end_layout

\begin_layout Proof
This term converges almost surely to the Riemann integral 
\begin_inset Formula $\int_{0}^{t}f''(B_{s})ds$
\end_inset

 since 
\begin_inset Formula $f''$
\end_inset

 is continuous.
 It also converges in 
\begin_inset Formula $L^{2}$
\end_inset

 by theorem by the dominated convergence theorem, since 
\begin_inset Formula $f''(\cdot)$
\end_inset

 is bounded by assumption.
 Therefore, to show that the second term converges to the same limit, it
 suffices to show that the 
\begin_inset Formula $L^{2}$
\end_inset

-distance between the second term and the Riemann sum goes to 
\begin_inset Formula $0$
\end_inset

.
 That is,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\lim_{n\to\infty}\mathbf{E}\left[\left(\sum_{j=0}^{n-1}f''(B_{t_{j}})\left\{ \left(B_{t_{j+1}}-B_{t_{j}}\right)^{2}-(t_{j+1}-t_{j})\right\} \right)^{2}\right]\label{eq:l2-convergence-of-second-term-to-riemann-integral}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
This is in the same spirit as the proof of the quadratic variation of the
 Brownian motion in theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:quadratic-variation-of-bm-approaches-t-in-mean-square"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 To lighten the notation, define the variables :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
X_{j} & :=(B_{t_{j+1}}-B_{t_{j}})^{2}-(t_{j+1}-t_{j}),\quad j\leq n-1
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We expand the square in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:l2-convergence-of-second-term-to-riemann-integral"
plural "false"
caps "false"
noprefix "false"

\end_inset

 to get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\sum_{j=0}^{n-1}\sum_{k=0}^{n-1}\mathbf{E}\left[f''(B_{t_{j}})f''(B_{t_{k}})X_{j}X_{k}\right]
\]

\end_inset


\end_layout

\begin_layout Proof
For 
\begin_inset Formula $j<k$
\end_inset

, we co`ndition on 
\begin_inset Formula $\mathcal{F}_{t_{k}}$
\end_inset

 to get :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sum_{j=0}^{n-1}\sum_{k=0}^{n-1}\mathbf{E}\left[f''(B_{t_{j}})f''(B_{t_{k}})X_{j}X_{k}\right] & =2\sum_{j<k}\mathbf{E}\left[\mathbf{E}\left[\left.f''(B_{t_{j}})f''(B_{t_{k}})X_{j}X_{k}\right|\mathcal{F}_{t_{k}}\right]\right]\\
 & +\sum_{j=0}^{n-1}\mathbf{E}\left[\left(f''(B_{t_{j}})\right)^{2}X_{j}^{2}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The first term on the right hand can be expressed as :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
2\sum_{j<k}^{n-1}\mathbf{E}\left[\mathbf{E}\left[\left.f''(B_{t_{j}})f''(B_{t_{k}})X_{j}X_{k}\right|\mathcal{F}_{t_{k}}\right]\right] & =2\sum_{j<k}^{n-1}\mathbf{E}\left[f''(B_{t_{j}})f''(B_{t_{k}})X_{j}\mathbf{E}\left[\left.X_{k}\right|\mathcal{F}_{t_{k}}\right]\right]\\
 & \{\text{Taking out what is known}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The random variable 
\begin_inset Formula $\mathbf{E}\left[\left.X_{k}\right|\mathcal{F}_{t_{k}}\right]$
\end_inset

 turns out to be:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\left.X_{k}\right|\mathcal{F}_{t_{k}}\right] & =\mathbf{E}\left[(B_{t_{k+1}}-B_{t_{k}})^{2}\right]-(t_{k+1}-t_{k})\\
 & \text{\{\ensuremath{\because B_{t_{k+1}}-B_{t_{k}}\text{ is independent of \ensuremath{\mathcal{F}_{t_{k}}\}}}}}\\
 & =(t_{k+1}-t_{k})-(t_{k+1}-t_{k})\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
So, the entire summand of the first term equals 
\begin_inset Formula $0$
\end_inset

, and we are left with:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
 & \sum_{j=0}^{n-1}\mathbf{E}\left[\left(f''(B_{t_{j}})\right)^{2}X_{j}^{2}\right]\\
= & \sum_{j=0}^{n-1}\mathbf{E}\left[\left(f''(B_{t_{j}})\right)^{2}\left\{ \left(B_{t_{j+1}}-B_{t_{j}}\right)^{2}-(t_{j+1}-t_{j})\right\} ^{2}\right]\\
= & \sum_{j=0}^{n-1}\mathbf{E}\left[\left(f''(B_{t_{j}})\right)^{2}\left\{ \left(B_{t_{j+1}}-B_{t_{j}}\right)^{4}-2\left(B_{t_{j+1}}-B_{t_{j}}\right)^{2}(t_{j+1}-t_{j})+(t_{j+1}-t_{j})^{2}\right\} \right]\\
= & \sum_{j=0}^{n-1}\mathbf{E}\left[\mathbf{E}\left[\left.\left(f''(B_{t_{j}})\right)^{2}\left\{ \left(B_{t_{j+1}}-B_{t_{j}}\right)^{4}-2\left(B_{t_{j+1}}-B_{t_{j}}\right)^{2}(t_{j+1}-t_{j})+(t_{j+1}-t_{j})^{2}\right\} \right|\mathcal{F}_{t_{j}}\right]\right]\\
 & \{\text{Conditioning on \ensuremath{\mathcal{F}_{t_{j}}\}}}\\
= & \sum_{j=0}^{n-1}\mathbf{E}\left[\left(f''(B_{t_{j}})\right)^{2}\mathbf{E}\left[\left.\left\{ \left(B_{t_{j+1}}-B_{t_{j}}\right)^{4}-2\left(B_{t_{j+1}}-B_{t_{j}}\right)^{2}(t_{j+1}-t_{j})+(t_{j+1}-t_{j})^{2}\right\} \right|\mathcal{F}_{t_{j}}\right]\right]\\
 & \text{\{ Taking out what is known \}}\\
= & \sum_{j=0}^{n-1}\mathbf{E}\left[\left(f''(B_{t_{j}})\right)^{2}\mathbf{E}\left[\left\{ \left(B_{t_{j+1}}-B_{t_{j}}\right)^{4}-2\left(B_{t_{j+1}}-B_{t_{j}}\right)^{2}(t_{j+1}-t_{j})+(t_{j+1}-t_{j})^{2}\right\} \right]\right]\\
 & \text{\{ Independence \}}\\
= & \sum_{j=0}^{n-1}\mathbf{E}\left[\left(f''(B_{t_{j}})\right)^{2}\left(3(t_{j+1}-t_{j})^{2}-2(t_{j+1}-t_{j})^{2}+(t_{j+1}-t_{j})^{2}\right)\right]\\
= & 2\sum_{j=0}^{n-1}\mathbf{E}\left[\left(f''(B_{t_{j}})\right)^{2}\right](t_{j+1}-t_{j})^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $f''(x)$
\end_inset

 is bounded, the last result approaches 
\begin_inset Formula $0$
\end_inset

, as the mesh size becomes finer and finer and 
\begin_inset Formula $n\to\infty$
\end_inset

.
 It remains to handle the error term in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:second-order-taylors-series-expansion-f(B_t)-f(B_0)"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 This follows the same idea as for the second term and we omit it.
\end_layout

\begin_layout Proof
To extend the formula to the whole interval 
\begin_inset Formula $[0,T]$
\end_inset

, notice that the processes of both sides of the equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Ito's-formula-I"
plural "false"
caps "false"
noprefix "false"

\end_inset

 have continuous paths.
 Since they are equal with probability one at any fixed time by the above
 argument, they must be equal for any countable set of times.
 It suffices to consider the processes on the rational times in 
\begin_inset Formula $[0,T]$
\end_inset

, which are dense in 
\begin_inset Formula $[0,T]$
\end_inset

.
 Since the paths are continuous and they are equal on these times, they
 must be equal at all times on 
\begin_inset Formula $[0,T]$
\end_inset

.
\end_layout

\begin_layout Standard
Recall from equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:ito's-formula-in-differential-form"
plural "false"
caps "false"
noprefix "false"

\end_inset

, that Ito's formula can be written in the differential form:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
df(B_{t}) & =f'(B_{t})dB_{t}+\frac{1}{2}f''(B_{t})dt
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This notation has no meaning by itself.
 It is a compact way to write 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Ito's-formula-I"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 This allows us to derive an easy and useful computational formula: if we
 blindly apply the classical differential to 
\begin_inset Formula $f$
\end_inset

 to second order in the Taylor expansion, we formally obtain:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
df(B_{t}) & =f'(B_{t})dB_{t}+\frac{1}{2}f''(B_{t})(dB_{t})^{2}\label{eq:blind-application-of-second-order-taylors-series}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Therefore, Ito's formula is equivalent to applying the rule 
\begin_inset Formula $dt=dB_{t}\cdot dB_{t}$
\end_inset

.
 In fact, it is counterproductive to learn Ito's formula by heart.
 It is much better to simply compute the differential upto the second order
 and apply the following 
\emph on
simple 
\emph default
rules of Ito calculus:
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\cdot$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dt$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dB_{t}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dt$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dB_{t}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dt$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
It is not hard to extend Ito's formula to a function 
\begin_inset Formula $f(t,x)$
\end_inset

 of both time and space:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
f:[0,T]\times\mathbf{R} & \mapsto\mathbf{R}\\
(t,x) & \mapsto f(t,x)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Such functions have partial derivatives that are themselves functions of
 time and space.
 We will use the following notation for the partial derivatives:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\partial_{t}f(t,x)=\frac{\partial f}{\partial t}(t,x),\quad\partial_{x}f(t,x)=\frac{\partial f}{\partial x}(t,x),\quad\partial_{xx}(t,x)=\frac{\partial^{2}f}{\partial x^{2}}f(t,x)
\]

\end_inset


\end_layout

\begin_layout Standard
The reason for this notation is to avoid confusion between the variable
 that is being 
\emph on
differentiated
\emph default
 and the value of time and space at which the derivative is 
\emph on
being evaluated
\emph default
.
 It might appear strange at first, but it will avoid confusion down the
 road (especially when dealing with several space variables in a later section).
 To apply Ito's formula, we will need that the partial derivative with respect
 to time 
\begin_inset Formula $\partial_{t}f$
\end_inset

 exists and is continuous as a function on 
\begin_inset Formula $[0,T]\times\mathbf{R}$
\end_inset

 and that the first and second partial derivatives in space 
\begin_inset Formula $\partial_{x}f$
\end_inset

 and 
\begin_inset Formula $\partial_{xx}f$
\end_inset

 exist and are continuous.
 We say that such a function 
\begin_inset Formula $f$
\end_inset

 is in 
\begin_inset Formula $\mathcal{C}^{1,2}[0,T]\times\mathbf{R}$
\end_inset

.
 Then, with probability 
\begin_inset Formula $1$
\end_inset

, we have for every 
\begin_inset Formula $t\in[0,T]$
\end_inset

:
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:ito's-formula-in-time-and-space"

\end_inset

(Ito's formula) Let 
\begin_inset Formula $(B_{t}:t\leq T)$
\end_inset

 be a standard brownian motion on 
\begin_inset Formula $[0,T]$
\end_inset

.
 Consider a function 
\begin_inset Formula $f$
\end_inset

 of time and space with 
\begin_inset Formula $f\in\mathcal{C}^{1,2}(\text{[0,T]\ensuremath{\times\mathbf{R})}}$
\end_inset

.
 Then, with probability one, we have for every 
\begin_inset Formula $t\in[0,T]$
\end_inset

,
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
f(t,B_{t})-f(0,B_{0}) & =\int_{0}^{t}\partial_{x}f(s,B_{s})dB_{s}+\int_{0}^{t}\left\{ \partial_{t}f(s,B_{s})+\frac{1}{2}\partial_{xx}f(s,B_{s})\right\} ds
\end{align*}

\end_inset


\end_layout

\begin_layout Proposition
or in differential form we have:
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align*}
df(t,B_{t}) & =\partial_{x}f(t,B_{t})dB_{t}+\left(\partial_{t}f(t,B_{t})+\frac{1}{2}\partial_{xx}f(t,B_{t})\right)dt
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The idea of the proof is similar as for a function of space only, as it
 depends on a Taylor's approximation and on the quadratic variation.
 Here, however, we need to apply Taylor's approximation to second order
 in space and to the first order in time.
 We then get something of the form:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
f(t,B_{t})-f(0,B_{0}) & =\sum_{j=0}^{n-1}\partial_{x}f(t_{j},B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})+\partial_{t}f(t_{j},B_{t_{j}})(t_{j+1}-t_{j})\\
 & +\frac{1}{2}\partial_{xx}f(t_{j},B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})^{2}\\
 & +\partial_{t}\partial_{x}f(t_{j},B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})(t_{j+1}-t_{j})+\mathcal{E}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The first two lines becomes the integrals in the Ito's formula.
 We see a new animal on the last line: the mixed derivative 
\begin_inset Formula $\partial_{t}\partial_{x}f$
\end_inset

.
 This term is related to the limit in the cross variation between 
\begin_inset Formula $B_{t}$
\end_inset

 and 
\begin_inset Formula $t$
\end_inset

 given by:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\lim_{n\to\infty}\sum_{j=0}^{n-1}(B_{t_{j+1}}-B_{t_{j}})(t_{j+1}-t_{j})
\]

\end_inset


\end_layout

\begin_layout Proof
It can be shown that it goes to 
\begin_inset Formula $0$
\end_inset

 in a suitable sense.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $(t_{j}:j\leq n)$
\end_inset

 be a sequence of partitions on 
\begin_inset Formula $[0,t]$
\end_inset

.
 We have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbf{E}\left[\left(\sum_{j=0}^{n-1}(t_{j+1}-t_{j})(B_{t_{j+1}}-B_{t_{j}})\right)^{2}\right] & \leq\left\Vert \Delta_{n}\right\Vert ^{2}\mathbf{E}\left[\left(\sum_{j=0}^{n-1}(B_{t_{j+1}}-B_{t_{j}})\right)^{2}\right]\\
 & =\left\Vert \Delta_{n}\right\Vert ^{2}\sum_{j=0}^{n-1}\mathbf{E}\left[(B_{t+1}-B_{t_{j}})^{2}\right]\\
 & +2\left\Vert \Delta_{n}\right\Vert ^{2}\sum_{j<k}\mathbf{E}\left[(B_{t+1}-B_{t_{j}})(B_{t_{k+1}}-B_{t_{k}})\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $\mathbf{E}[(B_{t_{j+1}}-B_{t_{j}})(B_{t_{k+1}}-B_{t_{k}})]=0$
\end_inset

 and 
\begin_inset Formula $\mathbf{E}[(B_{t_{j+1}}-B_{t_{j}})^{2}]=(t_{j+1}-t_{j})$
\end_inset

, we find that the above variance is 
\begin_inset Formula $\left\Vert \Delta_{n}\right\Vert ^{2}\cdot t$
\end_inset

.
 As 
\begin_inset Formula $n\to\infty$
\end_inset

, 
\begin_inset Formula $\left\Vert \Delta_{n}\right\Vert ^{2}\to0$
\end_inset

.
 Consequently, the cross-variation approaches 
\begin_inset Formula $0$
\end_inset

 in the mean square sense.
\end_layout

\begin_layout Proof
This justifies the rule 
\begin_inset Formula $dt\cdot dB_{t}=0$
\end_inset

.
 We can also justify the rule 
\begin_inset Formula $dt\cdot dt=0$
\end_inset

.
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sum_{j=0}^{n-1}(t_{j+1}-t_{j})^{2} & \leq\left\Vert \Delta_{n}\right\Vert \sum_{j=0}^{n-1}(t_{j+1}-t_{j})\\
 & =\left\Vert \Delta_{n}\right\Vert \cdot t
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
As 
\begin_inset Formula $n\to\infty$
\end_inset

, 
\begin_inset Formula $\left\Vert \Delta_{n}\right\Vert \to0$
\end_inset

, and we get the desired result.
\end_layout

\begin_layout Proof
Once these facts are known, the rest of the proof is done similarly to the
 one for the function of space only.
 We do notice though that the formula is easy to derive once we accept the
 rules of Ito calculus.
 By writing the differential to second order in space, and to first order
 in time and applying the rules of Ito calculus, we get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
df(t,B_{t}) & =\partial_{x}f(t,B_{t})dB_{t}+\left\{ \partial_{t}f(t,B_{t})+\frac{1}{2}\partial_{xx}f(t,B_{t})\right\} dt
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
As in the one variable case, we get a corollary to construct Martingales:
\end_layout

\begin_layout Corollary
(Brownian Martingales) Let 
\begin_inset Formula $(B_{t}:t\leq T)$
\end_inset

 be a standard Brownian motion.
 Consider 
\begin_inset Formula $f\in\mathcal{C}^{1,2}([0,T]\times\mathbf{R})$
\end_inset

 such that the process 
\begin_inset Formula $(\partial_{x}f(t,B_{t}):t\leq T)\in\mathcal{L}_{c}^{2}(T)$
\end_inset

.
 Then, the process 
\end_layout

\begin_layout Corollary
\begin_inset Formula 
\[
\left(f(t,B_{t})-\int_{0}^{t}\left\{ \partial_{s}f(s,B_{s})+\frac{1}{2}\partial_{xx}f(s,B_{s})\right\} ds,t\leq T\right)
\]

\end_inset


\end_layout

\begin_layout Corollary
is a martingale for the Brownian filtration.
 In particular, if 
\begin_inset Formula $f(t,x)$
\end_inset

 satisfies the partial differential equation 
\begin_inset Formula $\partial_{t}f=-\frac{1}{2}\partial_{xx}f$
\end_inset

, then the process 
\begin_inset Formula $(f(t,B_{t}),t\leq T)$
\end_inset

 is itself a martingale.
\end_layout

\begin_layout Standard
We now catch a glimpse of the powerful connection between two fields of
 mathematics: 
\emph on
the study of martingales is closely connected to the study of differential
 equations.
 
\emph default
We will see this connection in action in the gambler's ruin problem in the
 next section.
 
\end_layout

\begin_layout Example
Consider the function 
\begin_inset Formula $f(t,x)=tx$
\end_inset

.
 In this case, we have: 
\begin_inset Formula $\partial_{t}f=x$
\end_inset

, 
\begin_inset Formula $\partial_{x}f=t$
\end_inset

 and 
\begin_inset Formula $\partial_{xx}f=0$
\end_inset

.
 Ito's formula yields:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
d(tB_{t}) & =tdB_{t}+xdt
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Therefore, the process 
\begin_inset Formula $M_{t}=tB_{t}-\int_{0}^{t}B_{s}ds$
\end_inset

 is a martingale for the Brownian filtration.
 It is also a Gaussian process by corollary 
\begin_inset CommandInset ref
LatexCommand eqref
reference "cor:wiener-integral"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The mean is 
\begin_inset Formula $0$
\end_inset

 and the covariance by corollary 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:example-of-covariance-of-ito-integrals"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[M_{t}M_{t'}] & =\int_{0}^{t\land t'}s^{2}ds=\frac{(t\land t')^{3}}{3}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(Vasicek Interest Rate Model) Let 
\begin_inset Formula $(B_{t}:t\leq T)$
\end_inset

 be a standard Brownian motion.
 Vasicek assumed that the instantaneous spot rate under the real-world measure
 evolves as an Ornstein-Uhlenbeck process with constant coefficients.
 Thus:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align}
dr_{t} & =k(\theta-r_{t})dt+\sigma dB_{t}\label{eq:Vasicek}
\end{align}

\end_inset


\end_layout

\begin_layout Example
Rearranging the equation, multiplying both sides by the integrating factor
 and integrating from 
\begin_inset Formula $s$
\end_inset

 to 
\begin_inset Formula $t$
\end_inset

, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
dr_{t} & =k\theta dt-kr_{t}dt+\sigma dB_{t}\\
dr_{t}+kr_{t}dt & =k\theta dt+\sigma dB_{t}\\
e^{kt}dr_{t}+kr_{t}e^{kt}dt & =k\theta e^{kt}dt+\sigma e^{kt}dB_{t}\\
d(e^{kt}r_{t}) & =k\theta e^{kt}dt+\sigma e^{kt}dB_{t}\\
e^{kt}r_{t}-e^{ks}r_{s} & =\theta(e^{kt}-e^{ks})+\sigma\int_{s}^{t}e^{kt}dB_{t}\\
e^{kt}r_{t} & =r_{s}e^{ks}+\theta(e^{kt}-e^{ks})+\sigma\int_{s}^{t}e^{kt}dB_{t}\\
r_{t} & =r_{s}e^{-k(t-s)}+\theta(1-e^{-k(t-s)})+\sigma\int_{s}^{t}e^{-k(t-u)}dB_{u}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
for all 
\begin_inset Formula $t$
\end_inset

.
 By corollary 
\begin_inset CommandInset ref
LatexCommand eqref
reference "cor:wiener-integral"
plural "false"
caps "false"
noprefix "false"

\end_inset

, 
\begin_inset Formula $\int_{s}^{t}e^{-k(t-u)}dB_{u}$
\end_inset

 is a Gaussian process with mean 
\begin_inset Formula $0$
\end_inset

 and variance:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\int_{s}^{t}e^{-2k(t-u)}du & =e^{-2kt}\int_{s}^{t}e^{2ku}du\\
 & =\frac{e^{-2kt}}{2k}[e^{2ku}]_{s}^{t}\\
 & =\frac{e^{-2kt}}{2k}[e^{2kt}-e^{2ks}]\\
 & =\frac{1}{2k}(1-e^{-2k(t-s)})
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Thus, the Vasicek process is Gaussian with mean:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[r_{t}] & =r_{s}e^{-k(t-s)}+\theta(1-e^{-k(t-s)})
\end{align*}

\end_inset


\end_layout

\begin_layout Example
and variance:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Var[r_{t}] & =\frac{\sigma^{2}(1-e^{-2k(t-s)})}{2k}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Thus, 
\begin_inset Formula $r_{t}$
\end_inset

 can be negative with positive probability.
 The possibility of negative rates is indeed a major drawback of the Vasicek
 model.
 However, the analytical tractability that is implied by a Gaussian density
 is hardly achieved when assuming other distributions for the process 
\begin_inset Formula $r$
\end_inset

.
 If we let 
\begin_inset Formula $t\to\infty,$
\end_inset

 we get 
\begin_inset Formula $\mathbf{E}[r_{t}]=\theta$
\end_inset

.
 So, the drift of process 
\begin_inset Formula $(r_{t}:t\leq T)$
\end_inset

 is positive, whenever 
\begin_inset Formula $r_{t}<\theta$
\end_inset

 and whilst it is negative, whenever 
\begin_inset Formula $r_{t}>\theta$
\end_inset

 and so it is pushed everytime, to be closer on average to the level 
\begin_inset Formula $\theta$
\end_inset

.
 Hence, it is mean reverting.
\end_layout

\begin_layout Example
The solution of the stochastic differential equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Vasicek"
plural "false"
caps "false"
noprefix "false"

\end_inset

 can also be verified using Ito's lemma.
 Let:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
r_{t} & =r_{0}e^{-kt}+\theta(1-e^{-kt})+\sigma\int_{0}^{t}e^{-k(t-u)}dB_{u}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
And consider the function:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
f(t,x) & =r_{0}e^{-kt}+\theta(1-e^{-kt})+\sigma e^{-kt}x
\end{align*}

\end_inset


\end_layout

\begin_layout Example
where 
\begin_inset Formula $(X_{t},t\leq T)=\int_{0}^{t}e^{ku}dB_{u}$
\end_inset


\end_layout

\begin_layout Example
Then, 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\partial_{x}f(t,X_{t}) & =\sigma e^{-kt}\\
\partial_{t}f(t,X_{t}) & =-r_{0}ke^{-kt}+k\theta e^{-kt}-\sigma kX_{t}e^{-kt}=-kf(t,x)+k\theta\\
\partial_{xx}f(t,X_{t}) & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
By Ito's Lemma:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
df(t,X_{t}) & =\sigma e^{-kt}dX_{t}+(-kf(t,x)+k\theta)dt\\
df(t,X_{t}) & =k(\theta-f(t,x))dt+\sigma dB_{t}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(Cox-Ingersoll-Ross (CIR) Model).
 Let 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

 be a Brownian motion.
 The Cox-Ingersoll-Ross model for the instantaneous spot interest rate process
 
\begin_inset Formula $r_{t}$
\end_inset

 is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
dr_{t} & =k(\theta-r_{t})dt+\sigma\sqrt{r_{t}}dB_{t}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
They introduced a square-root term in the diffusion coefficient of the instantan
eous short-rate dynamics proposed by Vasicek.
 The resulting model has been a benchmark for many years because of its
 analytical tractability and the fact, that contrary to Vasicek (1977) model,
 the instantaneous short rate is always positive.
 The condition 
\begin_inset Formula $2k\theta>\sigma^{2}$
\end_inset

 has to be imposed to ensure that the origin is inaccessible to the process.
 Unlike the Vasicek equation the CIR model does not have a closed-form solution.
 
\end_layout

\begin_layout Example
Although, we cannot derive a closed-form solution , the expectation and
 variance of 
\begin_inset Formula $r_{t}$
\end_inset

 can be be computed.
 
\end_layout

\begin_layout Example
Consider the function 
\begin_inset Formula $f(t,x)=e^{kt}x$
\end_inset

, where 
\begin_inset Formula $X_{t}=r_{t}$
\end_inset

.
 We have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\partial_{x}f(t,x) & =e^{kt}\\
\partial_{t}f(t,x) & =ke^{kt}x\\
\partial_{xx}f(t,x) & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
By the Ito's-Lemma, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
df(t,X_{t}) & =e^{kt}dX_{t}+ke^{kt}xdt\\
 & =e^{kt}(k(\theta-r_{t}))dt+e^{kt}\sigma\sqrt{r_{t}}dB_{t}+ke^{kt}r_{t}dt\\
d(e^{kt}r_{t}) & =e^{kt}k\theta dt+e^{kt}\sigma\sqrt{r_{t}}dB_{t}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Integrating both sides of the equation, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
e^{kt}r_{t}|_{0}^{t} & =k\theta\int_{0}^{t}e^{kt}dt+\sigma\int_{0}^{t}e^{kt}\sqrt{r_{t}}dB_{t}\\
e^{kt}r_{t}-r_{0} & =\theta(e^{kt}-1)+\sigma\int_{0}^{t}e^{kt}\sqrt{r_{t}}dB_{t}\\
r_{t} & =r_{0}e^{-kt}+\theta(1-e^{-kt})+\sigma\int_{0}^{t}\sqrt{r_{t}}dB_{t}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We know that, 
\begin_inset Formula $(I_{t}=\int_{0}^{t}\sqrt{r_{t}}dB_{t},t\leq T)$
\end_inset

 is an Ito integral with mean 
\begin_inset Formula $0$
\end_inset

.
 So, the mean of the process 
\begin_inset Formula $(r_{t}:t\leq T)$
\end_inset

 is :
\end_layout

\begin_layout Example
\begin_inset Formula 
\[
\mathbf{E}[r_{t}]=r_{0}e^{-kt}+\theta(1-e^{-kt})
\]

\end_inset


\end_layout

\begin_layout Example
The variance of the Ito integral is given by:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Var[I_{t}]=\mathbf{E}[I_{t}^{2}] & =\int_{0}^{t}\mathbf{E}[\left(\sqrt{r}_{t}\right)^{2}]dt\\
 & =\int_{0}^{t}\mathbf{E}[r_{t}]dt\\
 & =\int_{0}^{t}(r_{0}e^{-kt}+\theta(1-e^{-kt}))dt\\
 & =(r_{0}-\theta)\int_{0}^{t}e^{-kt}dt+\theta\int_{0}^{t}dt\\
 & =(r_{0}-\theta)\frac{(e^{-kt}-1)}{-k}+\theta t\\
 & =\frac{(r_{0}-\theta)}{k}(1-e^{-kt})+\theta t
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(Geometric Brownian Motion revisited).
 Consider an asset price process that satisfies
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
S_{t} & =f(t,B_{t})=S_{0}e^{\left(\mu-\frac{\sigma^{2}}{2}\right)t+\sigma B_{t}}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Thus, 
\begin_inset Formula $f(t,x)=S_{0}e^{\left(\mu-\frac{\sigma^{2}}{2}\right)t+\sigma x}$
\end_inset

.
 
\begin_inset Formula $\partial_{x}f(t,B_{t})=S_{0}\sigma e^{(\mu-\sigma^{2}/2)t+\sigma B_{t}}=\sigma S_{t}$
\end_inset

, 
\begin_inset Formula $\partial_{xx}f(t,B_{t})=S_{0}\sigma^{2}e^{(\mu-\sigma^{2}/2)t+\sigma B_{t}}=\sigma^{2}S_{t}$
\end_inset

 and 
\begin_inset Formula $\partial_{t}f(t,B_{t})=\left(\mu-\frac{\sigma^{2}}{2}\right)S_{t}$
\end_inset

.
 Therefore, by Ito's Lemma:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
dS_{t} & =\sigma S_{t}dB_{t}+\left\{ \frac{1}{2}\sigma^{2}S_{t}+\mu S_{t}-\frac{\sigma^{2}}{2}S_{t}\right\} dt\\
 & =\mu S_{t}dt+\sigma S_{t}dB_{t}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In integral notation, the asset price 
\begin_inset Formula $(S_{t}:t\leq T)$
\end_inset

 is given by:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
S_{t} & =S_{0}+\sigma\int_{0}^{t}f(t,B_{t})dB_{t}+\int_{0}^{t}\mu f(t,B_{t})dt
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Gambler's ruin for Brownian Motion with a Drift.
\end_layout

\begin_layout Standard
We solved the Gambler's ruin problem for the standard Brownian motion in
 example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "example:probability-of-hitting-times"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 We now deal with the case where a drift is present.
 Consider the Brownian motion with a drift:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
X_{t} & =\sigma B_{t}+\mu t
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $(B_{t},t\geq0)$
\end_inset

 is a standard Brownian motion.
\end_layout

\begin_layout Section
Multivariate Ito Calculus.
\end_layout

\begin_layout Subsection
Multidimensional Brownian motion.
\end_layout

\begin_layout Definition
(Brownian motion in 
\begin_inset Formula $\mathbf{R}^{d})$
\end_inset

.
 Take 
\begin_inset Formula $d\in\mathbf{N}$
\end_inset

.
 Let 
\begin_inset Formula $B^{(1)},\ldots,B^{(d)}$
\end_inset

 be independent standard Brownian motions in 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 The process 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

 taking values in 
\begin_inset Formula $\mathbf{R}^{d}$
\end_inset

 defined by :
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
B_{t} & =(B_{t}^{(1)},\ldots,B_{t}^{(d)}),\quad t\geq0
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
is called a 
\begin_inset Formula $d-$
\end_inset

dimensional Brownian motion or a Brownian motion in 
\begin_inset Formula $\mathbf{R}^{d}$
\end_inset

.
\end_layout

\begin_layout Definition
The Brownian filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

 is now composed of the information of all Brownian motions.
 In other words, it is given by the sigma-fields:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
\mathcal{F}_{t} & =\sigma(B_{s}^{(i)},1\leq i\leq d,s\leq t)
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
For every outcome 
\begin_inset Formula $\omega$
\end_inset

, the path of trajectory of a 
\begin_inset Formula $d-$
\end_inset

dimensional Brownian motion is a curve in space parametrized by the time
 
\begin_inset Formula $t$
\end_inset

:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align*}
t\mapsto B_{t}(\omega) & =(B_{t}^{(1)}(\omega),B_{t}^{(2)}(\omega),\ldots,B_{t}^{(d)}(\omega))
\end{align*}

\end_inset


\end_layout

\begin_layout Definition
Of course, this curve is continuous, since each coordinate is.
 The below numerical project gives an example of one path of a two-dimensional
 brownian motion.
 This is a very rugged and intertwined curve! We might wonder, what it does
 as 
\begin_inset Formula $t\to\infty$
\end_inset

.
 Does it wander around 
\begin_inset Formula $(0,0)$
\end_inset

 ad infinitum or does it eventually escape to infinity? We will answer this
 question in a later section.
 For doing so, we shall need a version of Ito's formula for multi-dimensional
 Brownian motion.
 We finish this section by noticing that it is also easy to construct Brownian
 motions in higher dimensions for which the coordinates are correlated.
 
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "ex:bm-with-correlated-coordinates"

\end_inset

(Example of Brownian motion with correlated coordinates) Let 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

 be a two dimensional brownian motion.
 Let 
\begin_inset Formula $-1<\rho<1$
\end_inset

.
 We construct the two dimensional process as follows: 
\begin_inset Formula $W_{t}=(W_{t}^{(1)},W_{t}^{(2)})$
\end_inset

 where:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
W_{t}^{(1)} & =B_{t}^{(1)}\\
W_{t}^{(2)} & =\rho B_{t}^{(1)}+\sqrt{1-\rho^{2}}B_{t}^{(2)}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
\begin_inset Formula $W_{t}^{(1)}=B_{t}^{(1)}$
\end_inset

 is Gaussian with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $t$
\end_inset

.
 Since, 
\begin_inset Formula $B_{t}^{(1)}$
\end_inset

 and 
\begin_inset Formula $B_{t}^{(2)}$
\end_inset

are independent gaussian random variables and the sum of IID Gaussians is
 Gaussian, 
\begin_inset Formula $W_{t}^{(2)}$
\end_inset

 is Gaussian with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $t$
\end_inset

.
 The covariance between 
\begin_inset Formula $W_{t}^{(1)}$
\end_inset

 and 
\begin_inset Formula $W_{t}^{(2)}$
\end_inset

 is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbf{E}[W_{t}^{(1)}W_{t}^{(2)}] & =\mathbf{E}[B_{t}^{(1)}(\rho B_{t}^{(1)}+\sqrt{1-\rho^{2}}B_{t}^{(2)})]\\
 & =\mathbf{E}[\rho(B_{t}^{(1)})^{2}+\sqrt{1-\rho^{2}}B_{t}^{(1)}B_{t}^{(2)}]\\
 & =\rho t
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Hence, the coordinates at time 
\begin_inset Formula $t$
\end_inset

 are not independent.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Exercise

\series bold
2D Brownian Motion
\series default
.
 Consider a two-dimensional Brownian motion 
\begin_inset Formula $(B_{t}^{(1)},B_{2}^{(2)})$
\end_inset

 starting at 
\begin_inset Formula $(0,0)$
\end_inset

.
\end_layout

\begin_layout Exercise
(a) Plot one path of this Brownian motion on the plane 
\begin_inset Formula $\mathbf{R}^{2}$
\end_inset

 on the plane in 
\begin_inset Formula $\mathbf{R}^{2}$
\end_inset

 on the time interval 
\begin_inset Formula $[0,5]$
\end_inset

 using a discretization of 
\begin_inset Formula $0.005$
\end_inset

 and 
\begin_inset Formula $0.001$
\end_inset

.
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/brownianMotion2d.tex"

\end_inset


\end_layout

\begin_layout Standard
(b) Consider now the process 
\begin_inset Formula $(W_{t}:t\geq0)$
\end_inset

 for 
\begin_inset Formula $\rho=1/2$
\end_inset

 as in example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:bm-with-correlated-coordinates"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Plot one path of this process on the plane 
\begin_inset Formula $\mathbf{R}^{2}$
\end_inset

 on the time-interval 
\begin_inset Formula $[0,5]$
\end_inset

 using a discretization of 
\begin_inset Formula $0.001$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/correlatedBrownianMotions.tex"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "D:/data/dev/quasar/python/QuantPy/QuantPy/miscellaneous/correlatedBrownianMotions-2.tex"

\end_inset


\end_layout

\begin_layout Subsection
Ito's Formula.
\end_layout

\begin_layout Theorem
Ito's Formula.
 Let 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

 be a 
\begin_inset Formula $d-$
\end_inset

dimensional brownian motion.
 Consider 
\begin_inset Formula $f\in\mathcal{C}^{2}(\mathbf{R}^{d})$
\end_inset

.
 Then, we have with probability one that for all 
\begin_inset Formula $t\geq0$
\end_inset

:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align}
f(B_{t})-f(B_{0}) & =\sum_{i=1}^{d}\int_{0}^{t}\partial_{x_{i}}f(B_{s})dB_{s}^{(i)}+\frac{1}{2}\int_{0}^{t}\sum_{i=1}^{d}\partial_{x_{i}}^{2}f(B_{s})ds\label{eq:multidimensional-ito-formula}
\end{align}

\end_inset


\end_layout

\begin_layout Remark*
We stress that, as in the one-dimensional case, in theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Ito's-formula-I"
plural "false"
caps "false"
noprefix "false"

\end_inset

, Ito's formula is an equality of processes (and not an equality in distribution
).
 Thus, the processes on both sides must agree for each path.
 Interestingly, the mixed partials 
\begin_inset Formula $\partial_{x_{i}x_{j}}f(B_{s})$
\end_inset

, 
\begin_inset Formula $i\neq j$
\end_inset

 do not appear in the formula! We see from Ito's formula that the process
 
\begin_inset Formula $f(B_{t})$
\end_inset

 can be represented as a sum of 
\begin_inset Formula $d+1$
\end_inset

 processes: 
\begin_inset Formula $d$
\end_inset

 Ito integrals and one Riemann integral (which is a process of finite variation).
 In vector notation, the formula takes the form:
\end_layout

\begin_layout Remark*
\begin_inset Formula 
\begin{align*}
f(B_{t})-f(B_{0}) & =\int_{0}^{t}\nabla f(B_{s})^{T}dB_{s}+\frac{1}{2}\int_{0}^{t}\nabla^{2}f(B_{s})ds
\end{align*}

\end_inset


\end_layout

\begin_layout Remark*
where it is understood that the first term is the sum of the 
\begin_inset Formula $d$
\end_inset

 Ito integrals in the equation.
 The symbol 
\begin_inset Formula $\nabla^{2}$
\end_inset

 is the Laplacian of 
\begin_inset Formula $f$
\end_inset

: 
\begin_inset Formula $\sum_{i=1}^{d}\frac{\partial^{2}}{\partial x_{i}^{2}}f(B_{s}^{(1)},\ldots,B_{s}^{(d)})ds$
\end_inset


\end_layout

\begin_layout Remark*
In differential form, Ito's formula becomes very neat:
\end_layout

\begin_layout Remark*
\begin_inset Formula 
\begin{align*}
df(B_{t}) & =\sum_{i=1}^{d}\partial_{x_{i}}f(B_{s})dB_{t}^{(i)}+\frac{1}{2}\sum_{i=1}^{d}\partial_{x_{i}}^{2}f(B_{s})dt=\nabla f(B_{t})^{T}dB_{s}+\frac{1}{2}\nabla^{2}f(B_{t})dt
\end{align*}

\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "ex:applying-multidim-ito-formula"

\end_inset

Consider the functions (1) 
\begin_inset Formula $f(x_{1},x_{2})=x_{1}^{2}+x_{2}^{2}$
\end_inset

 (2) 
\begin_inset Formula $f(x_{1},x_{2})=e^{x_{1}}\cos x_{2}$
\end_inset

 and the processes 
\begin_inset Formula $(X_{t}:t\geq0)$
\end_inset

 and 
\begin_inset Formula $(Y_{t}:t\geq0)$
\end_inset

.
 If we apply Ito's formula to the first process, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
X_{t} & =\int_{0}^{t}2B_{s}^{(1)}dB_{s}^{(1)}+\int_{0}^{t}2B_{s}^{(2)}dB_{s}^{(2)}+\frac{1}{2}\int_{0}^{t}(4dt)\\
 & =\int_{0}^{t}2B_{s}^{(1)}dB_{s}^{(1)}+\int_{0}^{t}2B_{s}^{(2)}dB_{s}^{(2)}+2t
\end{align*}

\end_inset


\end_layout

\begin_layout Example
The second process gives:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Y_{t} & =\cos B_{s}^{(2)}\int_{0}^{t}e^{B_{s}^{(1)}}dB_{s}^{(1)}-e^{B_{s}^{(1)}}\int\sin B_{s}^{(2)}dB_{s}^{(2)}+\frac{1}{2}\int_{0}^{t}\left(e^{B_{s}^{(1)}}\cos B_{s}^{(2)}-e^{B_{s}^{(1)}}\cos B_{s}^{(2)}\right)dt\\
 & =1+\cos B_{s}^{(2)}\int_{0}^{t}e^{B_{s}^{(1)}}dB_{s}^{(1)}-e^{B_{s}^{(1)}}\int\sin B_{s}^{(2)}dB_{s}^{(2)}
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
\begin_inset CommandInset label
LatexCommand label
name "exercise:cross-variation-of-2-brownian-motions"

\end_inset

Cross-Variation of 
\begin_inset Formula $B_{t}^{(1)}$
\end_inset

 and 
\begin_inset Formula $B_{t}^{(2)}$
\end_inset

.
 Let 
\begin_inset Formula $(t_{j}:j\leq n)$
\end_inset

 be a sequence of partitions of 
\begin_inset Formula $[0,t]$
\end_inset

 such that 
\begin_inset Formula $\max_{j}|t_{j+1}-t_{j}|\to0$
\end_inset

 as 
\begin_inset Formula $n\to\infty$
\end_inset

.
 Prove that:
\end_layout

\begin_layout Exercise
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)}) & =0\quad\text{in \ensuremath{L^{2}}}
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
This justifies the rule 
\begin_inset Formula $dB_{t}^{(1)}\cdot dB_{t}^{(2)}=0$
\end_inset

.
\end_layout

\begin_layout Exercise

\emph on
Hint
\emph default
: Just compute the second moment of the sum.
\end_layout

\begin_layout Solution*
We have:
\end_layout

\begin_layout Solution*
\begin_inset Formula 
\begin{align*}
 & \mathbf{E}\left[\left(\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})\right)^{2}\right]\\
= & \sum_{j=0}^{n-1}\mathbf{E}[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})^{2}(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})^{2}]\\
+ & 2\sum_{j<k}\mathbf{E}\left[(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{k+1}}^{(1)}-B_{t_{k}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})(B_{t_{k+1}}^{(2)}-B_{t_{k}}^{(2)})\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Solution*
Both these expectations are zero, since the brownian motions are independent
 and non-overlapping increments are independent.
\end_layout

\begin_layout Solution*
Consequently, 
\begin_inset Formula $\sum_{j=0}^{n-1}(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)})(B_{t_{j+1}}^{(2)}-B_{t_{j}}^{(2)})\to0$
\end_inset

 in the 
\begin_inset Formula $L^{2}$
\end_inset

 sense.
\end_layout

\begin_layout Proof
The proof of the formula follows the usual recipe: Taylor's theorem together
 with the quadratic variation and the cross-variation.
 In this case, we do get a cross-variation between the different Brownian
 motions.
 More precisely, consider a partition 
\begin_inset Formula $(t_{j}:j\leq n)$
\end_inset

 of 
\begin_inset Formula $[0,t]$
\end_inset

.
 Then we can write:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
f(B_{t})-f(B_{0}) & =\sum_{j=0}^{n-1}(f(B_{t_{j+1}})-f(B_{t_{j}}))
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
We can apply the Taylor's series expansion for each 
\begin_inset Formula $j$
\end_inset

 to get:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
f(B_{t})-f(B_{0}) & =\sum_{j=0}^{n-1}\nabla f(B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})\\
 & +\frac{1}{2}\sum_{j=0}^{n-1}(B_{t_{j+1}}-B_{t_{j}})^{T}Hf(B_{t_{j}})(B_{t_{j+1}}-B_{t_{j}})+\mathcal{E}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
where 
\begin_inset Formula $Hf$
\end_inset

 is the Hessian matrix of 
\begin_inset Formula $f$
\end_inset

.
 We wrote the expansion using the vector notation to be economical.
 Let's keep in mind that each term is a sum over the derivatives.
 The first term will converge to 
\begin_inset Formula $d$
\end_inset

 Ito integrals as in the one-dimensional case.
 Now, the summand in the second term is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
(B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)},\ldots,B_{t_{j+1}}^{(d)}-B_{t_{j}}^{(d)})\left[\begin{array}{ccc}
\partial_{x_{1}}^{2}f(B_{t_{j}}) & \ldots & \partial_{x_{1}x_{d}}^{2}f(B_{t_{j}})\\
\vdots & \ddots\\
\partial_{x_{d}x_{1}}^{2}f(B_{t_{j}}) &  & \partial_{x_{d}}^{2}f(B_{t_{j}})
\end{array}\right]\left[\begin{array}{c}
B_{t_{j+1}}^{(1)}-B_{t_{j}}^{(1)}\\
\vdots\\
B_{t_{j+1}}^{(d)}-B_{t_{j}}^{(d)}
\end{array}\right]
\]

\end_inset


\end_layout

\begin_layout Proof
So, 
\begin_inset Formula $(B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})$
\end_inset

 is pre-multiplied with the term 
\begin_inset Formula $\partial_{x_{i}x_{k}}^{2}f(B_{t_{j}})$
\end_inset

 and it is post-multiplied 
\begin_inset Formula $(B_{t_{j+1}}^{(k)}-B_{t_{j}}^{(k)})$
\end_inset

.
 Consequently, the second term in the Taylor's series expansion can be re-writte
n as:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
\sum_{j=0}^{n-1}\left(\sum_{i=1}^{d}\partial_{x_{i}}^{2}f(B_{t_{j}})(B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})^{2}+\sum_{1\leq i<k\leq d}\partial_{x_{i}x_{k}}^{2}f(B_{t_{j}})(B_{t_{j+1}}^{(i)}-B_{t_{j}}^{(i)})(B_{t_{j+1}}^{(k)}-B_{t_{j}}^{(k)})\right)
\]

\end_inset


\end_layout

\begin_layout Proof
The second term on the right converges to 
\begin_inset Formula $0$
\end_inset

 in the 
\begin_inset Formula $L^{2}$
\end_inset

 sense when 
\begin_inset Formula $i\neq k$
\end_inset

, from exercise 
\begin_inset CommandInset ref
LatexCommand eqref
reference "exercise:cross-variation-of-2-brownian-motions"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 This explains why the mixed derivatives disappear in the multi-dimensional
 Ito's formula.
 As for the case 
\begin_inset Formula $i=k$
\end_inset

, it reduces to the quadratic variation as in the one-dimensional case.
 This is where the Riemann integral arises, after suitable conditioning
 on 
\begin_inset Formula $\mathcal{F}_{t_{j}}$
\end_inset

, the sigma-field generated by 
\begin_inset Formula $B_{s}$
\end_inset

, 
\begin_inset Formula $s\leq t_{j}$
\end_inset

.
\end_layout

\begin_layout Standard
As in the one-dimensional case,it is not necessary to learn Ito's formula
 by heart.
 It suffices to write the differential of the function 
\begin_inset Formula $f$
\end_inset

 to second order.
 We can then apply the rules of multivariate Ito calculus:
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\cdot$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dt$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dB_{t}^{(1)}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dB_{t}^{(2)}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\ldots$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dt$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dB_{t}^{(1)}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dt$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dB_{t}^{(2)}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dt$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\ldots$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $0$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $dt$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
Note that the rule 
\begin_inset Formula $dB_{t}^{(i)}dB_{t}^{(j)}=0$
\end_inset

 for 
\begin_inset Formula $i\neq j$
\end_inset

 is being motivated by the cross-variation result 
\begin_inset CommandInset ref
LatexCommand eqref
reference "exercise:cross-variation-of-2-brownian-motions"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
How can we construct martingales using the Ito's formula? Recall that an
 Ito integral 
\begin_inset Formula $(\int_{0}^{t}X_{s}dB_{s},t\leq T)$
\end_inset

 is a martingale whenever the integrand is in 
\begin_inset Formula $\mathcal{L}_{c}^{2}(T)$
\end_inset

, the space of adapted processes with continuous paths and for which:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\int_{0}^{T}\mathbf{E}[X_{s}^{2}]ds & <\infty
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The only difference here is that the integrand is a function of many Brownian
 motions.
 However, the integrands involved in the Ito integrals of the multidimensional
 Ito's formula 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:multidimensional-ito-formula"
plural "false"
caps "false"
noprefix "false"

\end_inset

 are clearly adapted to the filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

 of 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

 as they are functions of the Brownian motion at the time.
 The arguments of Ito integral in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:properties-of-ito-integral-discrete-case"
plural "false"
caps "false"
noprefix "false"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:properties-of-ito-integral"
plural "false"
caps "false"
noprefix "false"

\end_inset

 apply verbatim, if we take the definition of 
\begin_inset Formula $\mathcal{L}_{c}^{2}(t)$
\end_inset

 with the filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

 of 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

.
 With this in mind, we have the following corollary.
 
\end_layout

\begin_layout Corollary
\begin_inset CommandInset label
LatexCommand label
name "cor:brownian-martingales-in-Rd"

\end_inset

(Brownian Martingales) Let 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

 be a Brownian motion in 
\begin_inset Formula $\mathbf{R}^{d}$
\end_inset

.
 Consider 
\begin_inset Formula $f\in\mathcal{C}^{2}(\mathbf{R}^{d})$
\end_inset

 such that processes 
\begin_inset Formula $(\partial_{x_{i}}f(B_{t}),t\leq T)\in\mathcal{L}_{c}^{2}(T)$
\end_inset

 for every 
\begin_inset Formula $i\leq d$
\end_inset

.
 Then, the process :
\end_layout

\begin_layout Corollary
\begin_inset Formula 
\[
f(B_{t})-\frac{1}{2}\int_{0}^{t}\nabla^{2}f(B_{s})ds,\quad t\leq T
\]

\end_inset


\end_layout

\begin_layout Corollary
where 
\begin_inset Formula $\nabla^{2}=\sum_{i=1}^{d}\partial_{x_{i}}^{2}$
\end_inset

 is the Laplacian, is a martingale for the Brownian filtration.
 
\end_layout

\begin_layout Standard
For example, consider the processes 
\begin_inset Formula $X_{t}=(B_{t}^{(1)})^{2}+(B_{t}^{(2)})^{2}$
\end_inset

 and 
\begin_inset Formula $Y_{t}=\exp(B_{t}^{(1)})\cos(B_{t}^{(2)})$
\end_inset

.
 Then, we have :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{1}{2}\int_{0}^{t}\nabla^{2}X_{s}ds=\frac{1}{2}\int_{0}^{t}4ds=2t
\]

\end_inset


\end_layout

\begin_layout Standard
and 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\frac{1}{2}\int_{0}^{t}\nabla^{2}Y_{s}ds & =\frac{1}{2}\int_{0}^{t}0\cdot ds=0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Thus, the processes 
\begin_inset Formula $X_{t}-2t$
\end_inset

 and 
\begin_inset Formula $Y_{t}$
\end_inset

 are martingales for the Brownian filtration.
 In one dimension, there are no interesting martingales constructed with
 functions of 
\emph on
space 
\emph default
only.
 Indeed, 
\begin_inset Formula $(f(B_{t}):t\geq0)$
\end_inset

 is a martingale if and only if 
\begin_inset Formula $f''(x)=0$
\end_inset

 for all 
\begin_inset Formula $x$
\end_inset

.
 But, such functions are of the form 
\begin_inset Formula $f(x)=ax+b$
\end_inset

, 
\begin_inset Formula $a,b\in\mathbf{R}$
\end_inset

.
 In other words, in one dimension, Brownian martingales of the form 
\begin_inset Formula $f(B_{t})$
\end_inset

 are simply 
\begin_inset Formula $aB_{t}+b$
\end_inset

.
 Not very surprising! The situation is very different in higher dimensions.
 Indeed, corollary 
\begin_inset CommandInset ref
LatexCommand eqref
reference "cor:brownian-martingales-in-Rd"
plural "false"
caps "false"
noprefix "false"

\end_inset

 implies that 
\begin_inset Formula $f(B_{t})$
\end_inset

 is a martingale whenever 
\begin_inset Formula $f$
\end_inset

 is a harmonic function:
\end_layout

\begin_layout Definition
A function 
\begin_inset Formula $f:\mathbf{R}^{d}\to\mathbf{R}$
\end_inset

 is harmonic in 
\begin_inset Formula $\mathbf{R}^{d}$
\end_inset

 if and only if 
\begin_inset Formula $\nabla^{2}f(x)\equiv0$
\end_inset

 for all 
\begin_inset Formula $x\in\mathbf{R}^{d}$
\end_inset

.
 More generally, a function 
\begin_inset Formula $f:\mathbf{R}^{d}\to\mathbf{R}$
\end_inset

 is harmonic in the region 
\begin_inset Formula $\mathcal{O}\subset\mathbf{R}^{d}$
\end_inset

 if and only if 
\begin_inset Formula $\nabla^{2}f(x)\equiv0$
\end_inset

 for all 
\begin_inset Formula $x\in\mathcal{O}$
\end_inset

.
\end_layout

\begin_layout Standard
Note that the function 
\begin_inset Formula $f(x)=e^{x_{1}}\cos x_{2}$
\end_inset

 is harmonic in 
\begin_inset Formula $\mathbf{R}^{d}$
\end_inset

.
 This is why the process 
\begin_inset Formula $Y_{t}=\exp(B_{t}^{(1)})\cos(B_{t}^{(2)})$
\end_inset

 is a martingale.
 The distinction to a subset of 
\begin_inset Formula $\mathbf{R}^{d}$
\end_inset

 in the above definition is important since it may happen that the function
 is harmonic only in a subset of the space; see for example equation.
 It is possible to define a Brownian martingale in such cases by considering
 the process until it exits the region.
 This will turn out to be important as we move ahead.
\end_layout

\begin_layout Standard
The multidimensional Ito's formula generalizes to functions of time and
 space as in proposition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "prop:ito's-formula-in-time-and-space"
plural "false"
caps "false"
noprefix "false"

\end_inset

:
\end_layout

\begin_layout Definition
A function 
\begin_inset Formula $f:[0,\infty)\times\mathbf{R}^{d}\to\mathbf{R}$
\end_inset

 is in 
\begin_inset Formula $\mathcal{C}^{1,2}([0,T]\times\mathbf{R}^{d})$
\end_inset

 if the partial derivative in 
\emph on
time
\emph default
 :
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
\frac{\partial}{\partial t}f(t,\mathbf{x})
\]

\end_inset


\end_layout

\begin_layout Definition
exists and is continuous and the second order partial derivatives in space:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
\frac{\partial^{2}}{\partial x_{i}^{2}}f(t,x_{1},x_{2},\ldots,x_{i},\ldots,x_{d}),\quad1\leq i\leq d
\]

\end_inset


\end_layout

\begin_layout Definition
exist and are continuous.
\end_layout

\begin_layout Theorem
(Ito's formula) Let 
\begin_inset Formula $(B_{t}:t\leq T)$
\end_inset

 be a 
\begin_inset Formula $d$
\end_inset

-dimensional Brownian motion.
 Consider a function 
\begin_inset Formula $f\in\mathcal{C}^{1,2}([0,T]\times\mathbf{R}^{d})$
\end_inset

.
 Then, we have with probability one for all 
\begin_inset Formula $t\leq T$
\end_inset

:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
f(t,B_{t})-f(0,B_{0}) & =\sum_{i=1}^{d}\int_{0}^{t}\partial_{x_{i}}f(s,B_{s})dB_{s}^{(i)}+\int_{0}^{t}\left(\partial_{t}f(s,B_{s})+\sum_{i=1}^{d}\partial_{x_{i}}^{2}f(s,B_{s})\right)ds
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The martingale condition is then similar to the ones in corollary 
\begin_inset CommandInset ref
LatexCommand eqref
reference "cor:brownian-martingales-in-Rd"
plural "false"
caps "false"
noprefix "false"

\end_inset

: if the processes 
\begin_inset Formula $(\partial_{x_{i}}f(s,B_{s}),t\leq T)\in\mathcal{L}_{c}^{2}(T)$
\end_inset

 for every 
\begin_inset Formula $1\leq i\leq d$
\end_inset

, then the process 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f(t,B_{t})-\int_{0}^{t}\left\{ \partial_{t}f(s,B_{s})++\sum_{i=1}^{d}\partial_{x_{i}}^{2}f(s,B_{s})\right\} ds,\quad t\leq T
\]

\end_inset


\end_layout

\begin_layout Standard
is a martingale for the Brownian filtration.
 In particular, if 
\begin_inset Formula $f$
\end_inset

 satisfies the partial differential equation:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\frac{\partial f}{\partial t}+\frac{1}{2}\nabla^{2}f & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
then the process 
\begin_inset Formula $(f(t,B_{t}):t\leq T)$
\end_inset

 itself is a martingale.
\end_layout

\begin_layout Subsection
Recurrence and Transience of Brownian Motion.
 
\end_layout

\begin_layout Standard
In one dimension, we established in example 
\end_layout

\begin_layout Section
Ito Processes and Stochastic Differential Equations.
\end_layout

\begin_layout Standard
Let's start with the definition of Ito processes.
\end_layout

\begin_layout Definition
(Ito Process).
 Let 
\begin_inset Formula $(B(t):t\geq0)$
\end_inset

 be a standard brownian motion defined on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 An Ito process 
\begin_inset Formula $(X(t):t\geq0)$
\end_inset

 is of the form:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align}
X(t) & =X(0)+\int_{0}^{t}V(s)dB(s)+\int_{0}^{t}D(s)ds\label{eq:ito-process}
\end{align}

\end_inset


\end_layout

\begin_layout Definition
where 
\begin_inset Formula $(V(t),t\geq0)$
\end_inset

 and 
\begin_inset Formula $(D(t),t\geq0)$
\end_inset

 are two adapted processes for which the integrals make sense in the sense
 of Ito and Riemann.
 We refer to 
\begin_inset Formula $(V(t):t\geq0)$
\end_inset

 as the
\emph on
 local volatility
\emph default
 and to 
\begin_inset Formula $(D(t):t\geq0)$
\end_inset

 as the 
\emph on
local drift
\emph default
.
 
\end_layout

\begin_layout Standard
We will often denote an Ito process 
\begin_inset Formula $(X(t):t\geq0)$
\end_inset

 in differential form as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
dX(t) & =D(t)dt+V(t)dB(t)\label{eq:ito-process-differential-form}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
This form makes no rigorous sense; when we write it, we mean 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:ito-process"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Nevertheless, the differential equation has two great advantages:
\end_layout

\begin_layout Standard
(1) It gives some intuition on what drives the variation of 
\begin_inset Formula $X(t)$
\end_inset

.
 On one hand, there is a contribution of the Brownian increments which are
 modulated by the volatility 
\begin_inset Formula $V(t)$
\end_inset

.
 On the other hand, there is a smoother contribution coming from the time
 variation which is modulated by the drift 
\begin_inset Formula $D(t)$
\end_inset

.
\end_layout

\begin_layout Standard
(2) The differential notation has computational power.
 In particular, evaluating Ito's formula is reduced to computing differentials,
 as in classical calculus, but by doing it upto the second order.
\end_layout

\begin_layout Standard
An important class of Ito processes is given by processes for which the
 volatility and the drift are simply functions of the position of the process.
 
\end_layout

\begin_layout Definition
Let 
\begin_inset Formula $(B(t):t\geq0)$
\end_inset

 be a standard Brownian motion.
 An Ito process 
\begin_inset Formula $(X(t):t\geq0)$
\end_inset

 of the form 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{align}
dX(t) & =\mu(X(t))dt+\sigma(X(t))dB(t),\quad X(0)=x\label{eq:time-homogenous-ito-process}
\end{align}

\end_inset


\end_layout

\begin_layout Definition
where 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\sigma$
\end_inset

 are functions from 
\begin_inset Formula $\mathbf{R}$
\end_inset

 to 
\begin_inset Formula $\mathbf{R}$
\end_inset

, is called a time-homogenous diffusion.
 An Ito-process 
\begin_inset Formula $(Y(t),t\geq0)$
\end_inset

 of the form:
\end_layout

\begin_layout Definition
\begin_inset Formula 
\begin{alignat}{1}
dY(t) & =\mu(t,X(t))dt+\sigma(t,X(t))dB(t)\quad Y(0)=y\label{eq:time-inhomogenous-SDE}
\end{alignat}

\end_inset


\end_layout

\begin_layout Definition
where 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\sigma$
\end_inset

 are now functions 
\begin_inset Formula $[0,\infty)\times\mathbf{R}\to\mathbf{R}$
\end_inset

 is called a time-inhomogenous diffusion.
 The equations above are called 
\emph on
stochastic differential equations
\emph default
 (SDE) of the respective process 
\begin_inset Formula $(X(t))$
\end_inset

 and 
\begin_inset Formula $(Y(t))$
\end_inset

.
\end_layout

\begin_layout Standard
In other words, a diffusion 
\begin_inset Formula $(X(t),t\geq0)$
\end_inset

 is called an Ito process whose local volatility 
\begin_inset Formula $V(t)$
\end_inset

 and local drift 
\begin_inset Formula $D(t)$
\end_inset

 at time 
\begin_inset Formula $t$
\end_inset

 depend only on the position of the process at time 
\begin_inset Formula $t$
\end_inset

 and possibly on the time 
\begin_inset Formula $t$
\end_inset

 itself.
 It cannot depend on the path of the process before time 
\begin_inset Formula $t$
\end_inset

 or on the explicit values of the driving Brownian motion at that time (which
 is not the process 
\begin_inset Formula $X(t)$
\end_inset

 itself).
 The class of diffusions, and of the Ito processes in general, constitutes
 a huge collection of stochastic processes for stochastic modelling.
 
\end_layout

\begin_layout Standard
Note that an SDE is a generalization of ordinary differential equations
 or ODEs.
 Indeed, if there were no randomness, that is, no Brownian motion, the SDE
 would be reduced to 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
dX(t) & =\mu(X(t))dt
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This can be written for 
\begin_inset Formula $X(t)=f(t)$
\end_inset

 as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\frac{df}{dt} & =\mu(f)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This is a first-order ordinary differential equation.
 It governs the deterministic evolution of the function 
\begin_inset Formula $X(t)=f(t)$
\end_inset

 in time.
 An SDE adds a random term to this evolution that is formally written as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\frac{dX}{dt} & =\mu(X(t))+\sigma(X(t))\frac{dB(t)}{dt}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We know very well, that Brownian motion is not differentiable; hence the
 above is not well-defined.
 The ill-defined term 
\begin_inset Formula $dB(t)/dt$
\end_inset

 is sometimes called white noise.
 However, equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:time-homogenous-ito-process"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is well-defined in the sense of the Ito process.
 These types of equations are well-suited to model phenomena with intrinsic
 randomness.
 
\end_layout

\begin_layout Standard
Here are some examples of diffusions:
\end_layout

\begin_layout Example
(Brownian Motion with a drift).
 If we take 
\begin_inset Formula $X(t)=\sigma B(t)+\mu t$
\end_inset

 for some 
\begin_inset Formula $\sigma>0$
\end_inset

 and 
\begin_inset Formula $\mu\in\mathbf{R}$
\end_inset

, then we can write 
\begin_inset Formula $X(t)$
\end_inset

 as:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
X(t) & =\int_{0}^{t}\sigma dB(t)+\int_{0}^{t}\mu dt,\quad X(0)=0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In the differential form this becomes 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
dX(t) & =\mu dt+\sigma dB(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In this case, the local drift and the local volatility are constant.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(Geometric Brownian Motion).
 We consider the process 
\begin_inset Formula $S(t)=\exp((\mu-\sigma^{2}/2)t+\sigma B(t))$
\end_inset

.
 To find the stochastic differential equation, we apply the Ito's Lemma
 to 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
f(t,x) & =\exp((\mu-\sigma^{2}/2)t+\sigma x)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
df(t,x) & =\left((\mu-\sigma^{2}/2)+\frac{1}{2}\sigma^{2}\right)\exp((\mu-\sigma^{2}/2)t+\sigma x)dt+\sigma\exp((\mu-\sigma^{2}/2)t+\sigma x)dB(t)\\
 & =\mu S(t)dt+\sigma S(t)dB(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Note that the local drift and the local volatility are now proportional
 to the position.
 So, the higher 
\begin_inset Formula $S(t)$
\end_inset

, the higher the volatility and drift.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(Any smooth function of Brownian motion).
 Ito's formula gurarantees that any smooth function 
\begin_inset Formula $f(t,B(t))$
\end_inset

 of time and a Brownian motion is an Ito process with volatility 
\begin_inset Formula $V(t)=\partial_{t}f(t,B(t))$
\end_inset

 and drift 
\begin_inset Formula $D(t)=\partial_{x}f(t,B(t))+\frac{1}{2}\partial_{xx}f(t,B(t))$
\end_inset

.
 We will see in further ahead, that, in general, any reasonable function
 of an Ito process remains an Ito process.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(An Ito process that is not a diffusion) Consider the process 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
X(t) & =\int_{0}^{t}B^{2}(s)dB(s)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
This is an Ito process with local volatility 
\begin_inset Formula $V(t)=B(t)^{2}$
\end_inset

 and local drift 
\begin_inset Formula $D(t)=0$
\end_inset

.
 However, it is not a diffusion, because the local volatility is not an
 explicit function of 
\begin_inset Formula $X(t)$
\end_inset

.
\end_layout

\begin_layout Example
It turns out that the Brownian bridge is a time-inhomogenous diffusion and
 that the Ornstein-Uhlenbeck process is a time-homogenous diffusion.
 To understand these examples, we need to extend Ito's formula to Ito processes.
\end_layout

\begin_layout Subsection
Ito's Formula.
\end_layout

\begin_layout Standard
The first step towards a general Ito's formula is the quadratic variation
 of an Ito process.
 
\end_layout

\begin_layout Proposition
(Quadratic variation of an Ito process).
 Let 
\begin_inset Formula $(B(t),t\geq0)$
\end_inset

 be a standard Brownian motion and 
\begin_inset Formula $(X(t):t\geq0)$
\end_inset

 be an Ito process of the form 
\begin_inset Formula $dX(t)=V(t)dB(t)+D(t)dt$
\end_inset

.
 Then, the quadratic variation of the process 
\begin_inset Formula $(X(t):t\geq0)$
\end_inset

 is:
\end_layout

\begin_layout Proposition
\begin_inset Formula 
\begin{align}
<X,X>_{t} & =\lim_{n\to\infty}\sum_{j=0}^{n-1}(X(t_{j+1})-X(t_{j}))^{2}=\int_{0}^{t}V(s)^{2}ds\label{eq:quadratic-variation-ito-process}
\end{align}

\end_inset


\end_layout

\begin_layout Proposition
for any partition 
\begin_inset Formula $(t_{j},j\leq n)$
\end_inset

 of 
\begin_inset Formula $[0,t]$
\end_inset

, where the limit is in probability.
\end_layout

\begin_layout Remark*
Note that the quadratic variation is increasing in 
\begin_inset Formula $t$
\end_inset

, but it is not deterministic in general! The quadratic variation is a smooth
 stochastic process.
 (It is differentiable) Observe that we recover the quadratic variation
 for the Brownian motion for 
\begin_inset Formula $V(t)=1$
\end_inset

 as expected.
 We also notice that the formula follows easily from the rules of Ito Calculus,
 thereby showing the consistency of the theory.
 Indeed we have:
\end_layout

\begin_layout Remark*
\begin_inset Formula 
\begin{align*}
d<X,X>_{t} & =(dX(t))^{2}=(V(t)dB(t)+D(t)dt)^{2}\\
 & =V(t)^{2}(dB(t))^{2}+2V(t)D(t)dB(t)\cdot dt+D^{2}(t)(dt)^{2}\\
 & =V(t)^{2}dt
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The proof is involved, but it reviews some important concepts of stochastic
 calculus.
 We prove the case when the process 
\begin_inset Formula $V$
\end_inset

 is in 
\begin_inset Formula $\mathcal{L}_{c}^{2}(T)$
\end_inset

 for some 
\begin_inset Formula $T>0$
\end_inset

.
 We write 
\begin_inset Formula $I(t)=\int_{0}^{t}V(s)dB(s)$
\end_inset

 and 
\begin_inset Formula $R(t)=\int_{0}^{t}D(s)ds$
\end_inset

.
 We first show that only the Ito integral contributes to the quadratic variation
 and the Riemann integral does not contribute, so that:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
<X,X>_{t} & =<I,I>_{t}\label{eq:quadratic-variation-ito-process-ii}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
We have that the increment square of 
\begin_inset Formula $X(t)$
\end_inset

 is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
(X(t_{j+1})-X(t_{j}))^{2} & =(I(t_{j+1})-I(t_{j}))^{2}+2(I(t_{j+1})-I(t_{j}))(R(t_{j+1})-R(t_{j}))+(R(t_{j+1})-R(t_{j}))^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The Cauchy-Schwarz inequality implies :
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))(R(t_{j+1})-R(t_{j})) & \leq\left(\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}\right)^{1/2}\left(\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2}\right)^{1/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Therefore, to prove equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:quadratic-variation-ito-process-ii"
plural "false"
caps "false"
noprefix "false"

\end_inset

, it suffices to show that 
\begin_inset Formula $\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2}\to0$
\end_inset

 almost surely.
 Since 
\begin_inset Formula $D(s)$
\end_inset

 is an almost surely continuous process, the stochastic process 
\begin_inset Formula $R(t)=\int_{0}^{t}D(s)ds$
\end_inset

 has continuous paths with probability 
\begin_inset Formula $1$
\end_inset

.
 Therefore:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))^{2} & =\max_{1\leq j\leq n}|R(t_{j+1})-R(t_{j})|\sum_{j=0}^{n-1}(R(t_{j+1})-R(t_{j}))
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Since, 
\begin_inset Formula $R(t)$
\end_inset

 is continuous on the compact set 
\begin_inset Formula $[0,t]$
\end_inset

, it is uniformly continuous a.s.
 So, as 
\begin_inset Formula $|t_{j+1}-t_{j}|\to0$
\end_inset

, by uniform continuity it follows that 
\begin_inset Formula $\max|R(t_{j+1})-R(t_{j})|\to0$
\end_inset

 a.s.
 
\end_layout

\begin_layout Proof
It remains to prove that 
\begin_inset Formula $<I,I>_{t}=\int_{0}^{t}V(s)^{2}ds$
\end_inset

.
 We first prove the case when 
\begin_inset Formula $V\in\mathcal{S}(T)$
\end_inset

 is a simple adapted process.
 Consider a partition 
\begin_inset Formula $(t_{j}:j\leq n)$
\end_inset

 of 
\begin_inset Formula $[0,t]$
\end_inset

.
 Without loss of generality, we can suppose that 
\begin_inset Formula $V$
\end_inset

 is constant on each 
\begin_inset Formula $[t_{j},t_{j+1})$
\end_inset

 by refining the partition.
 We then have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2} & =\sum_{j=0}^{n-1}V(t_{j})^{2}(B(t_{j+1})-B(t_{j}))^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Now, we have seen in the proof of Ito's formula 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:l2-convergence-of-second-term-to-riemann-integral"
plural "false"
caps "false"
noprefix "false"

\end_inset

 that 
\begin_inset Formula $\mathbb{E}\left[\left\{ \sum_{j=0}^{n-1}V(t_{j})^{2}((B(t_{j+1})-B(t_{j}))^{2}-(t_{j+1}-t_{j})\right\} ^{2}\right]\to0$
\end_inset

, so 
\begin_inset Formula $\sum_{j=0}^{n-1}V(t_{j})^{2}(B(t_{j+1})-B(t_{j}))^{2}$
\end_inset

 approaches 
\begin_inset Formula $\sum_{j=0}^{n-1}V(t_{j})^{2}(t_{j+1}-t_{j})$
\end_inset

 in the mean square sense.
 As the mesh size becomes finer, the 
\begin_inset Formula $L^{2}$
\end_inset

-limit is 
\begin_inset Formula $\int_{0}^{t}V(t)^{2}dt$
\end_inset

.
\end_layout

\begin_layout Proof
The case 
\begin_inset Formula $V\in\mathcal{L}_{c}^{2}(T)$
\end_inset

 is proved by approximating 
\begin_inset Formula $V$
\end_inset

 by a simple process in 
\begin_inset Formula $\mathcal{S}(T)$
\end_inset

.
 More precisely, we can find a simple process 
\begin_inset Formula $V^{(\epsilon)}(t)$
\end_inset

 that is 
\begin_inset Formula $\epsilon$
\end_inset

-close to 
\begin_inset Formula $V$
\end_inset

 in the sense:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
||I^{(\epsilon)}-I|| & =||\int V^{\epsilon}dB(t)-\int VdB(t)||=\int_{0}^{t}\mathbb{E}[(V^{(\epsilon)}(t)-V(t))^{2}]ds<\epsilon\label{eq:sequence-of-simple-processes}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
To prove the claim, we need to show that for 
\begin_inset Formula $t\leq T$
\end_inset

,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[\left|\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-\int_{0}^{t}(V(s))^{2}ds\right|\right] & \to0\quad\text{as }\quad n\to\infty
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
\begin_inset Formula $L^{1}$
\end_inset

-convergence implies convergence in probability of the sequence 
\begin_inset Formula $\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}$
\end_inset

.
 We now introduce the 
\begin_inset Formula $V^{(\epsilon)}(t)$
\end_inset

 approximation inside the absolute value as well as its corresponding integral
 
\begin_inset Formula $I^{(\epsilon)}(t)=\int_{0}^{t}V^{(\epsilon)}(s)ds$
\end_inset

.
 By the triangle inequality, we have:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
 & \mathbb{E}\left[\left|\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-\int_{0}^{t}(V(s))^{2}ds\right|\right]\nonumber \\
= & \mathbb{E}\left[\Biggl|\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-(I^{(\epsilon)}(t_{j+1})-I^{(\epsilon)}(t_{j}))^{2}+(I^{(\epsilon)}(t_{j+1})-I^{(\epsilon)}(t_{j}))^{2}-\int_{0}^{t}(V^{(\epsilon)}(s))^{2}ds\right.\nonumber \\
 & +\int_{0}^{t}(V^{(\epsilon)}(s))^{2}ds-\int_{0}^{t}(V(s))^{2}ds\Biggr|\Biggr]\nonumber \\
\leq & \mathbb{E}\left[\left|\sum_{j=0}^{n-1}(I(t_{j+1})-I(t_{j}))^{2}-(I^{(\epsilon)}(t_{j+1})-I^{(\epsilon)}(t_{j}))^{2}\right|\right]+\mathbb{E}\left[\left|\sum_{j=0}^{n-1}(I^{(\epsilon)}(t_{j+1})-I^{(\epsilon)}(t_{j}))^{2}-\int_{0}^{t}(V^{(\epsilon)}(s))^{2}ds\right|\right]\label{eq:quadratic-variation-of-ito-process-i}\\
 & +\mathbb{E}\left[\Biggl|\int_{0}^{t}(V^{(\epsilon)}(s))^{2}ds-\int_{0}^{t}(V(s))^{2}ds\Biggr|\right]\nonumber 
\end{align}

\end_inset


\end_layout

\begin_layout Proof
We show that the first and third terms converge uniformly and that the second
 term goes to 
\begin_inset Formula $0$
\end_inset

 as 
\begin_inset Formula $n\to\infty$
\end_inset

.
\end_layout

\begin_layout Proof
The second term goes to 
\begin_inset Formula $0$
\end_inset

 as 
\begin_inset Formula $n\to\infty$
\end_inset

 by the argument for simple processes.
 
\begin_inset Formula $<I^{(\epsilon)},I^{(\epsilon)}>_{t}=\int_{0}^{t}V^{(\epsilon)}(s)^{2}ds$
\end_inset

.
\end_layout

\begin_layout Proof
For the third term, the linearity of the integral and the Cauchy Schwarz
 inequality (applied to 
\begin_inset Formula $\mathbb{E}\int_{0}^{t}$
\end_inset

) imply that it is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[\Biggl|\int_{0}^{t}(V^{(\epsilon)}(s))^{2}ds-\int_{0}^{t}(V(s))^{2}ds\Biggr|\right] & \leq\mathbb{E}\left[\Biggl|\int_{0}^{t}(V^{(\epsilon)}(s)-V(s))^{2}ds\Biggr|\right]^{1/2}\mathbb{E}\left[\Biggl|\int_{0}^{t}(V^{(\epsilon)}(s)+V(s))^{2}ds\Biggr|\right]^{1/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
The first factor is smaller than the square root of 
\begin_inset Formula $\epsilon$
\end_inset

 by equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sequence-of-simple-processes"
plural "false"
caps "false"
noprefix "false"

\end_inset

, whereas the second factor is bounded.
\end_layout

\begin_layout Proof
The first term in equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:quadratic-variation-of-ito-process-i"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is handled similarly.
 The linearity of the Ito integral and the Cauchy-Schwarz inequality applied
 to 
\begin_inset Formula $\mathbb{E}\left[\sum_{j=0}^{n-1}\left(\int_{t_{j}}^{t_{j+1}}\cdot\right)\right]$
\end_inset

 give that the first term is:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
 & \mathbb{E}\left[\left|\sum_{j=0}^{n-1}\int_{t_{j}}^{t_{j+1}}(V(s))^{2}dB(s)-\int_{t_{j}}^{t_{j+1}}(V^{\epsilon}(s))^{2}dB(s)\right|\right]\\
= & \mathbb{E}\left[\left|\sum_{j=0}^{n-1}\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\epsilon}(s))dB(s)\int_{t_{j}}^{t_{j+1}}(V(s)+V^{\epsilon}(s))dB(s)\right|\right]\\
\leq & \mathbb{E}\left[\sum_{j=0}^{n-1}\left(\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\epsilon}(s))dB(s)\right)^{2}\right]^{1/2}\mathbb{E}\left[\Biggl|\sum_{j=0}^{n-1}\left(\int_{t_{j}}^{t_{j+1}}(V(s)+V^{\epsilon}(s))dB(s)\right)^{2}\Biggr|\right]^{1/2}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By Ito isometry, the first factor in the above expression can be simplified:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[\sum_{j=0}^{n-1}\left(\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\epsilon}(s))dB(s)\right)^{2}\right]^{1/2} & =\sum_{j=0}^{n-1}\mathbb{E}\left(\int_{t_{j}}^{t_{j+1}}(V(s)-V^{\epsilon}(s))dB(s)\right)^{2}\\
 & =\sum_{j=0}^{n-1}\int_{t_{j}}^{t_{j+1}}\mathbb{E}[(V(s)-V^{\epsilon}(s))^{2}]ds
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
By equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:sequence-of-simple-processes"
plural "false"
caps "false"
noprefix "false"

\end_inset

, this factor is smaller than 
\begin_inset Formula $\epsilon$
\end_inset

.
 The second factor equals 
\begin_inset Formula $\sum_{j=0}^{n-1}\int_{t_{j}}^{t_{j+1}}\mathbb{E}[(V(s)+V^{\epsilon}(s))^{2}]ds$
\end_inset

 by Ito-isometry and is uniformly bounded.
 This concludes the proof of the proposition.
\end_layout

\begin_layout Standard
Note that quadratic variation 
\begin_inset Formula $<I,I>_{t}=\int(V(s))^{2}ds$
\end_inset

 is computed path-by-path and hence the result is random.
 On the other the variance of the Ito integral 
\begin_inset Formula $Var(I(t))=\mathbb{E}[I_{t}^{2}]=\int\mathbb{E}[V_{s}^{2}]ds$
\end_inset

 is the mean value of all possible paths of the quadratic variation and
 hence is non-random.
 We are now ready to state Ito's formula for Ito processes.
 We write the result in differential form for conciseness.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "th:ito-formula-for-ito-processes"

\end_inset

(Ito's formula for Ito processes).
 Let 
\begin_inset Formula $(B(t):t\geq0)$
\end_inset

 be a standard brownian motion, and let 
\begin_inset Formula $(X(t):t\geq0)$
\end_inset

 be an Ito process of the form 
\begin_inset Formula $dX(t)=V(t)dB(t)+D(t)dt$
\end_inset

.
 Consider a function 
\begin_inset Formula $f(t,x)\in\mathcal{C}^{1,2}([0,T]\times\mathbf{R})$
\end_inset

.
 Then we have with probability one for all 
\begin_inset Formula $t\leq T$
\end_inset

:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
df(t,X(t)) & =\partial_{x}f(t,X(t))dX(t)+\partial_{t}f(t,X(t))dt+\frac{1}{2}\partial_{xx}f(t,X(t))d<X,X>_{t}
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
This can also be written as:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
df(t,X(t))= & \partial_{x}f(t,X(t))V(t)dB(t)+\left[\partial_{x}f(t,X(t))D(t)+\partial_{t}f(t,X(t))+\frac{1}{2}(V(t))^{2}\partial_{xx}f(t,X(t))\right]dt
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The proof of the theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:ito-formula-for-ito-processes"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is again a Taylor approximation with the form of the quadratic variation
 of the process.
 We will omit it.
\end_layout

\begin_layout Example
(Ornstein-Uhlenbeck Process).
 Consider the Ornstein-Uhlenbeck process 
\begin_inset Formula $(Y(t):t\geq0)$
\end_inset

:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Y(t) & =Y(0)e^{-t}+e^{-t}\int_{0}^{t}e^{s}dB(s)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Note that this process is an explicit function of 
\begin_inset Formula $t$
\end_inset

 and of the Ito process 
\begin_inset Formula $X(t)=Y(0)+\int_{0}^{t}e^{s}dB(s)$
\end_inset

.
 Indeed, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
Y(t) & =e^{-t}X(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $f(t,x)=e^{-t}x$
\end_inset

.
 Then, 
\begin_inset Formula $f_{x}(t,x)=e^{-t}$
\end_inset

, 
\begin_inset Formula $f_{xx}(t,x)=0$
\end_inset

 and 
\begin_inset Formula $f_{t}(t,x)=-e^{-t}x$
\end_inset

.
 So, by Ito's lemma,
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align}
df(t,x) & =f_{t}(t,X(t))dt+f_{x}(t,X(t))dX(t)+\frac{1}{2}f_{xx}(t,X(t))d<X,X>_{t}\nonumber \\
dY(t) & =-Y(t)dt+e^{-t}dX(t)\nonumber \\
dY(t) & =-Y(t)dt+e^{-t}(e^{t}dB(t))\nonumber \\
dY(t) & =-Y(t)dt+dB(t)\label{eq:ornstein-uhlenbeck-sde}
\end{align}

\end_inset


\end_layout

\begin_layout Example
This is the SDE for the Ornstein Uhlenbeck process.
\end_layout

\begin_layout Example
The SDE has a very nice interpretation: The drift is positive if 
\begin_inset Formula $Y(t)<0$
\end_inset

 and negative if 
\begin_inset Formula $Y(t)>0$
\end_inset

.
 Moreover, the drift is proportional to the position (exactly like a spring
 pulling the process back to the 
\begin_inset Formula $x$
\end_inset

-axis following the Hooke's law!).
 This is the mechanism that ensures that the process does not venture too
 far from 
\begin_inset Formula $0$
\end_inset

 and is eventually stationary.
 
\end_layout

\begin_layout Example
The SDE 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:ornstein-uhlenbeck-sde"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is now easily generalized by adding two parameters for the volatility and
 the drift:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align}
dY(t) & =-kY(t)dt+\sigma dB(t),\quad k\in\mathbf{R},\sigma>0\label{eq:ornstein-uhlenbeck-sde-ii}
\end{align}

\end_inset


\end_layout

\begin_layout Example
It is not hard to check that the solution to the SDE is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align}
Y(t) & =Y(0)e^{-kt}+e^{-kt}\int_{0}^{t}e^{ks}\sigma dB(s)\label{eq:solution-to-the-ornstein-uhlenbeck-sde}
\end{align}

\end_inset


\end_layout

\begin_layout Exercise

\series bold
The Ornstein-Uhlenbeck process with parameters.
 
\series default
Use the Ito's formula to show that the equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:solution-to-the-ornstein-uhlenbeck-sde"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is the solution to the Ornstein-Uhlenbeck SDE 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:ornstein-uhlenbeck-sde-ii"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $X(t)=Y(0)+\int_{0}^{t}e^{ks}\sigma dB(s)$
\end_inset

, so 
\begin_inset Formula $dX(t)=e^{kt}\sigma dB(t)$
\end_inset

.
 Then, 
\begin_inset Formula $Y(t)=e^{-kt}X(t)$
\end_inset

.
 Let 
\begin_inset Formula $f(t,x)=e^{-kt}x$
\end_inset

.
 Then, by Ito's formula:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
df(t,x) & =-ke^{-kt}X(t)dt+e^{-kt}dX(t)\\
dY(t) & =-kY(t)dt+e^{-kt}e^{kt}\sigma dB(t)\\
dY(t) & =-kY(t)dt+\sigma dB(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The latest version of Ito's formula is another useful tool for producing
 martingales from a function of an Ito process.
 We start with two examples generalizing martingales for Brownian motion.
\end_layout

\begin_layout Example
(A generalization of 
\begin_inset Formula $(B(t))^{2}-t$
\end_inset

).
 Let 
\begin_inset Formula $(V(t):t\leq T)$
\end_inset

 be a process in 
\begin_inset Formula $\mathcal{L}_{c}^{2}(T)$
\end_inset

.
 Consider an Ito process 
\begin_inset Formula $(X(t):t\leq T)$
\end_inset

 given by 
\begin_inset Formula $dX(t)=V(t)dB(t)$
\end_inset

.
 Note that 
\begin_inset Formula $((X(t))^{2}:t\leq T)$
\end_inset

 is a submartingale by Jensen's inequality, since 
\begin_inset Formula $\mathbb{E}[X^{2}(t)|\mathcal{F}_{s}]\geq(\mathbb{E}[X(t)|\mathcal{F}_{s})^{2}=X^{2}(s)$
\end_inset

.
 We show that the compensated process
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
M(t) & =X^{2}(t)-\int_{0}^{t}V^{2}(s)ds,\quad t\leq T
\end{align*}

\end_inset


\end_layout

\begin_layout Example
is a martingale for the Brownian filtration.
 (This is another instance of the Doob-Meyer decomposition).
 By the Ito's formula for 
\begin_inset Formula $f(x)=x^{2}$
\end_inset

, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
df(x) & =f_{x}(X(t)dX(t)+\frac{1}{2}f_{xx}(X(t))d<X,X>_{t}\\
 & =2X(t)dX(t)+(V(t))^{2}dt\\
df(X(t)) & =2X(t)V(t)dB(t)+(V(t))^{2}dt
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In Integral form this implies:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
(X(t))^{2} & =(X(0))^{2}+2\int_{0}^{t}X(s)V(s)dB(s)+\int_{0}^{t}(V(s))^{2}ds\\
M(t)=(X(t))^{2}-\int_{0}^{t}(V(s))^{2}ds & =(X(0))^{2}+2\int_{0}^{t}X(s)V(s)dB(s)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
We conclude that 
\begin_inset Formula $(M(t):t\leq T)$
\end_inset

 is a martingale, provided 
\begin_inset Formula $X(t)V(t)\in L_{c}^{2}(T)$
\end_inset

.
\end_layout

\begin_layout Example
There is another more direct way to prove that 
\begin_inset Formula $(M(t):t\leq T)$
\end_inset

 is a martingale whenever 
\begin_inset Formula $(V(t):t\leq T)\in\mathcal{L}_{c}^{2}(T)$
\end_inset

.
 This is by using increments: for 
\begin_inset Formula $t'<t\leq T$
\end_inset

,
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}[X_{t'}^{2}|\mathcal{F}_{t}] & =\mathbb{E}[(X_{t}+(X_{t'}-X_{t}))^{2}|\mathcal{F}_{t}]\\
 & =\mathbb{E}[X_{t}^{2}+2X_{t}(X_{t'}-X_{t})+(X_{t'}-X_{t})^{2}|\mathcal{F}_{t}]\\
 & =X_{t}^{2}+2X_{t}\mathbb{E}[X_{t'}-X_{t}|\mathcal{F}_{t}]+\mathbb{E}[(X_{t'}-X_{t})^{2}|\mathcal{F}_{t}]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Since 
\begin_inset Formula $(X_{t}:t\geq0)$
\end_inset

 is a martingale, 
\begin_inset Formula $\mathbb{E}[(X_{t'}-X_{t})|M_{t}]=0$
\end_inset

, so the middle term equals zero and we are left with:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}[X_{t'}^{2}|\mathcal{F}_{t}] & =X_{t}^{2}+\mathbb{E}[(X_{t'}-X_{t})^{2}|\mathcal{F}_{t}]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
By conditional Ito Isometry,
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}[(X_{t'}-X_{t})^{2}|\mathcal{F}_{t}] & =\int_{0}^{t'}V_{s}^{2}ds-\int_{0}^{t}V_{s}^{2}ds=\int_{t}^{t'}V_{s}^{2}ds
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
(A generalization of the geometric Brownian motion).
 Let 
\begin_inset Formula $\sigma(t)$
\end_inset

 be a continuous, deterministic function such that 
\begin_inset Formula $|\sigma(t)|\leq1$
\end_inset

, 
\begin_inset Formula $t\in[0,T]$
\end_inset

.
 The process 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
M(t) & =\exp\left(\int_{0}^{t}\sigma(s)dB(s)-\frac{1}{2}\int_{0}^{t}\sigma^{2}(s)ds\right),\quad t\leq T
\end{align*}

\end_inset


\end_layout

\begin_layout Example
is a martingale for the Brownian filtration.
 To see this, note that we can write 
\begin_inset Formula $M(t)=f(t,X(t))$
\end_inset

 where 
\begin_inset Formula $f(t,x)=\exp(x-\frac{1}{2}\int\sigma^{2}(s)ds)$
\end_inset

 and 
\begin_inset Formula $X(t)=\int_{0}^{t}\sigma(s)dB(s)$
\end_inset

, so 
\begin_inset Formula $dX(t)=\sigma(t)dB(t)$
\end_inset

.
 Ito's formula gives:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
df(t,x) & =f_{t}(t,X(t)dt+f_{x}(t,X(t))dX(t)+\frac{1}{2}f_{xx}(t,X(t))d<X,X>_{t}\\
dM(t) & =-\frac{1}{2}\sigma^{2}(t)M(t)dt+M(t)\sigma(t)dB(t)+\frac{1}{2}M(t)\sigma^{2}(t)dt\\
 & =M(t)\sigma(t)dB(t)\\
M(t) & =M(0)+\int_{0}^{t}M(s)\sigma(s)dB(s)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Observe also that:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mathbb{E}[M_{t}^{2}] & =e^{-\int_{0}^{t}\sigma^{2}(s)ds}\mathbb{E}[e^{2\int_{0}^{t}\sigma(s)dB(s)}]=e^{\int_{0}^{t}\sigma^{2}(s)ds}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
since 
\begin_inset Formula $\int_{0}^{t}\sigma(s)dB(s)$
\end_inset

 is a Gaussian random variable with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $\int_{0}^{t}\sigma^{2}(s)ds$
\end_inset

.
 So, 
\begin_inset Formula $\mathbb{E}[e^{2\int_{0}^{t}\sigma(s)dB(s)}]=\exp[\frac{1}{2}\times4\times\int_{0}^{t}\sigma^{2}(s)ds]=\exp(2\int_{0}^{t}\sigma^{2}(s)ds)$
\end_inset

.
\end_layout

\begin_layout Example
We conclude from the equation that 
\begin_inset Formula $(M(t),t\geq0)$
\end_inset

 is a martingale.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example

\series bold
(Martingales of Geometric Brownian Motion)
\series default
.
 Let 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
S(t) & =S(0)\exp(\sigma B(t)-\sigma^{2}t/2)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
be a geometric brownian motion.
 We find a PDE satisfied by 
\begin_inset Formula $f(t,x)$
\end_inset

 for 
\begin_inset Formula $f(t,S(t))$
\end_inset

 to be a martingale.
 It suffices to apply Ito's formula of theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:ito-formula-for-ito-processes"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 We get:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
df(t,S(t)) & =f_{t}(t,S(t))dt+f_{x}(t,S(t))dS(t)+\frac{1}{2}f_{xx}(t,S(t))dS(t)\cdot dS(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Now note from the earlier result that 
\begin_inset Formula $dS(t)=S(t)\sigma dB(t)$
\end_inset

.
 So, 
\begin_inset Formula $dS(t)\cdot dS(t)=\frac{1}{2}\sigma^{2}(S(t))^{2}dt$
\end_inset

.
 So,
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
df(t,S(t)) & =\left\{ \frac{\partial f}{\partial t}+\frac{1}{2}\sigma^{2}(S(t))^{2}\frac{\partial^{2}f}{\partial x^{2}}\right\} dt+\sigma S(t)\frac{\partial f}{\partial x}dB(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Finally, the PDE for 
\begin_inset Formula $f(t,x)$
\end_inset

 is obtained by setting the factor in front of 
\begin_inset Formula $dt$
\end_inset

 to 
\begin_inset Formula $0$
\end_inset

, because we want 
\begin_inset Formula $f$
\end_inset

 to be a martingale process.
 It is important to keep in mind, that the PDE should always be written
 in terms of the time variable 
\begin_inset Formula $t$
\end_inset

 and the space variable 
\begin_inset Formula $x$
\end_inset

.
 Therefore, the PDE of 
\begin_inset Formula $f$
\end_inset

 as a function of time and space is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\frac{1}{2}\sigma^{2}x^{2}\frac{\partial^{2}f}{\partial x^{2}}(t,x)+\frac{\partial f}{\partial t}(t,x) & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
No more randomness appears in the PDE!
\end_layout

\begin_layout Standard
Here is a specific case where we can apply the Ito's formula to construct
 martingales of Ito processes.
\end_layout

\begin_layout Example
Consider the process given by the SDE:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
dX(t) & =X(t)dB(t),\quad X(0)=2
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Let's find a PDE for which 
\begin_inset Formula $f(t,X(t))$
\end_inset

 is a martingale for the Brownian filtration.
 We have by Ito's formula that:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
df(t,X(t)) & =f_{t}(t,X(t))dt+f_{x}(t,X(t))dX(t)+\frac{1}{2}f_{xx}(t,X(t))d<X,X>_{t}\\
 & =\left(\frac{\partial f}{\partial t}+\frac{1}{2}(X(t))^{2}\frac{\partial^{2}f}{\partial x^{2}}\right)dt+X(t)\frac{\partial f}{\partial x}dB(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Setting the drift term to 
\begin_inset Formula $0$
\end_inset

 gives the PDE:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\frac{\partial f}{\partial t}+\frac{1}{2}x^{2}\frac{\partial^{2}f}{\partial x^{2}} & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
It is then easy to check that 
\begin_inset Formula $X(t)$
\end_inset

 is a martingale and so is 
\begin_inset Formula $t+\log(X(t))^{2}$
\end_inset

, since the functions 
\begin_inset Formula $f(t,x)=x$
\end_inset

 and 
\begin_inset Formula $f(t,x)=t+\log x^{2}$
\end_inset

 satisfy the PDE.
 However, the process 
\begin_inset Formula $tX(t)$
\end_inset

 is not, as the function 
\begin_inset Formula $f(t,x)=xt$
\end_inset

 is not a solution of the PDE.
\end_layout

\begin_layout Example

\end_layout

\begin_layout Subsection
Multivariate Extension.
\end_layout

\begin_layout Standard
Ito's formula can be generalized to several Ito processes.
 Let's start by stating an example of a function of two Ito processes.
 Such a function 
\begin_inset Formula $f(x_{1},x_{2})$
\end_inset

 will be a function of two space variables.
 Not surprisingly, it needs to have two derivatives in each variable and
 they need to be a continuous function; we need 
\begin_inset Formula $f\in\mathcal{C}^{2\times2}(\mathbf{R}\times\mathbf{R})$
\end_inset

.
\end_layout

\begin_layout Theorem
(Ito's formula for many Ito processes) Let 
\begin_inset Formula $(X(t):t\geq0)$
\end_inset

 and 
\begin_inset Formula $(Y(t):t\geq0)$
\end_inset

 be two Ito processes of the form:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align}
dX(t) & =V(t)dB(t)+D(t)dt\nonumber \\
dY(t) & =U(t)dB(t)+R(t)dt\label{eq:two-ito-processes}
\end{align}

\end_inset


\end_layout

\begin_layout Theorem
where 
\begin_inset Formula $(B(t):t\geq0)$
\end_inset

 is a standard Brownian motion.
 Then, for 
\begin_inset Formula $f\in\mathcal{C}^{2\times2}(\mathbf{R}\times\mathbf{R})$
\end_inset

, we have:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
df(X(t),Y(t)) & =f_{x}(X(t),Y(t))dX(t)+f_{y}(X(t),Y(t))dY(t)+\frac{1}{2}f_{xx}(X(t),Y(t))d<X,X>_{t}\\
 & +f_{xy}(X(t),Y(t))d<X,Y>_{t}+\frac{1}{2}f_{yy}(X(t),Y(t))d<Y,Y>_{t}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The idea of the proof is the same as in theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "th:ito-formula-for-ito-processes"
plural "false"
caps "false"
noprefix "false"

\end_inset

 : Taylor's expansion and quadratic variation, together with the cross-variation
 of two processes.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
dX(t)\cdot dY(t) & =(V(t)dB(t)+D(t)dt)(U(t)dB(t)+R(t)dt)\\
 & =U(t)V(t)dt
\end{align*}

\end_inset


\end_layout

\begin_layout Example
(Product Rule) An important example of this formula is Ito's product rule.
 Let 
\begin_inset Formula $X(t)$
\end_inset

 and 
\begin_inset Formula $Y(t)$
\end_inset

 be as in equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:two-ito-processes"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Then:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
d(X(t)Y(t)) & =Y(t)dX(t)+X(t)dY(t)+dX(t)\cdot dY(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
Let 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 be a probability space and let 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

 be a standard brownian motion.
 Using integration by parts, show that 
\end_layout

\begin_layout Exercise
\begin_inset Formula 
\begin{align*}
\int_{0}^{t}B(s)ds & =\int_{0}^{t}(t-s)dB(s)
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
and prove that 
\begin_inset Formula $\int_{0}^{t}B(s)ds\sim\mathcal{N}(0,t^{3}/3)$
\end_inset

.
\end_layout

\begin_layout Exercise
Is 
\end_layout

\begin_layout Exercise
\begin_inset Formula 
\begin{align*}
X(t) & =\begin{cases}
0 & t=0\\
\frac{\sqrt{3}}{t}\int_{0}^{t}B(s)ds & t>0
\end{cases}
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
a standard Wiener process?
\end_layout

\begin_layout Exercise

\emph on
Solution.
\end_layout

\begin_layout Exercise
Using integration by parts:
\end_layout

\begin_layout Exercise
\begin_inset Formula 
\begin{align*}
\int u\left(\frac{dv}{ds}\right)ds & =uv-\int v\left(\frac{du}{ds}\right)ds
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
We set 
\begin_inset Formula $u=B(s)$
\end_inset

 and 
\begin_inset Formula $dv/ds=1$
\end_inset

.
 Then:
\end_layout

\begin_layout Exercise
\begin_inset Formula 
\begin{align*}
\int_{0}^{t}B(s)ds & =sB(s)|_{0}^{t}-\int_{0}^{t}sdB(s)\\
 & =tB(t)-\int_{0}^{t}sdB(s)\\
 & =\int_{s=0}^{s=t}tdB(s)-\int_{0}^{t}sdB(s)\\
 & =\int_{0}^{t}(t-s)dB(s)
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
Thus, 
\begin_inset Formula $\int_{0}^{t}B(s)ds$
\end_inset

 is a Gaussian random variable with:
\end_layout

\begin_layout Exercise
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[\int_{0}^{t}B(s)ds\right] & =\mathbb{E}\left[\int_{0}^{t}(t-s)dB(s)\right]\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
and 
\end_layout

\begin_layout Exercise
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[\left(\int_{0}^{t}B(s)ds\right)^{2}\right] & =\int_{0}^{t}(t-s)^{2}ds\\
 & =\left.\frac{(t-s)^{3}}{-3}\right|_{0}^{t}\\
 & =\frac{t^{3}}{3}
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
Thus, using the properties of Ito Integral, 
\begin_inset Formula $\int_{0}^{t}B(s)ds=\int_{0}^{t}(t-s)dB(s)$
\end_inset

 is a martingale.
 Now the quadratic variation 
\begin_inset Formula $<M,M>_{t}=0$
\end_inset

, and this can be a bit tricky.
 Remember, 
\begin_inset Formula $\left\langle \int_{0}^{t}f(s,B_{s})dB(s),\int_{0}^{t}f(s,B_{s})dB(s)\right\rangle =\int_{0}^{t}f^{2}(s,B_{s})ds$
\end_inset

 if and only if 
\begin_inset Formula $f$
\end_inset

 is a function of the time 
\begin_inset Formula $s$
\end_inset

 and the position of the Brownian motion 
\begin_inset Formula $B(s)$
\end_inset

.
 Since, 
\begin_inset Formula $f$
\end_inset

 is a function of 
\begin_inset Formula $t$
\end_inset

 as well, this rule cannot be applied.
 
\end_layout

\begin_layout Exercise
By first principles, we can show that, the quadratic variation is indeed
 
\begin_inset Formula $0$
\end_inset

:
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}\mathbb{E}\left[\sum_{j=0}^{n-1}\left(I(t_{j+1})-I(t_{j})\right)^{2}\right] & =\lim_{n\to\infty}\mathbb{E}\left[\sum_{j=0}^{n-1}B_{t_{j}}^{2}(t_{j+1}-t_{j})^{2}\right]\\
 & =\lim_{n\to\infty}\max_{1\leq j\leq n}|t_{j+1}-t_{j}|\cdot\mathbb{E}\left[\sum_{j=0}^{n-1}B_{t_{j}}^{2}(t_{j+1}-t_{j})\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
Since the paths of 
\begin_inset Formula $B_{t}$
\end_inset

 are continuous, so are the paths 
\begin_inset Formula $B_{t}^{2}$
\end_inset

 on the compact interval 
\begin_inset Formula $[0,t]$
\end_inset

.
 So, 
\begin_inset Formula $(B_{s}^{2},s\in[0,t])$
\end_inset

 is uniformly bounded.
 Thus, the expectation term is bounded.
 As 
\begin_inset Formula $n\to\infty$
\end_inset

, the mesh size approaches zero, and consequently the quadratic variation
 approaches zero.
 
\end_layout

\begin_layout Example
Let 
\begin_inset Formula $X_{t}=\int_{0}^{t}B_{s}dB_{s}$
\end_inset

 and 
\begin_inset Formula $Y_{t}=\int_{0}^{t}B_{s}^{2}dB_{s}$
\end_inset

.
 Is 
\begin_inset Formula $(X_{t}Y_{t},t\geq0)$
\end_inset

 a martingale?
\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
By Ito's product rule, we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
d(X_{t}Y_{t}) & =X_{t}dY_{t}+Y_{t}dX_{t}+dX_{t}\cdot dY_{t}\\
 & =X_{t}B_{s}^{2}dB_{s}+Y_{t}B_{s}dB_{s}+(B_{s}dB_{s})\cdot(B_{s}^{2}dB_{s})\\
 & =X_{t}B_{s}^{2}dB_{s}+Y_{t}B_{s}dB_{s}+B_{s}^{3}dt\\
X_{t}Y_{t} & =X_{0}Y_{0}+\int_{0}^{t}X_{t}B_{s}^{2}dB_{s}+\int_{0}^{t}Y_{t}B_{s}dB_{s}+\int_{0}^{t}B_{s}^{3}dt
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The term in 
\begin_inset Formula $dt$
\end_inset

 is not zero, so the product cannot be a martingale.
\end_layout

\begin_layout Example
(A generalization of Geometric Brownian Motion).
 Consider 
\begin_inset Formula $(\int_{0}^{t}V_{s}dB_{s},t\geq0)$
\end_inset

 an Ito process.
 Define the positive process:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align}
M_{t} & =\exp\left(\int_{0}^{t}V_{s}dB_{s}-\frac{1}{2}\int_{0}^{t}V_{s}^{2}ds\right),\quad t\geq0
\end{align}

\end_inset


\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
Ito's formula applied to the processes 
\begin_inset Formula $X_{t}=\int_{0}^{t}V_{s}dB_{s}$
\end_inset

 and 
\begin_inset Formula $Y_{t}=\frac{1}{2}\int_{0}^{t}V_{s}^{2}ds$
\end_inset

 with the function 
\begin_inset Formula $f(x,y)=e^{x-y}$
\end_inset

 yields:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
df(x,y) & =f_{x}(X_{t},Y_{t})dX_{t}+f_{y}(X_{t},Y_{t})dY_{t}\\
 & +\frac{1}{2}f_{xx}(X_{t},Y_{t})dX_{t}\cdot dX_{t}+\frac{1}{2}f_{yy}(X_{t},Y_{t})dY_{t}\cdot dY_{t}\\
 & +f_{xy}(X_{t},Y_{t})dX_{t}\cdot dY_{t}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Now, all first and second order derivatives are 
\begin_inset Formula $\partial_{x}(e^{x-y})=M_{t}$
\end_inset

, 
\begin_inset Formula $\partial_{y}(e^{x-y})=-e^{x-y}=-M_{t}$
\end_inset

.
 
\begin_inset Formula $dX_{t}=V_{t}dB_{t}$
\end_inset

.
 
\begin_inset Formula $dY_{t}=\frac{1}{2}V_{t}^{2}dt$
\end_inset

.
 
\begin_inset Formula $dX_{t}\cdot dX_{t}=V_{t}^{2}dt$
\end_inset

, 
\begin_inset Formula $dX_{t}\cdot dY_{t}=0$
\end_inset

, 
\begin_inset Formula $dY_{t}\cdot dY_{t}=0$
\end_inset

.
 Consequently, we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
dM_{t} & =M_{t}V_{t}dB_{t}-\frac{1}{2}M_{t}V_{t}^{2}dt\\
 & +\frac{1}{2}M_{t}V_{t}^{2}dt\\
 & =M_{t}V_{t}dB_{t}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Thus, 
\begin_inset Formula $(M_{t},t\geq0)$
\end_inset

 is a martingale.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Exercise
(Generalized Ito Integral).
 Let 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 be a probability space and let 
\begin_inset Formula $(B_{t}:t\geq0)$
\end_inset

 be a standard brownian motion.
 Given that 
\begin_inset Formula $f$
\end_inset

 is a simple process, show that:
\end_layout

\begin_layout Exercise
\begin_inset Formula 
\begin{align*}
\int_{0}^{t}f(s,B_{s})dB_{s} & =B_{t}f(t,B_{t})-\int_{0}^{t}\left[B_{s}\frac{\partial f}{\partial t}+\frac{\partial f}{\partial x}+\frac{1}{2}B_{s}\frac{\partial^{2}f}{\partial x^{2}}\right]ds\\
 & -\int_{0}^{t}B_{s}\frac{\partial f}{\partial x}dB_{s}
\end{align*}

\end_inset


\end_layout

\begin_layout Exercise
and 
\end_layout

\begin_layout Exercise
\begin_inset Formula 
\begin{align*}
\int_{0}^{t}f(s,B_{s})ds & =tf(t,B_{t})-\int_{0}^{t}s\left[\frac{\partial f}{\partial t}+\frac{1}{2}\frac{\partial^{2}f}{\partial x^{2}}\right]ds-\int_{0}^{t}s\frac{\partial f}{\partial x}dB_{s}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard

\emph on
Solution.
\end_layout

\begin_layout Standard
I suppress 
\begin_inset Formula $(t,B_{t})$
\end_inset

 for simplicity.
 Applying the product rule to 
\begin_inset Formula $B_{t}f$
\end_inset

, we get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
d(B_{t}f) & =fdB_{t}+B_{t}df+dB_{t}\cdot df\\
 & =fdB_{t}+B_{t}\left(\frac{\partial f}{\partial t}dt+\frac{\partial f}{\partial x}dB_{t}+\frac{1}{2}\frac{\partial^{2}f}{\partial x^{2}}(dB_{t})^{2}\right)\\
 & +dB_{t}\cdot\left(\frac{\partial f}{\partial t}dt+\frac{\partial f}{\partial x}dB_{t}+\frac{1}{2}\frac{\partial^{2}f}{\partial x^{2}}(dB_{t})^{2}\right)\\
 & =fdB_{t}+\left(B_{t}\frac{\partial f}{\partial t}+\frac{\partial f}{\partial x}+\frac{1}{2}B_{t}\right)dt+B_{t}\frac{\partial f}{\partial x}dB_{t}\\
B_{t}f & =\int_{0}^{t}fdB_{s}+\int_{0}^{t}\left(B_{s}\frac{\partial f}{\partial t}+\frac{\partial f}{\partial x}+\frac{1}{2}\frac{\partial^{2}f}{\partial x^{2}}B_{s}\right)ds+\int_{0}^{t}B_{s}\frac{\partial f}{\partial x}dB_{s}\\
\int_{0}^{t}fdB_{s} & =B_{t}f-\int_{0}^{t}\left(B_{s}\frac{\partial f}{\partial t}+\frac{\partial f}{\partial x}+\frac{1}{2}\frac{\partial^{2}f}{\partial x^{2}}B_{s}\right)ds-\int_{0}^{t}B_{s}\frac{\partial f}{\partial x}dB_{s}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Applying product rule to 
\begin_inset Formula $tf(t,B_{t})$
\end_inset

, we get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
d(tf) & =fdt+tdf+dt\cdot df\\
 & =fdt+t\left(\frac{\partial f}{\partial t}dt+\frac{\partial f}{\partial x}dB_{t}+\frac{1}{2}\frac{\partial^{2}f}{\partial x^{2}}(dB_{t})^{2}\right)\\
 & +dt\left(\frac{\partial f}{\partial t}dt+\frac{\partial f}{\partial x}dB_{t}+\frac{1}{2}\frac{\partial^{2}f}{\partial x^{2}}(dB_{t})^{2}\right)\\
 & =fdt+t\left(\frac{\partial f}{\partial t}+\frac{1}{2}\frac{\partial^{2}f}{\partial x^{2}}\right)dt+t\frac{\partial f}{\partial x}dB_{t}\\
tf & =\int_{0}^{t}fds+\int_{0}^{t}s\left(\frac{\partial f}{\partial t}+\frac{1}{2}\frac{\partial^{2}f}{\partial x^{2}}\right)ds+\int_{0}^{t}s\frac{\partial f}{\partial x}dB_{s}\\
\int_{0}^{t}fds & =tf-\int_{0}^{t}s\left(\frac{\partial f}{\partial t}+\frac{1}{2}\frac{\partial^{2}f}{\partial x^{2}}\right)ds-\int_{0}^{t}s\frac{\partial f}{\partial x}dB_{s}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The following example will be important when we discuss the Girsanov theorem.
 
\end_layout

\begin_layout Subsection
Numerical Simulation of SDEs.
\end_layout

\begin_layout Standard
It is not too hard to implement iterative schemes to sample paths of a diffusion.
 Consider 
\begin_inset Formula $(X_{t}:t\leq T)$
\end_inset

 a solution to the SDE:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
dX_{t} & =\sigma(X_{t})dB_{t}+\mu(X_{t})dt,\quad X_{0}=x
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Existence and Uniqueness of solutions to SDEs.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "th:existence-and-uniqueness-of-solutions-to-sde"

\end_inset

(Existence and uniqueness of solutions to SDEs).
 Consider the SDE 
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
dX_{t} & =\mu(X_{t})dt+\sigma(X_{t})dB_{t},\quad X_{0}=x,\quad t\in[0,T]
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
If the functions 
\begin_inset Formula $\sigma$
\end_inset

 and 
\begin_inset Formula $\mu$
\end_inset

 grow not faster than 
\begin_inset Formula $Kx^{2}$
\end_inset

 for some 
\begin_inset Formula $K>0$
\end_inset

 and are differentiable with bounded derivatives on 
\begin_inset Formula $\mathbf{R}$
\end_inset

, then there exists a unique solution 
\begin_inset Formula $(X_{t}:t\in[0,T])$
\end_inset

 to the SDE.
 In other words, there exists a continuous process 
\begin_inset Formula $(X_{t},t\leq T)$
\end_inset

 adapted to the filtration of the brownian motion:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
X_{t} & =x+\int_{0}^{t}\mu(X_{s})ds+\int_{0}^{t}\sigma(X_{s})dB_{s},\quad t\leq T
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Consider the SDE:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
dX_{t} & =\sqrt{1+X_{t}^{2}}dB_{t}+\sin X_{t}dt,\quad X_{0}=0
\end{align*}

\end_inset


\end_layout

\begin_layout Example
There exists a unique diffusion process 
\begin_inset Formula $(X_{t}:t\geq0)$
\end_inset

 that is a solution of this SDE.
 To see this, we verify the conditions of theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:existence-and-uniqueness-of-solutions-to-sde"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 We have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\mu(x) & =\sin x\\
\sigma(x) & =\sqrt{1+x^{2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
Clearly, these functions satisfy the growth condition since 
\begin_inset Formula $\mu$
\end_inset

 is bounded and 
\begin_inset Formula $\sigma$
\end_inset

 grows like 
\begin_inset Formula $|x|$
\end_inset

 for 
\begin_inset Formula $x$
\end_inset

 large.
 As for the derivatives, we have 
\begin_inset Formula $\sigma'(x)=\frac{1}{2\sqrt{1+x^{2}}}$
\end_inset

 and 
\begin_inset Formula $\mu'(x)=\cos x$
\end_inset

.
 These two derivatives 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
Martingale Representation and Levy's characterization
\end_layout

\begin_layout Standard
We know, very well, by now that an Ito integral is a continuous martingale
 with respect to the Brownian fitration, whenever the integrand is in 
\begin_inset Formula $\mathcal{L}_{c}^{2}(T)$
\end_inset

.
 What can we say about the converse? In other words, if we have a martingale
 with respect to some Brownian filtration, can it be expressed as an Ito-integra
l for some integrand 
\begin_inset Formula $(V(t):t\in[0,T])$
\end_inset

.
 Amazingly the answer to this question is yes.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "th:martingale-representation-thm"

\end_inset

(Martingale Representation Theorem).
 Let 
\begin_inset Formula $(B(t):t\in[0,T])$
\end_inset

 be a Brownian motion with filtration 
\begin_inset Formula $(\mathcal{F}_{t}:t\geq0)$
\end_inset

 on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Consider a martingale 
\begin_inset Formula $(M(t):t\in[0,T])$
\end_inset

 with respect to this filtration.
 Then, there exists an adapted process 
\begin_inset Formula $(V_{t}:t\leq T)$
\end_inset

 such that:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align}
M_{t} & =M_{0}+\int_{0}^{t}V_{s}dB_{s},\quad t\leq T\label{eq:martingale-representation-theorem}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
One striking fact of this result is that 
\begin_inset Formula $(M_{t}:t\leq T)$
\end_inset

 ought to be continuous.
 In other words, we cannot construct a process with a jump that is a martingale
 adapted to a Brownian motion!
\end_layout

\begin_layout Standard
Instead of proving the theorem, we will see how the result is not too surprising
 with stronger assumptions.
 Instead of supposing that 
\begin_inset Formula $M_{t}$
\end_inset

 is 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

-measurable, take that 
\begin_inset Formula $M_{t}$
\end_inset

 is 
\begin_inset Formula $\sigma(B_{t})$
\end_inset

-measurable.
 In other words, 
\begin_inset Formula $M_{t}=h(B_{t})$
\end_inset

 for some function 
\begin_inset Formula $h$
\end_inset

.
 In the case that 
\begin_inset Formula $h$
\end_inset

 is smooth, then it is clear by the Ito's formula that the representation
 in equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:martingale-representation-theorem"
plural "false"
caps "false"
noprefix "false"

\end_inset

 holds and 
\begin_inset Formula $V_{s}=h'(B_{t})$
\end_inset

.
\end_layout

\begin_layout Standard
The relevance to hedging of this is that the only source of uncertainty
 in the model is the Brownian motion appearing in theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:martingale-representation-thm"
plural "false"
caps "false"
noprefix "false"

\end_inset

, and hence there is only one source of uncertainty to be removed by hedging.
 This assumption implies that the martingale cannot have jumps because Ito
 integrals are continuous.
 If we want to have a martingale with jumps, we will need to build a model
 that includes sources of uncertainty different from or in addition to Brownian
 motion.
 
\end_layout

\begin_layout Section
Change of Probability.
\end_layout

\begin_layout Subsection
Change of Probability for a Random Variable.
\end_layout

\begin_layout Standard
Consider a random variable 
\begin_inset Formula $X$
\end_inset

 defined on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 with 
\begin_inset Formula $\mathbb{E}[X]=0$
\end_inset

.
 We would like to change the mean of 
\begin_inset Formula $X$
\end_inset

 so that 
\begin_inset Formula $\mu\neq0$
\end_inset

.
 Of course, it is easy to change the mean of a random variable: If 
\begin_inset Formula $X$
\end_inset

 has mean 
\begin_inset Formula $0$
\end_inset

, then the random variable 
\begin_inset Formula $X+\mu$
\end_inset

 has mean 
\begin_inset Formula $\mu$
\end_inset

.
 However, it might be that the variable 
\begin_inset Formula $X+\mu$
\end_inset

 does not share the same possible values as 
\begin_inset Formula $X$
\end_inset

.
 For example, take 
\begin_inset Formula $X$
\end_inset

 to be a uniform random variable on 
\begin_inset Formula $[-1,1]$
\end_inset

.
 While 
\begin_inset Formula $X+1$
\end_inset

 has mean 
\begin_inset Formula $1$
\end_inset

, the density of 
\begin_inset Formula $X+1$
\end_inset

 would be non-zero on 
\begin_inset Formula $[0,2]$
\end_inset

 instead of 
\begin_inset Formula $[-1,1]$
\end_inset

.
\end_layout

\begin_layout Standard
Our goal is to find a good way to change the underlying probability 
\begin_inset Formula $\mathbb{P}$
\end_inset

, and thus the distribution of 
\begin_inset Formula $X$
\end_inset

, so that the set of outcomes is unchanged.
 If 
\begin_inset Formula $X$
\end_inset

 is a discrete random variable, say with 
\begin_inset Formula $\mathbb{P}(X=-1)=\mathbb{P}(X=1)=1/2$
\end_inset

, we can change the probability in order to change the mean easily.
 It suffices to take 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

 so that 
\begin_inset Formula $\tilde{\mathbb{P}}(X=1)=p$
\end_inset

 and 
\begin_inset Formula $\mathbb{P}(X=-1)=1-p$
\end_inset

 for some appropriate 
\begin_inset Formula $0\leq p\leq1$
\end_inset

.
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $X$
\end_inset

 is a continuous random variable, with a PDF 
\begin_inset Formula $f_{X}$
\end_inset

, the probabilities can be changed by modifying the PDF.
 Consider the a new PDF:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\tilde{f}_{X}(x) & =f_{X}(x)g(x)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
for some function 
\begin_inset Formula $g(x)>0$
\end_inset

 such that 
\begin_inset Formula $\int f(x)g(x)dx=1$
\end_inset

.
 Clearly, 
\begin_inset Formula $f_{X}(x)g(x)$
\end_inset

 is also a PDF and 
\begin_inset Formula $f_{X}(x)>0$
\end_inset

 if and only if 
\begin_inset Formula $f_{X}(x)g(x)>0$
\end_inset

, so that the possible values of 
\begin_inset Formula $X$
\end_inset

 are unchanged.
 A convenient (and important!) choice of function 
\begin_inset Formula $g$
\end_inset

 is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
g(x) & =\frac{e^{ax}}{\int_{\mathbf{R}}e^{ax}f_{X}(x)dx}=\frac{e^{ax}}{\mathbb{E}[e^{aX}]},\quad a\in\mathbf{R}\label{eq:change-of-probability-of-an-rv}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
assuming 
\begin_inset Formula $X$
\end_inset

 has a well-defined MGF.
 Here 
\begin_inset Formula $a$
\end_inset

 is a parameter that can be tuned to fit to a specific mean.
 The normalization factor in the denominator is the MGF of 
\begin_inset Formula $X$
\end_inset

.
 It ensures that 
\begin_inset Formula $f_{X}(x)g(x)$
\end_inset

 is a PDF.
 Note that if 
\begin_inset Formula $a>0$
\end_inset

, the function 
\begin_inset Formula $g$
\end_inset

 gives a bigger weight to large values of 
\begin_inset Formula $X$
\end_inset

.
 We say that 
\begin_inset Formula $g$
\end_inset

 is biased towards the large values.
\end_layout

\begin_layout Example
(Biasing a uniform random variable).
 Let 
\begin_inset Formula $X$
\end_inset

 be a uniform random variable on 
\begin_inset Formula $[0,1]$
\end_inset

 defined on
\begin_inset space ~
\end_inset


\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Clearly, 
\begin_inset Formula $\mathbb{E}[X]=1/2$
\end_inset

.
 How can we change the PDF of 
\begin_inset Formula $X$
\end_inset

 so that the possible values are still 
\begin_inset Formula $[0,1]$
\end_inset

, but the mean is 
\begin_inset Formula $1/4$
\end_inset

.
 We have that the PDF is 
\begin_inset Formula $f_{X}(x)=1$
\end_inset

 if 
\begin_inset Formula $x\in[0,1]$
\end_inset

 and 
\begin_inset Formula $0$
\end_inset

 elsewhere.
 Therefore, the mean with the new PDF with parameter 
\begin_inset Formula $a$
\end_inset

 as in the equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:change-of-probability-of-an-rv"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\tilde{\mathbb{E}}[X] & =\int_{0}^{1}x\tilde{f}(x)dx\\
 & =\int_{0}^{1}\frac{xe^{ax}}{\mathbb{E}[e^{aX}]}dx\\
 & =\frac{a}{e^{a}-1}\int_{0}^{1}xe^{ax}dx\\
 & =\frac{a}{e^{a}-1}\left(\left[x\frac{e^{ax}}{a}\right]_{0}^{1}-\frac{1}{a}\int_{0}^{1}e^{ax}dx\right)\\
 & =\frac{a}{e^{a}-1}\left(\frac{e^{a}}{a}-\frac{1}{a}\frac{e^{a}-1}{a}\right)\\
 & =\frac{e^{a}}{e^{a}-1}-\frac{1}{a}
\end{align*}

\end_inset


\end_layout

\begin_layout Example
For 
\begin_inset Formula $\tilde{\mathbb{E}[X]}$
\end_inset

to be equal to 
\begin_inset Formula $1/4$
\end_inset

, we get numerically 
\begin_inset Formula $a\approx-3.6$
\end_inset

.
 Note that the possible values of 
\begin_inset Formula $X$
\end_inset

 remain the same under the new probability.
 However, the new distribution is no longer uniform! It has bias towards
 values closer to zero, as it should.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "ex:biasing-a-gaussian-random-variable"

\end_inset

(Biasing a Gaussian random variable).
 Let 
\begin_inset Formula $X$
\end_inset

 be a Gaussian random variable with mean 
\begin_inset Formula $\mu$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
 How can we change the PDF of 
\begin_inset Formula $X$
\end_inset

 to have mean 
\begin_inset Formula $0$
\end_inset

? Going back to 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:change-of-probability-of-an-rv"
plural "false"
caps "false"
noprefix "false"

\end_inset

, the mean 
\begin_inset Formula $\mu$
\end_inset

 under the new PDF with parameter 
\begin_inset Formula $a$
\end_inset

 is:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\tilde{\mathbb{E}}[X] & =\int_{-\infty}^{\infty}x\tilde{f}(x)dx\\
 & =\int_{-\infty}^{\infty}xg(x)f(x)dx\\
 & =\int_{-\infty}^{\infty}x\cdot\frac{e^{ax}}{\mathbb{E}[e^{aX}]}\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^{2}}dx\\
 & =\frac{1}{e^{\mu a+\frac{1}{2}a^{2}\sigma^{2}}}\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{\infty}x\cdot\exp\left[-\frac{1}{2}\left(\frac{x^{2}-2\mu x+\mu^{2}-2a\sigma^{2}x}{\sigma^{2}}\right)\right]dx\\
 & =\frac{1}{e^{\mu a+\frac{1}{2}a^{2}\sigma^{2}}}\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{\infty}x\cdot\exp\left[-\frac{1}{2}\left(\frac{x^{2}-2(\mu+a\sigma^{2})x+(\mu+a\sigma^{2})^{2}-2\mu a\sigma^{2}-a^{2}\sigma^{4}}{\sigma^{2}}\right)\right]dx\\
 & =\frac{e^{\mu a+a^{2}\sigma^{2}/2}}{e^{\mu a+\frac{1}{2}a^{2}\sigma^{2}}}\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{\infty}x\exp\left[-\frac{1}{2}\left(\frac{x-(\mu+a\sigma^{2})}{\sigma}\right)^{2}\right]dx\\
 & =\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{\infty}x\exp\left[-\frac{1}{2}\left(\frac{x-(\mu+a\sigma^{2})}{\sigma}\right)^{2}\right]dx
\end{align*}

\end_inset


\end_layout

\begin_layout Example
For the specific choice of the parameter 
\begin_inset Formula $a=\mu/\sigma^{2}$
\end_inset

, we recover the PDF of a Gaussian random variable with mean 
\begin_inset Formula $0$
\end_inset

.
 But, we can deduce more.
 The new PDF is also Gaussian.
 This was not the case for uniform random variables.
 In fact, the new PDF is exactly the same as the one of 
\begin_inset Formula $X-\mu$
\end_inset

.
 For if, 
\begin_inset Formula $a=\mu/\sigma^{2}$
\end_inset

, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\tilde{\mathbb{E}}[X] & =\frac{1}{\sqrt{2\pi}\sigma}\int_{-\infty}^{\infty}x\exp\left[-\frac{x^{2}}{2\sigma^{2}}\right]dx
\end{align*}

\end_inset


\end_layout

\begin_layout Example
and observe that if 
\begin_inset Formula $Y=X-\mu$
\end_inset

, then:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
F_{Y}(x) & =\mathbb{P}(X-\mu<x)\\
 & =\mathbb{P}(X\leq x+\mu)\\
 & =F_{X}(x+\mu)\\
\frac{d}{dx}(F_{Y}(x)) & =\frac{d}{dx}(F_{X}(x+\mu))\\
f_{Y}(x) & =f_{X}(x+\mu)\cdot\frac{d}{dx}(x+\mu)\\
f_{Y}(x) & =f_{X}(x+\mu)\\
 & =\frac{1}{\sqrt{2\pi}\sigma}\exp\left[-\frac{1}{2}\left(\frac{x+\mu-\mu}{\sigma}\right)^{2}\right]\\
 & =\frac{1}{\sqrt{2\pi}\sigma}\exp\left[-\frac{x^{2}}{2\sigma^{2}}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In other words: 
\end_layout

\begin_layout Example

\emph on
For Gaussians, changing the mean by recentering is equivalent to changing
 the probability as in 
\emph default

\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:change-of-probability-of-an-rv"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Example
This is a very special property of the Gaussian distribution.
 The exponential and Poisson distributions have a similar property.
\end_layout

\begin_layout Example
Example 
\begin_inset CommandInset ref
LatexCommand eqref
reference "ex:biasing-a-gaussian-random-variable"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is very important and we will state it as a theorem.
 Before doing so, we notice that the change of PDF 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:change-of-probability-of-an-rv"
plural "false"
caps "false"
noprefix "false"

\end_inset

 can be expressed more generally by changing the underlying probability
 measure(length, area, weights) 
\begin_inset Formula $\mathbb{P}$
\end_inset

 on the sample space 
\begin_inset Formula $\Omega$
\end_inset

 on which the random variables are defined.
 More precisely, let 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 be a probability space, and let 
\begin_inset Formula $X$
\end_inset

 be a random variable defined on 
\begin_inset Formula $\Omega$
\end_inset

.
 We define a new probability 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

 on 
\begin_inset Formula $\Omega$
\end_inset

 as follows:
\end_layout

\begin_layout Example
If 
\begin_inset Formula $\mathcal{E}$
\end_inset

 is an event in 
\begin_inset Formula $\mathcal{F}$
\end_inset

, then:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align}
\mathbb{\tilde{P}}(\mathcal{E}) & =\mathbb{\tilde{E}}[1_{\mathcal{E}}]=\int_{\mathbf{R}}1_{\mathcal{E}}\cdot\tilde{f}(x)dx\nonumber \\
 & =\int_{\mathbf{R}}1_{\mathcal{E}}\cdot g(x)f_{X}(x)dx\nonumber \\
 & =\int_{\mathbf{R}}1_{\mathcal{E}}\cdot\frac{e^{ax}}{\mathbb{E}[e^{aX}]}f_{X}(x)dx\nonumber \\
 & =\mathbb{E}\left[1_{\mathcal{E}}\frac{e^{aX}}{\mathbb{E}[e^{aX}]}\right]
\end{align}

\end_inset


\end_layout

\begin_layout Example
Intuitively, we are changing the probability of each outcome 
\begin_inset Formula $\omega\in\mathcal{E}$
\end_inset

, by the factor 
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{equation}
\frac{e^{aX(\omega)}}{\mathbb{E}[e^{aX}]}\label{eq:girsanov-probability-scaling}
\end{equation}

\end_inset


\end_layout

\begin_layout Example
In other words, if 
\begin_inset Formula $a>0$
\end_inset

, the outcomes 
\begin_inset Formula $\omega$
\end_inset

 for which 
\begin_inset Formula $X$
\end_inset

 has large values are favored.
 Note that equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:change-of-probability-of-an-rv"
plural "false"
caps "false"
noprefix "false"

\end_inset

 for the PDF is recovered, since for any function 
\begin_inset Formula $h$
\end_inset

 of 
\begin_inset Formula $X$
\end_inset

, we have:
\end_layout

\begin_layout Example
\begin_inset Formula 
\begin{align*}
\tilde{\mathbb{E}}[h(X)] & =\mathbb{E}\left[\frac{e^{aX}}{\mathbb{E}[e^{aX}]}h(X)\right]\\
 & =\int_{\mathbf{R}}h(x)\frac{e^{ax}}{\mathbb{E}[e^{aX}]}f_{X}(x)dx
\end{align*}

\end_inset


\end_layout

\begin_layout Example
In this setting, the above example becomes the preliminary version of the
 Cameron-Martin-Girsanov theorem:
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "th:change-of-probability-for-a-random-variable"

\end_inset

Let 
\begin_inset Formula $X$
\end_inset

 be a Gaussian random variable with mean 
\begin_inset Formula $\mu$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

 defined on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Then, under the probability 
\begin_inset Formula $\mathbb{\tilde{P}}$
\end_inset

 given by:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align}
\mathbb{\tilde{P}}(\mathcal{E}) & =\mathbb{E}\left[1_{\mathcal{E}}e^{-\frac{\mu}{\sigma^{2}}X+\frac{1}{2}\frac{\mu^{2}}{\sigma^{2}}}\right],\quad\mathcal{E}\in\mathcal{F}\label{eq:preliminary-version-girsanov-theorem}
\end{align}

\end_inset


\end_layout

\begin_layout Theorem
the random variable 
\begin_inset Formula $X$
\end_inset

 is Gaussian with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
\end_layout

\begin_layout Theorem
Moreover, since 
\begin_inset Formula $X$
\end_inset

 can be written as 
\begin_inset Formula $X=Y+\mu$
\end_inset

 where 
\begin_inset Formula $Y$
\end_inset

 is Gaussian with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

 under 
\begin_inset Formula $\mathbb{P}$
\end_inset

, we have that 
\begin_inset Formula $\mathbb{\tilde{P}}$
\end_inset

 can be written as:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align}
\mathbb{\tilde{P}}(\mathcal{E}) & =\mathbb{E}\left[1_{\mathcal{E}}e^{-\frac{\mu}{\sigma^{2}}Y-\frac{1}{2}\frac{\mu^{2}}{\sigma^{2}}}\right],\quad\mathcal{E}\in\mathcal{F}\label{eq:preliminary-version-girsanov-theorem-II}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
It is good to pause for a second and look at the signs in the exponential
 of equations 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:preliminary-version-girsanov-theorem"
plural "false"
caps "false"
noprefix "false"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:preliminary-version-girsanov-theorem-II"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The signs in the exponential might be very confusing and is the source
 of many mistakes in the Cameron-Martin-Girsanov theorem.
 A good trick is to say that, if we want to remove 
\begin_inset Formula $\mu$
\end_inset

, then the sign in front of 
\begin_inset Formula $X$
\end_inset

 or 
\begin_inset Formula $Y$
\end_inset

 must be negative.
 Then, we add the exponential factor needed for 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

 to be a probability.
 This is given by the MGF of 
\begin_inset Formula $X$
\end_inset

 or 
\begin_inset Formula $Y$
\end_inset

 depending on how we want to express it.
\end_layout

\begin_layout Standard
The probabilities 
\begin_inset Formula $\mathbb{P}$
\end_inset

 and 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

, as defined in the equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:preliminary-version-girsanov-theorem"
plural "false"
caps "false"
noprefix "false"

\end_inset

 are obviously not equal since they differ by a factor in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:girsanov-probability-scaling"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 However, they share some similarities.
 Most notably, if 
\begin_inset Formula $\mathcal{E}$
\end_inset

 is an event of positive 
\begin_inset Formula $\mathbb{P}$
\end_inset

-probability, 
\begin_inset Formula $\mathbb{P}(\mathcal{E})>0$
\end_inset

, then we must have 
\begin_inset Formula $\tilde{\mathbb{P}}(\mathcal{E})>0$
\end_inset

, since the factor in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:girsanov-probability-scaling"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is always strictly positive.
 The converse is also true: if 
\begin_inset Formula $\mathcal{E}$
\end_inset

 is an event of positive 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

-probability, 
\begin_inset Formula $\tilde{\mathbb{P}}(\mathcal{E})>0$
\end_inset

, then we must have that 
\begin_inset Formula $\mathbb{P}(\mathcal{E})>0$
\end_inset

.
 This is because the factor in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:girsanov-probability-scaling"
plural "false"
caps "false"
noprefix "false"

\end_inset

 can be inverted, being strictly positive.
 More precisely, we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{P}(\mathcal{E}) & =\mathbb{E}[1_{\mathcal{E}}]\\
 & =\mathbb{E}\left[1_{\mathcal{E}}\frac{e^{aX(\omega)}}{\mathbb{E}[e^{aX}]}\left(\frac{e^{aX(\omega)}}{\mathbb{E}[e^{aX}]}\right)^{-1}\right]\\
 & =\tilde{\mathbb{E}}\left[1_{\mathcal{E}}\left(\frac{e^{aX(\omega)}}{\mathbb{E}[e^{aX}]}\right)^{-1}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The factor 
\begin_inset Formula $\left(\frac{e^{aX(\omega)}}{\mathbb{E}[e^{aX}]}\right)^{-1}$
\end_inset

 is also strictly positive, proving the claim.
 To sum it all up, the probabilities 
\begin_inset Formula $\mathbb{P}$
\end_inset

 and 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

 essentially share the same possible outcomes.
 Such probability measures are said to be equivalent measures.
\end_layout

\begin_layout Definition
Consider the two probabilities 
\begin_inset Formula $\mathbb{P}$
\end_inset

 and 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

 on 
\begin_inset Formula $(\Omega,\mathcal{F})$
\end_inset

.
 They are said to be equivalent, if for any event 
\begin_inset Formula $\mathcal{E}\in\mathcal{F}$
\end_inset

, we have 
\begin_inset Formula $\mathbb{P}(\mathcal{E})>0$
\end_inset

 if and only if 
\begin_inset Formula $\mathbb{P}(\mathcal{E})>0$
\end_inset

.
 Thus, 
\begin_inset Formula $\mathbb{P}$
\end_inset

 and 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

 agree on the null sets.
 If 
\begin_inset Formula $A\in\mathcal{F}$
\end_inset

 is such that 
\begin_inset Formula $\mathbb{P}(A)=0$
\end_inset

, then 
\begin_inset Formula $\mathbb{\tilde{P}}(A)=0$
\end_inset

 and vice-versa.
\end_layout

\begin_layout Standard
Keep in mind that two probabilities that are equivalent might still be very
 far from being equal!
\end_layout

\begin_layout Subsection
The Cameron-Martin Theorem.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "th:girsanov-theorem-for-constant-drift-case"

\end_inset

(Cameron-Martin Theorem for constant drift).
 Let 
\begin_inset Formula $(\tilde{B(t)},t\in[0,T])$
\end_inset

 be a 
\begin_inset Formula $\mathbb{P}-$
\end_inset

Brownian motion with constant drift 
\begin_inset Formula $\theta$
\end_inset

 defined on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Consider the probability 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

on 
\begin_inset Formula $\Omega$
\end_inset

 given by:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align}
\tilde{\mathbb{P}}(\mathcal{E}) & =\mathbb{E}\left[e^{-\theta\tilde{B}(T)+\frac{\theta^{2}}{2}T}1_{\mathcal{E}}\right],\quad\mathcal{E}\in\mathcal{F}\label{eq:girsanov-theorem-constant-drift-case}
\end{align}

\end_inset


\end_layout

\begin_layout Theorem
Then, the process 
\begin_inset Formula $(\tilde{B}(t),t\in[0,T])$
\end_inset

 under 
\begin_inset Formula $\mathbb{\tilde{P}}$
\end_inset

is distributed like a standard brownian motion.
 Moreover, since we can write 
\begin_inset Formula $\tilde{B_{t}}=\theta t+B_{t}$
\end_inset

 for some standard brownian motion 
\begin_inset Formula $(B_{t},t\in[0,T])$
\end_inset

 on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

, the probability 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

 can also be written as:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align}
\tilde{\mathbb{P}}(\mathcal{E}) & =\mathbb{E}\left[e^{-\theta B(T)-\frac{\theta^{2}}{2}T}1_{\mathcal{E}}\right]\label{eq:girsanov-theorem-constant-drift-case-II}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
It is a good idea to pause again and look at the signs in the exponential
 in equations 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:girsanov-theorem-constant-drift-case"
plural "false"
caps "false"
noprefix "false"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:girsanov-theorem-constant-drift-case-II"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 They behave the same way as in theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:change-of-probability-for-a-random-variable"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 There is a minus sign in front of 
\begin_inset Formula $B_{T}$
\end_inset

 to remove the drift.
 Before proving the theorem, we make some important remarks.
 
\end_layout

\begin_layout Standard
(1) 
\series bold
The end-point
\series default
.
 Note that only the endpoint 
\begin_inset Formula $\tilde{B}(T)$
\end_inset

 of the Brownian motion is involved in the change of probability.
 In particular, 
\begin_inset Formula $T$
\end_inset

 cannot be 
\begin_inset Formula $+\infty$
\end_inset

.
 The Cameron-Martin theorem can only be applied on a finite interval.
 
\end_layout

\begin_layout Standard
(2) 
\series bold
A martingale.
 
\series default
The factor 
\begin_inset Formula $M_{T}=e^{-\theta B(T)-\frac{\theta^{2}}{2}T}=e^{-\theta\tilde{B}(T)+\frac{1}{2}\theta^{2}T}$
\end_inset

 involved in the change of probability is the end-point of a 
\begin_inset Formula $\mathbb{P}-$
\end_inset

martingale, that is, it is a martingale under the original probability 
\begin_inset Formula $\mathbb{P}$
\end_inset

.
 To see this:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}[M_{T}|\mathcal{F}_{t}] & =\mathbb{E}\left[e^{-\theta B(T)-\frac{1}{2}\theta^{2}T}|\mathcal{F}_{t}\right]\\
 & =e^{-\theta B(t)}\mathbb{E}\left[e^{-\theta(B(T)-B(t))}|\mathcal{F}_{t}\right]e^{-\frac{\theta^{2}}{2}T}\\
 & \{\text{Using }B(T)-B(t)\perp\mathcal{F}_{t}\}\\
 & =e^{-\theta B(t)}\mathbb{E}\left[e^{-\theta(B(T)-B(t))}\right]e^{-\frac{\theta^{2}}{2}T}\\
 & =e^{-\theta B(t)}e^{\frac{\theta^{2}}{2}(T-t)}e^{-\frac{\theta^{2}}{2}T}\\
 & =e^{-\theta B(t)-\frac{\theta^{2}}{2}t}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In fact, since 
\begin_inset Formula $B(t)$
\end_inset

 is a 
\begin_inset Formula $\mathbb{P}$
\end_inset

-standard Brownian motion, 
\begin_inset Formula $M(t)=e^{-\theta B(t)-\frac{\theta^{2}}{2}t}$
\end_inset

 is a geometric brownian motion.
 
\end_layout

\begin_layout Standard
Interestingly, the drift of 
\begin_inset Formula $\tilde{B}(t)$
\end_inset

 becomes the volatility factor in 
\begin_inset Formula $M_{T}$
\end_inset

! 
\begin_inset Formula $\mathbb{E}[M_{T}^{2}]=\mathbb{E}[e^{-2\theta B(T)-\theta^{2}T}]=e^{-\theta^{2}T}\cdot\mathbb{E}[e^{-2\theta B(T)}]=e^{-\theta^{2}T}\cdot e^{2\theta^{2}T}=e^{\theta^{2}T}$
\end_inset

.
 
\end_layout

\begin_layout Standard
The fact that 
\begin_inset Formula $M(t)$
\end_inset

 is a martingale is very helpful in calculations.
 Indeed, suppose we want to compute the expectation of a function 
\begin_inset Formula $F(\tilde{B}(s))$
\end_inset

 of a Brownian motion with drift at time 
\begin_inset Formula $s<T$
\end_inset

.
 Then, we have by theorem 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:girsanov-theorem-for-constant-drift-case"
plural "false"
caps "false"
noprefix "false"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}[F(\tilde{B}(s))] & =\mathbb{E}[M_{T}M_{T}^{-1}F(\tilde{B}(s))]\\
 & =\tilde{\mathbb{E}}[M_{T}^{-1}F(\tilde{B}(s))]\\
 & =\tilde{\mathbb{E}}[e^{\theta\tilde{B}(T)-\frac{1}{2}\theta^{2}T}F(\tilde{B}(s))]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Now, we know that under 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

probability, 
\begin_inset Formula $(\tilde{B}(t),t\in[0,T])$
\end_inset

 is a standard brownian motion, or 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

-standard brownian motion for short.
 Therefore, the process 
\begin_inset Formula $e^{\theta\tilde{B}(t)-\frac{1}{2}\theta^{2}t}$
\end_inset

 is a martingale under the new probability measure 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

, or a 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

-martingale for short.
 By conditioning over 
\begin_inset Formula $\mathcal{F}_{s}$
\end_inset

 and applying the martingale property, we get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[F(\tilde{B}_{s})\right] & =\tilde{\mathbb{E}}[e^{\theta\tilde{B}(T)-\frac{1}{2}\theta^{2}T}F(\tilde{B}(s))]\\
 & =\tilde{\mathbb{E}}[\tilde{\mathbb{E}}[e^{\theta\tilde{B}(T)-\frac{1}{2}\theta^{2}T}F(\tilde{B}(s))|\mathcal{F}_{s}]]\\
 & =\tilde{\mathbb{E}}[e^{\theta\tilde{B}(s)-\frac{1}{2}\theta^{2}s}F(\tilde{B}(s))]\\
 & =\mathbb{E}[e^{\theta B(s)-\frac{1}{2}\theta^{2}s}F(B(s))]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The last equality may seem wrong as removed all the tildes.
 It is not! It holds because 
\begin_inset Formula $(\tilde{B}(t))$
\end_inset

 under 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

 has the same distribution as 
\begin_inset Formula $(B(t))$
\end_inset

 under 
\begin_inset Formula $\mathbb{P}$
\end_inset

: a standard brownian motion.
 Of course, it would be possible to directly evaluate 
\begin_inset Formula $\mathbb{E}[F(\tilde{B}(s))]$
\end_inset

 here as we know the distribution of a Brownian motion with drift.
 However, when the function will involve more than one point (such as the
 maximum of the path), the Cameron-Martin theorem is a powerful tool to
 evaluate expectations.
\end_layout

\begin_layout Standard
(3) 
\series bold
The paths with or without the drift are the same.

\series default
 Let 
\begin_inset Formula $(B(t),t\leq T)$
\end_inset

 be a standard Brownian motion defined on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Heuristically, it is fruitful to think of the sample space of 
\begin_inset Formula $\Omega$
\end_inset

 as the different continuous paths of Brownian motion.
 Since, the change of probability from 
\begin_inset Formula $\mathbb{P}$
\end_inset

 to 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

simply changes the relative weights of the paths (and this change of weight
 is never zero, similarly to equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:girsanov-probability-scaling"
plural "false"
caps "false"
noprefix "false"

\end_inset

 for a single random variable), the theorem suggests that the paths of a
 standard Brownian motion and those of a Brownian motion with a constant
 drift 
\begin_inset Formula $\theta$
\end_inset

 (with volatility 
\begin_inset Formula $1$
\end_inset

) are essentially the same.
 
\end_layout

\begin_layout Standard
The form of the factor 
\begin_inset Formula $M_{T}=e^{-\theta\tilde{B}_{T}+\theta^{2}T}$
\end_inset

 can be easily understood at the heuristic level.
 For each outcome 
\begin_inset Formula $\omega$
\end_inset

, it is proportional to 
\begin_inset Formula $e^{-\theta\tilde{B}_{T}(\omega)}$
\end_inset

 (The term 
\begin_inset Formula $e^{(\theta^{2}/2)T}$
\end_inset

 is simply to ensure that 
\begin_inset Formula $\mathbb{P}(\Omega)=1$
\end_inset

) Therefore, the factor 
\begin_inset Formula $M_{T}$
\end_inset

 penalizes the paths for which 
\begin_inset Formula $\tilde{B}_{T}(\omega)$
\end_inset

 is large and positive (if 
\begin_inset Formula $\theta>0$
\end_inset

).
 In particular, it is conceivable that the Brownian motion with positive
 drift is reduced to standard Brownian motion under the new probability.
 
\end_layout

\begin_layout Standard
(4) 
\series bold
Changing the volatility.

\series default
 What about the volatility? Is it possible to change the probability 
\begin_inset Formula $\mathbb{P}$
\end_inset

 to 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

 in such a way that the Brownian motion under 
\begin_inset Formula $\mathbb{P}$
\end_inset

 has volatility 
\begin_inset Formula $\sigma\neq1$
\end_inset

 under 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

? The answer is no! The paths of the Brownian motions with different volatilitie
s are inherently different.
 Indeed, it suffices to compute the quadratic variation.
 If 
\begin_inset Formula $(B_{t}:t\in[0,T])$
\end_inset

 has volatility 
\begin_inset Formula $1$
\end_inset

 and 
\begin_inset Formula $(\tilde{B_{t}},t\in[0,T])$
\end_inset

 has volatility 
\begin_inset Formula $2$
\end_inset

.
 then the following convergence holds for 
\begin_inset Formula $\omega$
\end_inset

 in a set of probability one (for a partition fine enough, say 
\begin_inset Formula $t_{j+1}-t_{j}=2^{-n}$
\end_inset

.
 Then 
\begin_inset Formula $B_{t}=\int1\cdot dB_{t}$
\end_inset

 and 
\begin_inset Formula $\tilde{B_{t}}=\int2\cdot dB_{t}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}\sum_{j=0}^{n-1}(B_{t_{j+1}}(\omega)-B_{t_{j}}(\omega))^{2} & =\int_{0}^{T}1^{2}\cdot ds=T
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}\sum_{j=0}^{n-1}(\tilde{B}_{t_{j+1}}(\omega)-\tilde{B}_{t_{j}}(\omega))^{2} & =\int_{0}^{T}2^{2}\cdot ds=4T
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In other words, the distribution of the standard brownian motion on 
\begin_inset Formula $[0,T]$
\end_inset

 is supported on paths whose quadratic variation is 
\begin_inset Formula $T$
\end_inset

, whereas the distribution of 
\begin_inset Formula $(\tilde{B}_{t},t\geq0)$
\end_inset

 is supported on paths where the quadratic variation is 
\begin_inset Formula $4T$
\end_inset

.
 These paths are very different.
 We conclude that the distributions of the two processes are not equivalent.
 Hence, a change of probability from 
\begin_inset Formula $\mathbb{P}$
\end_inset

 to 
\begin_inset Formula $\mathbb{\tilde{P}}$
\end_inset

 is not possible.
 In fact, we say that they are mutually singular, meaning the set of paths
 on which they are supported are disjoint.
 
\end_layout

\begin_layout Standard

\emph on
Proof.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $(\tilde{B}_{t}:t\in[0,T])$
\end_inset

 be a Brownian motion with constant drift 
\begin_inset Formula $\theta$
\end_inset

 defined on 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 Thus, 
\begin_inset Formula $\tilde{B}_{t}=\theta t+B_{t}$
\end_inset

.
 
\end_layout

\begin_layout Standard

\series bold
Claim
\series default
.
 
\begin_inset Formula $\tilde{B}_{t}$
\end_inset

 is a 
\begin_inset Formula $\mathbb{\tilde{P}}$
\end_inset

-martingale.
\end_layout

\begin_layout Standard
Let
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
M_{t} & =f(t,B_{t})=\exp(-\theta B_{t}-(\theta^{2}/2)t)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
So:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
dM_{t} & =-\frac{\theta^{2}}{2}M_{t}dt-\theta M_{t}dB_{t}+\frac{1}{2}\theta^{2}M(t)dt\\
 & =-\theta M_{t}dB_{t}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Consider the product 
\begin_inset Formula $(M_{t}\tilde{B}_{t})$
\end_inset

.
 We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
d(M_{t}\tilde{B}_{t}) & =\tilde{B}_{t}dM_{t}+M_{t}d\tilde{B}_{t}+dM_{t}\cdot d\tilde{B}_{t}\\
 & =-\tilde{B}_{t}\theta M_{t}dB_{t}+M_{t}(\theta dt+dB_{t})-\theta M_{t}dB_{t}(\theta dt+dB_{t})\\
 & =-\tilde{B}_{t}\theta M_{t}dB_{t}+\theta M_{t}dt+M_{t}dB_{t}-\theta M_{t}dt\\
 & =(-\tilde{B}_{t}\theta+1)M_{t}dB_{t}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Thus, by the properties of Ito integral,
\begin_inset Formula $M_{t}\tilde{B}_{t}$
\end_inset

 is a martingale under 
\begin_inset Formula $\mathbb{P}$
\end_inset

.
 By the abstract Bayes formula 
\begin_inset CommandInset ref
LatexCommand eqref
reference "th:abstract-bayes-formula"
plural "false"
caps "false"
noprefix "false"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\tilde{\mathbb{E}}[\tilde{B}_{t}|\mathcal{F}_{s}] & =\frac{1}{M_{s}}\mathbb{E}[M_{t}\tilde{B}_{t}|\mathcal{F}_{s}]\\
 & =\frac{1}{M_{s}}\cdot M_{s}\tilde{B}_{s}\\
 & =\tilde{B}_{s}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Thus, 
\begin_inset Formula $\tilde{B}_{t}$
\end_inset

 is a 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

-martingale.
\end_layout

\begin_layout Standard

\series bold
Claim
\series default
.
 Our claim is that under the 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

 measure, 
\begin_inset Formula $\tilde{B}_{t}\sim\mathcal{N}^{\mathbb{\tilde{P}}}(0,t)$
\end_inset

 and to do this we rely on the the moment-generating function.
\end_layout

\begin_layout Standard
By definition, for a constant 
\begin_inset Formula $\Psi$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
M_{\tilde{B}_{t}}(\Psi) & =\tilde{\mathbb{E}}\left[\exp\left(\Psi\tilde{B}_{t}\right)\right]\\
 & =\mathbb{E}\left[M_{T}\exp\left(\Psi\tilde{B}_{t}\right)\right]\\
 & =\mathbb{E}\left[\exp\left(-\theta\tilde{B}_{T}+\frac{\theta^{2}}{2}T+\Psi\tilde{B}_{t}\right)\right]\\
 & =\mathbb{E}\left[\exp\left(-\theta(\theta T+B_{T})+\frac{\theta^{2}}{2}T+\Psi(\theta t+B_{t})\right)\right]\\
 & =\mathbb{E}\left[\exp\left(-\theta B_{T}-\frac{\theta^{2}}{2}T+\Psi\theta t+\Psi B_{t})\right)\right]\\
 & =\mathbb{E}\left[\exp\left(-\theta(B_{T}-B_{t})-\frac{\theta^{2}}{2}T+\Psi\theta t+(\Psi-\theta)B_{t})\right)\right]\\
 & =\exp\left(-\frac{\theta^{2}}{2}T+\Psi\theta t\right)\mathbb{E}\left(-\theta(B_{T}-B_{t})\right)\mathbb{E}\left((\Psi-\theta)B_{t}\right)\\
 & =\exp\left(-\frac{\theta^{2}}{2}T+\Psi\theta t\right)\exp\left[\frac{1}{2}\theta^{2}(T-t)\right]\exp\left[\frac{1}{2}(\Psi-\theta)^{2}t\right]\\
 & =\exp\left[-\frac{1}{2}\left(\theta^{2}-2\Psi\theta-(\Psi-\theta)^{2}\right)t\right]\\
 & =\exp\left[-\frac{1}{2}\left(\theta^{2}-2\Psi\theta-(\Psi^{2}-2\Psi\theta+\theta^{2}\right)t\right]\\
 & =\exp(-\Psi^{2}t)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Thus, 
\begin_inset Formula $\tilde{B}_{t}\sim\mathcal{N}^{\tilde{\mathbb{P}}}(0,t)$
\end_inset

.
 
\end_layout

\begin_layout Standard

\series bold
Claim
\series default
.
 Finally, to show that 
\begin_inset Formula $\tilde{B}_{t}$
\end_inset

 is indeed a 
\begin_inset Formula $\mathbb{\tilde{P}}-$
\end_inset

standard brownian motion, we have the following:
\end_layout

\begin_layout Standard
(a) 
\begin_inset Formula $\tilde{B}_{0}=\theta(0)+B_{0}=0$
\end_inset

 and 
\begin_inset Formula $\tilde{B}_{t}$
\end_inset

 has almost surely continuous paths.
\end_layout

\begin_layout Standard
(b) We would like to prove that, for 
\begin_inset Formula $s<t$
\end_inset

, 
\begin_inset Formula $\tilde{B}_{t}-\tilde{B}_{s}\sim\mathcal{N}^{\tilde{\mathbb{P}}}(0,t-s)$
\end_inset

.
 We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}[\tilde{B}_{t}-\tilde{B}_{s}] & =\tilde{\mathbb{E}}[\tilde{B}_{t}]-\tilde{\mathbb{E}}[B_{s}]\\
 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
And, 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\tilde{\mathbb{E}}[(\tilde{B}_{t}-\tilde{B}_{s})^{2}] & =\tilde{\mathbb{E}}[\tilde{B}_{t}^{2}-2\tilde{B}_{t}\tilde{B}_{s}+\tilde{B}_{s}^{2}]\\
 & =\tilde{\mathbb{E}}[B_{t}^{2}]-2\tilde{\mathbb{E}}[\tilde{B}_{t}\tilde{B}_{s}]+\tilde{\mathbb{E}}[\tilde{B}_{s}^{2}]\\
 & =t+s-2\tilde{\mathbb{E}}[\tilde{B}_{t}\tilde{B}_{s}]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
(c) The non-overlapping increments of a 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

-martingale are independent.
 To see this, suppose 
\begin_inset Formula $t_{1}\leq t_{2}\leq t_{3}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\tilde{\mathbb{E}}[(B_{t_{3}}-B_{t_{2}})(B_{t_{2}}-B_{t_{1}})] & =\tilde{\mathbb{E}}[\tilde{\mathbb{E}}[(B_{t_{3}}-B_{t_{2}})(B_{t_{2}}-B_{t_{1}})|\mathcal{F}_{t_{2}}]]\\
 & =\tilde{\mathbb{E}}[(B_{t_{2}}-B_{t_{1}})\tilde{\mathbb{E}}[(B_{t_{3}}-B_{t_{2}})|\mathcal{F}_{t_{2}}]]\\
 & =\tilde{\mathbb{E}}[(B_{t_{2}}-B_{t_{1}})(B_{t_{2}}-B_{t_{2}})]]=0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Also, the covariance 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\tilde{\mathbb{E}}[\tilde{B}_{t}\tilde{B}_{s}] & =\tilde{\mathbb{E}}[(\tilde{B}_{t}-\tilde{B}_{s})\tilde{B}_{s}]+\tilde{\mathbb{E}}[\tilde{B}_{s}^{2}]\\
 & =0+s
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
So, 
\begin_inset Formula $\mathbb{E}[(\tilde{B}_{t}-\tilde{B}_{s})^{2}]=t+s-2s=t-s$
\end_inset

.
\end_layout

\begin_layout Standard
Consequently, 
\begin_inset Formula $\tilde{B}_{t}$
\end_inset

 is a 
\begin_inset Formula $\tilde{\mathbb{P}}$
\end_inset

-standard brownian motion.
\end_layout

\begin_layout Example
(Bachelier's formula for Brownian motion with a drift) One of the most interesti
ng formulas we have seen so far is Bachelier's formula for the maximum of
 the Brownian motion in proposition 
\end_layout

\begin_layout Subsection
Radon-Nikodym Theorem.
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 be a probability space.
 Let 
\begin_inset Formula $\mathbb{Q}$
\end_inset

 be another probability measure.
 Under the assumption that 
\begin_inset Formula $\mathbb{Q}$
\end_inset

 is absolutely continuous with respect to 
\begin_inset Formula $\mathbb{P}$
\end_inset

, that is, 
\begin_inset Formula $\mathbb{Q}(A)=0\Longleftrightarrow\mathbb{P}(A)=0$
\end_inset

, there exists a non-negative random variable 
\begin_inset Formula $Z$
\end_inset

 such that:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
Z & :=\frac{d\mathbb{Q}}{d\mathbb{P}}
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
and we call 
\begin_inset Formula $Z$
\end_inset

 the Radon-Nikodym derivative of 
\begin_inset Formula $\mathbb{Q}$
\end_inset

 with respect to 
\begin_inset Formula $\mathbb{P}$
\end_inset

.
\end_layout

\begin_layout Standard
At a heuristic level, as long as 
\begin_inset Formula $\mathbb{P}$
\end_inset

 and 
\begin_inset Formula $\mathbb{Q}$
\end_inset

 agree on the possible events (and null sets), we can define a likelihood
 ratio of the little probability elements 
\begin_inset Formula $d\mathbb{Q}(\omega)$
\end_inset

 and 
\begin_inset Formula $d\mathbb{P}(\omega)$
\end_inset

.
 This is an almost surely non-negative random variable with expectation
 
\begin_inset Formula $1$
\end_inset

.
\end_layout

\begin_layout Standard
It follows that:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{Q}(\mathcal{E}) & =\mathbb{E}^{\mathbb{Q}}[1_{\mathcal{E}}]\\
 & =\int_{\Omega}1_{\{\omega\in\mathcal{E}\}}d\mathbb{Q}(\omega)\\
 & =\int_{\Omega}1_{\{\omega\in\mathcal{E}\}}Zd\mathbb{P}(\omega)\\
 & =\mathbb{E}^{\mathbb{P}}[Z1_{\mathcal{E}}]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $\mathbb{Q}$
\end_inset

 is a probability measure, 
\begin_inset Formula $\mathbb{Q}(\Omega)=\mathbb{E}^{\mathbb{P}}[Z\cdot1_{\Omega}]=\mathbb{E}^{\mathbb{P}}[Z]=1$
\end_inset

.
\end_layout

\begin_layout Standard
and
\begin_inset Formula 
\begin{align*}
\mathbb{E}^{\mathbb{Q}}[X] & =\mathbb{E}^{\mathbb{P}}[ZX]\\
\mathbb{E}^{\mathbb{P}}[X] & =\mathbb{E}^{\mathbb{Q}}[\frac{1}{Z}X]
\end{align*}

\end_inset


\end_layout

\begin_layout Definition

\emph on
(Density Process)
\emph default
.
 We can define the Radon-Nikodym derivative(likelihood ratio) process:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
Z(t) & =\left.\frac{d\mathbb{Q}}{d\mathbb{P}}\right|_{t}=\mathbb{E}^{\mathbb{P}}[Z|\mathcal{F}_{t}]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Then, 
\begin_inset Formula $Z(t)$
\end_inset

 is a 
\begin_inset Formula $\mathbb{P}-$
\end_inset

martingale with 
\begin_inset Formula $Z(0)=\mathbb{E}^{\mathbb{P}}[Z(t)]=1$
\end_inset

.
 To see this:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}^{\mathbb{P}}[Z(t)|\mathcal{F}_{s}] & =\mathbb{E}^{\mathbb{P}}[\mathbb{E}^{\mathbb{P}}[Z|\mathcal{F}_{t}]|\mathcal{F}_{s}]\\
 & =\mathbb{E}^{\mathbb{P}}[Z|\mathcal{F}_{s}]\\
 & \{\text{Tower law}\}\\
 & =Z(s)
\end{align*}

\end_inset


\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "th:abstract-bayes-formula"

\end_inset

(Abstract Bayes' Formula) Let 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 be a probability space and let 
\begin_inset Formula $\mathbb{Q}$
\end_inset

 be any other probability measure on it and suppose that 
\begin_inset Formula $\mathbb{Q}<<\mathbb{P}$
\end_inset

.
 By the Radon-Nikodym theorem, 
\begin_inset Formula $\exists Z=d\mathbb{Q}/d\mathbb{P}$
\end_inset

, 
\begin_inset Formula $Z\geq0$
\end_inset

 a.s.
 with 
\begin_inset Formula $\mathbb{E}^{\mathbb{P}}[Z]=1$
\end_inset

.
 Then, we have:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
\mathbb{E}^{\mathbb{Q}}[X|\mathcal{F}_{t}] & =\frac{\mathbb{E}^{\mathbb{P}}[ZX|\mathcal{F}_{t}]}{\mathbb{E}^{\mathbb{P}}[Z|\mathcal{F}_{t}]}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proof
We use the definition of conditional expectations.
 Our claim is that for all 
\begin_inset Formula $A\in\mathcal{F}_{t}$
\end_inset

,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\int_{A}\mathbb{E}^{\mathbb{P}}[ZX|\mathcal{F}_{t}]d\mathbb{P} & =\int_{A}\mathbb{E}^{\mathbb{P}}[Z|\mathcal{F}_{t}]\mathbb{E}^{\mathbb{Q}}[X|\mathcal{F}_{t}]d\mathbb{P}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
For the left side:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\int_{A}\mathbb{E}^{\mathbb{P}}[ZX|\mathcal{F}_{t}]d\mathbb{P} & =\int_{A}ZXd\mathbb{P}\\
 & \{\text{Definition of conditional expectations}\}\\
 & =\int_{A}Xd\mathbb{Q}\\
 & \{\text{Radon-Nikodym Derivative}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
For the right side:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\int_{A}\mathbb{E}^{\mathbb{P}}[Z|\mathcal{F}_{t}]\mathbb{E}^{\mathbb{Q}}[X|\mathcal{F}_{t}]d\mathbb{P} & =\int_{A}\mathbb{E}^{\mathbb{P}}[Z\mathbb{E}^{\mathbb{Q}}[X|\mathcal{F}_{t}]|\mathcal{F}_{t}]d\mathbb{P}\\
 & \{\text{Since }\mathbb{E}^{\mathbb{Q}}[X|\mathcal{F}_{t}]\text{ is }\mathcal{F}_{t}-\text{measurable}\}\\
 & =\int_{A}Z\mathbb{E}^{\mathbb{Q}}[X|\mathcal{F}_{t}]d\mathbb{P}\\
 & \{\text{Definition of conditional expectations}\}\\
 & =\int_{A}\mathbb{E}^{\mathbb{Q}}[X|\mathcal{F}_{t}]d\mathbb{Q}\\
 & \{\text{Radon-Nikodym Derivative}\}\\
 & =\int_{A}Xd\mathbb{Q}
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Change of Measure for processes.
\end_layout

\begin_layout Theorem
(Change of Measure).
 Let 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

 be a probability space and let 
\begin_inset Formula $M(t)$
\end_inset

 be any density process.
 Let 
\begin_inset Formula $X(t)$
\end_inset

 be any 
\begin_inset Formula $\mathcal{F}_{t}$
\end_inset

-measurable random variable.
 Then:
\end_layout

\begin_layout Theorem
\begin_inset Formula 
\begin{align*}
\mathbb{E}^{\mathbb{Q}}[X(T)|\mathcal{F}_{t}] & =\mathbb{E}^{\mathbb{P}}\left[\frac{M(T)}{M(t)}X(T)|\mathcal{F}_{t}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Recall that 
\begin_inset Formula $M=d\mathbb{Q}/d\mathbb{P}$
\end_inset

.
 By the conditional Bayes' formula:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align*}
\mathbb{E}^{\mathbb{Q}}[X(T)|\mathcal{F}_{t}] & =\frac{\mathbb{E}^{\mathbb{P}}[MX(T)|\mathcal{F}_{t}]}{\mathbb{E}^{\mathbb{P}}[M|\mathcal{F}_{t}]}\\
 & =\frac{\mathbb{E}^{\mathbb{P}}[\mathbb{E}[MX(T)|\mathcal{F}_{T}]|\mathcal{F}_{t}]}{M(t)}\\
 & \{\text{Tower law; definition of density process}M(t)\}\\
 & =\frac{\mathbb{E}^{\mathbb{P}}[X(T)\mathbb{E}[M|\mathcal{F}_{T}]|\mathcal{F}_{t}]}{M(t)}\\
 & \{\text{Taking out what is known}\}\\
 & =\frac{\mathbb{E}^{\mathbb{P}}[X(T)M(T)|\mathcal{F}_{t}]}{M(t)}\\
 & =\frac{\mathbb{E}^{\mathbb{P}}[X(T)M(T)|\mathcal{F}_{t}]}{M(t)}\\
 & =\mathbb{E}^{\mathbb{P}}\left[\frac{M(T)}{M(t)}X(T)|\mathcal{F}_{t}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
A density process may be used to artificially construct a new measure.
 Let 
\begin_inset Formula $M(t)$
\end_inset

 be any 
\begin_inset Formula $\mathbb{P}$
\end_inset

-martingale with 
\begin_inset Formula $M(0)=1$
\end_inset

.
 We choose a final horizon time 
\begin_inset Formula $T$
\end_inset

 and define the Radon-Nikodym derivative as 
\begin_inset Formula $Z=M(T)$
\end_inset

.
 The corresponding measure:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{Q}(A) & =\mathbb{E}^{\mathbb{Q}}[1_{A}]=\mathbb{E}^{\mathbb{P}}[M(T)1_{A}]
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Black-Scholes Merton Option Pricing Formulae.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $(W(t),t\in[0,T])$
\end_inset

 be a Brownian motion on the probability space 
\begin_inset Formula $(\Omega,\mathcal{F},\mathbb{P})$
\end_inset

.
 The Black-Scholes model consists of two assets (i) a stock and (ii) a risk-free
 bank account with dynamics as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
dS(t) & =\mu S(t)dt+\sigma S(t)dW(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $f(x)=\ln x$
\end_inset

.
 Then, by Ito's lemma:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
df(x) & =f_{x}(x)dx+\frac{1}{2}f_{xx}(x)dx\cdot dx\\
df(S(t)) & =\frac{1}{S(t)}dS(t)-\frac{1}{2}\frac{1}{S(t)^{2}}dS(t)dS(t)\\
 & =\mu dt+\sigma dW(t)-\frac{1}{2}\frac{1}{S(t)^{2}}\sigma^{2}S^{2}(t)dt\\
d(\ln S(t)) & =\left(\mu-\frac{1}{2}\sigma^{2}\right)dt+\sigma dW(t)\\
\ln\left(\frac{S(t)}{S(0)}\right) & =\int_{0}^{t}\left(\mu-\frac{1}{2}\sigma^{2}\right)dt+\int_{0}^{t}\sigma dW(t)\\
S(t) & =S(0)\exp\left[\left(\mu-\frac{1}{2}\sigma^{2}\right)r+\sigma W(t)\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The dynamics of the locally risk-free bank account are:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
dB(t) & =rB(t)dt
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The dynamics of the discounted stock price process are:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
d(e^{-rt}S(t)) & =d(e^{-rt})S(t)+e^{-rt}dS(t)+d(e^{-rt})dS(t)\\
 & =-re^{-rt}dtS(t)+e^{-rt}(\mu S(t)dt+\sigma S(t)dW(t))\\
 & =e^{-rt}S(t)(\mu-r)dt+e^{-rt}\sigma S(t)dW(t)\\
 & =e^{-rt}\sigma S(t)\left\{ \frac{(\mu-r)}{\sigma}dt+dW(t)\right\} \\
 & =e^{-rt}\sigma S(t)(\theta dt+dW(t))
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Define 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\left.\frac{d\mathbb{Q}}{d\mathbb{P}}\right|_{t} & =e^{-\theta W(t)-\frac{\theta^{2}}{2}t}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
and 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
W^{\mathbb{Q}}(t) & =W(t)+\theta t\\
dW^{\mathbb{Q}}(t) & =dW(t)+\theta dt
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Then, by the Girsanov theorem, 
\begin_inset Formula $W^{\mathbb{Q}}(t)$
\end_inset

 is a 
\begin_inset Formula $\mathbb{Q}$
\end_inset

-standard brownian motion.
 
\begin_inset Formula $W^{\mathbb{Q}}(t)\sim\mathcal{N}^{\mathbb{Q}}(0,t)$
\end_inset

.
 Under 
\begin_inset Formula $\mathbb{Q}$
\end_inset

, the dynamics of the discounted stock price is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
d(e^{-rt}S(t)) & =e^{-rt}\sigma S(t)dW^{\mathbb{Q}}(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The measure 
\begin_inset Formula $\mathbb{Q}$
\end_inset

 is said to be 
\emph on
risk-neutral 
\emph default
because it is equivalent to 
\begin_inset Formula $\mathbb{P}$
\end_inset

 (
\begin_inset Formula $\mathbb{Q}(A)=0$
\end_inset

 
\begin_inset Formula $\Longleftrightarrow\mathbb{P}(A)=0$
\end_inset

; they agree on null sets) and in addition it renders the discounted stock
 price into a martingale.
 Indeed: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
e^{-rt}S(t) & =S(0)+\int_{0}^{t}e^{-rt}\sigma S(u)dW^{\mathbb{Q}}(u)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
and the process 
\begin_inset Formula $\int_{0}^{t}e^{-rt}\sigma S(u)dW^{\mathbb{Q}}(u)$
\end_inset

 is an Ito-integral and therefore a 
\begin_inset Formula $\mathbb{Q}$
\end_inset

-martingale.
 
\end_layout

\begin_layout Standard
The undiscounted stock price process 
\begin_inset Formula $(S(t),t\in[0,T)$
\end_inset

 is described by the 
\begin_inset Formula $\mathbb{Q}$
\end_inset

-dynamics:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
dS(t) & =\mu S(t)dt+\sigma S(t)(dW^{\mathbb{Q}}(t)-\theta dt)\\
 & =\mu S(t)dt-\sigma S(t)\cdot\frac{\mu-r}{\sigma}dt+\sigma S(t)dW^{\mathbb{Q}}(t)\\
 & =\mu S(t)dt-\mu S(t)dt+rS(t)dt+\sigma S(t)dW^{\mathbb{Q}}(t)\\
 & =rS(t)dt+\sigma S(t)dW^{\mathbb{Q}}(t)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
and
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
S(t) & =S(0)\exp\left[(r-\sigma^{2}/2)t+\sigma W^{\mathbb{Q}}(t)\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
By the risk-neutral pricing formula, the price of a derivative security
 with payoff 
\begin_inset Formula $V(T)$
\end_inset

 is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
V(t) & =\mathbb{E}^{\mathbb{Q}}[e^{-\int_{t}^{T}r(u)du}V(T)|\mathcal{F}_{t}]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We have 
\begin_inset Formula $r(u)\equiv r$
\end_inset

.
 And further, for a european call option: 
\begin_inset Formula $V(T)=((S(T)-K)\cdot1_{\{S_{T}>K\}}$
\end_inset

.
 Thus:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
V(t) & =e^{-r(T-t)}\mathbb{E}^{\mathbb{Q}}[(S(T)-K)\cdot1_{\{S(T)>K\}}|\mathcal{F}_{t}]\\
 & =e^{-r(T-t)}\mathbb{E}^{\mathbb{Q}}[S(T)\cdot1_{\{S(T)>K\}}|\mathcal{F}_{t}]-e^{-r(T-t)}\mathbb{E}^{\mathbb{Q}}[K\cdot1_{\{S(T)>K\}}|\mathcal{F}_{t}]\\
 & =e^{-r(T-t)}\mathbb{E}^{\mathbb{Q}}[S(T)\cdot1_{\{S(T)>K\}}|\mathcal{F}_{t}]-Ke^{-r(T-t)}\mathbb{E}^{\mathbb{Q}}[1_{\{S(T)>K\}}|\mathcal{F}_{t}]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The second expectation is easily solved.
 We have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}^{\mathbb{Q}}[1_{\{S(T)>K}|\mathcal{F}_{t}] & =\mathbb{Q}\{S(T)>K|\mathcal{F}_{t}]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Using the fact, that 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{Q}\{S(T)>K|\mathcal{F}_{t}\} & =\mathbb{Q}\{\log S(T)>\log K|\mathcal{F}_{t}\}\\
 & =\mathbb{Q}\{\log S(t)+\left(r-\frac{\sigma^{2}}{2}\right)(T-t)+\sigma(W^{\mathbb{Q}}(T)-W^{\mathbb{Q}}(t))>\log K\}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $Z$
\end_inset

 be a standard normal random variable following 
\begin_inset Formula $\mathcal{N}^{\mathbb{Q}}(0,1)$
\end_inset

.
 Then, 
\begin_inset Formula $W^{\mathbb{Q}}(T)-W^{\mathbb{Q}}(t)=\sqrt{T-t}Z$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{Q}\{S(T)>K|\mathcal{F}_{t}\} & =\mathbb{Q}\{\log S(t)+\left(r-\frac{\sigma^{2}}{2}\right)(T-t)+\sigma(W^{\mathbb{Q}}(T)-W^{\mathbb{Q}}(t))>\log K\}\\
 & =\mathbb{Q}\{\log S(t)+\left(r-\frac{\sigma^{2}}{2}\right)(T-t)+\sigma\sqrt{T-t}Z>\log K\}\\
 & =\mathbb{Q}\{Z>\frac{\log K-\log S(t)-\left(r-\frac{\sigma^{2}}{2}\right)(T-t)}{\sigma\sqrt{T-t}}\}\\
 & =\mathbb{Q}\{Z\leq\frac{\log\frac{S(t)}{K}+\left(r-\frac{\sigma^{2}}{2}\right)(T-t)}{\sigma\sqrt{T-t}}\}\\
 & =\Phi(d_{-}(\tau,S(t))),\quad\tau=T-t
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The first expectation is typically solved using a change of numeraire.
 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\tilde{\mathbb{Q}}$
\end_inset

 be another probability measure related to 
\begin_inset Formula $\mathbb{Q}$
\end_inset

 defined by the Radon-Nikodym derivative:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
M=\frac{d\mathbb{\tilde{Q}}}{d\mathbb{Q}} & :=\frac{S(T)e^{-rT}}{S(0)}=\exp\left[-\frac{\sigma^{2}}{2}T+\sigma W^{\mathbb{Q}}(T)\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
and correspondingly, let us define the Radon-Nikodym derivative process
 
\begin_inset Formula $(M(t),t\in[0,T])$
\end_inset

 as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
M(t)=\left.\frac{d\mathbb{\tilde{Q}}}{d\mathbb{Q}}\right|_{t} & =\mathbb{E}^{\mathbb{Q}}[M|\mathcal{F}_{t}]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Clearly, 
\begin_inset Formula $M(T)$
\end_inset

 is a non-negative random variable.
\end_layout

\begin_layout Standard
We note that:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}^{\mathbb{Q}}[M(T)] & =\frac{\mathbb{E}^{\mathbb{Q}}[S(T)e^{-rT}]}{S(0)}\\
 & =\frac{S(0)}{S(0)}=1\\
 & \{\text{Discount stock price is a martingale under }\mathbb{Q}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Further, 
\begin_inset Formula $M(t)$
\end_inset

 is an exponential 
\begin_inset Formula $\mathbb{Q}$
\end_inset

-martingale.
 So:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
M(t) & =\frac{S(t)e^{-rt}}{S(0)}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
By the change-of-measure theorem, the first expectation can be expressed
 as follows.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{E}^{\tilde{\mathbb{Q}}}[1_{\{S(T)>K\}}|\mathcal{F}_{t}] & =\mathbb{E}^{\mathbb{Q}}\left[\frac{S(T)e^{-rT}}{S(t)e^{-rt}}\cdot1_{\{S(T)>K\}}|\mathcal{F}_{t}\right]\\
S(t)\mathbb{E}^{\tilde{\mathbb{Q}}}[1_{\{S(T)>K\}}|\mathcal{F}_{t}] & =\mathbb{E}^{\mathbb{Q}}\left[S(T)e^{-r(T-t)}\cdot1_{\{S(T)>K\}}|\mathcal{F}_{t}\right]\\
\Longrightarrow\mathbb{E}^{\mathbb{Q}}\left[S(T)e^{-r(T-t)}\cdot1_{\{S(T)>K\}}|\mathcal{F}_{t}\right] & =S(t)\mathbb{\tilde{Q}}\{S(T)>K|\mathcal{F}_{t}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
So, the value of a European call option can be written as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
V(t) & =\mathbb{E}^{\mathbb{\tilde{Q}}}[S(t)\cdot1_{\{S(T)>K\}}|\mathcal{F}_{t}]-e^{-r(T-t)}\mathbb{E}^{\mathbb{Q}}[K\cdot1_{\{S(T)>K\}}]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
or equivalently:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
V(t) & =S(t)\mathbb{\tilde{Q}}\{S(T)>K|\mathcal{F}_{t}\}-Ke^{-r(T-t)}\mathbb{Q}\{S(T)>K|\mathcal{F}_{t}\}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Finally:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{\tilde{Q}}\{S(T)>K|\mathcal{F}_{t}\} & =\mathbb{E}^{\mathbb{Q}}\left[\frac{M(T)}{M(t)}1_{\{S(T)>K\}}|\mathcal{F}_{t}\right]\\
 & =\mathbb{E}^{\mathbb{Q}}\left[e^{-\frac{\sigma^{2}}{2}(T-t)+\sigma(W^{\mathbb{Q}}(T)-W^{\mathbb{Q}}(t))}1_{\{S(T)>K\}}|\mathcal{F}_{t}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Define 
\begin_inset Formula $Y:=\mathcal{N}^{\mathbb{Q}}(0,1)$
\end_inset

.
 Then, 
\begin_inset Formula $W^{\mathbb{Q}}(T)-W^{\mathbb{Q}}(t)=\sqrt{(T-t)}Y$
\end_inset

.
 Now, it is easy to see that the event 
\begin_inset Formula $\{S_{T}>K\}$
\end_inset

 is the same as 
\begin_inset Formula $\{Y<d_{-}(\tau,S(t))\}$
\end_inset

.
 Thus:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{\tilde{Q}}\{S(T)>K|\mathcal{F}_{t}\} & =\int_{-\infty}^{d_{-}(\tau,S(t))}\exp\left(-\frac{\sigma^{2}}{2}\tau+\sigma\sqrt{\tau}y\right)f_{Y}^{\mathbb{Q}}(y)dy\\
 & =\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{d_{-}(\tau,S(t))}\exp\left(-\frac{\sigma^{2}}{2}\tau+\sigma\sqrt{\tau}y\right)\exp\left(-\frac{y^{2}}{2}\right)dy\\
 & =\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{d_{-}(\tau,S(t))}\exp\left[-\frac{1}{2}\left(\sigma^{2}\tau+2\sigma\sqrt{\tau}y+y^{2}\right)\right]dy\\
 & =\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{d_{-}(\tau,S(t))}\exp\left[-\frac{1}{2}\left(y+\sigma\sqrt{\tau}\right)^{2}\right]dy\\
 & =\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{d_{-}(\tau,S(t))+\sigma\sqrt{\tau}}\exp\left[-\frac{1}{2}z^{2}\right]dz
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $d_{+}(\tau,S(t))=d_{-}(\tau,S(t))+\sigma\sqrt{\tau}.$
\end_inset

 Then:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathbb{\tilde{Q}}\{S(T)>K|\mathcal{F}_{t}\} & =\Phi(d_{+}(\tau,S(t))
\end{align*}

\end_inset


\end_layout

\end_body
\end_document
